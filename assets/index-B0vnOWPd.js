(function(){const ue=document.createElement("link").relList;if(ue&&ue.supports&&ue.supports("modulepreload"))return;for(const N of document.querySelectorAll('link[rel="modulepreload"]'))y(N);new MutationObserver(N=>{for(const F of N)if(F.type==="childList")for(const Y of F.addedNodes)Y.tagName==="LINK"&&Y.rel==="modulepreload"&&y(Y)}).observe(document,{childList:!0,subtree:!0});function j(N){const F={};return N.integrity&&(F.integrity=N.integrity),N.referrerPolicy&&(F.referrerPolicy=N.referrerPolicy),N.crossOrigin==="use-credentials"?F.credentials="include":N.crossOrigin==="anonymous"?F.credentials="omit":F.credentials="same-origin",F}function y(N){if(N.ep)return;N.ep=!0;const F=j(N);fetch(N.href,F)}})();var ol={exports:{}},br={};var gp;function $g(){if(gp)return br;gp=1;var T=Symbol.for("react.transitional.element"),ue=Symbol.for("react.fragment");function j(y,N,F){var Y=null;if(F!==void 0&&(Y=""+F),N.key!==void 0&&(Y=""+N.key),"key"in N){F={};for(var Z in N)Z!=="key"&&(F[Z]=N[Z])}else F=N;return N=F.ref,{$$typeof:T,type:y,key:Y,ref:N!==void 0?N:null,props:F}}return br.Fragment=ue,br.jsx=j,br.jsxs=j,br}var yp;function Yg(){return yp||(yp=1,ol.exports=$g()),ol.exports}var ot=Yg(),al={exports:{}},x={};var hp;function Jg(){if(hp)return x;hp=1;var T=Symbol.for("react.transitional.element"),ue=Symbol.for("react.portal"),j=Symbol.for("react.fragment"),y=Symbol.for("react.strict_mode"),N=Symbol.for("react.profiler"),F=Symbol.for("react.consumer"),Y=Symbol.for("react.context"),Z=Symbol.for("react.forward_ref"),I=Symbol.for("react.suspense"),b=Symbol.for("react.memo"),B=Symbol.for("react.lazy"),D=Symbol.for("react.activity"),$=Symbol.iterator;function xe(u){return u===null||typeof u!="object"?null:(u=$&&u[$]||u["@@iterator"],typeof u=="function"?u:null)}var De={isMounted:function(){return!1},enqueueForceUpdate:function(){},enqueueReplaceState:function(){},enqueueSetState:function(){}},Ne=Object.assign,kt={};function Ke(u,A,L){this.props=u,this.context=A,this.refs=kt,this.updater=L||De}Ke.prototype.isReactComponent={},Ke.prototype.setState=function(u,A){if(typeof u!="object"&&typeof u!="function"&&u!=null)throw Error("takes an object of state variables to update or a function which returns an object of state variables.");this.updater.enqueueSetState(this,u,A,"setState")},Ke.prototype.forceUpdate=function(u){this.updater.enqueueForceUpdate(this,u,"forceUpdate")};function $t(){}$t.prototype=Ke.prototype;function Pe(u,A,L){this.props=u,this.context=A,this.refs=kt,this.updater=L||De}var at=Pe.prototype=new $t;at.constructor=Pe,Ne(at,Ke.prototype),at.isPureReactComponent=!0;var St=Array.isArray;function qe(){}var Q={H:null,A:null,T:null,S:null},Be=Object.prototype.hasOwnProperty;function At(u,A,L){var W=L.ref;return{$$typeof:T,type:u,key:A,ref:W!==void 0?W:null,props:L}}function Hn(u,A){return At(u.type,A,u.props)}function wt(u){return typeof u=="object"&&u!==null&&u.$$typeof===T}function ze(u){var A={"=":"=0",":":"=2"};return"$"+u.replace(/[=:]/g,function(L){return A[L]})}var An=/\/+/g;function It(u,A){return typeof u=="object"&&u!==null&&u.key!=null?ze(""+u.key):A.toString(36)}function vt(u){switch(u.status){case"fulfilled":return u.value;case"rejected":throw u.reason;default:switch(typeof u.status=="string"?u.then(qe,qe):(u.status="pending",u.then(function(A){u.status==="pending"&&(u.status="fulfilled",u.value=A)},function(A){u.status==="pending"&&(u.status="rejected",u.reason=A)})),u.status){case"fulfilled":return u.value;case"rejected":throw u.reason}}throw u}function f(u,A,L,W,M){var z=typeof u;(z==="undefined"||z==="boolean")&&(u=null);var te=!1;if(u===null)te=!0;else switch(z){case"bigint":case"string":case"number":te=!0;break;case"object":switch(u.$$typeof){case T:case ue:te=!0;break;case B:return te=u._init,f(te(u._payload),A,L,W,M)}}if(te)return M=M(u),te=W===""?"."+It(u,0):W,St(M)?(L="",te!=null&&(L=te.replace(An,"$&/")+"/"),f(M,A,L,"",function(Wi){return Wi})):M!=null&&(wt(M)&&(M=Hn(M,L+(M.key==null||u&&u.key===M.key?"":(""+M.key).replace(An,"$&/")+"/")+te)),A.push(M)),1;te=0;var Me=W===""?".":W+":";if(St(u))for(var he=0;he<u.length;he++)W=u[he],z=Me+It(W,he),te+=f(W,A,L,z,M);else if(he=xe(u),typeof he=="function")for(u=he.call(u),he=0;!(W=u.next()).done;)W=W.value,z=Me+It(W,he++),te+=f(W,A,L,z,M);else if(z==="object"){if(typeof u.then=="function")return f(vt(u),A,L,W,M);throw A=String(u),Error("Objects are not valid as a React child (found: "+(A==="[object Object]"?"object with keys {"+Object.keys(u).join(", ")+"}":A)+"). If you meant to render a collection of children, use an array instead.")}return te}function w(u,A,L){if(u==null)return u;var W=[],M=0;return f(u,W,"","",function(z){return A.call(L,z,M++)}),W}function O(u){if(u._status===-1){var A=u._result;A=A(),A.then(function(L){(u._status===0||u._status===-1)&&(u._status=1,u._result=L)},function(L){(u._status===0||u._status===-1)&&(u._status=2,u._result=L)}),u._status===-1&&(u._status=0,u._result=A)}if(u._status===1)return u._result.default;throw u._result}var re=typeof reportError=="function"?reportError:function(u){if(typeof window=="object"&&typeof window.ErrorEvent=="function"){var A=new window.ErrorEvent("error",{bubbles:!0,cancelable:!0,message:typeof u=="object"&&u!==null&&typeof u.message=="string"?String(u.message):String(u),error:u});if(!window.dispatchEvent(A))return}else if(typeof process=="object"&&typeof process.emit=="function"){process.emit("uncaughtException",u);return}console.error(u)},le={map:w,forEach:function(u,A,L){w(u,function(){A.apply(this,arguments)},L)},count:function(u){var A=0;return w(u,function(){A++}),A},toArray:function(u){return w(u,function(A){return A})||[]},only:function(u){if(!wt(u))throw Error("React.Children.only expected to receive a single React element child.");return u}};return x.Activity=D,x.Children=le,x.Component=Ke,x.Fragment=j,x.Profiler=N,x.PureComponent=Pe,x.StrictMode=y,x.Suspense=I,x.__CLIENT_INTERNALS_DO_NOT_USE_OR_WARN_USERS_THEY_CANNOT_UPGRADE=Q,x.__COMPILER_RUNTIME={__proto__:null,c:function(u){return Q.H.useMemoCache(u)}},x.cache=function(u){return function(){return u.apply(null,arguments)}},x.cacheSignal=function(){return null},x.cloneElement=function(u,A,L){if(u==null)throw Error("The argument must be a React element, but you passed "+u+".");var W=Ne({},u.props),M=u.key;if(A!=null)for(z in A.key!==void 0&&(M=""+A.key),A)!Be.call(A,z)||z==="key"||z==="__self"||z==="__source"||z==="ref"&&A.ref===void 0||(W[z]=A[z]);var z=arguments.length-2;if(z===1)W.children=L;else if(1<z){for(var te=Array(z),Me=0;Me<z;Me++)te[Me]=arguments[Me+2];W.children=te}return At(u.type,M,W)},x.createContext=function(u){return u={$$typeof:Y,_currentValue:u,_currentValue2:u,_threadCount:0,Provider:null,Consumer:null},u.Provider=u,u.Consumer={$$typeof:F,_context:u},u},x.createElement=function(u,A,L){var W,M={},z=null;if(A!=null)for(W in A.key!==void 0&&(z=""+A.key),A)Be.call(A,W)&&W!=="key"&&W!=="__self"&&W!=="__source"&&(M[W]=A[W]);var te=arguments.length-2;if(te===1)M.children=L;else if(1<te){for(var Me=Array(te),he=0;he<te;he++)Me[he]=arguments[he+2];M.children=Me}if(u&&u.defaultProps)for(W in te=u.defaultProps,te)M[W]===void 0&&(M[W]=te[W]);return At(u,z,M)},x.createRef=function(){return{current:null}},x.forwardRef=function(u){return{$$typeof:Z,render:u}},x.isValidElement=wt,x.lazy=function(u){return{$$typeof:B,_payload:{_status:-1,_result:u},_init:O}},x.memo=function(u,A){return{$$typeof:b,type:u,compare:A===void 0?null:A}},x.startTransition=function(u){var A=Q.T,L={};Q.T=L;try{var W=u(),M=Q.S;M!==null&&M(L,W),typeof W=="object"&&W!==null&&typeof W.then=="function"&&W.then(qe,re)}catch(z){re(z)}finally{A!==null&&L.types!==null&&(A.types=L.types),Q.T=A}},x.unstable_useCacheRefresh=function(){return Q.H.useCacheRefresh()},x.use=function(u){return Q.H.use(u)},x.useActionState=function(u,A,L){return Q.H.useActionState(u,A,L)},x.useCallback=function(u,A){return Q.H.useCallback(u,A)},x.useContext=function(u){return Q.H.useContext(u)},x.useDebugValue=function(){},x.useDeferredValue=function(u,A){return Q.H.useDeferredValue(u,A)},x.useEffect=function(u,A){return Q.H.useEffect(u,A)},x.useEffectEvent=function(u){return Q.H.useEffectEvent(u)},x.useId=function(){return Q.H.useId()},x.useImperativeHandle=function(u,A,L){return Q.H.useImperativeHandle(u,A,L)},x.useInsertionEffect=function(u,A){return Q.H.useInsertionEffect(u,A)},x.useLayoutEffect=function(u,A){return Q.H.useLayoutEffect(u,A)},x.useMemo=function(u,A){return Q.H.useMemo(u,A)},x.useOptimistic=function(u,A){return Q.H.useOptimistic(u,A)},x.useReducer=function(u,A,L){return Q.H.useReducer(u,A,L)},x.useRef=function(u){return Q.H.useRef(u)},x.useState=function(u){return Q.H.useState(u)},x.useSyncExternalStore=function(u,A,L){return Q.H.useSyncExternalStore(u,A,L)},x.useTransition=function(){return Q.H.useTransition()},x.version="19.2.4",x}var vp;function pl(){return vp||(vp=1,al.exports=Jg()),al.exports}var Kt=pl(),sl={exports:{}},Sr={},ll={exports:{}},cl={};var fp;function Xg(){return fp||(fp=1,(function(T){function ue(f,w){var O=f.length;f.push(w);e:for(;0<O;){var re=O-1>>>1,le=f[re];if(0<N(le,w))f[re]=w,f[O]=le,O=re;else break e}}function j(f){return f.length===0?null:f[0]}function y(f){if(f.length===0)return null;var w=f[0],O=f.pop();if(O!==w){f[0]=O;e:for(var re=0,le=f.length,u=le>>>1;re<u;){var A=2*(re+1)-1,L=f[A],W=A+1,M=f[W];if(0>N(L,O))W<le&&0>N(M,L)?(f[re]=M,f[W]=O,re=W):(f[re]=L,f[A]=O,re=A);else if(W<le&&0>N(M,O))f[re]=M,f[W]=O,re=W;else break e}}return w}function N(f,w){var O=f.sortIndex-w.sortIndex;return O!==0?O:f.id-w.id}if(T.unstable_now=void 0,typeof performance=="object"&&typeof performance.now=="function"){var F=performance;T.unstable_now=function(){return F.now()}}else{var Y=Date,Z=Y.now();T.unstable_now=function(){return Y.now()-Z}}var I=[],b=[],B=1,D=null,$=3,xe=!1,De=!1,Ne=!1,kt=!1,Ke=typeof setTimeout=="function"?setTimeout:null,$t=typeof clearTimeout=="function"?clearTimeout:null,Pe=typeof setImmediate<"u"?setImmediate:null;function at(f){for(var w=j(b);w!==null;){if(w.callback===null)y(b);else if(w.startTime<=f)y(b),w.sortIndex=w.expirationTime,ue(I,w);else break;w=j(b)}}function St(f){if(Ne=!1,at(f),!De)if(j(I)!==null)De=!0,qe||(qe=!0,ze());else{var w=j(b);w!==null&&vt(St,w.startTime-f)}}var qe=!1,Q=-1,Be=5,At=-1;function Hn(){return kt?!0:!(T.unstable_now()-At<Be)}function wt(){if(kt=!1,qe){var f=T.unstable_now();At=f;var w=!0;try{e:{De=!1,Ne&&(Ne=!1,$t(Q),Q=-1),xe=!0;var O=$;try{t:{for(at(f),D=j(I);D!==null&&!(D.expirationTime>f&&Hn());){var re=D.callback;if(typeof re=="function"){D.callback=null,$=D.priorityLevel;var le=re(D.expirationTime<=f);if(f=T.unstable_now(),typeof le=="function"){D.callback=le,at(f),w=!0;break t}D===j(I)&&y(I),at(f)}else y(I);D=j(I)}if(D!==null)w=!0;else{var u=j(b);u!==null&&vt(St,u.startTime-f),w=!1}}break e}finally{D=null,$=O,xe=!1}w=void 0}}finally{w?ze():qe=!1}}}var ze;if(typeof Pe=="function")ze=function(){Pe(wt)};else if(typeof MessageChannel<"u"){var An=new MessageChannel,It=An.port2;An.port1.onmessage=wt,ze=function(){It.postMessage(null)}}else ze=function(){Ke(wt,0)};function vt(f,w){Q=Ke(function(){f(T.unstable_now())},w)}T.unstable_IdlePriority=5,T.unstable_ImmediatePriority=1,T.unstable_LowPriority=4,T.unstable_NormalPriority=3,T.unstable_Profiling=null,T.unstable_UserBlockingPriority=2,T.unstable_cancelCallback=function(f){f.callback=null},T.unstable_forceFrameRate=function(f){0>f||125<f?console.error("forceFrameRate takes a positive int between 0 and 125, forcing frame rates higher than 125 fps is not supported"):Be=0<f?Math.floor(1e3/f):5},T.unstable_getCurrentPriorityLevel=function(){return $},T.unstable_next=function(f){switch($){case 1:case 2:case 3:var w=3;break;default:w=$}var O=$;$=w;try{return f()}finally{$=O}},T.unstable_requestPaint=function(){kt=!0},T.unstable_runWithPriority=function(f,w){switch(f){case 1:case 2:case 3:case 4:case 5:break;default:f=3}var O=$;$=f;try{return w()}finally{$=O}},T.unstable_scheduleCallback=function(f,w,O){var re=T.unstable_now();switch(typeof O=="object"&&O!==null?(O=O.delay,O=typeof O=="number"&&0<O?re+O:re):O=re,f){case 1:var le=-1;break;case 2:le=250;break;case 5:le=1073741823;break;case 4:le=1e4;break;default:le=5e3}return le=O+le,f={id:B++,callback:w,priorityLevel:f,startTime:O,expirationTime:le,sortIndex:-1},O>re?(f.sortIndex=O,ue(b,f),j(I)===null&&f===j(b)&&(Ne?($t(Q),Q=-1):Ne=!0,vt(St,O-re))):(f.sortIndex=le,ue(I,f),De||xe||(De=!0,qe||(qe=!0,ze()))),f},T.unstable_shouldYield=Hn,T.unstable_wrapCallback=function(f){var w=$;return function(){var O=$;$=w;try{return f.apply(this,arguments)}finally{$=O}}}})(cl)),cl}var Cp;function Zg(){return Cp||(Cp=1,ll.exports=Xg()),ll.exports}var ul={exports:{}},Oe={};var bp;function ey(){if(bp)return Oe;bp=1;var T=pl();function ue(I){var b="https://react.dev/errors/"+I;if(1<arguments.length){b+="?args[]="+encodeURIComponent(arguments[1]);for(var B=2;B<arguments.length;B++)b+="&args[]="+encodeURIComponent(arguments[B])}return"Minified React error #"+I+"; visit "+b+" for the full message or use the non-minified dev environment for full errors and additional helpful warnings."}function j(){}var y={d:{f:j,r:function(){throw Error(ue(522))},D:j,C:j,L:j,m:j,X:j,S:j,M:j},p:0,findDOMNode:null},N=Symbol.for("react.portal");function F(I,b,B){var D=3<arguments.length&&arguments[3]!==void 0?arguments[3]:null;return{$$typeof:N,key:D==null?null:""+D,children:I,containerInfo:b,implementation:B}}var Y=T.__CLIENT_INTERNALS_DO_NOT_USE_OR_WARN_USERS_THEY_CANNOT_UPGRADE;function Z(I,b){if(I==="font")return"";if(typeof b=="string")return b==="use-credentials"?b:""}return Oe.__DOM_INTERNALS_DO_NOT_USE_OR_WARN_USERS_THEY_CANNOT_UPGRADE=y,Oe.createPortal=function(I,b){var B=2<arguments.length&&arguments[2]!==void 0?arguments[2]:null;if(!b||b.nodeType!==1&&b.nodeType!==9&&b.nodeType!==11)throw Error(ue(299));return F(I,b,null,B)},Oe.flushSync=function(I){var b=Y.T,B=y.p;try{if(Y.T=null,y.p=2,I)return I()}finally{Y.T=b,y.p=B,y.d.f()}},Oe.preconnect=function(I,b){typeof I=="string"&&(b?(b=b.crossOrigin,b=typeof b=="string"?b==="use-credentials"?b:"":void 0):b=null,y.d.C(I,b))},Oe.prefetchDNS=function(I){typeof I=="string"&&y.d.D(I)},Oe.preinit=function(I,b){if(typeof I=="string"&&b&&typeof b.as=="string"){var B=b.as,D=Z(B,b.crossOrigin),$=typeof b.integrity=="string"?b.integrity:void 0,xe=typeof b.fetchPriority=="string"?b.fetchPriority:void 0;B==="style"?y.d.S(I,typeof b.precedence=="string"?b.precedence:void 0,{crossOrigin:D,integrity:$,fetchPriority:xe}):B==="script"&&y.d.X(I,{crossOrigin:D,integrity:$,fetchPriority:xe,nonce:typeof b.nonce=="string"?b.nonce:void 0})}},Oe.preinitModule=function(I,b){if(typeof I=="string")if(typeof b=="object"&&b!==null){if(b.as==null||b.as==="script"){var B=Z(b.as,b.crossOrigin);y.d.M(I,{crossOrigin:B,integrity:typeof b.integrity=="string"?b.integrity:void 0,nonce:typeof b.nonce=="string"?b.nonce:void 0})}}else b==null&&y.d.M(I)},Oe.preload=function(I,b){if(typeof I=="string"&&typeof b=="object"&&b!==null&&typeof b.as=="string"){var B=b.as,D=Z(B,b.crossOrigin);y.d.L(I,B,{crossOrigin:D,integrity:typeof b.integrity=="string"?b.integrity:void 0,nonce:typeof b.nonce=="string"?b.nonce:void 0,type:typeof b.type=="string"?b.type:void 0,fetchPriority:typeof b.fetchPriority=="string"?b.fetchPriority:void 0,referrerPolicy:typeof b.referrerPolicy=="string"?b.referrerPolicy:void 0,imageSrcSet:typeof b.imageSrcSet=="string"?b.imageSrcSet:void 0,imageSizes:typeof b.imageSizes=="string"?b.imageSizes:void 0,media:typeof b.media=="string"?b.media:void 0})}},Oe.preloadModule=function(I,b){if(typeof I=="string")if(b){var B=Z(b.as,b.crossOrigin);y.d.m(I,{as:typeof b.as=="string"&&b.as!=="script"?b.as:void 0,crossOrigin:B,integrity:typeof b.integrity=="string"?b.integrity:void 0})}else y.d.m(I)},Oe.requestFormReset=function(I){y.d.r(I)},Oe.unstable_batchedUpdates=function(I,b){return I(b)},Oe.useFormState=function(I,b,B){return Y.H.useFormState(I,b,B)},Oe.useFormStatus=function(){return Y.H.useHostTransitionStatus()},Oe.version="19.2.4",Oe}var Sp;function ty(){if(Sp)return ul.exports;Sp=1;function T(){if(!(typeof __REACT_DEVTOOLS_GLOBAL_HOOK__>"u"||typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.checkDCE!="function"))try{__REACT_DEVTOOLS_GLOBAL_HOOK__.checkDCE(T)}catch(ue){console.error(ue)}}return T(),ul.exports=ey(),ul.exports}var Ap;function ny(){if(Ap)return Sr;Ap=1;var T=Zg(),ue=pl(),j=ty();function y(e){var t="https://react.dev/errors/"+e;if(1<arguments.length){t+="?args[]="+encodeURIComponent(arguments[1]);for(var n=2;n<arguments.length;n++)t+="&args[]="+encodeURIComponent(arguments[n])}return"Minified React error #"+e+"; visit "+t+" for the full message or use the non-minified dev environment for full errors and additional helpful warnings."}function N(e){return!(!e||e.nodeType!==1&&e.nodeType!==9&&e.nodeType!==11)}function F(e){var t=e,n=e;if(e.alternate)for(;t.return;)t=t.return;else{e=t;do t=e,(t.flags&4098)!==0&&(n=t.return),e=t.return;while(e)}return t.tag===3?n:null}function Y(e){if(e.tag===13){var t=e.memoizedState;if(t===null&&(e=e.alternate,e!==null&&(t=e.memoizedState)),t!==null)return t.dehydrated}return null}function Z(e){if(e.tag===31){var t=e.memoizedState;if(t===null&&(e=e.alternate,e!==null&&(t=e.memoizedState)),t!==null)return t.dehydrated}return null}function I(e){if(F(e)!==e)throw Error(y(188))}function b(e){var t=e.alternate;if(!t){if(t=F(e),t===null)throw Error(y(188));return t!==e?null:e}for(var n=e,i=t;;){var r=n.return;if(r===null)break;var o=r.alternate;if(o===null){if(i=r.return,i!==null){n=i;continue}break}if(r.child===o.child){for(o=r.child;o;){if(o===n)return I(r),e;if(o===i)return I(r),t;o=o.sibling}throw Error(y(188))}if(n.return!==i.return)n=r,i=o;else{for(var a=!1,s=r.child;s;){if(s===n){a=!0,n=r,i=o;break}if(s===i){a=!0,i=r,n=o;break}s=s.sibling}if(!a){for(s=o.child;s;){if(s===n){a=!0,n=o,i=r;break}if(s===i){a=!0,i=o,n=r;break}s=s.sibling}if(!a)throw Error(y(189))}}if(n.alternate!==i)throw Error(y(190))}if(n.tag!==3)throw Error(y(188));return n.stateNode.current===n?e:t}function B(e){var t=e.tag;if(t===5||t===26||t===27||t===6)return e;for(e=e.child;e!==null;){if(t=B(e),t!==null)return t;e=e.sibling}return null}var D=Object.assign,$=Symbol.for("react.element"),xe=Symbol.for("react.transitional.element"),De=Symbol.for("react.portal"),Ne=Symbol.for("react.fragment"),kt=Symbol.for("react.strict_mode"),Ke=Symbol.for("react.profiler"),$t=Symbol.for("react.consumer"),Pe=Symbol.for("react.context"),at=Symbol.for("react.forward_ref"),St=Symbol.for("react.suspense"),qe=Symbol.for("react.suspense_list"),Q=Symbol.for("react.memo"),Be=Symbol.for("react.lazy"),At=Symbol.for("react.activity"),Hn=Symbol.for("react.memo_cache_sentinel"),wt=Symbol.iterator;function ze(e){return e===null||typeof e!="object"?null:(e=wt&&e[wt]||e["@@iterator"],typeof e=="function"?e:null)}var An=Symbol.for("react.client.reference");function It(e){if(e==null)return null;if(typeof e=="function")return e.$$typeof===An?null:e.displayName||e.name||null;if(typeof e=="string")return e;switch(e){case Ne:return"Fragment";case Ke:return"Profiler";case kt:return"StrictMode";case St:return"Suspense";case qe:return"SuspenseList";case At:return"Activity"}if(typeof e=="object")switch(e.$$typeof){case De:return"Portal";case Pe:return e.displayName||"Context";case $t:return(e._context.displayName||"Context")+".Consumer";case at:var t=e.render;return e=e.displayName,e||(e=t.displayName||t.name||"",e=e!==""?"ForwardRef("+e+")":"ForwardRef"),e;case Q:return t=e.displayName||null,t!==null?t:It(e.type)||"Memo";case Be:t=e._payload,e=e._init;try{return It(e(t))}catch{}}return null}var vt=Array.isArray,f=ue.__CLIENT_INTERNALS_DO_NOT_USE_OR_WARN_USERS_THEY_CANNOT_UPGRADE,w=j.__DOM_INTERNALS_DO_NOT_USE_OR_WARN_USERS_THEY_CANNOT_UPGRADE,O={pending:!1,data:null,method:null,action:null},re=[],le=-1;function u(e){return{current:e}}function A(e){0>le||(e.current=re[le],re[le]=null,le--)}function L(e,t){le++,re[le]=e.current,e.current=t}var W=u(null),M=u(null),z=u(null),te=u(null);function Me(e,t){switch(L(z,t),L(M,e),L(W,null),t.nodeType){case 9:case 11:e=(e=t.documentElement)&&(e=e.namespaceURI)?Ud(e):0;break;default:if(e=t.tagName,t=t.namespaceURI)t=Ud(t),e=qd(t,e);else switch(e){case"svg":e=1;break;case"math":e=2;break;default:e=0}}A(W),L(W,e)}function he(){A(W),A(M),A(z)}function Wi(e){e.memoizedState!==null&&L(te,e);var t=W.current,n=qd(t,e.type);t!==n&&(L(M,e),L(W,n))}function Ar(e){M.current===e&&(A(W),A(M)),te.current===e&&(A(te),hr._currentValue=O)}var Go,ml;function wn(e){if(Go===void 0)try{throw Error()}catch(n){var t=n.stack.trim().match(/\n( *(at )?)/);Go=t&&t[1]||"",ml=-1<n.stack.indexOf(`
    at`)?" (<anonymous>)":-1<n.stack.indexOf("@")?"@unknown:0:0":""}return`
`+Go+e+ml}var Ho=!1;function jo(e,t){if(!e||Ho)return"";Ho=!0;var n=Error.prepareStackTrace;Error.prepareStackTrace=void 0;try{var i={DetermineComponentFrameRoot:function(){try{if(t){var S=function(){throw Error()};if(Object.defineProperty(S.prototype,"props",{set:function(){throw Error()}}),typeof Reflect=="object"&&Reflect.construct){try{Reflect.construct(S,[])}catch(h){var g=h}Reflect.construct(e,[],S)}else{try{S.call()}catch(h){g=h}e.call(S.prototype)}}else{try{throw Error()}catch(h){g=h}(S=e())&&typeof S.catch=="function"&&S.catch(function(){})}}catch(h){if(h&&g&&typeof h.stack=="string")return[h.stack,g.stack]}return[null,null]}};i.DetermineComponentFrameRoot.displayName="DetermineComponentFrameRoot";var r=Object.getOwnPropertyDescriptor(i.DetermineComponentFrameRoot,"name");r&&r.configurable&&Object.defineProperty(i.DetermineComponentFrameRoot,"name",{value:"DetermineComponentFrameRoot"});var o=i.DetermineComponentFrameRoot(),a=o[0],s=o[1];if(a&&s){var l=a.split(`
`),m=s.split(`
`);for(r=i=0;i<l.length&&!l[i].includes("DetermineComponentFrameRoot");)i++;for(;r<m.length&&!m[r].includes("DetermineComponentFrameRoot");)r++;if(i===l.length||r===m.length)for(i=l.length-1,r=m.length-1;1<=i&&0<=r&&l[i]!==m[r];)r--;for(;1<=i&&0<=r;i--,r--)if(l[i]!==m[r]){if(i!==1||r!==1)do if(i--,r--,0>r||l[i]!==m[r]){var v=`
`+l[i].replace(" at new "," at ");return e.displayName&&v.includes("<anonymous>")&&(v=v.replace("<anonymous>",e.displayName)),v}while(1<=i&&0<=r);break}}}finally{Ho=!1,Error.prepareStackTrace=n}return(n=e?e.displayName||e.name:"")?wn(n):""}function Ep(e,t){switch(e.tag){case 26:case 27:case 5:return wn(e.type);case 16:return wn("Lazy");case 13:return e.child!==t&&t!==null?wn("Suspense Fallback"):wn("Suspense");case 19:return wn("SuspenseList");case 0:case 15:return jo(e.type,!1);case 11:return jo(e.type.render,!1);case 1:return jo(e.type,!0);case 31:return wn("Activity");default:return""}}function gl(e){try{var t="",n=null;do t+=Ep(e,n),n=e,e=e.return;while(e);return t}catch(i){return`
Error generating stack: `+i.message+`
`+i.stack}}var Fo=Object.prototype.hasOwnProperty,_o=T.unstable_scheduleCallback,Vo=T.unstable_cancelCallback,Wp=T.unstable_shouldYield,kp=T.unstable_requestPaint,$e=T.unstable_now,Ip=T.unstable_getCurrentPriorityLevel,yl=T.unstable_ImmediatePriority,hl=T.unstable_UserBlockingPriority,wr=T.unstable_NormalPriority,Rp=T.unstable_LowPriority,vl=T.unstable_IdlePriority,Dp=T.log,Pp=T.unstable_setDisableYieldValue,ki=null,Ye=null;function Yt(e){if(typeof Dp=="function"&&Pp(e),Ye&&typeof Ye.setStrictMode=="function")try{Ye.setStrictMode(ki,e)}catch{}}var Je=Math.clz32?Math.clz32:Np,Op=Math.log,xp=Math.LN2;function Np(e){return e>>>=0,e===0?32:31-(Op(e)/xp|0)|0}var Lr=256,Tr=262144,Er=4194304;function Ln(e){var t=e&42;if(t!==0)return t;switch(e&-e){case 1:return 1;case 2:return 2;case 4:return 4;case 8:return 8;case 16:return 16;case 32:return 32;case 64:return 64;case 128:return 128;case 256:case 512:case 1024:case 2048:case 4096:case 8192:case 16384:case 32768:case 65536:case 131072:return e&261888;case 262144:case 524288:case 1048576:case 2097152:return e&3932160;case 4194304:case 8388608:case 16777216:case 33554432:return e&62914560;case 67108864:return 67108864;case 134217728:return 134217728;case 268435456:return 268435456;case 536870912:return 536870912;case 1073741824:return 0;default:return e}}function Wr(e,t,n){var i=e.pendingLanes;if(i===0)return 0;var r=0,o=e.suspendedLanes,a=e.pingedLanes;e=e.warmLanes;var s=i&134217727;return s!==0?(i=s&~o,i!==0?r=Ln(i):(a&=s,a!==0?r=Ln(a):n||(n=s&~e,n!==0&&(r=Ln(n))))):(s=i&~o,s!==0?r=Ln(s):a!==0?r=Ln(a):n||(n=i&~e,n!==0&&(r=Ln(n)))),r===0?0:t!==0&&t!==r&&(t&o)===0&&(o=r&-r,n=t&-t,o>=n||o===32&&(n&4194048)!==0)?t:r}function Ii(e,t){return(e.pendingLanes&~(e.suspendedLanes&~e.pingedLanes)&t)===0}function Mp(e,t){switch(e){case 1:case 2:case 4:case 8:case 64:return t+250;case 16:case 32:case 128:case 256:case 512:case 1024:case 2048:case 4096:case 8192:case 16384:case 32768:case 65536:case 131072:case 262144:case 524288:case 1048576:case 2097152:return t+5e3;case 4194304:case 8388608:case 16777216:case 33554432:return-1;case 67108864:case 134217728:case 268435456:case 536870912:case 1073741824:return-1;default:return-1}}function fl(){var e=Er;return Er<<=1,(Er&62914560)===0&&(Er=4194304),e}function Qo(e){for(var t=[],n=0;31>n;n++)t.push(e);return t}function Ri(e,t){e.pendingLanes|=t,t!==268435456&&(e.suspendedLanes=0,e.pingedLanes=0,e.warmLanes=0)}function Up(e,t,n,i,r,o){var a=e.pendingLanes;e.pendingLanes=n,e.suspendedLanes=0,e.pingedLanes=0,e.warmLanes=0,e.expiredLanes&=n,e.entangledLanes&=n,e.errorRecoveryDisabledLanes&=n,e.shellSuspendCounter=0;var s=e.entanglements,l=e.expirationTimes,m=e.hiddenUpdates;for(n=a&~n;0<n;){var v=31-Je(n),S=1<<v;s[v]=0,l[v]=-1;var g=m[v];if(g!==null)for(m[v]=null,v=0;v<g.length;v++){var h=g[v];h!==null&&(h.lane&=-536870913)}n&=~S}i!==0&&Cl(e,i,0),o!==0&&r===0&&e.tag!==0&&(e.suspendedLanes|=o&~(a&~t))}function Cl(e,t,n){e.pendingLanes|=t,e.suspendedLanes&=~t;var i=31-Je(t);e.entangledLanes|=t,e.entanglements[i]=e.entanglements[i]|1073741824|n&261930}function bl(e,t){var n=e.entangledLanes|=t;for(e=e.entanglements;n;){var i=31-Je(n),r=1<<i;r&t|e[i]&t&&(e[i]|=t),n&=~r}}function Sl(e,t){var n=t&-t;return n=(n&42)!==0?1:Ko(n),(n&(e.suspendedLanes|t))!==0?0:n}function Ko(e){switch(e){case 2:e=1;break;case 8:e=4;break;case 32:e=16;break;case 256:case 512:case 1024:case 2048:case 4096:case 8192:case 16384:case 32768:case 65536:case 131072:case 262144:case 524288:case 1048576:case 2097152:case 4194304:case 8388608:case 16777216:case 33554432:e=128;break;case 268435456:e=134217728;break;default:e=0}return e}function $o(e){return e&=-e,2<e?8<e?(e&134217727)!==0?32:268435456:8:2}function Al(){var e=w.p;return e!==0?e:(e=window.event,e===void 0?32:sp(e.type))}function wl(e,t){var n=w.p;try{return w.p=e,t()}finally{w.p=n}}var Jt=Math.random().toString(36).slice(2),Ee="__reactFiber$"+Jt,Ge="__reactProps$"+Jt,jn="__reactContainer$"+Jt,Yo="__reactEvents$"+Jt,qp="__reactListeners$"+Jt,Bp="__reactHandles$"+Jt,Ll="__reactResources$"+Jt,Di="__reactMarker$"+Jt;function Jo(e){delete e[Ee],delete e[Ge],delete e[Yo],delete e[qp],delete e[Bp]}function Fn(e){var t=e[Ee];if(t)return t;for(var n=e.parentNode;n;){if(t=n[jn]||n[Ee]){if(n=t.alternate,t.child!==null||n!==null&&n.child!==null)for(e=_d(e);e!==null;){if(n=e[Ee])return n;e=_d(e)}return t}e=n,n=e.parentNode}return null}function _n(e){if(e=e[Ee]||e[jn]){var t=e.tag;if(t===5||t===6||t===13||t===31||t===26||t===27||t===3)return e}return null}function Pi(e){var t=e.tag;if(t===5||t===26||t===27||t===6)return e.stateNode;throw Error(y(33))}function Vn(e){var t=e[Ll];return t||(t=e[Ll]={hoistableStyles:new Map,hoistableScripts:new Map}),t}function Le(e){e[Di]=!0}var Tl=new Set,El={};function Tn(e,t){Qn(e,t),Qn(e+"Capture",t)}function Qn(e,t){for(El[e]=t,e=0;e<t.length;e++)Tl.add(t[e])}var zp=RegExp("^[:A-Z_a-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD][:A-Z_a-z\\u00C0-\\u00D6\\u00D8-\\u00F6\\u00F8-\\u02FF\\u0370-\\u037D\\u037F-\\u1FFF\\u200C-\\u200D\\u2070-\\u218F\\u2C00-\\u2FEF\\u3001-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFFD\\-.0-9\\u00B7\\u0300-\\u036F\\u203F-\\u2040]*$"),Wl={},kl={};function Gp(e){return Fo.call(kl,e)?!0:Fo.call(Wl,e)?!1:zp.test(e)?kl[e]=!0:(Wl[e]=!0,!1)}function kr(e,t,n){if(Gp(t))if(n===null)e.removeAttribute(t);else{switch(typeof n){case"undefined":case"function":case"symbol":e.removeAttribute(t);return;case"boolean":var i=t.toLowerCase().slice(0,5);if(i!=="data-"&&i!=="aria-"){e.removeAttribute(t);return}}e.setAttribute(t,""+n)}}function Ir(e,t,n){if(n===null)e.removeAttribute(t);else{switch(typeof n){case"undefined":case"function":case"symbol":case"boolean":e.removeAttribute(t);return}e.setAttribute(t,""+n)}}function Rt(e,t,n,i){if(i===null)e.removeAttribute(n);else{switch(typeof i){case"undefined":case"function":case"symbol":case"boolean":e.removeAttribute(n);return}e.setAttributeNS(t,n,""+i)}}function st(e){switch(typeof e){case"bigint":case"boolean":case"number":case"string":case"undefined":return e;case"object":return e;default:return""}}function Il(e){var t=e.type;return(e=e.nodeName)&&e.toLowerCase()==="input"&&(t==="checkbox"||t==="radio")}function Hp(e,t,n){var i=Object.getOwnPropertyDescriptor(e.constructor.prototype,t);if(!e.hasOwnProperty(t)&&typeof i<"u"&&typeof i.get=="function"&&typeof i.set=="function"){var r=i.get,o=i.set;return Object.defineProperty(e,t,{configurable:!0,get:function(){return r.call(this)},set:function(a){n=""+a,o.call(this,a)}}),Object.defineProperty(e,t,{enumerable:i.enumerable}),{getValue:function(){return n},setValue:function(a){n=""+a},stopTracking:function(){e._valueTracker=null,delete e[t]}}}}function Xo(e){if(!e._valueTracker){var t=Il(e)?"checked":"value";e._valueTracker=Hp(e,t,""+e[t])}}function Rl(e){if(!e)return!1;var t=e._valueTracker;if(!t)return!0;var n=t.getValue(),i="";return e&&(i=Il(e)?e.checked?"true":"false":e.value),e=i,e!==n?(t.setValue(e),!0):!1}function Rr(e){if(e=e||(typeof document<"u"?document:void 0),typeof e>"u")return null;try{return e.activeElement||e.body}catch{return e.body}}var jp=/[\n"\\]/g;function lt(e){return e.replace(jp,function(t){return"\\"+t.charCodeAt(0).toString(16)+" "})}function Zo(e,t,n,i,r,o,a,s){e.name="",a!=null&&typeof a!="function"&&typeof a!="symbol"&&typeof a!="boolean"?e.type=a:e.removeAttribute("type"),t!=null?a==="number"?(t===0&&e.value===""||e.value!=t)&&(e.value=""+st(t)):e.value!==""+st(t)&&(e.value=""+st(t)):a!=="submit"&&a!=="reset"||e.removeAttribute("value"),t!=null?ea(e,a,st(t)):n!=null?ea(e,a,st(n)):i!=null&&e.removeAttribute("value"),r==null&&o!=null&&(e.defaultChecked=!!o),r!=null&&(e.checked=r&&typeof r!="function"&&typeof r!="symbol"),s!=null&&typeof s!="function"&&typeof s!="symbol"&&typeof s!="boolean"?e.name=""+st(s):e.removeAttribute("name")}function Dl(e,t,n,i,r,o,a,s){if(o!=null&&typeof o!="function"&&typeof o!="symbol"&&typeof o!="boolean"&&(e.type=o),t!=null||n!=null){if(!(o!=="submit"&&o!=="reset"||t!=null)){Xo(e);return}n=n!=null?""+st(n):"",t=t!=null?""+st(t):n,s||t===e.value||(e.value=t),e.defaultValue=t}i=i??r,i=typeof i!="function"&&typeof i!="symbol"&&!!i,e.checked=s?e.checked:!!i,e.defaultChecked=!!i,a!=null&&typeof a!="function"&&typeof a!="symbol"&&typeof a!="boolean"&&(e.name=a),Xo(e)}function ea(e,t,n){t==="number"&&Rr(e.ownerDocument)===e||e.defaultValue===""+n||(e.defaultValue=""+n)}function Kn(e,t,n,i){if(e=e.options,t){t={};for(var r=0;r<n.length;r++)t["$"+n[r]]=!0;for(n=0;n<e.length;n++)r=t.hasOwnProperty("$"+e[n].value),e[n].selected!==r&&(e[n].selected=r),r&&i&&(e[n].defaultSelected=!0)}else{for(n=""+st(n),t=null,r=0;r<e.length;r++){if(e[r].value===n){e[r].selected=!0,i&&(e[r].defaultSelected=!0);return}t!==null||e[r].disabled||(t=e[r])}t!==null&&(t.selected=!0)}}function Pl(e,t,n){if(t!=null&&(t=""+st(t),t!==e.value&&(e.value=t),n==null)){e.defaultValue!==t&&(e.defaultValue=t);return}e.defaultValue=n!=null?""+st(n):""}function Ol(e,t,n,i){if(t==null){if(i!=null){if(n!=null)throw Error(y(92));if(vt(i)){if(1<i.length)throw Error(y(93));i=i[0]}n=i}n==null&&(n=""),t=n}n=st(t),e.defaultValue=n,i=e.textContent,i===n&&i!==""&&i!==null&&(e.value=i),Xo(e)}function $n(e,t){if(t){var n=e.firstChild;if(n&&n===e.lastChild&&n.nodeType===3){n.nodeValue=t;return}}e.textContent=t}var Fp=new Set("animationIterationCount aspectRatio borderImageOutset borderImageSlice borderImageWidth boxFlex boxFlexGroup boxOrdinalGroup columnCount columns flex flexGrow flexPositive flexShrink flexNegative flexOrder gridArea gridRow gridRowEnd gridRowSpan gridRowStart gridColumn gridColumnEnd gridColumnSpan gridColumnStart fontWeight lineClamp lineHeight opacity order orphans scale tabSize widows zIndex zoom fillOpacity floodOpacity stopOpacity strokeDasharray strokeDashoffset strokeMiterlimit strokeOpacity strokeWidth MozAnimationIterationCount MozBoxFlex MozBoxFlexGroup MozLineClamp msAnimationIterationCount msFlex msZoom msFlexGrow msFlexNegative msFlexOrder msFlexPositive msFlexShrink msGridColumn msGridColumnSpan msGridRow msGridRowSpan WebkitAnimationIterationCount WebkitBoxFlex WebKitBoxFlexGroup WebkitBoxOrdinalGroup WebkitColumnCount WebkitColumns WebkitFlex WebkitFlexGrow WebkitFlexPositive WebkitFlexShrink WebkitLineClamp".split(" "));function xl(e,t,n){var i=t.indexOf("--")===0;n==null||typeof n=="boolean"||n===""?i?e.setProperty(t,""):t==="float"?e.cssFloat="":e[t]="":i?e.setProperty(t,n):typeof n!="number"||n===0||Fp.has(t)?t==="float"?e.cssFloat=n:e[t]=(""+n).trim():e[t]=n+"px"}function Nl(e,t,n){if(t!=null&&typeof t!="object")throw Error(y(62));if(e=e.style,n!=null){for(var i in n)!n.hasOwnProperty(i)||t!=null&&t.hasOwnProperty(i)||(i.indexOf("--")===0?e.setProperty(i,""):i==="float"?e.cssFloat="":e[i]="");for(var r in t)i=t[r],t.hasOwnProperty(r)&&n[r]!==i&&xl(e,r,i)}else for(var o in t)t.hasOwnProperty(o)&&xl(e,o,t[o])}function ta(e){if(e.indexOf("-")===-1)return!1;switch(e){case"annotation-xml":case"color-profile":case"font-face":case"font-face-src":case"font-face-uri":case"font-face-format":case"font-face-name":case"missing-glyph":return!1;default:return!0}}var _p=new Map([["acceptCharset","accept-charset"],["htmlFor","for"],["httpEquiv","http-equiv"],["crossOrigin","crossorigin"],["accentHeight","accent-height"],["alignmentBaseline","alignment-baseline"],["arabicForm","arabic-form"],["baselineShift","baseline-shift"],["capHeight","cap-height"],["clipPath","clip-path"],["clipRule","clip-rule"],["colorInterpolation","color-interpolation"],["colorInterpolationFilters","color-interpolation-filters"],["colorProfile","color-profile"],["colorRendering","color-rendering"],["dominantBaseline","dominant-baseline"],["enableBackground","enable-background"],["fillOpacity","fill-opacity"],["fillRule","fill-rule"],["floodColor","flood-color"],["floodOpacity","flood-opacity"],["fontFamily","font-family"],["fontSize","font-size"],["fontSizeAdjust","font-size-adjust"],["fontStretch","font-stretch"],["fontStyle","font-style"],["fontVariant","font-variant"],["fontWeight","font-weight"],["glyphName","glyph-name"],["glyphOrientationHorizontal","glyph-orientation-horizontal"],["glyphOrientationVertical","glyph-orientation-vertical"],["horizAdvX","horiz-adv-x"],["horizOriginX","horiz-origin-x"],["imageRendering","image-rendering"],["letterSpacing","letter-spacing"],["lightingColor","lighting-color"],["markerEnd","marker-end"],["markerMid","marker-mid"],["markerStart","marker-start"],["overlinePosition","overline-position"],["overlineThickness","overline-thickness"],["paintOrder","paint-order"],["panose-1","panose-1"],["pointerEvents","pointer-events"],["renderingIntent","rendering-intent"],["shapeRendering","shape-rendering"],["stopColor","stop-color"],["stopOpacity","stop-opacity"],["strikethroughPosition","strikethrough-position"],["strikethroughThickness","strikethrough-thickness"],["strokeDasharray","stroke-dasharray"],["strokeDashoffset","stroke-dashoffset"],["strokeLinecap","stroke-linecap"],["strokeLinejoin","stroke-linejoin"],["strokeMiterlimit","stroke-miterlimit"],["strokeOpacity","stroke-opacity"],["strokeWidth","stroke-width"],["textAnchor","text-anchor"],["textDecoration","text-decoration"],["textRendering","text-rendering"],["transformOrigin","transform-origin"],["underlinePosition","underline-position"],["underlineThickness","underline-thickness"],["unicodeBidi","unicode-bidi"],["unicodeRange","unicode-range"],["unitsPerEm","units-per-em"],["vAlphabetic","v-alphabetic"],["vHanging","v-hanging"],["vIdeographic","v-ideographic"],["vMathematical","v-mathematical"],["vectorEffect","vector-effect"],["vertAdvY","vert-adv-y"],["vertOriginX","vert-origin-x"],["vertOriginY","vert-origin-y"],["wordSpacing","word-spacing"],["writingMode","writing-mode"],["xmlnsXlink","xmlns:xlink"],["xHeight","x-height"]]),Vp=/^[\u0000-\u001F ]*j[\r\n\t]*a[\r\n\t]*v[\r\n\t]*a[\r\n\t]*s[\r\n\t]*c[\r\n\t]*r[\r\n\t]*i[\r\n\t]*p[\r\n\t]*t[\r\n\t]*:/i;function Dr(e){return Vp.test(""+e)?"javascript:throw new Error('React has blocked a javascript: URL as a security precaution.')":e}function Dt(){}var na=null;function ia(e){return e=e.target||e.srcElement||window,e.correspondingUseElement&&(e=e.correspondingUseElement),e.nodeType===3?e.parentNode:e}var Yn=null,Jn=null;function Ml(e){var t=_n(e);if(t&&(e=t.stateNode)){var n=e[Ge]||null;e:switch(e=t.stateNode,t.type){case"input":if(Zo(e,n.value,n.defaultValue,n.defaultValue,n.checked,n.defaultChecked,n.type,n.name),t=n.name,n.type==="radio"&&t!=null){for(n=e;n.parentNode;)n=n.parentNode;for(n=n.querySelectorAll('input[name="'+lt(""+t)+'"][type="radio"]'),t=0;t<n.length;t++){var i=n[t];if(i!==e&&i.form===e.form){var r=i[Ge]||null;if(!r)throw Error(y(90));Zo(i,r.value,r.defaultValue,r.defaultValue,r.checked,r.defaultChecked,r.type,r.name)}}for(t=0;t<n.length;t++)i=n[t],i.form===e.form&&Rl(i)}break e;case"textarea":Pl(e,n.value,n.defaultValue);break e;case"select":t=n.value,t!=null&&Kn(e,!!n.multiple,t,!1)}}}var ra=!1;function Ul(e,t,n){if(ra)return e(t,n);ra=!0;try{var i=e(t);return i}finally{if(ra=!1,(Yn!==null||Jn!==null)&&(Co(),Yn&&(t=Yn,e=Jn,Jn=Yn=null,Ml(t),e)))for(t=0;t<e.length;t++)Ml(e[t])}}function Oi(e,t){var n=e.stateNode;if(n===null)return null;var i=n[Ge]||null;if(i===null)return null;n=i[t];e:switch(t){case"onClick":case"onClickCapture":case"onDoubleClick":case"onDoubleClickCapture":case"onMouseDown":case"onMouseDownCapture":case"onMouseMove":case"onMouseMoveCapture":case"onMouseUp":case"onMouseUpCapture":case"onMouseEnter":(i=!i.disabled)||(e=e.type,i=!(e==="button"||e==="input"||e==="select"||e==="textarea")),e=!i;break e;default:e=!1}if(e)return null;if(n&&typeof n!="function")throw Error(y(231,t,typeof n));return n}var Pt=!(typeof window>"u"||typeof window.document>"u"||typeof window.document.createElement>"u"),oa=!1;if(Pt)try{var xi={};Object.defineProperty(xi,"passive",{get:function(){oa=!0}}),window.addEventListener("test",xi,xi),window.removeEventListener("test",xi,xi)}catch{oa=!1}var Xt=null,aa=null,Pr=null;function ql(){if(Pr)return Pr;var e,t=aa,n=t.length,i,r="value"in Xt?Xt.value:Xt.textContent,o=r.length;for(e=0;e<n&&t[e]===r[e];e++);var a=n-e;for(i=1;i<=a&&t[n-i]===r[o-i];i++);return Pr=r.slice(e,1<i?1-i:void 0)}function Or(e){var t=e.keyCode;return"charCode"in e?(e=e.charCode,e===0&&t===13&&(e=13)):e=t,e===10&&(e=13),32<=e||e===13?e:0}function xr(){return!0}function Bl(){return!1}function He(e){function t(n,i,r,o,a){this._reactName=n,this._targetInst=r,this.type=i,this.nativeEvent=o,this.target=a,this.currentTarget=null;for(var s in e)e.hasOwnProperty(s)&&(n=e[s],this[s]=n?n(o):o[s]);return this.isDefaultPrevented=(o.defaultPrevented!=null?o.defaultPrevented:o.returnValue===!1)?xr:Bl,this.isPropagationStopped=Bl,this}return D(t.prototype,{preventDefault:function(){this.defaultPrevented=!0;var n=this.nativeEvent;n&&(n.preventDefault?n.preventDefault():typeof n.returnValue!="unknown"&&(n.returnValue=!1),this.isDefaultPrevented=xr)},stopPropagation:function(){var n=this.nativeEvent;n&&(n.stopPropagation?n.stopPropagation():typeof n.cancelBubble!="unknown"&&(n.cancelBubble=!0),this.isPropagationStopped=xr)},persist:function(){},isPersistent:xr}),t}var En={eventPhase:0,bubbles:0,cancelable:0,timeStamp:function(e){return e.timeStamp||Date.now()},defaultPrevented:0,isTrusted:0},Nr=He(En),Ni=D({},En,{view:0,detail:0}),Qp=He(Ni),sa,la,Mi,Mr=D({},Ni,{screenX:0,screenY:0,clientX:0,clientY:0,pageX:0,pageY:0,ctrlKey:0,shiftKey:0,altKey:0,metaKey:0,getModifierState:ua,button:0,buttons:0,relatedTarget:function(e){return e.relatedTarget===void 0?e.fromElement===e.srcElement?e.toElement:e.fromElement:e.relatedTarget},movementX:function(e){return"movementX"in e?e.movementX:(e!==Mi&&(Mi&&e.type==="mousemove"?(sa=e.screenX-Mi.screenX,la=e.screenY-Mi.screenY):la=sa=0,Mi=e),sa)},movementY:function(e){return"movementY"in e?e.movementY:la}}),zl=He(Mr),Kp=D({},Mr,{dataTransfer:0}),$p=He(Kp),Yp=D({},Ni,{relatedTarget:0}),ca=He(Yp),Jp=D({},En,{animationName:0,elapsedTime:0,pseudoElement:0}),Xp=He(Jp),Zp=D({},En,{clipboardData:function(e){return"clipboardData"in e?e.clipboardData:window.clipboardData}}),em=He(Zp),tm=D({},En,{data:0}),Gl=He(tm),nm={Esc:"Escape",Spacebar:" ",Left:"ArrowLeft",Up:"ArrowUp",Right:"ArrowRight",Down:"ArrowDown",Del:"Delete",Win:"OS",Menu:"ContextMenu",Apps:"ContextMenu",Scroll:"ScrollLock",MozPrintableKey:"Unidentified"},im={8:"Backspace",9:"Tab",12:"Clear",13:"Enter",16:"Shift",17:"Control",18:"Alt",19:"Pause",20:"CapsLock",27:"Escape",32:" ",33:"PageUp",34:"PageDown",35:"End",36:"Home",37:"ArrowLeft",38:"ArrowUp",39:"ArrowRight",40:"ArrowDown",45:"Insert",46:"Delete",112:"F1",113:"F2",114:"F3",115:"F4",116:"F5",117:"F6",118:"F7",119:"F8",120:"F9",121:"F10",122:"F11",123:"F12",144:"NumLock",145:"ScrollLock",224:"Meta"},rm={Alt:"altKey",Control:"ctrlKey",Meta:"metaKey",Shift:"shiftKey"};function om(e){var t=this.nativeEvent;return t.getModifierState?t.getModifierState(e):(e=rm[e])?!!t[e]:!1}function ua(){return om}var am=D({},Ni,{key:function(e){if(e.key){var t=nm[e.key]||e.key;if(t!=="Unidentified")return t}return e.type==="keypress"?(e=Or(e),e===13?"Enter":String.fromCharCode(e)):e.type==="keydown"||e.type==="keyup"?im[e.keyCode]||"Unidentified":""},code:0,location:0,ctrlKey:0,shiftKey:0,altKey:0,metaKey:0,repeat:0,locale:0,getModifierState:ua,charCode:function(e){return e.type==="keypress"?Or(e):0},keyCode:function(e){return e.type==="keydown"||e.type==="keyup"?e.keyCode:0},which:function(e){return e.type==="keypress"?Or(e):e.type==="keydown"||e.type==="keyup"?e.keyCode:0}}),sm=He(am),lm=D({},Mr,{pointerId:0,width:0,height:0,pressure:0,tangentialPressure:0,tiltX:0,tiltY:0,twist:0,pointerType:0,isPrimary:0}),Hl=He(lm),cm=D({},Ni,{touches:0,targetTouches:0,changedTouches:0,altKey:0,metaKey:0,ctrlKey:0,shiftKey:0,getModifierState:ua}),um=He(cm),dm=D({},En,{propertyName:0,elapsedTime:0,pseudoElement:0}),pm=He(dm),mm=D({},Mr,{deltaX:function(e){return"deltaX"in e?e.deltaX:"wheelDeltaX"in e?-e.wheelDeltaX:0},deltaY:function(e){return"deltaY"in e?e.deltaY:"wheelDeltaY"in e?-e.wheelDeltaY:"wheelDelta"in e?-e.wheelDelta:0},deltaZ:0,deltaMode:0}),gm=He(mm),ym=D({},En,{newState:0,oldState:0}),hm=He(ym),vm=[9,13,27,32],da=Pt&&"CompositionEvent"in window,Ui=null;Pt&&"documentMode"in document&&(Ui=document.documentMode);var fm=Pt&&"TextEvent"in window&&!Ui,jl=Pt&&(!da||Ui&&8<Ui&&11>=Ui),Fl=" ",_l=!1;function Vl(e,t){switch(e){case"keyup":return vm.indexOf(t.keyCode)!==-1;case"keydown":return t.keyCode!==229;case"keypress":case"mousedown":case"focusout":return!0;default:return!1}}function Ql(e){return e=e.detail,typeof e=="object"&&"data"in e?e.data:null}var Xn=!1;function Cm(e,t){switch(e){case"compositionend":return Ql(t);case"keypress":return t.which!==32?null:(_l=!0,Fl);case"textInput":return e=t.data,e===Fl&&_l?null:e;default:return null}}function bm(e,t){if(Xn)return e==="compositionend"||!da&&Vl(e,t)?(e=ql(),Pr=aa=Xt=null,Xn=!1,e):null;switch(e){case"paste":return null;case"keypress":if(!(t.ctrlKey||t.altKey||t.metaKey)||t.ctrlKey&&t.altKey){if(t.char&&1<t.char.length)return t.char;if(t.which)return String.fromCharCode(t.which)}return null;case"compositionend":return jl&&t.locale!=="ko"?null:t.data;default:return null}}var Sm={color:!0,date:!0,datetime:!0,"datetime-local":!0,email:!0,month:!0,number:!0,password:!0,range:!0,search:!0,tel:!0,text:!0,time:!0,url:!0,week:!0};function Kl(e){var t=e&&e.nodeName&&e.nodeName.toLowerCase();return t==="input"?!!Sm[e.type]:t==="textarea"}function $l(e,t,n,i){Yn?Jn?Jn.push(i):Jn=[i]:Yn=i,t=Eo(t,"onChange"),0<t.length&&(n=new Nr("onChange","change",null,n,i),e.push({event:n,listeners:t}))}var qi=null,Bi=null;function Am(e){Dd(e,0)}function Ur(e){var t=Pi(e);if(Rl(t))return e}function Yl(e,t){if(e==="change")return t}var Jl=!1;if(Pt){var pa;if(Pt){var ma="oninput"in document;if(!ma){var Xl=document.createElement("div");Xl.setAttribute("oninput","return;"),ma=typeof Xl.oninput=="function"}pa=ma}else pa=!1;Jl=pa&&(!document.documentMode||9<document.documentMode)}function Zl(){qi&&(qi.detachEvent("onpropertychange",ec),Bi=qi=null)}function ec(e){if(e.propertyName==="value"&&Ur(Bi)){var t=[];$l(t,Bi,e,ia(e)),Ul(Am,t)}}function wm(e,t,n){e==="focusin"?(Zl(),qi=t,Bi=n,qi.attachEvent("onpropertychange",ec)):e==="focusout"&&Zl()}function Lm(e){if(e==="selectionchange"||e==="keyup"||e==="keydown")return Ur(Bi)}function Tm(e,t){if(e==="click")return Ur(t)}function Em(e,t){if(e==="input"||e==="change")return Ur(t)}function Wm(e,t){return e===t&&(e!==0||1/e===1/t)||e!==e&&t!==t}var Xe=typeof Object.is=="function"?Object.is:Wm;function zi(e,t){if(Xe(e,t))return!0;if(typeof e!="object"||e===null||typeof t!="object"||t===null)return!1;var n=Object.keys(e),i=Object.keys(t);if(n.length!==i.length)return!1;for(i=0;i<n.length;i++){var r=n[i];if(!Fo.call(t,r)||!Xe(e[r],t[r]))return!1}return!0}function tc(e){for(;e&&e.firstChild;)e=e.firstChild;return e}function nc(e,t){var n=tc(e);e=0;for(var i;n;){if(n.nodeType===3){if(i=e+n.textContent.length,e<=t&&i>=t)return{node:n,offset:t-e};e=i}e:{for(;n;){if(n.nextSibling){n=n.nextSibling;break e}n=n.parentNode}n=void 0}n=tc(n)}}function ic(e,t){return e&&t?e===t?!0:e&&e.nodeType===3?!1:t&&t.nodeType===3?ic(e,t.parentNode):"contains"in e?e.contains(t):e.compareDocumentPosition?!!(e.compareDocumentPosition(t)&16):!1:!1}function rc(e){e=e!=null&&e.ownerDocument!=null&&e.ownerDocument.defaultView!=null?e.ownerDocument.defaultView:window;for(var t=Rr(e.document);t instanceof e.HTMLIFrameElement;){try{var n=typeof t.contentWindow.location.href=="string"}catch{n=!1}if(n)e=t.contentWindow;else break;t=Rr(e.document)}return t}function ga(e){var t=e&&e.nodeName&&e.nodeName.toLowerCase();return t&&(t==="input"&&(e.type==="text"||e.type==="search"||e.type==="tel"||e.type==="url"||e.type==="password")||t==="textarea"||e.contentEditable==="true")}var km=Pt&&"documentMode"in document&&11>=document.documentMode,Zn=null,ya=null,Gi=null,ha=!1;function oc(e,t,n){var i=n.window===n?n.document:n.nodeType===9?n:n.ownerDocument;ha||Zn==null||Zn!==Rr(i)||(i=Zn,"selectionStart"in i&&ga(i)?i={start:i.selectionStart,end:i.selectionEnd}:(i=(i.ownerDocument&&i.ownerDocument.defaultView||window).getSelection(),i={anchorNode:i.anchorNode,anchorOffset:i.anchorOffset,focusNode:i.focusNode,focusOffset:i.focusOffset}),Gi&&zi(Gi,i)||(Gi=i,i=Eo(ya,"onSelect"),0<i.length&&(t=new Nr("onSelect","select",null,t,n),e.push({event:t,listeners:i}),t.target=Zn)))}function Wn(e,t){var n={};return n[e.toLowerCase()]=t.toLowerCase(),n["Webkit"+e]="webkit"+t,n["Moz"+e]="moz"+t,n}var ei={animationend:Wn("Animation","AnimationEnd"),animationiteration:Wn("Animation","AnimationIteration"),animationstart:Wn("Animation","AnimationStart"),transitionrun:Wn("Transition","TransitionRun"),transitionstart:Wn("Transition","TransitionStart"),transitioncancel:Wn("Transition","TransitionCancel"),transitionend:Wn("Transition","TransitionEnd")},va={},ac={};Pt&&(ac=document.createElement("div").style,"AnimationEvent"in window||(delete ei.animationend.animation,delete ei.animationiteration.animation,delete ei.animationstart.animation),"TransitionEvent"in window||delete ei.transitionend.transition);function kn(e){if(va[e])return va[e];if(!ei[e])return e;var t=ei[e],n;for(n in t)if(t.hasOwnProperty(n)&&n in ac)return va[e]=t[n];return e}var sc=kn("animationend"),lc=kn("animationiteration"),cc=kn("animationstart"),Im=kn("transitionrun"),Rm=kn("transitionstart"),Dm=kn("transitioncancel"),uc=kn("transitionend"),dc=new Map,fa="abort auxClick beforeToggle cancel canPlay canPlayThrough click close contextMenu copy cut drag dragEnd dragEnter dragExit dragLeave dragOver dragStart drop durationChange emptied encrypted ended error gotPointerCapture input invalid keyDown keyPress keyUp load loadedData loadedMetadata loadStart lostPointerCapture mouseDown mouseMove mouseOut mouseOver mouseUp paste pause play playing pointerCancel pointerDown pointerMove pointerOut pointerOver pointerUp progress rateChange reset resize seeked seeking stalled submit suspend timeUpdate touchCancel touchEnd touchStart volumeChange scroll toggle touchMove waiting wheel".split(" ");fa.push("scrollEnd");function ft(e,t){dc.set(e,t),Tn(t,[e])}var qr=typeof reportError=="function"?reportError:function(e){if(typeof window=="object"&&typeof window.ErrorEvent=="function"){var t=new window.ErrorEvent("error",{bubbles:!0,cancelable:!0,message:typeof e=="object"&&e!==null&&typeof e.message=="string"?String(e.message):String(e),error:e});if(!window.dispatchEvent(t))return}else if(typeof process=="object"&&typeof process.emit=="function"){process.emit("uncaughtException",e);return}console.error(e)},ct=[],ti=0,Ca=0;function Br(){for(var e=ti,t=Ca=ti=0;t<e;){var n=ct[t];ct[t++]=null;var i=ct[t];ct[t++]=null;var r=ct[t];ct[t++]=null;var o=ct[t];if(ct[t++]=null,i!==null&&r!==null){var a=i.pending;a===null?r.next=r:(r.next=a.next,a.next=r),i.pending=r}o!==0&&pc(n,r,o)}}function zr(e,t,n,i){ct[ti++]=e,ct[ti++]=t,ct[ti++]=n,ct[ti++]=i,Ca|=i,e.lanes|=i,e=e.alternate,e!==null&&(e.lanes|=i)}function ba(e,t,n,i){return zr(e,t,n,i),Gr(e)}function In(e,t){return zr(e,null,null,t),Gr(e)}function pc(e,t,n){e.lanes|=n;var i=e.alternate;i!==null&&(i.lanes|=n);for(var r=!1,o=e.return;o!==null;)o.childLanes|=n,i=o.alternate,i!==null&&(i.childLanes|=n),o.tag===22&&(e=o.stateNode,e===null||e._visibility&1||(r=!0)),e=o,o=o.return;return e.tag===3?(o=e.stateNode,r&&t!==null&&(r=31-Je(n),e=o.hiddenUpdates,i=e[r],i===null?e[r]=[t]:i.push(t),t.lane=n|536870912),o):null}function Gr(e){if(50<cr)throw cr=0,Is=null,Error(y(185));for(var t=e.return;t!==null;)e=t,t=e.return;return e.tag===3?e.stateNode:null}var ni={};function Pm(e,t,n,i){this.tag=e,this.key=n,this.sibling=this.child=this.return=this.stateNode=this.type=this.elementType=null,this.index=0,this.refCleanup=this.ref=null,this.pendingProps=t,this.dependencies=this.memoizedState=this.updateQueue=this.memoizedProps=null,this.mode=i,this.subtreeFlags=this.flags=0,this.deletions=null,this.childLanes=this.lanes=0,this.alternate=null}function Ze(e,t,n,i){return new Pm(e,t,n,i)}function Sa(e){return e=e.prototype,!(!e||!e.isReactComponent)}function Ot(e,t){var n=e.alternate;return n===null?(n=Ze(e.tag,t,e.key,e.mode),n.elementType=e.elementType,n.type=e.type,n.stateNode=e.stateNode,n.alternate=e,e.alternate=n):(n.pendingProps=t,n.type=e.type,n.flags=0,n.subtreeFlags=0,n.deletions=null),n.flags=e.flags&65011712,n.childLanes=e.childLanes,n.lanes=e.lanes,n.child=e.child,n.memoizedProps=e.memoizedProps,n.memoizedState=e.memoizedState,n.updateQueue=e.updateQueue,t=e.dependencies,n.dependencies=t===null?null:{lanes:t.lanes,firstContext:t.firstContext},n.sibling=e.sibling,n.index=e.index,n.ref=e.ref,n.refCleanup=e.refCleanup,n}function mc(e,t){e.flags&=65011714;var n=e.alternate;return n===null?(e.childLanes=0,e.lanes=t,e.child=null,e.subtreeFlags=0,e.memoizedProps=null,e.memoizedState=null,e.updateQueue=null,e.dependencies=null,e.stateNode=null):(e.childLanes=n.childLanes,e.lanes=n.lanes,e.child=n.child,e.subtreeFlags=0,e.deletions=null,e.memoizedProps=n.memoizedProps,e.memoizedState=n.memoizedState,e.updateQueue=n.updateQueue,e.type=n.type,t=n.dependencies,e.dependencies=t===null?null:{lanes:t.lanes,firstContext:t.firstContext}),e}function Hr(e,t,n,i,r,o){var a=0;if(i=e,typeof e=="function")Sa(e)&&(a=1);else if(typeof e=="string")a=Ug(e,n,W.current)?26:e==="html"||e==="head"||e==="body"?27:5;else e:switch(e){case At:return e=Ze(31,n,t,r),e.elementType=At,e.lanes=o,e;case Ne:return Rn(n.children,r,o,t);case kt:a=8,r|=24;break;case Ke:return e=Ze(12,n,t,r|2),e.elementType=Ke,e.lanes=o,e;case St:return e=Ze(13,n,t,r),e.elementType=St,e.lanes=o,e;case qe:return e=Ze(19,n,t,r),e.elementType=qe,e.lanes=o,e;default:if(typeof e=="object"&&e!==null)switch(e.$$typeof){case Pe:a=10;break e;case $t:a=9;break e;case at:a=11;break e;case Q:a=14;break e;case Be:a=16,i=null;break e}a=29,n=Error(y(130,e===null?"null":typeof e,"")),i=null}return t=Ze(a,n,t,r),t.elementType=e,t.type=i,t.lanes=o,t}function Rn(e,t,n,i){return e=Ze(7,e,i,t),e.lanes=n,e}function Aa(e,t,n){return e=Ze(6,e,null,t),e.lanes=n,e}function gc(e){var t=Ze(18,null,null,0);return t.stateNode=e,t}function wa(e,t,n){return t=Ze(4,e.children!==null?e.children:[],e.key,t),t.lanes=n,t.stateNode={containerInfo:e.containerInfo,pendingChildren:null,implementation:e.implementation},t}var yc=new WeakMap;function ut(e,t){if(typeof e=="object"&&e!==null){var n=yc.get(e);return n!==void 0?n:(t={value:e,source:t,stack:gl(t)},yc.set(e,t),t)}return{value:e,source:t,stack:gl(t)}}var ii=[],ri=0,jr=null,Hi=0,dt=[],pt=0,Zt=null,Lt=1,Tt="";function xt(e,t){ii[ri++]=Hi,ii[ri++]=jr,jr=e,Hi=t}function hc(e,t,n){dt[pt++]=Lt,dt[pt++]=Tt,dt[pt++]=Zt,Zt=e;var i=Lt;e=Tt;var r=32-Je(i)-1;i&=~(1<<r),n+=1;var o=32-Je(t)+r;if(30<o){var a=r-r%5;o=(i&(1<<a)-1).toString(32),i>>=a,r-=a,Lt=1<<32-Je(t)+r|n<<r|i,Tt=o+e}else Lt=1<<o|n<<r|i,Tt=e}function La(e){e.return!==null&&(xt(e,1),hc(e,1,0))}function Ta(e){for(;e===jr;)jr=ii[--ri],ii[ri]=null,Hi=ii[--ri],ii[ri]=null;for(;e===Zt;)Zt=dt[--pt],dt[pt]=null,Tt=dt[--pt],dt[pt]=null,Lt=dt[--pt],dt[pt]=null}function vc(e,t){dt[pt++]=Lt,dt[pt++]=Tt,dt[pt++]=Zt,Lt=t.id,Tt=t.overflow,Zt=e}var We=null,de=null,K=!1,en=null,mt=!1,Ea=Error(y(519));function tn(e){var t=Error(y(418,1<arguments.length&&arguments[1]!==void 0&&arguments[1]?"text":"HTML",""));throw ji(ut(t,e)),Ea}function fc(e){var t=e.stateNode,n=e.type,i=e.memoizedProps;switch(t[Ee]=e,t[Ge]=i,n){case"dialog":H("cancel",t),H("close",t);break;case"iframe":case"object":case"embed":H("load",t);break;case"video":case"audio":for(n=0;n<dr.length;n++)H(dr[n],t);break;case"source":H("error",t);break;case"img":case"image":case"link":H("error",t),H("load",t);break;case"details":H("toggle",t);break;case"input":H("invalid",t),Dl(t,i.value,i.defaultValue,i.checked,i.defaultChecked,i.type,i.name,!0);break;case"select":H("invalid",t);break;case"textarea":H("invalid",t),Ol(t,i.value,i.defaultValue,i.children)}n=i.children,typeof n!="string"&&typeof n!="number"&&typeof n!="bigint"||t.textContent===""+n||i.suppressHydrationWarning===!0||Nd(t.textContent,n)?(i.popover!=null&&(H("beforetoggle",t),H("toggle",t)),i.onScroll!=null&&H("scroll",t),i.onScrollEnd!=null&&H("scrollend",t),i.onClick!=null&&(t.onclick=Dt),t=!0):t=!1,t||tn(e,!0)}function Cc(e){for(We=e.return;We;)switch(We.tag){case 5:case 31:case 13:mt=!1;return;case 27:case 3:mt=!0;return;default:We=We.return}}function oi(e){if(e!==We)return!1;if(!K)return Cc(e),K=!0,!1;var t=e.tag,n;if((n=t!==3&&t!==27)&&((n=t===5)&&(n=e.type,n=!(n!=="form"&&n!=="button")||Fs(e.type,e.memoizedProps)),n=!n),n&&de&&tn(e),Cc(e),t===13){if(e=e.memoizedState,e=e!==null?e.dehydrated:null,!e)throw Error(y(317));de=Fd(e)}else if(t===31){if(e=e.memoizedState,e=e!==null?e.dehydrated:null,!e)throw Error(y(317));de=Fd(e)}else t===27?(t=de,hn(e.type)?(e=$s,$s=null,de=e):de=t):de=We?yt(e.stateNode.nextSibling):null;return!0}function Dn(){de=We=null,K=!1}function Wa(){var e=en;return e!==null&&(Ve===null?Ve=e:Ve.push.apply(Ve,e),en=null),e}function ji(e){en===null?en=[e]:en.push(e)}var ka=u(null),Pn=null,Nt=null;function nn(e,t,n){L(ka,t._currentValue),t._currentValue=n}function Mt(e){e._currentValue=ka.current,A(ka)}function Ia(e,t,n){for(;e!==null;){var i=e.alternate;if((e.childLanes&t)!==t?(e.childLanes|=t,i!==null&&(i.childLanes|=t)):i!==null&&(i.childLanes&t)!==t&&(i.childLanes|=t),e===n)break;e=e.return}}function Ra(e,t,n,i){var r=e.child;for(r!==null&&(r.return=e);r!==null;){var o=r.dependencies;if(o!==null){var a=r.child;o=o.firstContext;e:for(;o!==null;){var s=o;o=r;for(var l=0;l<t.length;l++)if(s.context===t[l]){o.lanes|=n,s=o.alternate,s!==null&&(s.lanes|=n),Ia(o.return,n,e),i||(a=null);break e}o=s.next}}else if(r.tag===18){if(a=r.return,a===null)throw Error(y(341));a.lanes|=n,o=a.alternate,o!==null&&(o.lanes|=n),Ia(a,n,e),a=null}else a=r.child;if(a!==null)a.return=r;else for(a=r;a!==null;){if(a===e){a=null;break}if(r=a.sibling,r!==null){r.return=a.return,a=r;break}a=a.return}r=a}}function ai(e,t,n,i){e=null;for(var r=t,o=!1;r!==null;){if(!o){if((r.flags&524288)!==0)o=!0;else if((r.flags&262144)!==0)break}if(r.tag===10){var a=r.alternate;if(a===null)throw Error(y(387));if(a=a.memoizedProps,a!==null){var s=r.type;Xe(r.pendingProps.value,a.value)||(e!==null?e.push(s):e=[s])}}else if(r===te.current){if(a=r.alternate,a===null)throw Error(y(387));a.memoizedState.memoizedState!==r.memoizedState.memoizedState&&(e!==null?e.push(hr):e=[hr])}r=r.return}e!==null&&Ra(t,e,n,i),t.flags|=262144}function Fr(e){for(e=e.firstContext;e!==null;){if(!Xe(e.context._currentValue,e.memoizedValue))return!0;e=e.next}return!1}function On(e){Pn=e,Nt=null,e=e.dependencies,e!==null&&(e.firstContext=null)}function ke(e){return bc(Pn,e)}function _r(e,t){return Pn===null&&On(e),bc(e,t)}function bc(e,t){var n=t._currentValue;if(t={context:t,memoizedValue:n,next:null},Nt===null){if(e===null)throw Error(y(308));Nt=t,e.dependencies={lanes:0,firstContext:t},e.flags|=524288}else Nt=Nt.next=t;return n}var Om=typeof AbortController<"u"?AbortController:function(){var e=[],t=this.signal={aborted:!1,addEventListener:function(n,i){e.push(i)}};this.abort=function(){t.aborted=!0,e.forEach(function(n){return n()})}},xm=T.unstable_scheduleCallback,Nm=T.unstable_NormalPriority,Ce={$$typeof:Pe,Consumer:null,Provider:null,_currentValue:null,_currentValue2:null,_threadCount:0};function Da(){return{controller:new Om,data:new Map,refCount:0}}function Fi(e){e.refCount--,e.refCount===0&&xm(Nm,function(){e.controller.abort()})}var _i=null,Pa=0,si=0,li=null;function Mm(e,t){if(_i===null){var n=_i=[];Pa=0,si=Ns(),li={status:"pending",value:void 0,then:function(i){n.push(i)}}}return Pa++,t.then(Sc,Sc),t}function Sc(){if(--Pa===0&&_i!==null){li!==null&&(li.status="fulfilled");var e=_i;_i=null,si=0,li=null;for(var t=0;t<e.length;t++)(0,e[t])()}}function Um(e,t){var n=[],i={status:"pending",value:null,reason:null,then:function(r){n.push(r)}};return e.then(function(){i.status="fulfilled",i.value=t;for(var r=0;r<n.length;r++)(0,n[r])(t)},function(r){for(i.status="rejected",i.reason=r,r=0;r<n.length;r++)(0,n[r])(void 0)}),i}var Ac=f.S;f.S=function(e,t){od=$e(),typeof t=="object"&&t!==null&&typeof t.then=="function"&&Mm(e,t),Ac!==null&&Ac(e,t)};var xn=u(null);function Oa(){var e=xn.current;return e!==null?e:ce.pooledCache}function Vr(e,t){t===null?L(xn,xn.current):L(xn,t.pool)}function wc(){var e=Oa();return e===null?null:{parent:Ce._currentValue,pool:e}}var ci=Error(y(460)),xa=Error(y(474)),Qr=Error(y(542)),Kr={then:function(){}};function Lc(e){return e=e.status,e==="fulfilled"||e==="rejected"}function Tc(e,t,n){switch(n=e[n],n===void 0?e.push(t):n!==t&&(t.then(Dt,Dt),t=n),t.status){case"fulfilled":return t.value;case"rejected":throw e=t.reason,Wc(e),e;default:if(typeof t.status=="string")t.then(Dt,Dt);else{if(e=ce,e!==null&&100<e.shellSuspendCounter)throw Error(y(482));e=t,e.status="pending",e.then(function(i){if(t.status==="pending"){var r=t;r.status="fulfilled",r.value=i}},function(i){if(t.status==="pending"){var r=t;r.status="rejected",r.reason=i}})}switch(t.status){case"fulfilled":return t.value;case"rejected":throw e=t.reason,Wc(e),e}throw Mn=t,ci}}function Nn(e){try{var t=e._init;return t(e._payload)}catch(n){throw n!==null&&typeof n=="object"&&typeof n.then=="function"?(Mn=n,ci):n}}var Mn=null;function Ec(){if(Mn===null)throw Error(y(459));var e=Mn;return Mn=null,e}function Wc(e){if(e===ci||e===Qr)throw Error(y(483))}var ui=null,Vi=0;function $r(e){var t=Vi;return Vi+=1,ui===null&&(ui=[]),Tc(ui,e,t)}function Qi(e,t){t=t.props.ref,e.ref=t!==void 0?t:null}function Yr(e,t){throw t.$$typeof===$?Error(y(525)):(e=Object.prototype.toString.call(t),Error(y(31,e==="[object Object]"?"object with keys {"+Object.keys(t).join(", ")+"}":e)))}function kc(e){function t(d,c){if(e){var p=d.deletions;p===null?(d.deletions=[c],d.flags|=16):p.push(c)}}function n(d,c){if(!e)return null;for(;c!==null;)t(d,c),c=c.sibling;return null}function i(d){for(var c=new Map;d!==null;)d.key!==null?c.set(d.key,d):c.set(d.index,d),d=d.sibling;return c}function r(d,c){return d=Ot(d,c),d.index=0,d.sibling=null,d}function o(d,c,p){return d.index=p,e?(p=d.alternate,p!==null?(p=p.index,p<c?(d.flags|=67108866,c):p):(d.flags|=67108866,c)):(d.flags|=1048576,c)}function a(d){return e&&d.alternate===null&&(d.flags|=67108866),d}function s(d,c,p,C){return c===null||c.tag!==6?(c=Aa(p,d.mode,C),c.return=d,c):(c=r(c,p),c.return=d,c)}function l(d,c,p,C){var R=p.type;return R===Ne?v(d,c,p.props.children,C,p.key):c!==null&&(c.elementType===R||typeof R=="object"&&R!==null&&R.$$typeof===Be&&Nn(R)===c.type)?(c=r(c,p.props),Qi(c,p),c.return=d,c):(c=Hr(p.type,p.key,p.props,null,d.mode,C),Qi(c,p),c.return=d,c)}function m(d,c,p,C){return c===null||c.tag!==4||c.stateNode.containerInfo!==p.containerInfo||c.stateNode.implementation!==p.implementation?(c=wa(p,d.mode,C),c.return=d,c):(c=r(c,p.children||[]),c.return=d,c)}function v(d,c,p,C,R){return c===null||c.tag!==7?(c=Rn(p,d.mode,C,R),c.return=d,c):(c=r(c,p),c.return=d,c)}function S(d,c,p){if(typeof c=="string"&&c!==""||typeof c=="number"||typeof c=="bigint")return c=Aa(""+c,d.mode,p),c.return=d,c;if(typeof c=="object"&&c!==null){switch(c.$$typeof){case xe:return p=Hr(c.type,c.key,c.props,null,d.mode,p),Qi(p,c),p.return=d,p;case De:return c=wa(c,d.mode,p),c.return=d,c;case Be:return c=Nn(c),S(d,c,p)}if(vt(c)||ze(c))return c=Rn(c,d.mode,p,null),c.return=d,c;if(typeof c.then=="function")return S(d,$r(c),p);if(c.$$typeof===Pe)return S(d,_r(d,c),p);Yr(d,c)}return null}function g(d,c,p,C){var R=c!==null?c.key:null;if(typeof p=="string"&&p!==""||typeof p=="number"||typeof p=="bigint")return R!==null?null:s(d,c,""+p,C);if(typeof p=="object"&&p!==null){switch(p.$$typeof){case xe:return p.key===R?l(d,c,p,C):null;case De:return p.key===R?m(d,c,p,C):null;case Be:return p=Nn(p),g(d,c,p,C)}if(vt(p)||ze(p))return R!==null?null:v(d,c,p,C,null);if(typeof p.then=="function")return g(d,c,$r(p),C);if(p.$$typeof===Pe)return g(d,c,_r(d,p),C);Yr(d,p)}return null}function h(d,c,p,C,R){if(typeof C=="string"&&C!==""||typeof C=="number"||typeof C=="bigint")return d=d.get(p)||null,s(c,d,""+C,R);if(typeof C=="object"&&C!==null){switch(C.$$typeof){case xe:return d=d.get(C.key===null?p:C.key)||null,l(c,d,C,R);case De:return d=d.get(C.key===null?p:C.key)||null,m(c,d,C,R);case Be:return C=Nn(C),h(d,c,p,C,R)}if(vt(C)||ze(C))return d=d.get(p)||null,v(c,d,C,R,null);if(typeof C.then=="function")return h(d,c,p,$r(C),R);if(C.$$typeof===Pe)return h(d,c,p,_r(c,C),R);Yr(c,C)}return null}function E(d,c,p,C){for(var R=null,J=null,k=c,q=c=0,V=null;k!==null&&q<p.length;q++){k.index>q?(V=k,k=null):V=k.sibling;var X=g(d,k,p[q],C);if(X===null){k===null&&(k=V);break}e&&k&&X.alternate===null&&t(d,k),c=o(X,c,q),J===null?R=X:J.sibling=X,J=X,k=V}if(q===p.length)return n(d,k),K&&xt(d,q),R;if(k===null){for(;q<p.length;q++)k=S(d,p[q],C),k!==null&&(c=o(k,c,q),J===null?R=k:J.sibling=k,J=k);return K&&xt(d,q),R}for(k=i(k);q<p.length;q++)V=h(k,d,q,p[q],C),V!==null&&(e&&V.alternate!==null&&k.delete(V.key===null?q:V.key),c=o(V,c,q),J===null?R=V:J.sibling=V,J=V);return e&&k.forEach(function(Sn){return t(d,Sn)}),K&&xt(d,q),R}function P(d,c,p,C){if(p==null)throw Error(y(151));for(var R=null,J=null,k=c,q=c=0,V=null,X=p.next();k!==null&&!X.done;q++,X=p.next()){k.index>q?(V=k,k=null):V=k.sibling;var Sn=g(d,k,X.value,C);if(Sn===null){k===null&&(k=V);break}e&&k&&Sn.alternate===null&&t(d,k),c=o(Sn,c,q),J===null?R=Sn:J.sibling=Sn,J=Sn,k=V}if(X.done)return n(d,k),K&&xt(d,q),R;if(k===null){for(;!X.done;q++,X=p.next())X=S(d,X.value,C),X!==null&&(c=o(X,c,q),J===null?R=X:J.sibling=X,J=X);return K&&xt(d,q),R}for(k=i(k);!X.done;q++,X=p.next())X=h(k,d,q,X.value,C),X!==null&&(e&&X.alternate!==null&&k.delete(X.key===null?q:X.key),c=o(X,c,q),J===null?R=X:J.sibling=X,J=X);return e&&k.forEach(function(Kg){return t(d,Kg)}),K&&xt(d,q),R}function se(d,c,p,C){if(typeof p=="object"&&p!==null&&p.type===Ne&&p.key===null&&(p=p.props.children),typeof p=="object"&&p!==null){switch(p.$$typeof){case xe:e:{for(var R=p.key;c!==null;){if(c.key===R){if(R=p.type,R===Ne){if(c.tag===7){n(d,c.sibling),C=r(c,p.props.children),C.return=d,d=C;break e}}else if(c.elementType===R||typeof R=="object"&&R!==null&&R.$$typeof===Be&&Nn(R)===c.type){n(d,c.sibling),C=r(c,p.props),Qi(C,p),C.return=d,d=C;break e}n(d,c);break}else t(d,c);c=c.sibling}p.type===Ne?(C=Rn(p.props.children,d.mode,C,p.key),C.return=d,d=C):(C=Hr(p.type,p.key,p.props,null,d.mode,C),Qi(C,p),C.return=d,d=C)}return a(d);case De:e:{for(R=p.key;c!==null;){if(c.key===R)if(c.tag===4&&c.stateNode.containerInfo===p.containerInfo&&c.stateNode.implementation===p.implementation){n(d,c.sibling),C=r(c,p.children||[]),C.return=d,d=C;break e}else{n(d,c);break}else t(d,c);c=c.sibling}C=wa(p,d.mode,C),C.return=d,d=C}return a(d);case Be:return p=Nn(p),se(d,c,p,C)}if(vt(p))return E(d,c,p,C);if(ze(p)){if(R=ze(p),typeof R!="function")throw Error(y(150));return p=R.call(p),P(d,c,p,C)}if(typeof p.then=="function")return se(d,c,$r(p),C);if(p.$$typeof===Pe)return se(d,c,_r(d,p),C);Yr(d,p)}return typeof p=="string"&&p!==""||typeof p=="number"||typeof p=="bigint"?(p=""+p,c!==null&&c.tag===6?(n(d,c.sibling),C=r(c,p),C.return=d,d=C):(n(d,c),C=Aa(p,d.mode,C),C.return=d,d=C),a(d)):n(d,c)}return function(d,c,p,C){try{Vi=0;var R=se(d,c,p,C);return ui=null,R}catch(k){if(k===ci||k===Qr)throw k;var J=Ze(29,k,null,d.mode);return J.lanes=C,J.return=d,J}}}var Un=kc(!0),Ic=kc(!1),rn=!1;function Na(e){e.updateQueue={baseState:e.memoizedState,firstBaseUpdate:null,lastBaseUpdate:null,shared:{pending:null,lanes:0,hiddenCallbacks:null},callbacks:null}}function Ma(e,t){e=e.updateQueue,t.updateQueue===e&&(t.updateQueue={baseState:e.baseState,firstBaseUpdate:e.firstBaseUpdate,lastBaseUpdate:e.lastBaseUpdate,shared:e.shared,callbacks:null})}function on(e){return{lane:e,tag:0,payload:null,callback:null,next:null}}function an(e,t,n){var i=e.updateQueue;if(i===null)return null;if(i=i.shared,(ee&2)!==0){var r=i.pending;return r===null?t.next=t:(t.next=r.next,r.next=t),i.pending=t,t=Gr(e),pc(e,null,n),t}return zr(e,i,t,n),Gr(e)}function Ki(e,t,n){if(t=t.updateQueue,t!==null&&(t=t.shared,(n&4194048)!==0)){var i=t.lanes;i&=e.pendingLanes,n|=i,t.lanes=n,bl(e,n)}}function Ua(e,t){var n=e.updateQueue,i=e.alternate;if(i!==null&&(i=i.updateQueue,n===i)){var r=null,o=null;if(n=n.firstBaseUpdate,n!==null){do{var a={lane:n.lane,tag:n.tag,payload:n.payload,callback:null,next:null};o===null?r=o=a:o=o.next=a,n=n.next}while(n!==null);o===null?r=o=t:o=o.next=t}else r=o=t;n={baseState:i.baseState,firstBaseUpdate:r,lastBaseUpdate:o,shared:i.shared,callbacks:i.callbacks},e.updateQueue=n;return}e=n.lastBaseUpdate,e===null?n.firstBaseUpdate=t:e.next=t,n.lastBaseUpdate=t}var qa=!1;function $i(){if(qa){var e=li;if(e!==null)throw e}}function Yi(e,t,n,i){qa=!1;var r=e.updateQueue;rn=!1;var o=r.firstBaseUpdate,a=r.lastBaseUpdate,s=r.shared.pending;if(s!==null){r.shared.pending=null;var l=s,m=l.next;l.next=null,a===null?o=m:a.next=m,a=l;var v=e.alternate;v!==null&&(v=v.updateQueue,s=v.lastBaseUpdate,s!==a&&(s===null?v.firstBaseUpdate=m:s.next=m,v.lastBaseUpdate=l))}if(o!==null){var S=r.baseState;a=0,v=m=l=null,s=o;do{var g=s.lane&-536870913,h=g!==s.lane;if(h?(_&g)===g:(i&g)===g){g!==0&&g===si&&(qa=!0),v!==null&&(v=v.next={lane:0,tag:s.tag,payload:s.payload,callback:null,next:null});e:{var E=e,P=s;g=t;var se=n;switch(P.tag){case 1:if(E=P.payload,typeof E=="function"){S=E.call(se,S,g);break e}S=E;break e;case 3:E.flags=E.flags&-65537|128;case 0:if(E=P.payload,g=typeof E=="function"?E.call(se,S,g):E,g==null)break e;S=D({},S,g);break e;case 2:rn=!0}}g=s.callback,g!==null&&(e.flags|=64,h&&(e.flags|=8192),h=r.callbacks,h===null?r.callbacks=[g]:h.push(g))}else h={lane:g,tag:s.tag,payload:s.payload,callback:s.callback,next:null},v===null?(m=v=h,l=S):v=v.next=h,a|=g;if(s=s.next,s===null){if(s=r.shared.pending,s===null)break;h=s,s=h.next,h.next=null,r.lastBaseUpdate=h,r.shared.pending=null}}while(!0);v===null&&(l=S),r.baseState=l,r.firstBaseUpdate=m,r.lastBaseUpdate=v,o===null&&(r.shared.lanes=0),dn|=a,e.lanes=a,e.memoizedState=S}}function Rc(e,t){if(typeof e!="function")throw Error(y(191,e));e.call(t)}function Dc(e,t){var n=e.callbacks;if(n!==null)for(e.callbacks=null,e=0;e<n.length;e++)Rc(n[e],t)}var di=u(null),Jr=u(0);function Pc(e,t){e=_t,L(Jr,e),L(di,t),_t=e|t.baseLanes}function Ba(){L(Jr,_t),L(di,di.current)}function za(){_t=Jr.current,A(di),A(Jr)}var et=u(null),gt=null;function sn(e){var t=e.alternate;L(ve,ve.current&1),L(et,e),gt===null&&(t===null||di.current!==null||t.memoizedState!==null)&&(gt=e)}function Ga(e){L(ve,ve.current),L(et,e),gt===null&&(gt=e)}function Oc(e){e.tag===22?(L(ve,ve.current),L(et,e),gt===null&&(gt=e)):ln()}function ln(){L(ve,ve.current),L(et,et.current)}function tt(e){A(et),gt===e&&(gt=null),A(ve)}var ve=u(0);function Xr(e){for(var t=e;t!==null;){if(t.tag===13){var n=t.memoizedState;if(n!==null&&(n=n.dehydrated,n===null||Qs(n)||Ks(n)))return t}else if(t.tag===19&&(t.memoizedProps.revealOrder==="forwards"||t.memoizedProps.revealOrder==="backwards"||t.memoizedProps.revealOrder==="unstable_legacy-backwards"||t.memoizedProps.revealOrder==="together")){if((t.flags&128)!==0)return t}else if(t.child!==null){t.child.return=t,t=t.child;continue}if(t===e)break;for(;t.sibling===null;){if(t.return===null||t.return===e)return null;t=t.return}t.sibling.return=t.return,t=t.sibling}return null}var Ut=0,U=null,oe=null,be=null,Zr=!1,pi=!1,qn=!1,eo=0,Ji=0,mi=null,qm=0;function ge(){throw Error(y(321))}function Ha(e,t){if(t===null)return!1;for(var n=0;n<t.length&&n<e.length;n++)if(!Xe(e[n],t[n]))return!1;return!0}function ja(e,t,n,i,r,o){return Ut=o,U=t,t.memoizedState=null,t.updateQueue=null,t.lanes=0,f.H=e===null||e.memoizedState===null?hu:rs,qn=!1,o=n(i,r),qn=!1,pi&&(o=Nc(t,n,i,r)),xc(e),o}function xc(e){f.H=er;var t=oe!==null&&oe.next!==null;if(Ut=0,be=oe=U=null,Zr=!1,Ji=0,mi=null,t)throw Error(y(300));e===null||Se||(e=e.dependencies,e!==null&&Fr(e)&&(Se=!0))}function Nc(e,t,n,i){U=e;var r=0;do{if(pi&&(mi=null),Ji=0,pi=!1,25<=r)throw Error(y(301));if(r+=1,be=oe=null,e.updateQueue!=null){var o=e.updateQueue;o.lastEffect=null,o.events=null,o.stores=null,o.memoCache!=null&&(o.memoCache.index=0)}f.H=vu,o=t(n,i)}while(pi);return o}function Bm(){var e=f.H,t=e.useState()[0];return t=typeof t.then=="function"?Xi(t):t,e=e.useState()[0],(oe!==null?oe.memoizedState:null)!==e&&(U.flags|=1024),t}function Fa(){var e=eo!==0;return eo=0,e}function _a(e,t,n){t.updateQueue=e.updateQueue,t.flags&=-2053,e.lanes&=~n}function Va(e){if(Zr){for(e=e.memoizedState;e!==null;){var t=e.queue;t!==null&&(t.pending=null),e=e.next}Zr=!1}Ut=0,be=oe=U=null,pi=!1,Ji=eo=0,mi=null}function Ue(){var e={memoizedState:null,baseState:null,baseQueue:null,queue:null,next:null};return be===null?U.memoizedState=be=e:be=be.next=e,be}function fe(){if(oe===null){var e=U.alternate;e=e!==null?e.memoizedState:null}else e=oe.next;var t=be===null?U.memoizedState:be.next;if(t!==null)be=t,oe=e;else{if(e===null)throw U.alternate===null?Error(y(467)):Error(y(310));oe=e,e={memoizedState:oe.memoizedState,baseState:oe.baseState,baseQueue:oe.baseQueue,queue:oe.queue,next:null},be===null?U.memoizedState=be=e:be=be.next=e}return be}function to(){return{lastEffect:null,events:null,stores:null,memoCache:null}}function Xi(e){var t=Ji;return Ji+=1,mi===null&&(mi=[]),e=Tc(mi,e,t),t=U,(be===null?t.memoizedState:be.next)===null&&(t=t.alternate,f.H=t===null||t.memoizedState===null?hu:rs),e}function no(e){if(e!==null&&typeof e=="object"){if(typeof e.then=="function")return Xi(e);if(e.$$typeof===Pe)return ke(e)}throw Error(y(438,String(e)))}function Qa(e){var t=null,n=U.updateQueue;if(n!==null&&(t=n.memoCache),t==null){var i=U.alternate;i!==null&&(i=i.updateQueue,i!==null&&(i=i.memoCache,i!=null&&(t={data:i.data.map(function(r){return r.slice()}),index:0})))}if(t==null&&(t={data:[],index:0}),n===null&&(n=to(),U.updateQueue=n),n.memoCache=t,n=t.data[t.index],n===void 0)for(n=t.data[t.index]=Array(e),i=0;i<e;i++)n[i]=Hn;return t.index++,n}function qt(e,t){return typeof t=="function"?t(e):t}function io(e){var t=fe();return Ka(t,oe,e)}function Ka(e,t,n){var i=e.queue;if(i===null)throw Error(y(311));i.lastRenderedReducer=n;var r=e.baseQueue,o=i.pending;if(o!==null){if(r!==null){var a=r.next;r.next=o.next,o.next=a}t.baseQueue=r=o,i.pending=null}if(o=e.baseState,r===null)e.memoizedState=o;else{t=r.next;var s=a=null,l=null,m=t,v=!1;do{var S=m.lane&-536870913;if(S!==m.lane?(_&S)===S:(Ut&S)===S){var g=m.revertLane;if(g===0)l!==null&&(l=l.next={lane:0,revertLane:0,gesture:null,action:m.action,hasEagerState:m.hasEagerState,eagerState:m.eagerState,next:null}),S===si&&(v=!0);else if((Ut&g)===g){m=m.next,g===si&&(v=!0);continue}else S={lane:0,revertLane:m.revertLane,gesture:null,action:m.action,hasEagerState:m.hasEagerState,eagerState:m.eagerState,next:null},l===null?(s=l=S,a=o):l=l.next=S,U.lanes|=g,dn|=g;S=m.action,qn&&n(o,S),o=m.hasEagerState?m.eagerState:n(o,S)}else g={lane:S,revertLane:m.revertLane,gesture:m.gesture,action:m.action,hasEagerState:m.hasEagerState,eagerState:m.eagerState,next:null},l===null?(s=l=g,a=o):l=l.next=g,U.lanes|=S,dn|=S;m=m.next}while(m!==null&&m!==t);if(l===null?a=o:l.next=s,!Xe(o,e.memoizedState)&&(Se=!0,v&&(n=li,n!==null)))throw n;e.memoizedState=o,e.baseState=a,e.baseQueue=l,i.lastRenderedState=o}return r===null&&(i.lanes=0),[e.memoizedState,i.dispatch]}function $a(e){var t=fe(),n=t.queue;if(n===null)throw Error(y(311));n.lastRenderedReducer=e;var i=n.dispatch,r=n.pending,o=t.memoizedState;if(r!==null){n.pending=null;var a=r=r.next;do o=e(o,a.action),a=a.next;while(a!==r);Xe(o,t.memoizedState)||(Se=!0),t.memoizedState=o,t.baseQueue===null&&(t.baseState=o),n.lastRenderedState=o}return[o,i]}function Mc(e,t,n){var i=U,r=fe(),o=K;if(o){if(n===void 0)throw Error(y(407));n=n()}else n=t();var a=!Xe((oe||r).memoizedState,n);if(a&&(r.memoizedState=n,Se=!0),r=r.queue,Xa(Bc.bind(null,i,r,e),[e]),r.getSnapshot!==t||a||be!==null&&be.memoizedState.tag&1){if(i.flags|=2048,gi(9,{destroy:void 0},qc.bind(null,i,r,n,t),null),ce===null)throw Error(y(349));o||(Ut&127)!==0||Uc(i,t,n)}return n}function Uc(e,t,n){e.flags|=16384,e={getSnapshot:t,value:n},t=U.updateQueue,t===null?(t=to(),U.updateQueue=t,t.stores=[e]):(n=t.stores,n===null?t.stores=[e]:n.push(e))}function qc(e,t,n,i){t.value=n,t.getSnapshot=i,zc(t)&&Gc(e)}function Bc(e,t,n){return n(function(){zc(t)&&Gc(e)})}function zc(e){var t=e.getSnapshot;e=e.value;try{var n=t();return!Xe(e,n)}catch{return!0}}function Gc(e){var t=In(e,2);t!==null&&Qe(t,e,2)}function Ya(e){var t=Ue();if(typeof e=="function"){var n=e;if(e=n(),qn){Yt(!0);try{n()}finally{Yt(!1)}}}return t.memoizedState=t.baseState=e,t.queue={pending:null,lanes:0,dispatch:null,lastRenderedReducer:qt,lastRenderedState:e},t}function Hc(e,t,n,i){return e.baseState=n,Ka(e,oe,typeof i=="function"?i:qt)}function zm(e,t,n,i,r){if(ao(e))throw Error(y(485));if(e=t.action,e!==null){var o={payload:r,action:e,next:null,isTransition:!0,status:"pending",value:null,reason:null,listeners:[],then:function(a){o.listeners.push(a)}};f.T!==null?n(!0):o.isTransition=!1,i(o),n=t.pending,n===null?(o.next=t.pending=o,jc(t,o)):(o.next=n.next,t.pending=n.next=o)}}function jc(e,t){var n=t.action,i=t.payload,r=e.state;if(t.isTransition){var o=f.T,a={};f.T=a;try{var s=n(r,i),l=f.S;l!==null&&l(a,s),Fc(e,t,s)}catch(m){Ja(e,t,m)}finally{o!==null&&a.types!==null&&(o.types=a.types),f.T=o}}else try{o=n(r,i),Fc(e,t,o)}catch(m){Ja(e,t,m)}}function Fc(e,t,n){n!==null&&typeof n=="object"&&typeof n.then=="function"?n.then(function(i){_c(e,t,i)},function(i){return Ja(e,t,i)}):_c(e,t,n)}function _c(e,t,n){t.status="fulfilled",t.value=n,Vc(t),e.state=n,t=e.pending,t!==null&&(n=t.next,n===t?e.pending=null:(n=n.next,t.next=n,jc(e,n)))}function Ja(e,t,n){var i=e.pending;if(e.pending=null,i!==null){i=i.next;do t.status="rejected",t.reason=n,Vc(t),t=t.next;while(t!==i)}e.action=null}function Vc(e){e=e.listeners;for(var t=0;t<e.length;t++)(0,e[t])()}function Qc(e,t){return t}function Kc(e,t){if(K){var n=ce.formState;if(n!==null){e:{var i=U;if(K){if(de){t:{for(var r=de,o=mt;r.nodeType!==8;){if(!o){r=null;break t}if(r=yt(r.nextSibling),r===null){r=null;break t}}o=r.data,r=o==="F!"||o==="F"?r:null}if(r){de=yt(r.nextSibling),i=r.data==="F!";break e}}tn(i)}i=!1}i&&(t=n[0])}}return n=Ue(),n.memoizedState=n.baseState=t,i={pending:null,lanes:0,dispatch:null,lastRenderedReducer:Qc,lastRenderedState:t},n.queue=i,n=mu.bind(null,U,i),i.dispatch=n,i=Ya(!1),o=is.bind(null,U,!1,i.queue),i=Ue(),r={state:t,dispatch:null,action:e,pending:null},i.queue=r,n=zm.bind(null,U,r,o,n),r.dispatch=n,i.memoizedState=e,[t,n,!1]}function $c(e){var t=fe();return Yc(t,oe,e)}function Yc(e,t,n){if(t=Ka(e,t,Qc)[0],e=io(qt)[0],typeof t=="object"&&t!==null&&typeof t.then=="function")try{var i=Xi(t)}catch(a){throw a===ci?Qr:a}else i=t;t=fe();var r=t.queue,o=r.dispatch;return n!==t.memoizedState&&(U.flags|=2048,gi(9,{destroy:void 0},Gm.bind(null,r,n),null)),[i,o,e]}function Gm(e,t){e.action=t}function Jc(e){var t=fe(),n=oe;if(n!==null)return Yc(t,n,e);fe(),t=t.memoizedState,n=fe();var i=n.queue.dispatch;return n.memoizedState=e,[t,i,!1]}function gi(e,t,n,i){return e={tag:e,create:n,deps:i,inst:t,next:null},t=U.updateQueue,t===null&&(t=to(),U.updateQueue=t),n=t.lastEffect,n===null?t.lastEffect=e.next=e:(i=n.next,n.next=e,e.next=i,t.lastEffect=e),e}function Xc(){return fe().memoizedState}function ro(e,t,n,i){var r=Ue();U.flags|=e,r.memoizedState=gi(1|t,{destroy:void 0},n,i===void 0?null:i)}function oo(e,t,n,i){var r=fe();i=i===void 0?null:i;var o=r.memoizedState.inst;oe!==null&&i!==null&&Ha(i,oe.memoizedState.deps)?r.memoizedState=gi(t,o,n,i):(U.flags|=e,r.memoizedState=gi(1|t,o,n,i))}function Zc(e,t){ro(8390656,8,e,t)}function Xa(e,t){oo(2048,8,e,t)}function Hm(e){U.flags|=4;var t=U.updateQueue;if(t===null)t=to(),U.updateQueue=t,t.events=[e];else{var n=t.events;n===null?t.events=[e]:n.push(e)}}function eu(e){var t=fe().memoizedState;return Hm({ref:t,nextImpl:e}),function(){if((ee&2)!==0)throw Error(y(440));return t.impl.apply(void 0,arguments)}}function tu(e,t){return oo(4,2,e,t)}function nu(e,t){return oo(4,4,e,t)}function iu(e,t){if(typeof t=="function"){e=e();var n=t(e);return function(){typeof n=="function"?n():t(null)}}if(t!=null)return e=e(),t.current=e,function(){t.current=null}}function ru(e,t,n){n=n!=null?n.concat([e]):null,oo(4,4,iu.bind(null,t,e),n)}function Za(){}function ou(e,t){var n=fe();t=t===void 0?null:t;var i=n.memoizedState;return t!==null&&Ha(t,i[1])?i[0]:(n.memoizedState=[e,t],e)}function au(e,t){var n=fe();t=t===void 0?null:t;var i=n.memoizedState;if(t!==null&&Ha(t,i[1]))return i[0];if(i=e(),qn){Yt(!0);try{e()}finally{Yt(!1)}}return n.memoizedState=[i,t],i}function es(e,t,n){return n===void 0||(Ut&1073741824)!==0&&(_&261930)===0?e.memoizedState=t:(e.memoizedState=n,e=sd(),U.lanes|=e,dn|=e,n)}function su(e,t,n,i){return Xe(n,t)?n:di.current!==null?(e=es(e,n,i),Xe(e,t)||(Se=!0),e):(Ut&42)===0||(Ut&1073741824)!==0&&(_&261930)===0?(Se=!0,e.memoizedState=n):(e=sd(),U.lanes|=e,dn|=e,t)}function lu(e,t,n,i,r){var o=w.p;w.p=o!==0&&8>o?o:8;var a=f.T,s={};f.T=s,is(e,!1,t,n);try{var l=r(),m=f.S;if(m!==null&&m(s,l),l!==null&&typeof l=="object"&&typeof l.then=="function"){var v=Um(l,i);Zi(e,t,v,rt(e))}else Zi(e,t,i,rt(e))}catch(S){Zi(e,t,{then:function(){},status:"rejected",reason:S},rt())}finally{w.p=o,a!==null&&s.types!==null&&(a.types=s.types),f.T=a}}function jm(){}function ts(e,t,n,i){if(e.tag!==5)throw Error(y(476));var r=cu(e).queue;lu(e,r,t,O,n===null?jm:function(){return uu(e),n(i)})}function cu(e){var t=e.memoizedState;if(t!==null)return t;t={memoizedState:O,baseState:O,baseQueue:null,queue:{pending:null,lanes:0,dispatch:null,lastRenderedReducer:qt,lastRenderedState:O},next:null};var n={};return t.next={memoizedState:n,baseState:n,baseQueue:null,queue:{pending:null,lanes:0,dispatch:null,lastRenderedReducer:qt,lastRenderedState:n},next:null},e.memoizedState=t,e=e.alternate,e!==null&&(e.memoizedState=t),t}function uu(e){var t=cu(e);t.next===null&&(t=e.alternate.memoizedState),Zi(e,t.next.queue,{},rt())}function ns(){return ke(hr)}function du(){return fe().memoizedState}function pu(){return fe().memoizedState}function Fm(e){for(var t=e.return;t!==null;){switch(t.tag){case 24:case 3:var n=rt();e=on(n);var i=an(t,e,n);i!==null&&(Qe(i,t,n),Ki(i,t,n)),t={cache:Da()},e.payload=t;return}t=t.return}}function _m(e,t,n){var i=rt();n={lane:i,revertLane:0,gesture:null,action:n,hasEagerState:!1,eagerState:null,next:null},ao(e)?gu(t,n):(n=ba(e,t,n,i),n!==null&&(Qe(n,e,i),yu(n,t,i)))}function mu(e,t,n){var i=rt();Zi(e,t,n,i)}function Zi(e,t,n,i){var r={lane:i,revertLane:0,gesture:null,action:n,hasEagerState:!1,eagerState:null,next:null};if(ao(e))gu(t,r);else{var o=e.alternate;if(e.lanes===0&&(o===null||o.lanes===0)&&(o=t.lastRenderedReducer,o!==null))try{var a=t.lastRenderedState,s=o(a,n);if(r.hasEagerState=!0,r.eagerState=s,Xe(s,a))return zr(e,t,r,0),ce===null&&Br(),!1}catch{}if(n=ba(e,t,r,i),n!==null)return Qe(n,e,i),yu(n,t,i),!0}return!1}function is(e,t,n,i){if(i={lane:2,revertLane:Ns(),gesture:null,action:i,hasEagerState:!1,eagerState:null,next:null},ao(e)){if(t)throw Error(y(479))}else t=ba(e,n,i,2),t!==null&&Qe(t,e,2)}function ao(e){var t=e.alternate;return e===U||t!==null&&t===U}function gu(e,t){pi=Zr=!0;var n=e.pending;n===null?t.next=t:(t.next=n.next,n.next=t),e.pending=t}function yu(e,t,n){if((n&4194048)!==0){var i=t.lanes;i&=e.pendingLanes,n|=i,t.lanes=n,bl(e,n)}}var er={readContext:ke,use:no,useCallback:ge,useContext:ge,useEffect:ge,useImperativeHandle:ge,useLayoutEffect:ge,useInsertionEffect:ge,useMemo:ge,useReducer:ge,useRef:ge,useState:ge,useDebugValue:ge,useDeferredValue:ge,useTransition:ge,useSyncExternalStore:ge,useId:ge,useHostTransitionStatus:ge,useFormState:ge,useActionState:ge,useOptimistic:ge,useMemoCache:ge,useCacheRefresh:ge};er.useEffectEvent=ge;var hu={readContext:ke,use:no,useCallback:function(e,t){return Ue().memoizedState=[e,t===void 0?null:t],e},useContext:ke,useEffect:Zc,useImperativeHandle:function(e,t,n){n=n!=null?n.concat([e]):null,ro(4194308,4,iu.bind(null,t,e),n)},useLayoutEffect:function(e,t){return ro(4194308,4,e,t)},useInsertionEffect:function(e,t){ro(4,2,e,t)},useMemo:function(e,t){var n=Ue();t=t===void 0?null:t;var i=e();if(qn){Yt(!0);try{e()}finally{Yt(!1)}}return n.memoizedState=[i,t],i},useReducer:function(e,t,n){var i=Ue();if(n!==void 0){var r=n(t);if(qn){Yt(!0);try{n(t)}finally{Yt(!1)}}}else r=t;return i.memoizedState=i.baseState=r,e={pending:null,lanes:0,dispatch:null,lastRenderedReducer:e,lastRenderedState:r},i.queue=e,e=e.dispatch=_m.bind(null,U,e),[i.memoizedState,e]},useRef:function(e){var t=Ue();return e={current:e},t.memoizedState=e},useState:function(e){e=Ya(e);var t=e.queue,n=mu.bind(null,U,t);return t.dispatch=n,[e.memoizedState,n]},useDebugValue:Za,useDeferredValue:function(e,t){var n=Ue();return es(n,e,t)},useTransition:function(){var e=Ya(!1);return e=lu.bind(null,U,e.queue,!0,!1),Ue().memoizedState=e,[!1,e]},useSyncExternalStore:function(e,t,n){var i=U,r=Ue();if(K){if(n===void 0)throw Error(y(407));n=n()}else{if(n=t(),ce===null)throw Error(y(349));(_&127)!==0||Uc(i,t,n)}r.memoizedState=n;var o={value:n,getSnapshot:t};return r.queue=o,Zc(Bc.bind(null,i,o,e),[e]),i.flags|=2048,gi(9,{destroy:void 0},qc.bind(null,i,o,n,t),null),n},useId:function(){var e=Ue(),t=ce.identifierPrefix;if(K){var n=Tt,i=Lt;n=(i&~(1<<32-Je(i)-1)).toString(32)+n,t="_"+t+"R_"+n,n=eo++,0<n&&(t+="H"+n.toString(32)),t+="_"}else n=qm++,t="_"+t+"r_"+n.toString(32)+"_";return e.memoizedState=t},useHostTransitionStatus:ns,useFormState:Kc,useActionState:Kc,useOptimistic:function(e){var t=Ue();t.memoizedState=t.baseState=e;var n={pending:null,lanes:0,dispatch:null,lastRenderedReducer:null,lastRenderedState:null};return t.queue=n,t=is.bind(null,U,!0,n),n.dispatch=t,[e,t]},useMemoCache:Qa,useCacheRefresh:function(){return Ue().memoizedState=Fm.bind(null,U)},useEffectEvent:function(e){var t=Ue(),n={impl:e};return t.memoizedState=n,function(){if((ee&2)!==0)throw Error(y(440));return n.impl.apply(void 0,arguments)}}},rs={readContext:ke,use:no,useCallback:ou,useContext:ke,useEffect:Xa,useImperativeHandle:ru,useInsertionEffect:tu,useLayoutEffect:nu,useMemo:au,useReducer:io,useRef:Xc,useState:function(){return io(qt)},useDebugValue:Za,useDeferredValue:function(e,t){var n=fe();return su(n,oe.memoizedState,e,t)},useTransition:function(){var e=io(qt)[0],t=fe().memoizedState;return[typeof e=="boolean"?e:Xi(e),t]},useSyncExternalStore:Mc,useId:du,useHostTransitionStatus:ns,useFormState:$c,useActionState:$c,useOptimistic:function(e,t){var n=fe();return Hc(n,oe,e,t)},useMemoCache:Qa,useCacheRefresh:pu};rs.useEffectEvent=eu;var vu={readContext:ke,use:no,useCallback:ou,useContext:ke,useEffect:Xa,useImperativeHandle:ru,useInsertionEffect:tu,useLayoutEffect:nu,useMemo:au,useReducer:$a,useRef:Xc,useState:function(){return $a(qt)},useDebugValue:Za,useDeferredValue:function(e,t){var n=fe();return oe===null?es(n,e,t):su(n,oe.memoizedState,e,t)},useTransition:function(){var e=$a(qt)[0],t=fe().memoizedState;return[typeof e=="boolean"?e:Xi(e),t]},useSyncExternalStore:Mc,useId:du,useHostTransitionStatus:ns,useFormState:Jc,useActionState:Jc,useOptimistic:function(e,t){var n=fe();return oe!==null?Hc(n,oe,e,t):(n.baseState=e,[e,n.queue.dispatch])},useMemoCache:Qa,useCacheRefresh:pu};vu.useEffectEvent=eu;function os(e,t,n,i){t=e.memoizedState,n=n(i,t),n=n==null?t:D({},t,n),e.memoizedState=n,e.lanes===0&&(e.updateQueue.baseState=n)}var as={enqueueSetState:function(e,t,n){e=e._reactInternals;var i=rt(),r=on(i);r.payload=t,n!=null&&(r.callback=n),t=an(e,r,i),t!==null&&(Qe(t,e,i),Ki(t,e,i))},enqueueReplaceState:function(e,t,n){e=e._reactInternals;var i=rt(),r=on(i);r.tag=1,r.payload=t,n!=null&&(r.callback=n),t=an(e,r,i),t!==null&&(Qe(t,e,i),Ki(t,e,i))},enqueueForceUpdate:function(e,t){e=e._reactInternals;var n=rt(),i=on(n);i.tag=2,t!=null&&(i.callback=t),t=an(e,i,n),t!==null&&(Qe(t,e,n),Ki(t,e,n))}};function fu(e,t,n,i,r,o,a){return e=e.stateNode,typeof e.shouldComponentUpdate=="function"?e.shouldComponentUpdate(i,o,a):t.prototype&&t.prototype.isPureReactComponent?!zi(n,i)||!zi(r,o):!0}function Cu(e,t,n,i){e=t.state,typeof t.componentWillReceiveProps=="function"&&t.componentWillReceiveProps(n,i),typeof t.UNSAFE_componentWillReceiveProps=="function"&&t.UNSAFE_componentWillReceiveProps(n,i),t.state!==e&&as.enqueueReplaceState(t,t.state,null)}function Bn(e,t){var n=t;if("ref"in t){n={};for(var i in t)i!=="ref"&&(n[i]=t[i])}if(e=e.defaultProps){n===t&&(n=D({},n));for(var r in e)n[r]===void 0&&(n[r]=e[r])}return n}function bu(e){qr(e)}function Su(e){console.error(e)}function Au(e){qr(e)}function so(e,t){try{var n=e.onUncaughtError;n(t.value,{componentStack:t.stack})}catch(i){setTimeout(function(){throw i})}}function wu(e,t,n){try{var i=e.onCaughtError;i(n.value,{componentStack:n.stack,errorBoundary:t.tag===1?t.stateNode:null})}catch(r){setTimeout(function(){throw r})}}function ss(e,t,n){return n=on(n),n.tag=3,n.payload={element:null},n.callback=function(){so(e,t)},n}function Lu(e){return e=on(e),e.tag=3,e}function Tu(e,t,n,i){var r=n.type.getDerivedStateFromError;if(typeof r=="function"){var o=i.value;e.payload=function(){return r(o)},e.callback=function(){wu(t,n,i)}}var a=n.stateNode;a!==null&&typeof a.componentDidCatch=="function"&&(e.callback=function(){wu(t,n,i),typeof r!="function"&&(pn===null?pn=new Set([this]):pn.add(this));var s=i.stack;this.componentDidCatch(i.value,{componentStack:s!==null?s:""})})}function Vm(e,t,n,i,r){if(n.flags|=32768,i!==null&&typeof i=="object"&&typeof i.then=="function"){if(t=n.alternate,t!==null&&ai(t,n,r,!0),n=et.current,n!==null){switch(n.tag){case 31:case 13:return gt===null?bo():n.alternate===null&&ye===0&&(ye=3),n.flags&=-257,n.flags|=65536,n.lanes=r,i===Kr?n.flags|=16384:(t=n.updateQueue,t===null?n.updateQueue=new Set([i]):t.add(i),Ps(e,i,r)),!1;case 22:return n.flags|=65536,i===Kr?n.flags|=16384:(t=n.updateQueue,t===null?(t={transitions:null,markerInstances:null,retryQueue:new Set([i])},n.updateQueue=t):(n=t.retryQueue,n===null?t.retryQueue=new Set([i]):n.add(i)),Ps(e,i,r)),!1}throw Error(y(435,n.tag))}return Ps(e,i,r),bo(),!1}if(K)return t=et.current,t!==null?((t.flags&65536)===0&&(t.flags|=256),t.flags|=65536,t.lanes=r,i!==Ea&&(e=Error(y(422),{cause:i}),ji(ut(e,n)))):(i!==Ea&&(t=Error(y(423),{cause:i}),ji(ut(t,n))),e=e.current.alternate,e.flags|=65536,r&=-r,e.lanes|=r,i=ut(i,n),r=ss(e.stateNode,i,r),Ua(e,r),ye!==4&&(ye=2)),!1;var o=Error(y(520),{cause:i});if(o=ut(o,n),lr===null?lr=[o]:lr.push(o),ye!==4&&(ye=2),t===null)return!0;i=ut(i,n),n=t;do{switch(n.tag){case 3:return n.flags|=65536,e=r&-r,n.lanes|=e,e=ss(n.stateNode,i,e),Ua(n,e),!1;case 1:if(t=n.type,o=n.stateNode,(n.flags&128)===0&&(typeof t.getDerivedStateFromError=="function"||o!==null&&typeof o.componentDidCatch=="function"&&(pn===null||!pn.has(o))))return n.flags|=65536,r&=-r,n.lanes|=r,r=Lu(r),Tu(r,e,n,i),Ua(n,r),!1}n=n.return}while(n!==null);return!1}var ls=Error(y(461)),Se=!1;function Ie(e,t,n,i){t.child=e===null?Ic(t,null,n,i):Un(t,e.child,n,i)}function Eu(e,t,n,i,r){n=n.render;var o=t.ref;if("ref"in i){var a={};for(var s in i)s!=="ref"&&(a[s]=i[s])}else a=i;return On(t),i=ja(e,t,n,a,o,r),s=Fa(),e!==null&&!Se?(_a(e,t,r),Bt(e,t,r)):(K&&s&&La(t),t.flags|=1,Ie(e,t,i,r),t.child)}function Wu(e,t,n,i,r){if(e===null){var o=n.type;return typeof o=="function"&&!Sa(o)&&o.defaultProps===void 0&&n.compare===null?(t.tag=15,t.type=o,ku(e,t,o,i,r)):(e=Hr(n.type,null,i,t,t.mode,r),e.ref=t.ref,e.return=t,t.child=e)}if(o=e.child,!hs(e,r)){var a=o.memoizedProps;if(n=n.compare,n=n!==null?n:zi,n(a,i)&&e.ref===t.ref)return Bt(e,t,r)}return t.flags|=1,e=Ot(o,i),e.ref=t.ref,e.return=t,t.child=e}function ku(e,t,n,i,r){if(e!==null){var o=e.memoizedProps;if(zi(o,i)&&e.ref===t.ref)if(Se=!1,t.pendingProps=i=o,hs(e,r))(e.flags&131072)!==0&&(Se=!0);else return t.lanes=e.lanes,Bt(e,t,r)}return cs(e,t,n,i,r)}function Iu(e,t,n,i){var r=i.children,o=e!==null?e.memoizedState:null;if(e===null&&t.stateNode===null&&(t.stateNode={_visibility:1,_pendingMarkers:null,_retryCache:null,_transitions:null}),i.mode==="hidden"){if((t.flags&128)!==0){if(o=o!==null?o.baseLanes|n:n,e!==null){for(i=t.child=e.child,r=0;i!==null;)r=r|i.lanes|i.childLanes,i=i.sibling;i=r&~o}else i=0,t.child=null;return Ru(e,t,o,n,i)}if((n&536870912)!==0)t.memoizedState={baseLanes:0,cachePool:null},e!==null&&Vr(t,o!==null?o.cachePool:null),o!==null?Pc(t,o):Ba(),Oc(t);else return i=t.lanes=536870912,Ru(e,t,o!==null?o.baseLanes|n:n,n,i)}else o!==null?(Vr(t,o.cachePool),Pc(t,o),ln(),t.memoizedState=null):(e!==null&&Vr(t,null),Ba(),ln());return Ie(e,t,r,n),t.child}function tr(e,t){return e!==null&&e.tag===22||t.stateNode!==null||(t.stateNode={_visibility:1,_pendingMarkers:null,_retryCache:null,_transitions:null}),t.sibling}function Ru(e,t,n,i,r){var o=Oa();return o=o===null?null:{parent:Ce._currentValue,pool:o},t.memoizedState={baseLanes:n,cachePool:o},e!==null&&Vr(t,null),Ba(),Oc(t),e!==null&&ai(e,t,i,!0),t.childLanes=r,null}function lo(e,t){return t=uo({mode:t.mode,children:t.children},e.mode),t.ref=e.ref,e.child=t,t.return=e,t}function Du(e,t,n){return Un(t,e.child,null,n),e=lo(t,t.pendingProps),e.flags|=2,tt(t),t.memoizedState=null,e}function Qm(e,t,n){var i=t.pendingProps,r=(t.flags&128)!==0;if(t.flags&=-129,e===null){if(K){if(i.mode==="hidden")return e=lo(t,i),t.lanes=536870912,tr(null,e);if(Ga(t),(e=de)?(e=jd(e,mt),e=e!==null&&e.data==="&"?e:null,e!==null&&(t.memoizedState={dehydrated:e,treeContext:Zt!==null?{id:Lt,overflow:Tt}:null,retryLane:536870912,hydrationErrors:null},n=gc(e),n.return=t,t.child=n,We=t,de=null)):e=null,e===null)throw tn(t);return t.lanes=536870912,null}return lo(t,i)}var o=e.memoizedState;if(o!==null){var a=o.dehydrated;if(Ga(t),r)if(t.flags&256)t.flags&=-257,t=Du(e,t,n);else if(t.memoizedState!==null)t.child=e.child,t.flags|=128,t=null;else throw Error(y(558));else if(Se||ai(e,t,n,!1),r=(n&e.childLanes)!==0,Se||r){if(i=ce,i!==null&&(a=Sl(i,n),a!==0&&a!==o.retryLane))throw o.retryLane=a,In(e,a),Qe(i,e,a),ls;bo(),t=Du(e,t,n)}else e=o.treeContext,de=yt(a.nextSibling),We=t,K=!0,en=null,mt=!1,e!==null&&vc(t,e),t=lo(t,i),t.flags|=4096;return t}return e=Ot(e.child,{mode:i.mode,children:i.children}),e.ref=t.ref,t.child=e,e.return=t,e}function co(e,t){var n=t.ref;if(n===null)e!==null&&e.ref!==null&&(t.flags|=4194816);else{if(typeof n!="function"&&typeof n!="object")throw Error(y(284));(e===null||e.ref!==n)&&(t.flags|=4194816)}}function cs(e,t,n,i,r){return On(t),n=ja(e,t,n,i,void 0,r),i=Fa(),e!==null&&!Se?(_a(e,t,r),Bt(e,t,r)):(K&&i&&La(t),t.flags|=1,Ie(e,t,n,r),t.child)}function Pu(e,t,n,i,r,o){return On(t),t.updateQueue=null,n=Nc(t,i,n,r),xc(e),i=Fa(),e!==null&&!Se?(_a(e,t,o),Bt(e,t,o)):(K&&i&&La(t),t.flags|=1,Ie(e,t,n,o),t.child)}function Ou(e,t,n,i,r){if(On(t),t.stateNode===null){var o=ni,a=n.contextType;typeof a=="object"&&a!==null&&(o=ke(a)),o=new n(i,o),t.memoizedState=o.state!==null&&o.state!==void 0?o.state:null,o.updater=as,t.stateNode=o,o._reactInternals=t,o=t.stateNode,o.props=i,o.state=t.memoizedState,o.refs={},Na(t),a=n.contextType,o.context=typeof a=="object"&&a!==null?ke(a):ni,o.state=t.memoizedState,a=n.getDerivedStateFromProps,typeof a=="function"&&(os(t,n,a,i),o.state=t.memoizedState),typeof n.getDerivedStateFromProps=="function"||typeof o.getSnapshotBeforeUpdate=="function"||typeof o.UNSAFE_componentWillMount!="function"&&typeof o.componentWillMount!="function"||(a=o.state,typeof o.componentWillMount=="function"&&o.componentWillMount(),typeof o.UNSAFE_componentWillMount=="function"&&o.UNSAFE_componentWillMount(),a!==o.state&&as.enqueueReplaceState(o,o.state,null),Yi(t,i,o,r),$i(),o.state=t.memoizedState),typeof o.componentDidMount=="function"&&(t.flags|=4194308),i=!0}else if(e===null){o=t.stateNode;var s=t.memoizedProps,l=Bn(n,s);o.props=l;var m=o.context,v=n.contextType;a=ni,typeof v=="object"&&v!==null&&(a=ke(v));var S=n.getDerivedStateFromProps;v=typeof S=="function"||typeof o.getSnapshotBeforeUpdate=="function",s=t.pendingProps!==s,v||typeof o.UNSAFE_componentWillReceiveProps!="function"&&typeof o.componentWillReceiveProps!="function"||(s||m!==a)&&Cu(t,o,i,a),rn=!1;var g=t.memoizedState;o.state=g,Yi(t,i,o,r),$i(),m=t.memoizedState,s||g!==m||rn?(typeof S=="function"&&(os(t,n,S,i),m=t.memoizedState),(l=rn||fu(t,n,l,i,g,m,a))?(v||typeof o.UNSAFE_componentWillMount!="function"&&typeof o.componentWillMount!="function"||(typeof o.componentWillMount=="function"&&o.componentWillMount(),typeof o.UNSAFE_componentWillMount=="function"&&o.UNSAFE_componentWillMount()),typeof o.componentDidMount=="function"&&(t.flags|=4194308)):(typeof o.componentDidMount=="function"&&(t.flags|=4194308),t.memoizedProps=i,t.memoizedState=m),o.props=i,o.state=m,o.context=a,i=l):(typeof o.componentDidMount=="function"&&(t.flags|=4194308),i=!1)}else{o=t.stateNode,Ma(e,t),a=t.memoizedProps,v=Bn(n,a),o.props=v,S=t.pendingProps,g=o.context,m=n.contextType,l=ni,typeof m=="object"&&m!==null&&(l=ke(m)),s=n.getDerivedStateFromProps,(m=typeof s=="function"||typeof o.getSnapshotBeforeUpdate=="function")||typeof o.UNSAFE_componentWillReceiveProps!="function"&&typeof o.componentWillReceiveProps!="function"||(a!==S||g!==l)&&Cu(t,o,i,l),rn=!1,g=t.memoizedState,o.state=g,Yi(t,i,o,r),$i();var h=t.memoizedState;a!==S||g!==h||rn||e!==null&&e.dependencies!==null&&Fr(e.dependencies)?(typeof s=="function"&&(os(t,n,s,i),h=t.memoizedState),(v=rn||fu(t,n,v,i,g,h,l)||e!==null&&e.dependencies!==null&&Fr(e.dependencies))?(m||typeof o.UNSAFE_componentWillUpdate!="function"&&typeof o.componentWillUpdate!="function"||(typeof o.componentWillUpdate=="function"&&o.componentWillUpdate(i,h,l),typeof o.UNSAFE_componentWillUpdate=="function"&&o.UNSAFE_componentWillUpdate(i,h,l)),typeof o.componentDidUpdate=="function"&&(t.flags|=4),typeof o.getSnapshotBeforeUpdate=="function"&&(t.flags|=1024)):(typeof o.componentDidUpdate!="function"||a===e.memoizedProps&&g===e.memoizedState||(t.flags|=4),typeof o.getSnapshotBeforeUpdate!="function"||a===e.memoizedProps&&g===e.memoizedState||(t.flags|=1024),t.memoizedProps=i,t.memoizedState=h),o.props=i,o.state=h,o.context=l,i=v):(typeof o.componentDidUpdate!="function"||a===e.memoizedProps&&g===e.memoizedState||(t.flags|=4),typeof o.getSnapshotBeforeUpdate!="function"||a===e.memoizedProps&&g===e.memoizedState||(t.flags|=1024),i=!1)}return o=i,co(e,t),i=(t.flags&128)!==0,o||i?(o=t.stateNode,n=i&&typeof n.getDerivedStateFromError!="function"?null:o.render(),t.flags|=1,e!==null&&i?(t.child=Un(t,e.child,null,r),t.child=Un(t,null,n,r)):Ie(e,t,n,r),t.memoizedState=o.state,e=t.child):e=Bt(e,t,r),e}function xu(e,t,n,i){return Dn(),t.flags|=256,Ie(e,t,n,i),t.child}var us={dehydrated:null,treeContext:null,retryLane:0,hydrationErrors:null};function ds(e){return{baseLanes:e,cachePool:wc()}}function ps(e,t,n){return e=e!==null?e.childLanes&~n:0,t&&(e|=it),e}function Nu(e,t,n){var i=t.pendingProps,r=!1,o=(t.flags&128)!==0,a;if((a=o)||(a=e!==null&&e.memoizedState===null?!1:(ve.current&2)!==0),a&&(r=!0,t.flags&=-129),a=(t.flags&32)!==0,t.flags&=-33,e===null){if(K){if(r?sn(t):ln(),(e=de)?(e=jd(e,mt),e=e!==null&&e.data!=="&"?e:null,e!==null&&(t.memoizedState={dehydrated:e,treeContext:Zt!==null?{id:Lt,overflow:Tt}:null,retryLane:536870912,hydrationErrors:null},n=gc(e),n.return=t,t.child=n,We=t,de=null)):e=null,e===null)throw tn(t);return Ks(e)?t.lanes=32:t.lanes=536870912,null}var s=i.children;return i=i.fallback,r?(ln(),r=t.mode,s=uo({mode:"hidden",children:s},r),i=Rn(i,r,n,null),s.return=t,i.return=t,s.sibling=i,t.child=s,i=t.child,i.memoizedState=ds(n),i.childLanes=ps(e,a,n),t.memoizedState=us,tr(null,i)):(sn(t),ms(t,s))}var l=e.memoizedState;if(l!==null&&(s=l.dehydrated,s!==null)){if(o)t.flags&256?(sn(t),t.flags&=-257,t=gs(e,t,n)):t.memoizedState!==null?(ln(),t.child=e.child,t.flags|=128,t=null):(ln(),s=i.fallback,r=t.mode,i=uo({mode:"visible",children:i.children},r),s=Rn(s,r,n,null),s.flags|=2,i.return=t,s.return=t,i.sibling=s,t.child=i,Un(t,e.child,null,n),i=t.child,i.memoizedState=ds(n),i.childLanes=ps(e,a,n),t.memoizedState=us,t=tr(null,i));else if(sn(t),Ks(s)){if(a=s.nextSibling&&s.nextSibling.dataset,a)var m=a.dgst;a=m,i=Error(y(419)),i.stack="",i.digest=a,ji({value:i,source:null,stack:null}),t=gs(e,t,n)}else if(Se||ai(e,t,n,!1),a=(n&e.childLanes)!==0,Se||a){if(a=ce,a!==null&&(i=Sl(a,n),i!==0&&i!==l.retryLane))throw l.retryLane=i,In(e,i),Qe(a,e,i),ls;Qs(s)||bo(),t=gs(e,t,n)}else Qs(s)?(t.flags|=192,t.child=e.child,t=null):(e=l.treeContext,de=yt(s.nextSibling),We=t,K=!0,en=null,mt=!1,e!==null&&vc(t,e),t=ms(t,i.children),t.flags|=4096);return t}return r?(ln(),s=i.fallback,r=t.mode,l=e.child,m=l.sibling,i=Ot(l,{mode:"hidden",children:i.children}),i.subtreeFlags=l.subtreeFlags&65011712,m!==null?s=Ot(m,s):(s=Rn(s,r,n,null),s.flags|=2),s.return=t,i.return=t,i.sibling=s,t.child=i,tr(null,i),i=t.child,s=e.child.memoizedState,s===null?s=ds(n):(r=s.cachePool,r!==null?(l=Ce._currentValue,r=r.parent!==l?{parent:l,pool:l}:r):r=wc(),s={baseLanes:s.baseLanes|n,cachePool:r}),i.memoizedState=s,i.childLanes=ps(e,a,n),t.memoizedState=us,tr(e.child,i)):(sn(t),n=e.child,e=n.sibling,n=Ot(n,{mode:"visible",children:i.children}),n.return=t,n.sibling=null,e!==null&&(a=t.deletions,a===null?(t.deletions=[e],t.flags|=16):a.push(e)),t.child=n,t.memoizedState=null,n)}function ms(e,t){return t=uo({mode:"visible",children:t},e.mode),t.return=e,e.child=t}function uo(e,t){return e=Ze(22,e,null,t),e.lanes=0,e}function gs(e,t,n){return Un(t,e.child,null,n),e=ms(t,t.pendingProps.children),e.flags|=2,t.memoizedState=null,e}function Mu(e,t,n){e.lanes|=t;var i=e.alternate;i!==null&&(i.lanes|=t),Ia(e.return,t,n)}function ys(e,t,n,i,r,o){var a=e.memoizedState;a===null?e.memoizedState={isBackwards:t,rendering:null,renderingStartTime:0,last:i,tail:n,tailMode:r,treeForkCount:o}:(a.isBackwards=t,a.rendering=null,a.renderingStartTime=0,a.last=i,a.tail=n,a.tailMode=r,a.treeForkCount=o)}function Uu(e,t,n){var i=t.pendingProps,r=i.revealOrder,o=i.tail;i=i.children;var a=ve.current,s=(a&2)!==0;if(s?(a=a&1|2,t.flags|=128):a&=1,L(ve,a),Ie(e,t,i,n),i=K?Hi:0,!s&&e!==null&&(e.flags&128)!==0)e:for(e=t.child;e!==null;){if(e.tag===13)e.memoizedState!==null&&Mu(e,n,t);else if(e.tag===19)Mu(e,n,t);else if(e.child!==null){e.child.return=e,e=e.child;continue}if(e===t)break e;for(;e.sibling===null;){if(e.return===null||e.return===t)break e;e=e.return}e.sibling.return=e.return,e=e.sibling}switch(r){case"forwards":for(n=t.child,r=null;n!==null;)e=n.alternate,e!==null&&Xr(e)===null&&(r=n),n=n.sibling;n=r,n===null?(r=t.child,t.child=null):(r=n.sibling,n.sibling=null),ys(t,!1,r,n,o,i);break;case"backwards":case"unstable_legacy-backwards":for(n=null,r=t.child,t.child=null;r!==null;){if(e=r.alternate,e!==null&&Xr(e)===null){t.child=r;break}e=r.sibling,r.sibling=n,n=r,r=e}ys(t,!0,n,null,o,i);break;case"together":ys(t,!1,null,null,void 0,i);break;default:t.memoizedState=null}return t.child}function Bt(e,t,n){if(e!==null&&(t.dependencies=e.dependencies),dn|=t.lanes,(n&t.childLanes)===0)if(e!==null){if(ai(e,t,n,!1),(n&t.childLanes)===0)return null}else return null;if(e!==null&&t.child!==e.child)throw Error(y(153));if(t.child!==null){for(e=t.child,n=Ot(e,e.pendingProps),t.child=n,n.return=t;e.sibling!==null;)e=e.sibling,n=n.sibling=Ot(e,e.pendingProps),n.return=t;n.sibling=null}return t.child}function hs(e,t){return(e.lanes&t)!==0?!0:(e=e.dependencies,!!(e!==null&&Fr(e)))}function Km(e,t,n){switch(t.tag){case 3:Me(t,t.stateNode.containerInfo),nn(t,Ce,e.memoizedState.cache),Dn();break;case 27:case 5:Wi(t);break;case 4:Me(t,t.stateNode.containerInfo);break;case 10:nn(t,t.type,t.memoizedProps.value);break;case 31:if(t.memoizedState!==null)return t.flags|=128,Ga(t),null;break;case 13:var i=t.memoizedState;if(i!==null)return i.dehydrated!==null?(sn(t),t.flags|=128,null):(n&t.child.childLanes)!==0?Nu(e,t,n):(sn(t),e=Bt(e,t,n),e!==null?e.sibling:null);sn(t);break;case 19:var r=(e.flags&128)!==0;if(i=(n&t.childLanes)!==0,i||(ai(e,t,n,!1),i=(n&t.childLanes)!==0),r){if(i)return Uu(e,t,n);t.flags|=128}if(r=t.memoizedState,r!==null&&(r.rendering=null,r.tail=null,r.lastEffect=null),L(ve,ve.current),i)break;return null;case 22:return t.lanes=0,Iu(e,t,n,t.pendingProps);case 24:nn(t,Ce,e.memoizedState.cache)}return Bt(e,t,n)}function qu(e,t,n){if(e!==null)if(e.memoizedProps!==t.pendingProps)Se=!0;else{if(!hs(e,n)&&(t.flags&128)===0)return Se=!1,Km(e,t,n);Se=(e.flags&131072)!==0}else Se=!1,K&&(t.flags&1048576)!==0&&hc(t,Hi,t.index);switch(t.lanes=0,t.tag){case 16:e:{var i=t.pendingProps;if(e=Nn(t.elementType),t.type=e,typeof e=="function")Sa(e)?(i=Bn(e,i),t.tag=1,t=Ou(null,t,e,i,n)):(t.tag=0,t=cs(null,t,e,i,n));else{if(e!=null){var r=e.$$typeof;if(r===at){t.tag=11,t=Eu(null,t,e,i,n);break e}else if(r===Q){t.tag=14,t=Wu(null,t,e,i,n);break e}}throw t=It(e)||e,Error(y(306,t,""))}}return t;case 0:return cs(e,t,t.type,t.pendingProps,n);case 1:return i=t.type,r=Bn(i,t.pendingProps),Ou(e,t,i,r,n);case 3:e:{if(Me(t,t.stateNode.containerInfo),e===null)throw Error(y(387));i=t.pendingProps;var o=t.memoizedState;r=o.element,Ma(e,t),Yi(t,i,null,n);var a=t.memoizedState;if(i=a.cache,nn(t,Ce,i),i!==o.cache&&Ra(t,[Ce],n,!0),$i(),i=a.element,o.isDehydrated)if(o={element:i,isDehydrated:!1,cache:a.cache},t.updateQueue.baseState=o,t.memoizedState=o,t.flags&256){t=xu(e,t,i,n);break e}else if(i!==r){r=ut(Error(y(424)),t),ji(r),t=xu(e,t,i,n);break e}else for(e=t.stateNode.containerInfo,e.nodeType===9?e=e.body:e=e.nodeName==="HTML"?e.ownerDocument.body:e,de=yt(e.firstChild),We=t,K=!0,en=null,mt=!0,n=Ic(t,null,i,n),t.child=n;n;)n.flags=n.flags&-3|4096,n=n.sibling;else{if(Dn(),i===r){t=Bt(e,t,n);break e}Ie(e,t,i,n)}t=t.child}return t;case 26:return co(e,t),e===null?(n=$d(t.type,null,t.pendingProps,null))?t.memoizedState=n:K||(n=t.type,e=t.pendingProps,i=Wo(z.current).createElement(n),i[Ee]=t,i[Ge]=e,Re(i,n,e),Le(i),t.stateNode=i):t.memoizedState=$d(t.type,e.memoizedProps,t.pendingProps,e.memoizedState),null;case 27:return Wi(t),e===null&&K&&(i=t.stateNode=Vd(t.type,t.pendingProps,z.current),We=t,mt=!0,r=de,hn(t.type)?($s=r,de=yt(i.firstChild)):de=r),Ie(e,t,t.pendingProps.children,n),co(e,t),e===null&&(t.flags|=4194304),t.child;case 5:return e===null&&K&&((r=i=de)&&(i=Lg(i,t.type,t.pendingProps,mt),i!==null?(t.stateNode=i,We=t,de=yt(i.firstChild),mt=!1,r=!0):r=!1),r||tn(t)),Wi(t),r=t.type,o=t.pendingProps,a=e!==null?e.memoizedProps:null,i=o.children,Fs(r,o)?i=null:a!==null&&Fs(r,a)&&(t.flags|=32),t.memoizedState!==null&&(r=ja(e,t,Bm,null,null,n),hr._currentValue=r),co(e,t),Ie(e,t,i,n),t.child;case 6:return e===null&&K&&((e=n=de)&&(n=Tg(n,t.pendingProps,mt),n!==null?(t.stateNode=n,We=t,de=null,e=!0):e=!1),e||tn(t)),null;case 13:return Nu(e,t,n);case 4:return Me(t,t.stateNode.containerInfo),i=t.pendingProps,e===null?t.child=Un(t,null,i,n):Ie(e,t,i,n),t.child;case 11:return Eu(e,t,t.type,t.pendingProps,n);case 7:return Ie(e,t,t.pendingProps,n),t.child;case 8:return Ie(e,t,t.pendingProps.children,n),t.child;case 12:return Ie(e,t,t.pendingProps.children,n),t.child;case 10:return i=t.pendingProps,nn(t,t.type,i.value),Ie(e,t,i.children,n),t.child;case 9:return r=t.type._context,i=t.pendingProps.children,On(t),r=ke(r),i=i(r),t.flags|=1,Ie(e,t,i,n),t.child;case 14:return Wu(e,t,t.type,t.pendingProps,n);case 15:return ku(e,t,t.type,t.pendingProps,n);case 19:return Uu(e,t,n);case 31:return Qm(e,t,n);case 22:return Iu(e,t,n,t.pendingProps);case 24:return On(t),i=ke(Ce),e===null?(r=Oa(),r===null&&(r=ce,o=Da(),r.pooledCache=o,o.refCount++,o!==null&&(r.pooledCacheLanes|=n),r=o),t.memoizedState={parent:i,cache:r},Na(t),nn(t,Ce,r)):((e.lanes&n)!==0&&(Ma(e,t),Yi(t,null,null,n),$i()),r=e.memoizedState,o=t.memoizedState,r.parent!==i?(r={parent:i,cache:i},t.memoizedState=r,t.lanes===0&&(t.memoizedState=t.updateQueue.baseState=r),nn(t,Ce,i)):(i=o.cache,nn(t,Ce,i),i!==r.cache&&Ra(t,[Ce],n,!0))),Ie(e,t,t.pendingProps.children,n),t.child;case 29:throw t.pendingProps}throw Error(y(156,t.tag))}function zt(e){e.flags|=4}function vs(e,t,n,i,r){if((t=(e.mode&32)!==0)&&(t=!1),t){if(e.flags|=16777216,(r&335544128)===r)if(e.stateNode.complete)e.flags|=8192;else if(dd())e.flags|=8192;else throw Mn=Kr,xa}else e.flags&=-16777217}function Bu(e,t){if(t.type!=="stylesheet"||(t.state.loading&4)!==0)e.flags&=-16777217;else if(e.flags|=16777216,!ep(t))if(dd())e.flags|=8192;else throw Mn=Kr,xa}function po(e,t){t!==null&&(e.flags|=4),e.flags&16384&&(t=e.tag!==22?fl():536870912,e.lanes|=t,fi|=t)}function nr(e,t){if(!K)switch(e.tailMode){case"hidden":t=e.tail;for(var n=null;t!==null;)t.alternate!==null&&(n=t),t=t.sibling;n===null?e.tail=null:n.sibling=null;break;case"collapsed":n=e.tail;for(var i=null;n!==null;)n.alternate!==null&&(i=n),n=n.sibling;i===null?t||e.tail===null?e.tail=null:e.tail.sibling=null:i.sibling=null}}function pe(e){var t=e.alternate!==null&&e.alternate.child===e.child,n=0,i=0;if(t)for(var r=e.child;r!==null;)n|=r.lanes|r.childLanes,i|=r.subtreeFlags&65011712,i|=r.flags&65011712,r.return=e,r=r.sibling;else for(r=e.child;r!==null;)n|=r.lanes|r.childLanes,i|=r.subtreeFlags,i|=r.flags,r.return=e,r=r.sibling;return e.subtreeFlags|=i,e.childLanes=n,t}function $m(e,t,n){var i=t.pendingProps;switch(Ta(t),t.tag){case 16:case 15:case 0:case 11:case 7:case 8:case 12:case 9:case 14:return pe(t),null;case 1:return pe(t),null;case 3:return n=t.stateNode,i=null,e!==null&&(i=e.memoizedState.cache),t.memoizedState.cache!==i&&(t.flags|=2048),Mt(Ce),he(),n.pendingContext&&(n.context=n.pendingContext,n.pendingContext=null),(e===null||e.child===null)&&(oi(t)?zt(t):e===null||e.memoizedState.isDehydrated&&(t.flags&256)===0||(t.flags|=1024,Wa())),pe(t),null;case 26:var r=t.type,o=t.memoizedState;return e===null?(zt(t),o!==null?(pe(t),Bu(t,o)):(pe(t),vs(t,r,null,i,n))):o?o!==e.memoizedState?(zt(t),pe(t),Bu(t,o)):(pe(t),t.flags&=-16777217):(e=e.memoizedProps,e!==i&&zt(t),pe(t),vs(t,r,e,i,n)),null;case 27:if(Ar(t),n=z.current,r=t.type,e!==null&&t.stateNode!=null)e.memoizedProps!==i&&zt(t);else{if(!i){if(t.stateNode===null)throw Error(y(166));return pe(t),null}e=W.current,oi(t)?fc(t):(e=Vd(r,i,n),t.stateNode=e,zt(t))}return pe(t),null;case 5:if(Ar(t),r=t.type,e!==null&&t.stateNode!=null)e.memoizedProps!==i&&zt(t);else{if(!i){if(t.stateNode===null)throw Error(y(166));return pe(t),null}if(o=W.current,oi(t))fc(t);else{var a=Wo(z.current);switch(o){case 1:o=a.createElementNS("http://www.w3.org/2000/svg",r);break;case 2:o=a.createElementNS("http://www.w3.org/1998/Math/MathML",r);break;default:switch(r){case"svg":o=a.createElementNS("http://www.w3.org/2000/svg",r);break;case"math":o=a.createElementNS("http://www.w3.org/1998/Math/MathML",r);break;case"script":o=a.createElement("div"),o.innerHTML="<script><\/script>",o=o.removeChild(o.firstChild);break;case"select":o=typeof i.is=="string"?a.createElement("select",{is:i.is}):a.createElement("select"),i.multiple?o.multiple=!0:i.size&&(o.size=i.size);break;default:o=typeof i.is=="string"?a.createElement(r,{is:i.is}):a.createElement(r)}}o[Ee]=t,o[Ge]=i;e:for(a=t.child;a!==null;){if(a.tag===5||a.tag===6)o.appendChild(a.stateNode);else if(a.tag!==4&&a.tag!==27&&a.child!==null){a.child.return=a,a=a.child;continue}if(a===t)break e;for(;a.sibling===null;){if(a.return===null||a.return===t)break e;a=a.return}a.sibling.return=a.return,a=a.sibling}t.stateNode=o;e:switch(Re(o,r,i),r){case"button":case"input":case"select":case"textarea":i=!!i.autoFocus;break e;case"img":i=!0;break e;default:i=!1}i&&zt(t)}}return pe(t),vs(t,t.type,e===null?null:e.memoizedProps,t.pendingProps,n),null;case 6:if(e&&t.stateNode!=null)e.memoizedProps!==i&&zt(t);else{if(typeof i!="string"&&t.stateNode===null)throw Error(y(166));if(e=z.current,oi(t)){if(e=t.stateNode,n=t.memoizedProps,i=null,r=We,r!==null)switch(r.tag){case 27:case 5:i=r.memoizedProps}e[Ee]=t,e=!!(e.nodeValue===n||i!==null&&i.suppressHydrationWarning===!0||Nd(e.nodeValue,n)),e||tn(t,!0)}else e=Wo(e).createTextNode(i),e[Ee]=t,t.stateNode=e}return pe(t),null;case 31:if(n=t.memoizedState,e===null||e.memoizedState!==null){if(i=oi(t),n!==null){if(e===null){if(!i)throw Error(y(318));if(e=t.memoizedState,e=e!==null?e.dehydrated:null,!e)throw Error(y(557));e[Ee]=t}else Dn(),(t.flags&128)===0&&(t.memoizedState=null),t.flags|=4;pe(t),e=!1}else n=Wa(),e!==null&&e.memoizedState!==null&&(e.memoizedState.hydrationErrors=n),e=!0;if(!e)return t.flags&256?(tt(t),t):(tt(t),null);if((t.flags&128)!==0)throw Error(y(558))}return pe(t),null;case 13:if(i=t.memoizedState,e===null||e.memoizedState!==null&&e.memoizedState.dehydrated!==null){if(r=oi(t),i!==null&&i.dehydrated!==null){if(e===null){if(!r)throw Error(y(318));if(r=t.memoizedState,r=r!==null?r.dehydrated:null,!r)throw Error(y(317));r[Ee]=t}else Dn(),(t.flags&128)===0&&(t.memoizedState=null),t.flags|=4;pe(t),r=!1}else r=Wa(),e!==null&&e.memoizedState!==null&&(e.memoizedState.hydrationErrors=r),r=!0;if(!r)return t.flags&256?(tt(t),t):(tt(t),null)}return tt(t),(t.flags&128)!==0?(t.lanes=n,t):(n=i!==null,e=e!==null&&e.memoizedState!==null,n&&(i=t.child,r=null,i.alternate!==null&&i.alternate.memoizedState!==null&&i.alternate.memoizedState.cachePool!==null&&(r=i.alternate.memoizedState.cachePool.pool),o=null,i.memoizedState!==null&&i.memoizedState.cachePool!==null&&(o=i.memoizedState.cachePool.pool),o!==r&&(i.flags|=2048)),n!==e&&n&&(t.child.flags|=8192),po(t,t.updateQueue),pe(t),null);case 4:return he(),e===null&&Bs(t.stateNode.containerInfo),pe(t),null;case 10:return Mt(t.type),pe(t),null;case 19:if(A(ve),i=t.memoizedState,i===null)return pe(t),null;if(r=(t.flags&128)!==0,o=i.rendering,o===null)if(r)nr(i,!1);else{if(ye!==0||e!==null&&(e.flags&128)!==0)for(e=t.child;e!==null;){if(o=Xr(e),o!==null){for(t.flags|=128,nr(i,!1),e=o.updateQueue,t.updateQueue=e,po(t,e),t.subtreeFlags=0,e=n,n=t.child;n!==null;)mc(n,e),n=n.sibling;return L(ve,ve.current&1|2),K&&xt(t,i.treeForkCount),t.child}e=e.sibling}i.tail!==null&&$e()>vo&&(t.flags|=128,r=!0,nr(i,!1),t.lanes=4194304)}else{if(!r)if(e=Xr(o),e!==null){if(t.flags|=128,r=!0,e=e.updateQueue,t.updateQueue=e,po(t,e),nr(i,!0),i.tail===null&&i.tailMode==="hidden"&&!o.alternate&&!K)return pe(t),null}else 2*$e()-i.renderingStartTime>vo&&n!==536870912&&(t.flags|=128,r=!0,nr(i,!1),t.lanes=4194304);i.isBackwards?(o.sibling=t.child,t.child=o):(e=i.last,e!==null?e.sibling=o:t.child=o,i.last=o)}return i.tail!==null?(e=i.tail,i.rendering=e,i.tail=e.sibling,i.renderingStartTime=$e(),e.sibling=null,n=ve.current,L(ve,r?n&1|2:n&1),K&&xt(t,i.treeForkCount),e):(pe(t),null);case 22:case 23:return tt(t),za(),i=t.memoizedState!==null,e!==null?e.memoizedState!==null!==i&&(t.flags|=8192):i&&(t.flags|=8192),i?(n&536870912)!==0&&(t.flags&128)===0&&(pe(t),t.subtreeFlags&6&&(t.flags|=8192)):pe(t),n=t.updateQueue,n!==null&&po(t,n.retryQueue),n=null,e!==null&&e.memoizedState!==null&&e.memoizedState.cachePool!==null&&(n=e.memoizedState.cachePool.pool),i=null,t.memoizedState!==null&&t.memoizedState.cachePool!==null&&(i=t.memoizedState.cachePool.pool),i!==n&&(t.flags|=2048),e!==null&&A(xn),null;case 24:return n=null,e!==null&&(n=e.memoizedState.cache),t.memoizedState.cache!==n&&(t.flags|=2048),Mt(Ce),pe(t),null;case 25:return null;case 30:return null}throw Error(y(156,t.tag))}function Ym(e,t){switch(Ta(t),t.tag){case 1:return e=t.flags,e&65536?(t.flags=e&-65537|128,t):null;case 3:return Mt(Ce),he(),e=t.flags,(e&65536)!==0&&(e&128)===0?(t.flags=e&-65537|128,t):null;case 26:case 27:case 5:return Ar(t),null;case 31:if(t.memoizedState!==null){if(tt(t),t.alternate===null)throw Error(y(340));Dn()}return e=t.flags,e&65536?(t.flags=e&-65537|128,t):null;case 13:if(tt(t),e=t.memoizedState,e!==null&&e.dehydrated!==null){if(t.alternate===null)throw Error(y(340));Dn()}return e=t.flags,e&65536?(t.flags=e&-65537|128,t):null;case 19:return A(ve),null;case 4:return he(),null;case 10:return Mt(t.type),null;case 22:case 23:return tt(t),za(),e!==null&&A(xn),e=t.flags,e&65536?(t.flags=e&-65537|128,t):null;case 24:return Mt(Ce),null;case 25:return null;default:return null}}function zu(e,t){switch(Ta(t),t.tag){case 3:Mt(Ce),he();break;case 26:case 27:case 5:Ar(t);break;case 4:he();break;case 31:t.memoizedState!==null&&tt(t);break;case 13:tt(t);break;case 19:A(ve);break;case 10:Mt(t.type);break;case 22:case 23:tt(t),za(),e!==null&&A(xn);break;case 24:Mt(Ce)}}function ir(e,t){try{var n=t.updateQueue,i=n!==null?n.lastEffect:null;if(i!==null){var r=i.next;n=r;do{if((n.tag&e)===e){i=void 0;var o=n.create,a=n.inst;i=o(),a.destroy=i}n=n.next}while(n!==r)}}catch(s){ie(t,t.return,s)}}function cn(e,t,n){try{var i=t.updateQueue,r=i!==null?i.lastEffect:null;if(r!==null){var o=r.next;i=o;do{if((i.tag&e)===e){var a=i.inst,s=a.destroy;if(s!==void 0){a.destroy=void 0,r=t;var l=n,m=s;try{m()}catch(v){ie(r,l,v)}}}i=i.next}while(i!==o)}}catch(v){ie(t,t.return,v)}}function Gu(e){var t=e.updateQueue;if(t!==null){var n=e.stateNode;try{Dc(t,n)}catch(i){ie(e,e.return,i)}}}function Hu(e,t,n){n.props=Bn(e.type,e.memoizedProps),n.state=e.memoizedState;try{n.componentWillUnmount()}catch(i){ie(e,t,i)}}function rr(e,t){try{var n=e.ref;if(n!==null){switch(e.tag){case 26:case 27:case 5:var i=e.stateNode;break;case 30:i=e.stateNode;break;default:i=e.stateNode}typeof n=="function"?e.refCleanup=n(i):n.current=i}}catch(r){ie(e,t,r)}}function Et(e,t){var n=e.ref,i=e.refCleanup;if(n!==null)if(typeof i=="function")try{i()}catch(r){ie(e,t,r)}finally{e.refCleanup=null,e=e.alternate,e!=null&&(e.refCleanup=null)}else if(typeof n=="function")try{n(null)}catch(r){ie(e,t,r)}else n.current=null}function ju(e){var t=e.type,n=e.memoizedProps,i=e.stateNode;try{e:switch(t){case"button":case"input":case"select":case"textarea":n.autoFocus&&i.focus();break e;case"img":n.src?i.src=n.src:n.srcSet&&(i.srcset=n.srcSet)}}catch(r){ie(e,e.return,r)}}function fs(e,t,n){try{var i=e.stateNode;fg(i,e.type,n,t),i[Ge]=t}catch(r){ie(e,e.return,r)}}function Fu(e){return e.tag===5||e.tag===3||e.tag===26||e.tag===27&&hn(e.type)||e.tag===4}function Cs(e){e:for(;;){for(;e.sibling===null;){if(e.return===null||Fu(e.return))return null;e=e.return}for(e.sibling.return=e.return,e=e.sibling;e.tag!==5&&e.tag!==6&&e.tag!==18;){if(e.tag===27&&hn(e.type)||e.flags&2||e.child===null||e.tag===4)continue e;e.child.return=e,e=e.child}if(!(e.flags&2))return e.stateNode}}function bs(e,t,n){var i=e.tag;if(i===5||i===6)e=e.stateNode,t?(n.nodeType===9?n.body:n.nodeName==="HTML"?n.ownerDocument.body:n).insertBefore(e,t):(t=n.nodeType===9?n.body:n.nodeName==="HTML"?n.ownerDocument.body:n,t.appendChild(e),n=n._reactRootContainer,n!=null||t.onclick!==null||(t.onclick=Dt));else if(i!==4&&(i===27&&hn(e.type)&&(n=e.stateNode,t=null),e=e.child,e!==null))for(bs(e,t,n),e=e.sibling;e!==null;)bs(e,t,n),e=e.sibling}function mo(e,t,n){var i=e.tag;if(i===5||i===6)e=e.stateNode,t?n.insertBefore(e,t):n.appendChild(e);else if(i!==4&&(i===27&&hn(e.type)&&(n=e.stateNode),e=e.child,e!==null))for(mo(e,t,n),e=e.sibling;e!==null;)mo(e,t,n),e=e.sibling}function _u(e){var t=e.stateNode,n=e.memoizedProps;try{for(var i=e.type,r=t.attributes;r.length;)t.removeAttributeNode(r[0]);Re(t,i,n),t[Ee]=e,t[Ge]=n}catch(o){ie(e,e.return,o)}}var Gt=!1,Ae=!1,Ss=!1,Vu=typeof WeakSet=="function"?WeakSet:Set,Te=null;function Jm(e,t){if(e=e.containerInfo,Hs=xo,e=rc(e),ga(e)){if("selectionStart"in e)var n={start:e.selectionStart,end:e.selectionEnd};else e:{n=(n=e.ownerDocument)&&n.defaultView||window;var i=n.getSelection&&n.getSelection();if(i&&i.rangeCount!==0){n=i.anchorNode;var r=i.anchorOffset,o=i.focusNode;i=i.focusOffset;try{n.nodeType,o.nodeType}catch{n=null;break e}var a=0,s=-1,l=-1,m=0,v=0,S=e,g=null;t:for(;;){for(var h;S!==n||r!==0&&S.nodeType!==3||(s=a+r),S!==o||i!==0&&S.nodeType!==3||(l=a+i),S.nodeType===3&&(a+=S.nodeValue.length),(h=S.firstChild)!==null;)g=S,S=h;for(;;){if(S===e)break t;if(g===n&&++m===r&&(s=a),g===o&&++v===i&&(l=a),(h=S.nextSibling)!==null)break;S=g,g=S.parentNode}S=h}n=s===-1||l===-1?null:{start:s,end:l}}else n=null}n=n||{start:0,end:0}}else n=null;for(js={focusedElem:e,selectionRange:n},xo=!1,Te=t;Te!==null;)if(t=Te,e=t.child,(t.subtreeFlags&1028)!==0&&e!==null)e.return=t,Te=e;else for(;Te!==null;){switch(t=Te,o=t.alternate,e=t.flags,t.tag){case 0:if((e&4)!==0&&(e=t.updateQueue,e=e!==null?e.events:null,e!==null))for(n=0;n<e.length;n++)r=e[n],r.ref.impl=r.nextImpl;break;case 11:case 15:break;case 1:if((e&1024)!==0&&o!==null){e=void 0,n=t,r=o.memoizedProps,o=o.memoizedState,i=n.stateNode;try{var E=Bn(n.type,r);e=i.getSnapshotBeforeUpdate(E,o),i.__reactInternalSnapshotBeforeUpdate=e}catch(P){ie(n,n.return,P)}}break;case 3:if((e&1024)!==0){if(e=t.stateNode.containerInfo,n=e.nodeType,n===9)Vs(e);else if(n===1)switch(e.nodeName){case"HEAD":case"HTML":case"BODY":Vs(e);break;default:e.textContent=""}}break;case 5:case 26:case 27:case 6:case 4:case 17:break;default:if((e&1024)!==0)throw Error(y(163))}if(e=t.sibling,e!==null){e.return=t.return,Te=e;break}Te=t.return}}function Qu(e,t,n){var i=n.flags;switch(n.tag){case 0:case 11:case 15:jt(e,n),i&4&&ir(5,n);break;case 1:if(jt(e,n),i&4)if(e=n.stateNode,t===null)try{e.componentDidMount()}catch(a){ie(n,n.return,a)}else{var r=Bn(n.type,t.memoizedProps);t=t.memoizedState;try{e.componentDidUpdate(r,t,e.__reactInternalSnapshotBeforeUpdate)}catch(a){ie(n,n.return,a)}}i&64&&Gu(n),i&512&&rr(n,n.return);break;case 3:if(jt(e,n),i&64&&(e=n.updateQueue,e!==null)){if(t=null,n.child!==null)switch(n.child.tag){case 27:case 5:t=n.child.stateNode;break;case 1:t=n.child.stateNode}try{Dc(e,t)}catch(a){ie(n,n.return,a)}}break;case 27:t===null&&i&4&&_u(n);case 26:case 5:jt(e,n),t===null&&i&4&&ju(n),i&512&&rr(n,n.return);break;case 12:jt(e,n);break;case 31:jt(e,n),i&4&&Yu(e,n);break;case 13:jt(e,n),i&4&&Ju(e,n),i&64&&(e=n.memoizedState,e!==null&&(e=e.dehydrated,e!==null&&(n=ag.bind(null,n),Eg(e,n))));break;case 22:if(i=n.memoizedState!==null||Gt,!i){t=t!==null&&t.memoizedState!==null||Ae,r=Gt;var o=Ae;Gt=i,(Ae=t)&&!o?Ft(e,n,(n.subtreeFlags&8772)!==0):jt(e,n),Gt=r,Ae=o}break;case 30:break;default:jt(e,n)}}function Ku(e){var t=e.alternate;t!==null&&(e.alternate=null,Ku(t)),e.child=null,e.deletions=null,e.sibling=null,e.tag===5&&(t=e.stateNode,t!==null&&Jo(t)),e.stateNode=null,e.return=null,e.dependencies=null,e.memoizedProps=null,e.memoizedState=null,e.pendingProps=null,e.stateNode=null,e.updateQueue=null}var me=null,je=!1;function Ht(e,t,n){for(n=n.child;n!==null;)$u(e,t,n),n=n.sibling}function $u(e,t,n){if(Ye&&typeof Ye.onCommitFiberUnmount=="function")try{Ye.onCommitFiberUnmount(ki,n)}catch{}switch(n.tag){case 26:Ae||Et(n,t),Ht(e,t,n),n.memoizedState?n.memoizedState.count--:n.stateNode&&(n=n.stateNode,n.parentNode.removeChild(n));break;case 27:Ae||Et(n,t);var i=me,r=je;hn(n.type)&&(me=n.stateNode,je=!1),Ht(e,t,n),mr(n.stateNode),me=i,je=r;break;case 5:Ae||Et(n,t);case 6:if(i=me,r=je,me=null,Ht(e,t,n),me=i,je=r,me!==null)if(je)try{(me.nodeType===9?me.body:me.nodeName==="HTML"?me.ownerDocument.body:me).removeChild(n.stateNode)}catch(o){ie(n,t,o)}else try{me.removeChild(n.stateNode)}catch(o){ie(n,t,o)}break;case 18:me!==null&&(je?(e=me,Gd(e.nodeType===9?e.body:e.nodeName==="HTML"?e.ownerDocument.body:e,n.stateNode),Ei(e)):Gd(me,n.stateNode));break;case 4:i=me,r=je,me=n.stateNode.containerInfo,je=!0,Ht(e,t,n),me=i,je=r;break;case 0:case 11:case 14:case 15:cn(2,n,t),Ae||cn(4,n,t),Ht(e,t,n);break;case 1:Ae||(Et(n,t),i=n.stateNode,typeof i.componentWillUnmount=="function"&&Hu(n,t,i)),Ht(e,t,n);break;case 21:Ht(e,t,n);break;case 22:Ae=(i=Ae)||n.memoizedState!==null,Ht(e,t,n),Ae=i;break;default:Ht(e,t,n)}}function Yu(e,t){if(t.memoizedState===null&&(e=t.alternate,e!==null&&(e=e.memoizedState,e!==null))){e=e.dehydrated;try{Ei(e)}catch(n){ie(t,t.return,n)}}}function Ju(e,t){if(t.memoizedState===null&&(e=t.alternate,e!==null&&(e=e.memoizedState,e!==null&&(e=e.dehydrated,e!==null))))try{Ei(e)}catch(n){ie(t,t.return,n)}}function Xm(e){switch(e.tag){case 31:case 13:case 19:var t=e.stateNode;return t===null&&(t=e.stateNode=new Vu),t;case 22:return e=e.stateNode,t=e._retryCache,t===null&&(t=e._retryCache=new Vu),t;default:throw Error(y(435,e.tag))}}function go(e,t){var n=Xm(e);t.forEach(function(i){if(!n.has(i)){n.add(i);var r=sg.bind(null,e,i);i.then(r,r)}})}function Fe(e,t){var n=t.deletions;if(n!==null)for(var i=0;i<n.length;i++){var r=n[i],o=e,a=t,s=a;e:for(;s!==null;){switch(s.tag){case 27:if(hn(s.type)){me=s.stateNode,je=!1;break e}break;case 5:me=s.stateNode,je=!1;break e;case 3:case 4:me=s.stateNode.containerInfo,je=!0;break e}s=s.return}if(me===null)throw Error(y(160));$u(o,a,r),me=null,je=!1,o=r.alternate,o!==null&&(o.return=null),r.return=null}if(t.subtreeFlags&13886)for(t=t.child;t!==null;)Xu(t,e),t=t.sibling}var Ct=null;function Xu(e,t){var n=e.alternate,i=e.flags;switch(e.tag){case 0:case 11:case 14:case 15:Fe(t,e),_e(e),i&4&&(cn(3,e,e.return),ir(3,e),cn(5,e,e.return));break;case 1:Fe(t,e),_e(e),i&512&&(Ae||n===null||Et(n,n.return)),i&64&&Gt&&(e=e.updateQueue,e!==null&&(i=e.callbacks,i!==null&&(n=e.shared.hiddenCallbacks,e.shared.hiddenCallbacks=n===null?i:n.concat(i))));break;case 26:var r=Ct;if(Fe(t,e),_e(e),i&512&&(Ae||n===null||Et(n,n.return)),i&4){var o=n!==null?n.memoizedState:null;if(i=e.memoizedState,n===null)if(i===null)if(e.stateNode===null){e:{i=e.type,n=e.memoizedProps,r=r.ownerDocument||r;t:switch(i){case"title":o=r.getElementsByTagName("title")[0],(!o||o[Di]||o[Ee]||o.namespaceURI==="http://www.w3.org/2000/svg"||o.hasAttribute("itemprop"))&&(o=r.createElement(i),r.head.insertBefore(o,r.querySelector("head > title"))),Re(o,i,n),o[Ee]=e,Le(o),i=o;break e;case"link":var a=Xd("link","href",r).get(i+(n.href||""));if(a){for(var s=0;s<a.length;s++)if(o=a[s],o.getAttribute("href")===(n.href==null||n.href===""?null:n.href)&&o.getAttribute("rel")===(n.rel==null?null:n.rel)&&o.getAttribute("title")===(n.title==null?null:n.title)&&o.getAttribute("crossorigin")===(n.crossOrigin==null?null:n.crossOrigin)){a.splice(s,1);break t}}o=r.createElement(i),Re(o,i,n),r.head.appendChild(o);break;case"meta":if(a=Xd("meta","content",r).get(i+(n.content||""))){for(s=0;s<a.length;s++)if(o=a[s],o.getAttribute("content")===(n.content==null?null:""+n.content)&&o.getAttribute("name")===(n.name==null?null:n.name)&&o.getAttribute("property")===(n.property==null?null:n.property)&&o.getAttribute("http-equiv")===(n.httpEquiv==null?null:n.httpEquiv)&&o.getAttribute("charset")===(n.charSet==null?null:n.charSet)){a.splice(s,1);break t}}o=r.createElement(i),Re(o,i,n),r.head.appendChild(o);break;default:throw Error(y(468,i))}o[Ee]=e,Le(o),i=o}e.stateNode=i}else Zd(r,e.type,e.stateNode);else e.stateNode=Jd(r,i,e.memoizedProps);else o!==i?(o===null?n.stateNode!==null&&(n=n.stateNode,n.parentNode.removeChild(n)):o.count--,i===null?Zd(r,e.type,e.stateNode):Jd(r,i,e.memoizedProps)):i===null&&e.stateNode!==null&&fs(e,e.memoizedProps,n.memoizedProps)}break;case 27:Fe(t,e),_e(e),i&512&&(Ae||n===null||Et(n,n.return)),n!==null&&i&4&&fs(e,e.memoizedProps,n.memoizedProps);break;case 5:if(Fe(t,e),_e(e),i&512&&(Ae||n===null||Et(n,n.return)),e.flags&32){r=e.stateNode;try{$n(r,"")}catch(E){ie(e,e.return,E)}}i&4&&e.stateNode!=null&&(r=e.memoizedProps,fs(e,r,n!==null?n.memoizedProps:r)),i&1024&&(Ss=!0);break;case 6:if(Fe(t,e),_e(e),i&4){if(e.stateNode===null)throw Error(y(162));i=e.memoizedProps,n=e.stateNode;try{n.nodeValue=i}catch(E){ie(e,e.return,E)}}break;case 3:if(Ro=null,r=Ct,Ct=ko(t.containerInfo),Fe(t,e),Ct=r,_e(e),i&4&&n!==null&&n.memoizedState.isDehydrated)try{Ei(t.containerInfo)}catch(E){ie(e,e.return,E)}Ss&&(Ss=!1,Zu(e));break;case 4:i=Ct,Ct=ko(e.stateNode.containerInfo),Fe(t,e),_e(e),Ct=i;break;case 12:Fe(t,e),_e(e);break;case 31:Fe(t,e),_e(e),i&4&&(i=e.updateQueue,i!==null&&(e.updateQueue=null,go(e,i)));break;case 13:Fe(t,e),_e(e),e.child.flags&8192&&e.memoizedState!==null!=(n!==null&&n.memoizedState!==null)&&(ho=$e()),i&4&&(i=e.updateQueue,i!==null&&(e.updateQueue=null,go(e,i)));break;case 22:r=e.memoizedState!==null;var l=n!==null&&n.memoizedState!==null,m=Gt,v=Ae;if(Gt=m||r,Ae=v||l,Fe(t,e),Ae=v,Gt=m,_e(e),i&8192)e:for(t=e.stateNode,t._visibility=r?t._visibility&-2:t._visibility|1,r&&(n===null||l||Gt||Ae||zn(e)),n=null,t=e;;){if(t.tag===5||t.tag===26){if(n===null){l=n=t;try{if(o=l.stateNode,r)a=o.style,typeof a.setProperty=="function"?a.setProperty("display","none","important"):a.display="none";else{s=l.stateNode;var S=l.memoizedProps.style,g=S!=null&&S.hasOwnProperty("display")?S.display:null;s.style.display=g==null||typeof g=="boolean"?"":(""+g).trim()}}catch(E){ie(l,l.return,E)}}}else if(t.tag===6){if(n===null){l=t;try{l.stateNode.nodeValue=r?"":l.memoizedProps}catch(E){ie(l,l.return,E)}}}else if(t.tag===18){if(n===null){l=t;try{var h=l.stateNode;r?Hd(h,!0):Hd(l.stateNode,!1)}catch(E){ie(l,l.return,E)}}}else if((t.tag!==22&&t.tag!==23||t.memoizedState===null||t===e)&&t.child!==null){t.child.return=t,t=t.child;continue}if(t===e)break e;for(;t.sibling===null;){if(t.return===null||t.return===e)break e;n===t&&(n=null),t=t.return}n===t&&(n=null),t.sibling.return=t.return,t=t.sibling}i&4&&(i=e.updateQueue,i!==null&&(n=i.retryQueue,n!==null&&(i.retryQueue=null,go(e,n))));break;case 19:Fe(t,e),_e(e),i&4&&(i=e.updateQueue,i!==null&&(e.updateQueue=null,go(e,i)));break;case 30:break;case 21:break;default:Fe(t,e),_e(e)}}function _e(e){var t=e.flags;if(t&2){try{for(var n,i=e.return;i!==null;){if(Fu(i)){n=i;break}i=i.return}if(n==null)throw Error(y(160));switch(n.tag){case 27:var r=n.stateNode,o=Cs(e);mo(e,o,r);break;case 5:var a=n.stateNode;n.flags&32&&($n(a,""),n.flags&=-33);var s=Cs(e);mo(e,s,a);break;case 3:case 4:var l=n.stateNode.containerInfo,m=Cs(e);bs(e,m,l);break;default:throw Error(y(161))}}catch(v){ie(e,e.return,v)}e.flags&=-3}t&4096&&(e.flags&=-4097)}function Zu(e){if(e.subtreeFlags&1024)for(e=e.child;e!==null;){var t=e;Zu(t),t.tag===5&&t.flags&1024&&t.stateNode.reset(),e=e.sibling}}function jt(e,t){if(t.subtreeFlags&8772)for(t=t.child;t!==null;)Qu(e,t.alternate,t),t=t.sibling}function zn(e){for(e=e.child;e!==null;){var t=e;switch(t.tag){case 0:case 11:case 14:case 15:cn(4,t,t.return),zn(t);break;case 1:Et(t,t.return);var n=t.stateNode;typeof n.componentWillUnmount=="function"&&Hu(t,t.return,n),zn(t);break;case 27:mr(t.stateNode);case 26:case 5:Et(t,t.return),zn(t);break;case 22:t.memoizedState===null&&zn(t);break;case 30:zn(t);break;default:zn(t)}e=e.sibling}}function Ft(e,t,n){for(n=n&&(t.subtreeFlags&8772)!==0,t=t.child;t!==null;){var i=t.alternate,r=e,o=t,a=o.flags;switch(o.tag){case 0:case 11:case 15:Ft(r,o,n),ir(4,o);break;case 1:if(Ft(r,o,n),i=o,r=i.stateNode,typeof r.componentDidMount=="function")try{r.componentDidMount()}catch(m){ie(i,i.return,m)}if(i=o,r=i.updateQueue,r!==null){var s=i.stateNode;try{var l=r.shared.hiddenCallbacks;if(l!==null)for(r.shared.hiddenCallbacks=null,r=0;r<l.length;r++)Rc(l[r],s)}catch(m){ie(i,i.return,m)}}n&&a&64&&Gu(o),rr(o,o.return);break;case 27:_u(o);case 26:case 5:Ft(r,o,n),n&&i===null&&a&4&&ju(o),rr(o,o.return);break;case 12:Ft(r,o,n);break;case 31:Ft(r,o,n),n&&a&4&&Yu(r,o);break;case 13:Ft(r,o,n),n&&a&4&&Ju(r,o);break;case 22:o.memoizedState===null&&Ft(r,o,n),rr(o,o.return);break;case 30:break;default:Ft(r,o,n)}t=t.sibling}}function As(e,t){var n=null;e!==null&&e.memoizedState!==null&&e.memoizedState.cachePool!==null&&(n=e.memoizedState.cachePool.pool),e=null,t.memoizedState!==null&&t.memoizedState.cachePool!==null&&(e=t.memoizedState.cachePool.pool),e!==n&&(e!=null&&e.refCount++,n!=null&&Fi(n))}function ws(e,t){e=null,t.alternate!==null&&(e=t.alternate.memoizedState.cache),t=t.memoizedState.cache,t!==e&&(t.refCount++,e!=null&&Fi(e))}function bt(e,t,n,i){if(t.subtreeFlags&10256)for(t=t.child;t!==null;)ed(e,t,n,i),t=t.sibling}function ed(e,t,n,i){var r=t.flags;switch(t.tag){case 0:case 11:case 15:bt(e,t,n,i),r&2048&&ir(9,t);break;case 1:bt(e,t,n,i);break;case 3:bt(e,t,n,i),r&2048&&(e=null,t.alternate!==null&&(e=t.alternate.memoizedState.cache),t=t.memoizedState.cache,t!==e&&(t.refCount++,e!=null&&Fi(e)));break;case 12:if(r&2048){bt(e,t,n,i),e=t.stateNode;try{var o=t.memoizedProps,a=o.id,s=o.onPostCommit;typeof s=="function"&&s(a,t.alternate===null?"mount":"update",e.passiveEffectDuration,-0)}catch(l){ie(t,t.return,l)}}else bt(e,t,n,i);break;case 31:bt(e,t,n,i);break;case 13:bt(e,t,n,i);break;case 23:break;case 22:o=t.stateNode,a=t.alternate,t.memoizedState!==null?o._visibility&2?bt(e,t,n,i):or(e,t):o._visibility&2?bt(e,t,n,i):(o._visibility|=2,yi(e,t,n,i,(t.subtreeFlags&10256)!==0||!1)),r&2048&&As(a,t);break;case 24:bt(e,t,n,i),r&2048&&ws(t.alternate,t);break;default:bt(e,t,n,i)}}function yi(e,t,n,i,r){for(r=r&&((t.subtreeFlags&10256)!==0||!1),t=t.child;t!==null;){var o=e,a=t,s=n,l=i,m=a.flags;switch(a.tag){case 0:case 11:case 15:yi(o,a,s,l,r),ir(8,a);break;case 23:break;case 22:var v=a.stateNode;a.memoizedState!==null?v._visibility&2?yi(o,a,s,l,r):or(o,a):(v._visibility|=2,yi(o,a,s,l,r)),r&&m&2048&&As(a.alternate,a);break;case 24:yi(o,a,s,l,r),r&&m&2048&&ws(a.alternate,a);break;default:yi(o,a,s,l,r)}t=t.sibling}}function or(e,t){if(t.subtreeFlags&10256)for(t=t.child;t!==null;){var n=e,i=t,r=i.flags;switch(i.tag){case 22:or(n,i),r&2048&&As(i.alternate,i);break;case 24:or(n,i),r&2048&&ws(i.alternate,i);break;default:or(n,i)}t=t.sibling}}var ar=8192;function hi(e,t,n){if(e.subtreeFlags&ar)for(e=e.child;e!==null;)td(e,t,n),e=e.sibling}function td(e,t,n){switch(e.tag){case 26:hi(e,t,n),e.flags&ar&&e.memoizedState!==null&&qg(n,Ct,e.memoizedState,e.memoizedProps);break;case 5:hi(e,t,n);break;case 3:case 4:var i=Ct;Ct=ko(e.stateNode.containerInfo),hi(e,t,n),Ct=i;break;case 22:e.memoizedState===null&&(i=e.alternate,i!==null&&i.memoizedState!==null?(i=ar,ar=16777216,hi(e,t,n),ar=i):hi(e,t,n));break;default:hi(e,t,n)}}function nd(e){var t=e.alternate;if(t!==null&&(e=t.child,e!==null)){t.child=null;do t=e.sibling,e.sibling=null,e=t;while(e!==null)}}function sr(e){var t=e.deletions;if((e.flags&16)!==0){if(t!==null)for(var n=0;n<t.length;n++){var i=t[n];Te=i,rd(i,e)}nd(e)}if(e.subtreeFlags&10256)for(e=e.child;e!==null;)id(e),e=e.sibling}function id(e){switch(e.tag){case 0:case 11:case 15:sr(e),e.flags&2048&&cn(9,e,e.return);break;case 3:sr(e);break;case 12:sr(e);break;case 22:var t=e.stateNode;e.memoizedState!==null&&t._visibility&2&&(e.return===null||e.return.tag!==13)?(t._visibility&=-3,yo(e)):sr(e);break;default:sr(e)}}function yo(e){var t=e.deletions;if((e.flags&16)!==0){if(t!==null)for(var n=0;n<t.length;n++){var i=t[n];Te=i,rd(i,e)}nd(e)}for(e=e.child;e!==null;){switch(t=e,t.tag){case 0:case 11:case 15:cn(8,t,t.return),yo(t);break;case 22:n=t.stateNode,n._visibility&2&&(n._visibility&=-3,yo(t));break;default:yo(t)}e=e.sibling}}function rd(e,t){for(;Te!==null;){var n=Te;switch(n.tag){case 0:case 11:case 15:cn(8,n,t);break;case 23:case 22:if(n.memoizedState!==null&&n.memoizedState.cachePool!==null){var i=n.memoizedState.cachePool.pool;i!=null&&i.refCount++}break;case 24:Fi(n.memoizedState.cache)}if(i=n.child,i!==null)i.return=n,Te=i;else e:for(n=e;Te!==null;){i=Te;var r=i.sibling,o=i.return;if(Ku(i),i===n){Te=null;break e}if(r!==null){r.return=o,Te=r;break e}Te=o}}}var Zm={getCacheForType:function(e){var t=ke(Ce),n=t.data.get(e);return n===void 0&&(n=e(),t.data.set(e,n)),n},cacheSignal:function(){return ke(Ce).controller.signal}},eg=typeof WeakMap=="function"?WeakMap:Map,ee=0,ce=null,G=null,_=0,ne=0,nt=null,un=!1,vi=!1,Ls=!1,_t=0,ye=0,dn=0,Gn=0,Ts=0,it=0,fi=0,lr=null,Ve=null,Es=!1,ho=0,od=0,vo=1/0,fo=null,pn=null,we=0,mn=null,Ci=null,Vt=0,Ws=0,ks=null,ad=null,cr=0,Is=null;function rt(){return(ee&2)!==0&&_!==0?_&-_:f.T!==null?Ns():Al()}function sd(){if(it===0)if((_&536870912)===0||K){var e=Tr;Tr<<=1,(Tr&3932160)===0&&(Tr=262144),it=e}else it=536870912;return e=et.current,e!==null&&(e.flags|=32),it}function Qe(e,t,n){(e===ce&&(ne===2||ne===9)||e.cancelPendingCommit!==null)&&(bi(e,0),gn(e,_,it,!1)),Ri(e,n),((ee&2)===0||e!==ce)&&(e===ce&&((ee&2)===0&&(Gn|=n),ye===4&&gn(e,_,it,!1)),Wt(e))}function ld(e,t,n){if((ee&6)!==0)throw Error(y(327));var i=!n&&(t&127)===0&&(t&e.expiredLanes)===0||Ii(e,t),r=i?ig(e,t):Ds(e,t,!0),o=i;do{if(r===0){vi&&!i&&gn(e,t,0,!1);break}else{if(n=e.current.alternate,o&&!tg(n)){r=Ds(e,t,!1),o=!1;continue}if(r===2){if(o=t,e.errorRecoveryDisabledLanes&o)var a=0;else a=e.pendingLanes&-536870913,a=a!==0?a:a&536870912?536870912:0;if(a!==0){t=a;e:{var s=e;r=lr;var l=s.current.memoizedState.isDehydrated;if(l&&(bi(s,a).flags|=256),a=Ds(s,a,!1),a!==2){if(Ls&&!l){s.errorRecoveryDisabledLanes|=o,Gn|=o,r=4;break e}o=Ve,Ve=r,o!==null&&(Ve===null?Ve=o:Ve.push.apply(Ve,o))}r=a}if(o=!1,r!==2)continue}}if(r===1){bi(e,0),gn(e,t,0,!0);break}e:{switch(i=e,o=r,o){case 0:case 1:throw Error(y(345));case 4:if((t&4194048)!==t)break;case 6:gn(i,t,it,!un);break e;case 2:Ve=null;break;case 3:case 5:break;default:throw Error(y(329))}if((t&62914560)===t&&(r=ho+300-$e(),10<r)){if(gn(i,t,it,!un),Wr(i,0,!0)!==0)break e;Vt=t,i.timeoutHandle=Bd(cd.bind(null,i,n,Ve,fo,Es,t,it,Gn,fi,un,o,"Throttled",-0,0),r);break e}cd(i,n,Ve,fo,Es,t,it,Gn,fi,un,o,null,-0,0)}}break}while(!0);Wt(e)}function cd(e,t,n,i,r,o,a,s,l,m,v,S,g,h){if(e.timeoutHandle=-1,S=t.subtreeFlags,S&8192||(S&16785408)===16785408){S={stylesheets:null,count:0,imgCount:0,imgBytes:0,suspenseyImages:[],waitingForImages:!0,waitingForViewTransition:!1,unsuspend:Dt},td(t,o,S);var E=(o&62914560)===o?ho-$e():(o&4194048)===o?od-$e():0;if(E=Bg(S,E),E!==null){Vt=o,e.cancelPendingCommit=E(vd.bind(null,e,t,o,n,i,r,a,s,l,v,S,null,g,h)),gn(e,o,a,!m);return}}vd(e,t,o,n,i,r,a,s,l)}function tg(e){for(var t=e;;){var n=t.tag;if((n===0||n===11||n===15)&&t.flags&16384&&(n=t.updateQueue,n!==null&&(n=n.stores,n!==null)))for(var i=0;i<n.length;i++){var r=n[i],o=r.getSnapshot;r=r.value;try{if(!Xe(o(),r))return!1}catch{return!1}}if(n=t.child,t.subtreeFlags&16384&&n!==null)n.return=t,t=n;else{if(t===e)break;for(;t.sibling===null;){if(t.return===null||t.return===e)return!0;t=t.return}t.sibling.return=t.return,t=t.sibling}}return!0}function gn(e,t,n,i){t&=~Ts,t&=~Gn,e.suspendedLanes|=t,e.pingedLanes&=~t,i&&(e.warmLanes|=t),i=e.expirationTimes;for(var r=t;0<r;){var o=31-Je(r),a=1<<o;i[o]=-1,r&=~a}n!==0&&Cl(e,n,t)}function Co(){return(ee&6)===0?(ur(0),!1):!0}function Rs(){if(G!==null){if(ne===0)var e=G.return;else e=G,Nt=Pn=null,Va(e),ui=null,Vi=0,e=G;for(;e!==null;)zu(e.alternate,e),e=e.return;G=null}}function bi(e,t){var n=e.timeoutHandle;n!==-1&&(e.timeoutHandle=-1,Sg(n)),n=e.cancelPendingCommit,n!==null&&(e.cancelPendingCommit=null,n()),Vt=0,Rs(),ce=e,G=n=Ot(e.current,null),_=t,ne=0,nt=null,un=!1,vi=Ii(e,t),Ls=!1,fi=it=Ts=Gn=dn=ye=0,Ve=lr=null,Es=!1,(t&8)!==0&&(t|=t&32);var i=e.entangledLanes;if(i!==0)for(e=e.entanglements,i&=t;0<i;){var r=31-Je(i),o=1<<r;t|=e[r],i&=~o}return _t=t,Br(),n}function ud(e,t){U=null,f.H=er,t===ci||t===Qr?(t=Ec(),ne=3):t===xa?(t=Ec(),ne=4):ne=t===ls?8:t!==null&&typeof t=="object"&&typeof t.then=="function"?6:1,nt=t,G===null&&(ye=1,so(e,ut(t,e.current)))}function dd(){var e=et.current;return e===null?!0:(_&4194048)===_?gt===null:(_&62914560)===_||(_&536870912)!==0?e===gt:!1}function pd(){var e=f.H;return f.H=er,e===null?er:e}function md(){var e=f.A;return f.A=Zm,e}function bo(){ye=4,un||(_&4194048)!==_&&et.current!==null||(vi=!0),(dn&134217727)===0&&(Gn&134217727)===0||ce===null||gn(ce,_,it,!1)}function Ds(e,t,n){var i=ee;ee|=2;var r=pd(),o=md();(ce!==e||_!==t)&&(fo=null,bi(e,t)),t=!1;var a=ye;e:do try{if(ne!==0&&G!==null){var s=G,l=nt;switch(ne){case 8:Rs(),a=6;break e;case 3:case 2:case 9:case 6:et.current===null&&(t=!0);var m=ne;if(ne=0,nt=null,Si(e,s,l,m),n&&vi){a=0;break e}break;default:m=ne,ne=0,nt=null,Si(e,s,l,m)}}ng(),a=ye;break}catch(v){ud(e,v)}while(!0);return t&&e.shellSuspendCounter++,Nt=Pn=null,ee=i,f.H=r,f.A=o,G===null&&(ce=null,_=0,Br()),a}function ng(){for(;G!==null;)gd(G)}function ig(e,t){var n=ee;ee|=2;var i=pd(),r=md();ce!==e||_!==t?(fo=null,vo=$e()+500,bi(e,t)):vi=Ii(e,t);e:do try{if(ne!==0&&G!==null){t=G;var o=nt;t:switch(ne){case 1:ne=0,nt=null,Si(e,t,o,1);break;case 2:case 9:if(Lc(o)){ne=0,nt=null,yd(t);break}t=function(){ne!==2&&ne!==9||ce!==e||(ne=7),Wt(e)},o.then(t,t);break e;case 3:ne=7;break e;case 4:ne=5;break e;case 7:Lc(o)?(ne=0,nt=null,yd(t)):(ne=0,nt=null,Si(e,t,o,7));break;case 5:var a=null;switch(G.tag){case 26:a=G.memoizedState;case 5:case 27:var s=G;if(a?ep(a):s.stateNode.complete){ne=0,nt=null;var l=s.sibling;if(l!==null)G=l;else{var m=s.return;m!==null?(G=m,So(m)):G=null}break t}}ne=0,nt=null,Si(e,t,o,5);break;case 6:ne=0,nt=null,Si(e,t,o,6);break;case 8:Rs(),ye=6;break e;default:throw Error(y(462))}}rg();break}catch(v){ud(e,v)}while(!0);return Nt=Pn=null,f.H=i,f.A=r,ee=n,G!==null?0:(ce=null,_=0,Br(),ye)}function rg(){for(;G!==null&&!Wp();)gd(G)}function gd(e){var t=qu(e.alternate,e,_t);e.memoizedProps=e.pendingProps,t===null?So(e):G=t}function yd(e){var t=e,n=t.alternate;switch(t.tag){case 15:case 0:t=Pu(n,t,t.pendingProps,t.type,void 0,_);break;case 11:t=Pu(n,t,t.pendingProps,t.type.render,t.ref,_);break;case 5:Va(t);default:zu(n,t),t=G=mc(t,_t),t=qu(n,t,_t)}e.memoizedProps=e.pendingProps,t===null?So(e):G=t}function Si(e,t,n,i){Nt=Pn=null,Va(t),ui=null,Vi=0;var r=t.return;try{if(Vm(e,r,t,n,_)){ye=1,so(e,ut(n,e.current)),G=null;return}}catch(o){if(r!==null)throw G=r,o;ye=1,so(e,ut(n,e.current)),G=null;return}t.flags&32768?(K||i===1?e=!0:vi||(_&536870912)!==0?e=!1:(un=e=!0,(i===2||i===9||i===3||i===6)&&(i=et.current,i!==null&&i.tag===13&&(i.flags|=16384))),hd(t,e)):So(t)}function So(e){var t=e;do{if((t.flags&32768)!==0){hd(t,un);return}e=t.return;var n=$m(t.alternate,t,_t);if(n!==null){G=n;return}if(t=t.sibling,t!==null){G=t;return}G=t=e}while(t!==null);ye===0&&(ye=5)}function hd(e,t){do{var n=Ym(e.alternate,e);if(n!==null){n.flags&=32767,G=n;return}if(n=e.return,n!==null&&(n.flags|=32768,n.subtreeFlags=0,n.deletions=null),!t&&(e=e.sibling,e!==null)){G=e;return}G=e=n}while(e!==null);ye=6,G=null}function vd(e,t,n,i,r,o,a,s,l){e.cancelPendingCommit=null;do Ao();while(we!==0);if((ee&6)!==0)throw Error(y(327));if(t!==null){if(t===e.current)throw Error(y(177));if(o=t.lanes|t.childLanes,o|=Ca,Up(e,n,o,a,s,l),e===ce&&(G=ce=null,_=0),Ci=t,mn=e,Vt=n,Ws=o,ks=r,ad=i,(t.subtreeFlags&10256)!==0||(t.flags&10256)!==0?(e.callbackNode=null,e.callbackPriority=0,lg(wr,function(){return Ad(),null})):(e.callbackNode=null,e.callbackPriority=0),i=(t.flags&13878)!==0,(t.subtreeFlags&13878)!==0||i){i=f.T,f.T=null,r=w.p,w.p=2,a=ee,ee|=4;try{Jm(e,t,n)}finally{ee=a,w.p=r,f.T=i}}we=1,fd(),Cd(),bd()}}function fd(){if(we===1){we=0;var e=mn,t=Ci,n=(t.flags&13878)!==0;if((t.subtreeFlags&13878)!==0||n){n=f.T,f.T=null;var i=w.p;w.p=2;var r=ee;ee|=4;try{Xu(t,e);var o=js,a=rc(e.containerInfo),s=o.focusedElem,l=o.selectionRange;if(a!==s&&s&&s.ownerDocument&&ic(s.ownerDocument.documentElement,s)){if(l!==null&&ga(s)){var m=l.start,v=l.end;if(v===void 0&&(v=m),"selectionStart"in s)s.selectionStart=m,s.selectionEnd=Math.min(v,s.value.length);else{var S=s.ownerDocument||document,g=S&&S.defaultView||window;if(g.getSelection){var h=g.getSelection(),E=s.textContent.length,P=Math.min(l.start,E),se=l.end===void 0?P:Math.min(l.end,E);!h.extend&&P>se&&(a=se,se=P,P=a);var d=nc(s,P),c=nc(s,se);if(d&&c&&(h.rangeCount!==1||h.anchorNode!==d.node||h.anchorOffset!==d.offset||h.focusNode!==c.node||h.focusOffset!==c.offset)){var p=S.createRange();p.setStart(d.node,d.offset),h.removeAllRanges(),P>se?(h.addRange(p),h.extend(c.node,c.offset)):(p.setEnd(c.node,c.offset),h.addRange(p))}}}}for(S=[],h=s;h=h.parentNode;)h.nodeType===1&&S.push({element:h,left:h.scrollLeft,top:h.scrollTop});for(typeof s.focus=="function"&&s.focus(),s=0;s<S.length;s++){var C=S[s];C.element.scrollLeft=C.left,C.element.scrollTop=C.top}}xo=!!Hs,js=Hs=null}finally{ee=r,w.p=i,f.T=n}}e.current=t,we=2}}function Cd(){if(we===2){we=0;var e=mn,t=Ci,n=(t.flags&8772)!==0;if((t.subtreeFlags&8772)!==0||n){n=f.T,f.T=null;var i=w.p;w.p=2;var r=ee;ee|=4;try{Qu(e,t.alternate,t)}finally{ee=r,w.p=i,f.T=n}}we=3}}function bd(){if(we===4||we===3){we=0,kp();var e=mn,t=Ci,n=Vt,i=ad;(t.subtreeFlags&10256)!==0||(t.flags&10256)!==0?we=5:(we=0,Ci=mn=null,Sd(e,e.pendingLanes));var r=e.pendingLanes;if(r===0&&(pn=null),$o(n),t=t.stateNode,Ye&&typeof Ye.onCommitFiberRoot=="function")try{Ye.onCommitFiberRoot(ki,t,void 0,(t.current.flags&128)===128)}catch{}if(i!==null){t=f.T,r=w.p,w.p=2,f.T=null;try{for(var o=e.onRecoverableError,a=0;a<i.length;a++){var s=i[a];o(s.value,{componentStack:s.stack})}}finally{f.T=t,w.p=r}}(Vt&3)!==0&&Ao(),Wt(e),r=e.pendingLanes,(n&261930)!==0&&(r&42)!==0?e===Is?cr++:(cr=0,Is=e):cr=0,ur(0)}}function Sd(e,t){(e.pooledCacheLanes&=t)===0&&(t=e.pooledCache,t!=null&&(e.pooledCache=null,Fi(t)))}function Ao(){return fd(),Cd(),bd(),Ad()}function Ad(){if(we!==5)return!1;var e=mn,t=Ws;Ws=0;var n=$o(Vt),i=f.T,r=w.p;try{w.p=32>n?32:n,f.T=null,n=ks,ks=null;var o=mn,a=Vt;if(we=0,Ci=mn=null,Vt=0,(ee&6)!==0)throw Error(y(331));var s=ee;if(ee|=4,id(o.current),ed(o,o.current,a,n),ee=s,ur(0,!1),Ye&&typeof Ye.onPostCommitFiberRoot=="function")try{Ye.onPostCommitFiberRoot(ki,o)}catch{}return!0}finally{w.p=r,f.T=i,Sd(e,t)}}function wd(e,t,n){t=ut(n,t),t=ss(e.stateNode,t,2),e=an(e,t,2),e!==null&&(Ri(e,2),Wt(e))}function ie(e,t,n){if(e.tag===3)wd(e,e,n);else for(;t!==null;){if(t.tag===3){wd(t,e,n);break}else if(t.tag===1){var i=t.stateNode;if(typeof t.type.getDerivedStateFromError=="function"||typeof i.componentDidCatch=="function"&&(pn===null||!pn.has(i))){e=ut(n,e),n=Lu(2),i=an(t,n,2),i!==null&&(Tu(n,i,t,e),Ri(i,2),Wt(i));break}}t=t.return}}function Ps(e,t,n){var i=e.pingCache;if(i===null){i=e.pingCache=new eg;var r=new Set;i.set(t,r)}else r=i.get(t),r===void 0&&(r=new Set,i.set(t,r));r.has(n)||(Ls=!0,r.add(n),e=og.bind(null,e,t,n),t.then(e,e))}function og(e,t,n){var i=e.pingCache;i!==null&&i.delete(t),e.pingedLanes|=e.suspendedLanes&n,e.warmLanes&=~n,ce===e&&(_&n)===n&&(ye===4||ye===3&&(_&62914560)===_&&300>$e()-ho?(ee&2)===0&&bi(e,0):Ts|=n,fi===_&&(fi=0)),Wt(e)}function Ld(e,t){t===0&&(t=fl()),e=In(e,t),e!==null&&(Ri(e,t),Wt(e))}function ag(e){var t=e.memoizedState,n=0;t!==null&&(n=t.retryLane),Ld(e,n)}function sg(e,t){var n=0;switch(e.tag){case 31:case 13:var i=e.stateNode,r=e.memoizedState;r!==null&&(n=r.retryLane);break;case 19:i=e.stateNode;break;case 22:i=e.stateNode._retryCache;break;default:throw Error(y(314))}i!==null&&i.delete(t),Ld(e,n)}function lg(e,t){return _o(e,t)}var wo=null,Ai=null,Os=!1,Lo=!1,xs=!1,yn=0;function Wt(e){e!==Ai&&e.next===null&&(Ai===null?wo=Ai=e:Ai=Ai.next=e),Lo=!0,Os||(Os=!0,ug())}function ur(e,t){if(!xs&&Lo){xs=!0;do for(var n=!1,i=wo;i!==null;){if(e!==0){var r=i.pendingLanes;if(r===0)var o=0;else{var a=i.suspendedLanes,s=i.pingedLanes;o=(1<<31-Je(42|e)+1)-1,o&=r&~(a&~s),o=o&201326741?o&201326741|1:o?o|2:0}o!==0&&(n=!0,kd(i,o))}else o=_,o=Wr(i,i===ce?o:0,i.cancelPendingCommit!==null||i.timeoutHandle!==-1),(o&3)===0||Ii(i,o)||(n=!0,kd(i,o));i=i.next}while(n);xs=!1}}function cg(){Td()}function Td(){Lo=Os=!1;var e=0;yn!==0&&bg()&&(e=yn);for(var t=$e(),n=null,i=wo;i!==null;){var r=i.next,o=Ed(i,t);o===0?(i.next=null,n===null?wo=r:n.next=r,r===null&&(Ai=n)):(n=i,(e!==0||(o&3)!==0)&&(Lo=!0)),i=r}we!==0&&we!==5||ur(e),yn!==0&&(yn=0)}function Ed(e,t){for(var n=e.suspendedLanes,i=e.pingedLanes,r=e.expirationTimes,o=e.pendingLanes&-62914561;0<o;){var a=31-Je(o),s=1<<a,l=r[a];l===-1?((s&n)===0||(s&i)!==0)&&(r[a]=Mp(s,t)):l<=t&&(e.expiredLanes|=s),o&=~s}if(t=ce,n=_,n=Wr(e,e===t?n:0,e.cancelPendingCommit!==null||e.timeoutHandle!==-1),i=e.callbackNode,n===0||e===t&&(ne===2||ne===9)||e.cancelPendingCommit!==null)return i!==null&&i!==null&&Vo(i),e.callbackNode=null,e.callbackPriority=0;if((n&3)===0||Ii(e,n)){if(t=n&-n,t===e.callbackPriority)return t;switch(i!==null&&Vo(i),$o(n)){case 2:case 8:n=hl;break;case 32:n=wr;break;case 268435456:n=vl;break;default:n=wr}return i=Wd.bind(null,e),n=_o(n,i),e.callbackPriority=t,e.callbackNode=n,t}return i!==null&&i!==null&&Vo(i),e.callbackPriority=2,e.callbackNode=null,2}function Wd(e,t){if(we!==0&&we!==5)return e.callbackNode=null,e.callbackPriority=0,null;var n=e.callbackNode;if(Ao()&&e.callbackNode!==n)return null;var i=_;return i=Wr(e,e===ce?i:0,e.cancelPendingCommit!==null||e.timeoutHandle!==-1),i===0?null:(ld(e,i,t),Ed(e,$e()),e.callbackNode!=null&&e.callbackNode===n?Wd.bind(null,e):null)}function kd(e,t){if(Ao())return null;ld(e,t,!0)}function ug(){Ag(function(){(ee&6)!==0?_o(yl,cg):Td()})}function Ns(){if(yn===0){var e=si;e===0&&(e=Lr,Lr<<=1,(Lr&261888)===0&&(Lr=256)),yn=e}return yn}function Id(e){return e==null||typeof e=="symbol"||typeof e=="boolean"?null:typeof e=="function"?e:Dr(""+e)}function Rd(e,t){var n=t.ownerDocument.createElement("input");return n.name=t.name,n.value=t.value,e.id&&n.setAttribute("form",e.id),t.parentNode.insertBefore(n,t),e=new FormData(e),n.parentNode.removeChild(n),e}function dg(e,t,n,i,r){if(t==="submit"&&n&&n.stateNode===r){var o=Id((r[Ge]||null).action),a=i.submitter;a&&(t=(t=a[Ge]||null)?Id(t.formAction):a.getAttribute("formAction"),t!==null&&(o=t,a=null));var s=new Nr("action","action",null,i,r);e.push({event:s,listeners:[{instance:null,listener:function(){if(i.defaultPrevented){if(yn!==0){var l=a?Rd(r,a):new FormData(r);ts(n,{pending:!0,data:l,method:r.method,action:o},null,l)}}else typeof o=="function"&&(s.preventDefault(),l=a?Rd(r,a):new FormData(r),ts(n,{pending:!0,data:l,method:r.method,action:o},o,l))},currentTarget:r}]})}}for(var Ms=0;Ms<fa.length;Ms++){var Us=fa[Ms],pg=Us.toLowerCase(),mg=Us[0].toUpperCase()+Us.slice(1);ft(pg,"on"+mg)}ft(sc,"onAnimationEnd"),ft(lc,"onAnimationIteration"),ft(cc,"onAnimationStart"),ft("dblclick","onDoubleClick"),ft("focusin","onFocus"),ft("focusout","onBlur"),ft(Im,"onTransitionRun"),ft(Rm,"onTransitionStart"),ft(Dm,"onTransitionCancel"),ft(uc,"onTransitionEnd"),Qn("onMouseEnter",["mouseout","mouseover"]),Qn("onMouseLeave",["mouseout","mouseover"]),Qn("onPointerEnter",["pointerout","pointerover"]),Qn("onPointerLeave",["pointerout","pointerover"]),Tn("onChange","change click focusin focusout input keydown keyup selectionchange".split(" ")),Tn("onSelect","focusout contextmenu dragend focusin keydown keyup mousedown mouseup selectionchange".split(" ")),Tn("onBeforeInput",["compositionend","keypress","textInput","paste"]),Tn("onCompositionEnd","compositionend focusout keydown keypress keyup mousedown".split(" ")),Tn("onCompositionStart","compositionstart focusout keydown keypress keyup mousedown".split(" ")),Tn("onCompositionUpdate","compositionupdate focusout keydown keypress keyup mousedown".split(" "));var dr="abort canplay canplaythrough durationchange emptied encrypted ended error loadeddata loadedmetadata loadstart pause play playing progress ratechange resize seeked seeking stalled suspend timeupdate volumechange waiting".split(" "),gg=new Set("beforetoggle cancel close invalid load scroll scrollend toggle".split(" ").concat(dr));function Dd(e,t){t=(t&4)!==0;for(var n=0;n<e.length;n++){var i=e[n],r=i.event;i=i.listeners;e:{var o=void 0;if(t)for(var a=i.length-1;0<=a;a--){var s=i[a],l=s.instance,m=s.currentTarget;if(s=s.listener,l!==o&&r.isPropagationStopped())break e;o=s,r.currentTarget=m;try{o(r)}catch(v){qr(v)}r.currentTarget=null,o=l}else for(a=0;a<i.length;a++){if(s=i[a],l=s.instance,m=s.currentTarget,s=s.listener,l!==o&&r.isPropagationStopped())break e;o=s,r.currentTarget=m;try{o(r)}catch(v){qr(v)}r.currentTarget=null,o=l}}}}function H(e,t){var n=t[Yo];n===void 0&&(n=t[Yo]=new Set);var i=e+"__bubble";n.has(i)||(Pd(t,e,2,!1),n.add(i))}function qs(e,t,n){var i=0;t&&(i|=4),Pd(n,e,i,t)}var To="_reactListening"+Math.random().toString(36).slice(2);function Bs(e){if(!e[To]){e[To]=!0,Tl.forEach(function(n){n!=="selectionchange"&&(gg.has(n)||qs(n,!1,e),qs(n,!0,e))});var t=e.nodeType===9?e:e.ownerDocument;t===null||t[To]||(t[To]=!0,qs("selectionchange",!1,t))}}function Pd(e,t,n,i){switch(sp(t)){case 2:var r=Hg;break;case 8:r=jg;break;default:r=el}n=r.bind(null,t,n,e),r=void 0,!oa||t!=="touchstart"&&t!=="touchmove"&&t!=="wheel"||(r=!0),i?r!==void 0?e.addEventListener(t,n,{capture:!0,passive:r}):e.addEventListener(t,n,!0):r!==void 0?e.addEventListener(t,n,{passive:r}):e.addEventListener(t,n,!1)}function zs(e,t,n,i,r){var o=i;if((t&1)===0&&(t&2)===0&&i!==null)e:for(;;){if(i===null)return;var a=i.tag;if(a===3||a===4){var s=i.stateNode.containerInfo;if(s===r)break;if(a===4)for(a=i.return;a!==null;){var l=a.tag;if((l===3||l===4)&&a.stateNode.containerInfo===r)return;a=a.return}for(;s!==null;){if(a=Fn(s),a===null)return;if(l=a.tag,l===5||l===6||l===26||l===27){i=o=a;continue e}s=s.parentNode}}i=i.return}Ul(function(){var m=o,v=ia(n),S=[];e:{var g=dc.get(e);if(g!==void 0){var h=Nr,E=e;switch(e){case"keypress":if(Or(n)===0)break e;case"keydown":case"keyup":h=sm;break;case"focusin":E="focus",h=ca;break;case"focusout":E="blur",h=ca;break;case"beforeblur":case"afterblur":h=ca;break;case"click":if(n.button===2)break e;case"auxclick":case"dblclick":case"mousedown":case"mousemove":case"mouseup":case"mouseout":case"mouseover":case"contextmenu":h=zl;break;case"drag":case"dragend":case"dragenter":case"dragexit":case"dragleave":case"dragover":case"dragstart":case"drop":h=$p;break;case"touchcancel":case"touchend":case"touchmove":case"touchstart":h=um;break;case sc:case lc:case cc:h=Xp;break;case uc:h=pm;break;case"scroll":case"scrollend":h=Qp;break;case"wheel":h=gm;break;case"copy":case"cut":case"paste":h=em;break;case"gotpointercapture":case"lostpointercapture":case"pointercancel":case"pointerdown":case"pointermove":case"pointerout":case"pointerover":case"pointerup":h=Hl;break;case"toggle":case"beforetoggle":h=hm}var P=(t&4)!==0,se=!P&&(e==="scroll"||e==="scrollend"),d=P?g!==null?g+"Capture":null:g;P=[];for(var c=m,p;c!==null;){var C=c;if(p=C.stateNode,C=C.tag,C!==5&&C!==26&&C!==27||p===null||d===null||(C=Oi(c,d),C!=null&&P.push(pr(c,C,p))),se)break;c=c.return}0<P.length&&(g=new h(g,E,null,n,v),S.push({event:g,listeners:P}))}}if((t&7)===0){e:{if(g=e==="mouseover"||e==="pointerover",h=e==="mouseout"||e==="pointerout",g&&n!==na&&(E=n.relatedTarget||n.fromElement)&&(Fn(E)||E[jn]))break e;if((h||g)&&(g=v.window===v?v:(g=v.ownerDocument)?g.defaultView||g.parentWindow:window,h?(E=n.relatedTarget||n.toElement,h=m,E=E?Fn(E):null,E!==null&&(se=F(E),P=E.tag,E!==se||P!==5&&P!==27&&P!==6)&&(E=null)):(h=null,E=m),h!==E)){if(P=zl,C="onMouseLeave",d="onMouseEnter",c="mouse",(e==="pointerout"||e==="pointerover")&&(P=Hl,C="onPointerLeave",d="onPointerEnter",c="pointer"),se=h==null?g:Pi(h),p=E==null?g:Pi(E),g=new P(C,c+"leave",h,n,v),g.target=se,g.relatedTarget=p,C=null,Fn(v)===m&&(P=new P(d,c+"enter",E,n,v),P.target=p,P.relatedTarget=se,C=P),se=C,h&&E)t:{for(P=yg,d=h,c=E,p=0,C=d;C;C=P(C))p++;C=0;for(var R=c;R;R=P(R))C++;for(;0<p-C;)d=P(d),p--;for(;0<C-p;)c=P(c),C--;for(;p--;){if(d===c||c!==null&&d===c.alternate){P=d;break t}d=P(d),c=P(c)}P=null}else P=null;h!==null&&Od(S,g,h,P,!1),E!==null&&se!==null&&Od(S,se,E,P,!0)}}e:{if(g=m?Pi(m):window,h=g.nodeName&&g.nodeName.toLowerCase(),h==="select"||h==="input"&&g.type==="file")var J=Yl;else if(Kl(g))if(Jl)J=Em;else{J=Lm;var k=wm}else h=g.nodeName,!h||h.toLowerCase()!=="input"||g.type!=="checkbox"&&g.type!=="radio"?m&&ta(m.elementType)&&(J=Yl):J=Tm;if(J&&(J=J(e,m))){$l(S,J,n,v);break e}k&&k(e,g,m),e==="focusout"&&m&&g.type==="number"&&m.memoizedProps.value!=null&&ea(g,"number",g.value)}switch(k=m?Pi(m):window,e){case"focusin":(Kl(k)||k.contentEditable==="true")&&(Zn=k,ya=m,Gi=null);break;case"focusout":Gi=ya=Zn=null;break;case"mousedown":ha=!0;break;case"contextmenu":case"mouseup":case"dragend":ha=!1,oc(S,n,v);break;case"selectionchange":if(km)break;case"keydown":case"keyup":oc(S,n,v)}var q;if(da)e:{switch(e){case"compositionstart":var V="onCompositionStart";break e;case"compositionend":V="onCompositionEnd";break e;case"compositionupdate":V="onCompositionUpdate";break e}V=void 0}else Xn?Vl(e,n)&&(V="onCompositionEnd"):e==="keydown"&&n.keyCode===229&&(V="onCompositionStart");V&&(jl&&n.locale!=="ko"&&(Xn||V!=="onCompositionStart"?V==="onCompositionEnd"&&Xn&&(q=ql()):(Xt=v,aa="value"in Xt?Xt.value:Xt.textContent,Xn=!0)),k=Eo(m,V),0<k.length&&(V=new Gl(V,e,null,n,v),S.push({event:V,listeners:k}),q?V.data=q:(q=Ql(n),q!==null&&(V.data=q)))),(q=fm?Cm(e,n):bm(e,n))&&(V=Eo(m,"onBeforeInput"),0<V.length&&(k=new Gl("onBeforeInput","beforeinput",null,n,v),S.push({event:k,listeners:V}),k.data=q)),dg(S,e,m,n,v)}Dd(S,t)})}function pr(e,t,n){return{instance:e,listener:t,currentTarget:n}}function Eo(e,t){for(var n=t+"Capture",i=[];e!==null;){var r=e,o=r.stateNode;if(r=r.tag,r!==5&&r!==26&&r!==27||o===null||(r=Oi(e,n),r!=null&&i.unshift(pr(e,r,o)),r=Oi(e,t),r!=null&&i.push(pr(e,r,o))),e.tag===3)return i;e=e.return}return[]}function yg(e){if(e===null)return null;do e=e.return;while(e&&e.tag!==5&&e.tag!==27);return e||null}function Od(e,t,n,i,r){for(var o=t._reactName,a=[];n!==null&&n!==i;){var s=n,l=s.alternate,m=s.stateNode;if(s=s.tag,l!==null&&l===i)break;s!==5&&s!==26&&s!==27||m===null||(l=m,r?(m=Oi(n,o),m!=null&&a.unshift(pr(n,m,l))):r||(m=Oi(n,o),m!=null&&a.push(pr(n,m,l)))),n=n.return}a.length!==0&&e.push({event:t,listeners:a})}var hg=/\r\n?/g,vg=/\u0000|\uFFFD/g;function xd(e){return(typeof e=="string"?e:""+e).replace(hg,`
`).replace(vg,"")}function Nd(e,t){return t=xd(t),xd(e)===t}function ae(e,t,n,i,r,o){switch(n){case"children":typeof i=="string"?t==="body"||t==="textarea"&&i===""||$n(e,i):(typeof i=="number"||typeof i=="bigint")&&t!=="body"&&$n(e,""+i);break;case"className":Ir(e,"class",i);break;case"tabIndex":Ir(e,"tabindex",i);break;case"dir":case"role":case"viewBox":case"width":case"height":Ir(e,n,i);break;case"style":Nl(e,i,o);break;case"data":if(t!=="object"){Ir(e,"data",i);break}case"src":case"href":if(i===""&&(t!=="a"||n!=="href")){e.removeAttribute(n);break}if(i==null||typeof i=="function"||typeof i=="symbol"||typeof i=="boolean"){e.removeAttribute(n);break}i=Dr(""+i),e.setAttribute(n,i);break;case"action":case"formAction":if(typeof i=="function"){e.setAttribute(n,"javascript:throw new Error('A React form was unexpectedly submitted. If you called form.submit() manually, consider using form.requestSubmit() instead. If you\\'re trying to use event.stopPropagation() in a submit event handler, consider also calling event.preventDefault().')");break}else typeof o=="function"&&(n==="formAction"?(t!=="input"&&ae(e,t,"name",r.name,r,null),ae(e,t,"formEncType",r.formEncType,r,null),ae(e,t,"formMethod",r.formMethod,r,null),ae(e,t,"formTarget",r.formTarget,r,null)):(ae(e,t,"encType",r.encType,r,null),ae(e,t,"method",r.method,r,null),ae(e,t,"target",r.target,r,null)));if(i==null||typeof i=="symbol"||typeof i=="boolean"){e.removeAttribute(n);break}i=Dr(""+i),e.setAttribute(n,i);break;case"onClick":i!=null&&(e.onclick=Dt);break;case"onScroll":i!=null&&H("scroll",e);break;case"onScrollEnd":i!=null&&H("scrollend",e);break;case"dangerouslySetInnerHTML":if(i!=null){if(typeof i!="object"||!("__html"in i))throw Error(y(61));if(n=i.__html,n!=null){if(r.children!=null)throw Error(y(60));e.innerHTML=n}}break;case"multiple":e.multiple=i&&typeof i!="function"&&typeof i!="symbol";break;case"muted":e.muted=i&&typeof i!="function"&&typeof i!="symbol";break;case"suppressContentEditableWarning":case"suppressHydrationWarning":case"defaultValue":case"defaultChecked":case"innerHTML":case"ref":break;case"autoFocus":break;case"xlinkHref":if(i==null||typeof i=="function"||typeof i=="boolean"||typeof i=="symbol"){e.removeAttribute("xlink:href");break}n=Dr(""+i),e.setAttributeNS("http://www.w3.org/1999/xlink","xlink:href",n);break;case"contentEditable":case"spellCheck":case"draggable":case"value":case"autoReverse":case"externalResourcesRequired":case"focusable":case"preserveAlpha":i!=null&&typeof i!="function"&&typeof i!="symbol"?e.setAttribute(n,""+i):e.removeAttribute(n);break;case"inert":case"allowFullScreen":case"async":case"autoPlay":case"controls":case"default":case"defer":case"disabled":case"disablePictureInPicture":case"disableRemotePlayback":case"formNoValidate":case"hidden":case"loop":case"noModule":case"noValidate":case"open":case"playsInline":case"readOnly":case"required":case"reversed":case"scoped":case"seamless":case"itemScope":i&&typeof i!="function"&&typeof i!="symbol"?e.setAttribute(n,""):e.removeAttribute(n);break;case"capture":case"download":i===!0?e.setAttribute(n,""):i!==!1&&i!=null&&typeof i!="function"&&typeof i!="symbol"?e.setAttribute(n,i):e.removeAttribute(n);break;case"cols":case"rows":case"size":case"span":i!=null&&typeof i!="function"&&typeof i!="symbol"&&!isNaN(i)&&1<=i?e.setAttribute(n,i):e.removeAttribute(n);break;case"rowSpan":case"start":i==null||typeof i=="function"||typeof i=="symbol"||isNaN(i)?e.removeAttribute(n):e.setAttribute(n,i);break;case"popover":H("beforetoggle",e),H("toggle",e),kr(e,"popover",i);break;case"xlinkActuate":Rt(e,"http://www.w3.org/1999/xlink","xlink:actuate",i);break;case"xlinkArcrole":Rt(e,"http://www.w3.org/1999/xlink","xlink:arcrole",i);break;case"xlinkRole":Rt(e,"http://www.w3.org/1999/xlink","xlink:role",i);break;case"xlinkShow":Rt(e,"http://www.w3.org/1999/xlink","xlink:show",i);break;case"xlinkTitle":Rt(e,"http://www.w3.org/1999/xlink","xlink:title",i);break;case"xlinkType":Rt(e,"http://www.w3.org/1999/xlink","xlink:type",i);break;case"xmlBase":Rt(e,"http://www.w3.org/XML/1998/namespace","xml:base",i);break;case"xmlLang":Rt(e,"http://www.w3.org/XML/1998/namespace","xml:lang",i);break;case"xmlSpace":Rt(e,"http://www.w3.org/XML/1998/namespace","xml:space",i);break;case"is":kr(e,"is",i);break;case"innerText":case"textContent":break;default:(!(2<n.length)||n[0]!=="o"&&n[0]!=="O"||n[1]!=="n"&&n[1]!=="N")&&(n=_p.get(n)||n,kr(e,n,i))}}function Gs(e,t,n,i,r,o){switch(n){case"style":Nl(e,i,o);break;case"dangerouslySetInnerHTML":if(i!=null){if(typeof i!="object"||!("__html"in i))throw Error(y(61));if(n=i.__html,n!=null){if(r.children!=null)throw Error(y(60));e.innerHTML=n}}break;case"children":typeof i=="string"?$n(e,i):(typeof i=="number"||typeof i=="bigint")&&$n(e,""+i);break;case"onScroll":i!=null&&H("scroll",e);break;case"onScrollEnd":i!=null&&H("scrollend",e);break;case"onClick":i!=null&&(e.onclick=Dt);break;case"suppressContentEditableWarning":case"suppressHydrationWarning":case"innerHTML":case"ref":break;case"innerText":case"textContent":break;default:if(!El.hasOwnProperty(n))e:{if(n[0]==="o"&&n[1]==="n"&&(r=n.endsWith("Capture"),t=n.slice(2,r?n.length-7:void 0),o=e[Ge]||null,o=o!=null?o[n]:null,typeof o=="function"&&e.removeEventListener(t,o,r),typeof i=="function")){typeof o!="function"&&o!==null&&(n in e?e[n]=null:e.hasAttribute(n)&&e.removeAttribute(n)),e.addEventListener(t,i,r);break e}n in e?e[n]=i:i===!0?e.setAttribute(n,""):kr(e,n,i)}}}function Re(e,t,n){switch(t){case"div":case"span":case"svg":case"path":case"a":case"g":case"p":case"li":break;case"img":H("error",e),H("load",e);var i=!1,r=!1,o;for(o in n)if(n.hasOwnProperty(o)){var a=n[o];if(a!=null)switch(o){case"src":i=!0;break;case"srcSet":r=!0;break;case"children":case"dangerouslySetInnerHTML":throw Error(y(137,t));default:ae(e,t,o,a,n,null)}}r&&ae(e,t,"srcSet",n.srcSet,n,null),i&&ae(e,t,"src",n.src,n,null);return;case"input":H("invalid",e);var s=o=a=r=null,l=null,m=null;for(i in n)if(n.hasOwnProperty(i)){var v=n[i];if(v!=null)switch(i){case"name":r=v;break;case"type":a=v;break;case"checked":l=v;break;case"defaultChecked":m=v;break;case"value":o=v;break;case"defaultValue":s=v;break;case"children":case"dangerouslySetInnerHTML":if(v!=null)throw Error(y(137,t));break;default:ae(e,t,i,v,n,null)}}Dl(e,o,s,l,m,a,r,!1);return;case"select":H("invalid",e),i=a=o=null;for(r in n)if(n.hasOwnProperty(r)&&(s=n[r],s!=null))switch(r){case"value":o=s;break;case"defaultValue":a=s;break;case"multiple":i=s;default:ae(e,t,r,s,n,null)}t=o,n=a,e.multiple=!!i,t!=null?Kn(e,!!i,t,!1):n!=null&&Kn(e,!!i,n,!0);return;case"textarea":H("invalid",e),o=r=i=null;for(a in n)if(n.hasOwnProperty(a)&&(s=n[a],s!=null))switch(a){case"value":i=s;break;case"defaultValue":r=s;break;case"children":o=s;break;case"dangerouslySetInnerHTML":if(s!=null)throw Error(y(91));break;default:ae(e,t,a,s,n,null)}Ol(e,i,r,o);return;case"option":for(l in n)n.hasOwnProperty(l)&&(i=n[l],i!=null)&&(l==="selected"?e.selected=i&&typeof i!="function"&&typeof i!="symbol":ae(e,t,l,i,n,null));return;case"dialog":H("beforetoggle",e),H("toggle",e),H("cancel",e),H("close",e);break;case"iframe":case"object":H("load",e);break;case"video":case"audio":for(i=0;i<dr.length;i++)H(dr[i],e);break;case"image":H("error",e),H("load",e);break;case"details":H("toggle",e);break;case"embed":case"source":case"link":H("error",e),H("load",e);case"area":case"base":case"br":case"col":case"hr":case"keygen":case"meta":case"param":case"track":case"wbr":case"menuitem":for(m in n)if(n.hasOwnProperty(m)&&(i=n[m],i!=null))switch(m){case"children":case"dangerouslySetInnerHTML":throw Error(y(137,t));default:ae(e,t,m,i,n,null)}return;default:if(ta(t)){for(v in n)n.hasOwnProperty(v)&&(i=n[v],i!==void 0&&Gs(e,t,v,i,n,void 0));return}}for(s in n)n.hasOwnProperty(s)&&(i=n[s],i!=null&&ae(e,t,s,i,n,null))}function fg(e,t,n,i){switch(t){case"div":case"span":case"svg":case"path":case"a":case"g":case"p":case"li":break;case"input":var r=null,o=null,a=null,s=null,l=null,m=null,v=null;for(h in n){var S=n[h];if(n.hasOwnProperty(h)&&S!=null)switch(h){case"checked":break;case"value":break;case"defaultValue":l=S;default:i.hasOwnProperty(h)||ae(e,t,h,null,i,S)}}for(var g in i){var h=i[g];if(S=n[g],i.hasOwnProperty(g)&&(h!=null||S!=null))switch(g){case"type":o=h;break;case"name":r=h;break;case"checked":m=h;break;case"defaultChecked":v=h;break;case"value":a=h;break;case"defaultValue":s=h;break;case"children":case"dangerouslySetInnerHTML":if(h!=null)throw Error(y(137,t));break;default:h!==S&&ae(e,t,g,h,i,S)}}Zo(e,a,s,l,m,v,o,r);return;case"select":h=a=s=g=null;for(o in n)if(l=n[o],n.hasOwnProperty(o)&&l!=null)switch(o){case"value":break;case"multiple":h=l;default:i.hasOwnProperty(o)||ae(e,t,o,null,i,l)}for(r in i)if(o=i[r],l=n[r],i.hasOwnProperty(r)&&(o!=null||l!=null))switch(r){case"value":g=o;break;case"defaultValue":s=o;break;case"multiple":a=o;default:o!==l&&ae(e,t,r,o,i,l)}t=s,n=a,i=h,g!=null?Kn(e,!!n,g,!1):!!i!=!!n&&(t!=null?Kn(e,!!n,t,!0):Kn(e,!!n,n?[]:"",!1));return;case"textarea":h=g=null;for(s in n)if(r=n[s],n.hasOwnProperty(s)&&r!=null&&!i.hasOwnProperty(s))switch(s){case"value":break;case"children":break;default:ae(e,t,s,null,i,r)}for(a in i)if(r=i[a],o=n[a],i.hasOwnProperty(a)&&(r!=null||o!=null))switch(a){case"value":g=r;break;case"defaultValue":h=r;break;case"children":break;case"dangerouslySetInnerHTML":if(r!=null)throw Error(y(91));break;default:r!==o&&ae(e,t,a,r,i,o)}Pl(e,g,h);return;case"option":for(var E in n)g=n[E],n.hasOwnProperty(E)&&g!=null&&!i.hasOwnProperty(E)&&(E==="selected"?e.selected=!1:ae(e,t,E,null,i,g));for(l in i)g=i[l],h=n[l],i.hasOwnProperty(l)&&g!==h&&(g!=null||h!=null)&&(l==="selected"?e.selected=g&&typeof g!="function"&&typeof g!="symbol":ae(e,t,l,g,i,h));return;case"img":case"link":case"area":case"base":case"br":case"col":case"embed":case"hr":case"keygen":case"meta":case"param":case"source":case"track":case"wbr":case"menuitem":for(var P in n)g=n[P],n.hasOwnProperty(P)&&g!=null&&!i.hasOwnProperty(P)&&ae(e,t,P,null,i,g);for(m in i)if(g=i[m],h=n[m],i.hasOwnProperty(m)&&g!==h&&(g!=null||h!=null))switch(m){case"children":case"dangerouslySetInnerHTML":if(g!=null)throw Error(y(137,t));break;default:ae(e,t,m,g,i,h)}return;default:if(ta(t)){for(var se in n)g=n[se],n.hasOwnProperty(se)&&g!==void 0&&!i.hasOwnProperty(se)&&Gs(e,t,se,void 0,i,g);for(v in i)g=i[v],h=n[v],!i.hasOwnProperty(v)||g===h||g===void 0&&h===void 0||Gs(e,t,v,g,i,h);return}}for(var d in n)g=n[d],n.hasOwnProperty(d)&&g!=null&&!i.hasOwnProperty(d)&&ae(e,t,d,null,i,g);for(S in i)g=i[S],h=n[S],!i.hasOwnProperty(S)||g===h||g==null&&h==null||ae(e,t,S,g,i,h)}function Md(e){switch(e){case"css":case"script":case"font":case"img":case"image":case"input":case"link":return!0;default:return!1}}function Cg(){if(typeof performance.getEntriesByType=="function"){for(var e=0,t=0,n=performance.getEntriesByType("resource"),i=0;i<n.length;i++){var r=n[i],o=r.transferSize,a=r.initiatorType,s=r.duration;if(o&&s&&Md(a)){for(a=0,s=r.responseEnd,i+=1;i<n.length;i++){var l=n[i],m=l.startTime;if(m>s)break;var v=l.transferSize,S=l.initiatorType;v&&Md(S)&&(l=l.responseEnd,a+=v*(l<s?1:(s-m)/(l-m)))}if(--i,t+=8*(o+a)/(r.duration/1e3),e++,10<e)break}}if(0<e)return t/e/1e6}return navigator.connection&&(e=navigator.connection.downlink,typeof e=="number")?e:5}var Hs=null,js=null;function Wo(e){return e.nodeType===9?e:e.ownerDocument}function Ud(e){switch(e){case"http://www.w3.org/2000/svg":return 1;case"http://www.w3.org/1998/Math/MathML":return 2;default:return 0}}function qd(e,t){if(e===0)switch(t){case"svg":return 1;case"math":return 2;default:return 0}return e===1&&t==="foreignObject"?0:e}function Fs(e,t){return e==="textarea"||e==="noscript"||typeof t.children=="string"||typeof t.children=="number"||typeof t.children=="bigint"||typeof t.dangerouslySetInnerHTML=="object"&&t.dangerouslySetInnerHTML!==null&&t.dangerouslySetInnerHTML.__html!=null}var _s=null;function bg(){var e=window.event;return e&&e.type==="popstate"?e===_s?!1:(_s=e,!0):(_s=null,!1)}var Bd=typeof setTimeout=="function"?setTimeout:void 0,Sg=typeof clearTimeout=="function"?clearTimeout:void 0,zd=typeof Promise=="function"?Promise:void 0,Ag=typeof queueMicrotask=="function"?queueMicrotask:typeof zd<"u"?function(e){return zd.resolve(null).then(e).catch(wg)}:Bd;function wg(e){setTimeout(function(){throw e})}function hn(e){return e==="head"}function Gd(e,t){var n=t,i=0;do{var r=n.nextSibling;if(e.removeChild(n),r&&r.nodeType===8)if(n=r.data,n==="/$"||n==="/&"){if(i===0){e.removeChild(r),Ei(t);return}i--}else if(n==="$"||n==="$?"||n==="$~"||n==="$!"||n==="&")i++;else if(n==="html")mr(e.ownerDocument.documentElement);else if(n==="head"){n=e.ownerDocument.head,mr(n);for(var o=n.firstChild;o;){var a=o.nextSibling,s=o.nodeName;o[Di]||s==="SCRIPT"||s==="STYLE"||s==="LINK"&&o.rel.toLowerCase()==="stylesheet"||n.removeChild(o),o=a}}else n==="body"&&mr(e.ownerDocument.body);n=r}while(n);Ei(t)}function Hd(e,t){var n=e;e=0;do{var i=n.nextSibling;if(n.nodeType===1?t?(n._stashedDisplay=n.style.display,n.style.display="none"):(n.style.display=n._stashedDisplay||"",n.getAttribute("style")===""&&n.removeAttribute("style")):n.nodeType===3&&(t?(n._stashedText=n.nodeValue,n.nodeValue=""):n.nodeValue=n._stashedText||""),i&&i.nodeType===8)if(n=i.data,n==="/$"){if(e===0)break;e--}else n!=="$"&&n!=="$?"&&n!=="$~"&&n!=="$!"||e++;n=i}while(n)}function Vs(e){var t=e.firstChild;for(t&&t.nodeType===10&&(t=t.nextSibling);t;){var n=t;switch(t=t.nextSibling,n.nodeName){case"HTML":case"HEAD":case"BODY":Vs(n),Jo(n);continue;case"SCRIPT":case"STYLE":continue;case"LINK":if(n.rel.toLowerCase()==="stylesheet")continue}e.removeChild(n)}}function Lg(e,t,n,i){for(;e.nodeType===1;){var r=n;if(e.nodeName.toLowerCase()!==t.toLowerCase()){if(!i&&(e.nodeName!=="INPUT"||e.type!=="hidden"))break}else if(i){if(!e[Di])switch(t){case"meta":if(!e.hasAttribute("itemprop"))break;return e;case"link":if(o=e.getAttribute("rel"),o==="stylesheet"&&e.hasAttribute("data-precedence"))break;if(o!==r.rel||e.getAttribute("href")!==(r.href==null||r.href===""?null:r.href)||e.getAttribute("crossorigin")!==(r.crossOrigin==null?null:r.crossOrigin)||e.getAttribute("title")!==(r.title==null?null:r.title))break;return e;case"style":if(e.hasAttribute("data-precedence"))break;return e;case"script":if(o=e.getAttribute("src"),(o!==(r.src==null?null:r.src)||e.getAttribute("type")!==(r.type==null?null:r.type)||e.getAttribute("crossorigin")!==(r.crossOrigin==null?null:r.crossOrigin))&&o&&e.hasAttribute("async")&&!e.hasAttribute("itemprop"))break;return e;default:return e}}else if(t==="input"&&e.type==="hidden"){var o=r.name==null?null:""+r.name;if(r.type==="hidden"&&e.getAttribute("name")===o)return e}else return e;if(e=yt(e.nextSibling),e===null)break}return null}function Tg(e,t,n){if(t==="")return null;for(;e.nodeType!==3;)if((e.nodeType!==1||e.nodeName!=="INPUT"||e.type!=="hidden")&&!n||(e=yt(e.nextSibling),e===null))return null;return e}function jd(e,t){for(;e.nodeType!==8;)if((e.nodeType!==1||e.nodeName!=="INPUT"||e.type!=="hidden")&&!t||(e=yt(e.nextSibling),e===null))return null;return e}function Qs(e){return e.data==="$?"||e.data==="$~"}function Ks(e){return e.data==="$!"||e.data==="$?"&&e.ownerDocument.readyState!=="loading"}function Eg(e,t){var n=e.ownerDocument;if(e.data==="$~")e._reactRetry=t;else if(e.data!=="$?"||n.readyState!=="loading")t();else{var i=function(){t(),n.removeEventListener("DOMContentLoaded",i)};n.addEventListener("DOMContentLoaded",i),e._reactRetry=i}}function yt(e){for(;e!=null;e=e.nextSibling){var t=e.nodeType;if(t===1||t===3)break;if(t===8){if(t=e.data,t==="$"||t==="$!"||t==="$?"||t==="$~"||t==="&"||t==="F!"||t==="F")break;if(t==="/$"||t==="/&")return null}}return e}var $s=null;function Fd(e){e=e.nextSibling;for(var t=0;e;){if(e.nodeType===8){var n=e.data;if(n==="/$"||n==="/&"){if(t===0)return yt(e.nextSibling);t--}else n!=="$"&&n!=="$!"&&n!=="$?"&&n!=="$~"&&n!=="&"||t++}e=e.nextSibling}return null}function _d(e){e=e.previousSibling;for(var t=0;e;){if(e.nodeType===8){var n=e.data;if(n==="$"||n==="$!"||n==="$?"||n==="$~"||n==="&"){if(t===0)return e;t--}else n!=="/$"&&n!=="/&"||t++}e=e.previousSibling}return null}function Vd(e,t,n){switch(t=Wo(n),e){case"html":if(e=t.documentElement,!e)throw Error(y(452));return e;case"head":if(e=t.head,!e)throw Error(y(453));return e;case"body":if(e=t.body,!e)throw Error(y(454));return e;default:throw Error(y(451))}}function mr(e){for(var t=e.attributes;t.length;)e.removeAttributeNode(t[0]);Jo(e)}var ht=new Map,Qd=new Set;function ko(e){return typeof e.getRootNode=="function"?e.getRootNode():e.nodeType===9?e:e.ownerDocument}var Qt=w.d;w.d={f:Wg,r:kg,D:Ig,C:Rg,L:Dg,m:Pg,X:xg,S:Og,M:Ng};function Wg(){var e=Qt.f(),t=Co();return e||t}function kg(e){var t=_n(e);t!==null&&t.tag===5&&t.type==="form"?uu(t):Qt.r(e)}var wi=typeof document>"u"?null:document;function Kd(e,t,n){var i=wi;if(i&&typeof t=="string"&&t){var r=lt(t);r='link[rel="'+e+'"][href="'+r+'"]',typeof n=="string"&&(r+='[crossorigin="'+n+'"]'),Qd.has(r)||(Qd.add(r),e={rel:e,crossOrigin:n,href:t},i.querySelector(r)===null&&(t=i.createElement("link"),Re(t,"link",e),Le(t),i.head.appendChild(t)))}}function Ig(e){Qt.D(e),Kd("dns-prefetch",e,null)}function Rg(e,t){Qt.C(e,t),Kd("preconnect",e,t)}function Dg(e,t,n){Qt.L(e,t,n);var i=wi;if(i&&e&&t){var r='link[rel="preload"][as="'+lt(t)+'"]';t==="image"&&n&&n.imageSrcSet?(r+='[imagesrcset="'+lt(n.imageSrcSet)+'"]',typeof n.imageSizes=="string"&&(r+='[imagesizes="'+lt(n.imageSizes)+'"]')):r+='[href="'+lt(e)+'"]';var o=r;switch(t){case"style":o=Li(e);break;case"script":o=Ti(e)}ht.has(o)||(e=D({rel:"preload",href:t==="image"&&n&&n.imageSrcSet?void 0:e,as:t},n),ht.set(o,e),i.querySelector(r)!==null||t==="style"&&i.querySelector(gr(o))||t==="script"&&i.querySelector(yr(o))||(t=i.createElement("link"),Re(t,"link",e),Le(t),i.head.appendChild(t)))}}function Pg(e,t){Qt.m(e,t);var n=wi;if(n&&e){var i=t&&typeof t.as=="string"?t.as:"script",r='link[rel="modulepreload"][as="'+lt(i)+'"][href="'+lt(e)+'"]',o=r;switch(i){case"audioworklet":case"paintworklet":case"serviceworker":case"sharedworker":case"worker":case"script":o=Ti(e)}if(!ht.has(o)&&(e=D({rel:"modulepreload",href:e},t),ht.set(o,e),n.querySelector(r)===null)){switch(i){case"audioworklet":case"paintworklet":case"serviceworker":case"sharedworker":case"worker":case"script":if(n.querySelector(yr(o)))return}i=n.createElement("link"),Re(i,"link",e),Le(i),n.head.appendChild(i)}}}function Og(e,t,n){Qt.S(e,t,n);var i=wi;if(i&&e){var r=Vn(i).hoistableStyles,o=Li(e);t=t||"default";var a=r.get(o);if(!a){var s={loading:0,preload:null};if(a=i.querySelector(gr(o)))s.loading=5;else{e=D({rel:"stylesheet",href:e,"data-precedence":t},n),(n=ht.get(o))&&Ys(e,n);var l=a=i.createElement("link");Le(l),Re(l,"link",e),l._p=new Promise(function(m,v){l.onload=m,l.onerror=v}),l.addEventListener("load",function(){s.loading|=1}),l.addEventListener("error",function(){s.loading|=2}),s.loading|=4,Io(a,t,i)}a={type:"stylesheet",instance:a,count:1,state:s},r.set(o,a)}}}function xg(e,t){Qt.X(e,t);var n=wi;if(n&&e){var i=Vn(n).hoistableScripts,r=Ti(e),o=i.get(r);o||(o=n.querySelector(yr(r)),o||(e=D({src:e,async:!0},t),(t=ht.get(r))&&Js(e,t),o=n.createElement("script"),Le(o),Re(o,"link",e),n.head.appendChild(o)),o={type:"script",instance:o,count:1,state:null},i.set(r,o))}}function Ng(e,t){Qt.M(e,t);var n=wi;if(n&&e){var i=Vn(n).hoistableScripts,r=Ti(e),o=i.get(r);o||(o=n.querySelector(yr(r)),o||(e=D({src:e,async:!0,type:"module"},t),(t=ht.get(r))&&Js(e,t),o=n.createElement("script"),Le(o),Re(o,"link",e),n.head.appendChild(o)),o={type:"script",instance:o,count:1,state:null},i.set(r,o))}}function $d(e,t,n,i){var r=(r=z.current)?ko(r):null;if(!r)throw Error(y(446));switch(e){case"meta":case"title":return null;case"style":return typeof n.precedence=="string"&&typeof n.href=="string"?(t=Li(n.href),n=Vn(r).hoistableStyles,i=n.get(t),i||(i={type:"style",instance:null,count:0,state:null},n.set(t,i)),i):{type:"void",instance:null,count:0,state:null};case"link":if(n.rel==="stylesheet"&&typeof n.href=="string"&&typeof n.precedence=="string"){e=Li(n.href);var o=Vn(r).hoistableStyles,a=o.get(e);if(a||(r=r.ownerDocument||r,a={type:"stylesheet",instance:null,count:0,state:{loading:0,preload:null}},o.set(e,a),(o=r.querySelector(gr(e)))&&!o._p&&(a.instance=o,a.state.loading=5),ht.has(e)||(n={rel:"preload",as:"style",href:n.href,crossOrigin:n.crossOrigin,integrity:n.integrity,media:n.media,hrefLang:n.hrefLang,referrerPolicy:n.referrerPolicy},ht.set(e,n),o||Mg(r,e,n,a.state))),t&&i===null)throw Error(y(528,""));return a}if(t&&i!==null)throw Error(y(529,""));return null;case"script":return t=n.async,n=n.src,typeof n=="string"&&t&&typeof t!="function"&&typeof t!="symbol"?(t=Ti(n),n=Vn(r).hoistableScripts,i=n.get(t),i||(i={type:"script",instance:null,count:0,state:null},n.set(t,i)),i):{type:"void",instance:null,count:0,state:null};default:throw Error(y(444,e))}}function Li(e){return'href="'+lt(e)+'"'}function gr(e){return'link[rel="stylesheet"]['+e+"]"}function Yd(e){return D({},e,{"data-precedence":e.precedence,precedence:null})}function Mg(e,t,n,i){e.querySelector('link[rel="preload"][as="style"]['+t+"]")?i.loading=1:(t=e.createElement("link"),i.preload=t,t.addEventListener("load",function(){return i.loading|=1}),t.addEventListener("error",function(){return i.loading|=2}),Re(t,"link",n),Le(t),e.head.appendChild(t))}function Ti(e){return'[src="'+lt(e)+'"]'}function yr(e){return"script[async]"+e}function Jd(e,t,n){if(t.count++,t.instance===null)switch(t.type){case"style":var i=e.querySelector('style[data-href~="'+lt(n.href)+'"]');if(i)return t.instance=i,Le(i),i;var r=D({},n,{"data-href":n.href,"data-precedence":n.precedence,href:null,precedence:null});return i=(e.ownerDocument||e).createElement("style"),Le(i),Re(i,"style",r),Io(i,n.precedence,e),t.instance=i;case"stylesheet":r=Li(n.href);var o=e.querySelector(gr(r));if(o)return t.state.loading|=4,t.instance=o,Le(o),o;i=Yd(n),(r=ht.get(r))&&Ys(i,r),o=(e.ownerDocument||e).createElement("link"),Le(o);var a=o;return a._p=new Promise(function(s,l){a.onload=s,a.onerror=l}),Re(o,"link",i),t.state.loading|=4,Io(o,n.precedence,e),t.instance=o;case"script":return o=Ti(n.src),(r=e.querySelector(yr(o)))?(t.instance=r,Le(r),r):(i=n,(r=ht.get(o))&&(i=D({},n),Js(i,r)),e=e.ownerDocument||e,r=e.createElement("script"),Le(r),Re(r,"link",i),e.head.appendChild(r),t.instance=r);case"void":return null;default:throw Error(y(443,t.type))}else t.type==="stylesheet"&&(t.state.loading&4)===0&&(i=t.instance,t.state.loading|=4,Io(i,n.precedence,e));return t.instance}function Io(e,t,n){for(var i=n.querySelectorAll('link[rel="stylesheet"][data-precedence],style[data-precedence]'),r=i.length?i[i.length-1]:null,o=r,a=0;a<i.length;a++){var s=i[a];if(s.dataset.precedence===t)o=s;else if(o!==r)break}o?o.parentNode.insertBefore(e,o.nextSibling):(t=n.nodeType===9?n.head:n,t.insertBefore(e,t.firstChild))}function Ys(e,t){e.crossOrigin==null&&(e.crossOrigin=t.crossOrigin),e.referrerPolicy==null&&(e.referrerPolicy=t.referrerPolicy),e.title==null&&(e.title=t.title)}function Js(e,t){e.crossOrigin==null&&(e.crossOrigin=t.crossOrigin),e.referrerPolicy==null&&(e.referrerPolicy=t.referrerPolicy),e.integrity==null&&(e.integrity=t.integrity)}var Ro=null;function Xd(e,t,n){if(Ro===null){var i=new Map,r=Ro=new Map;r.set(n,i)}else r=Ro,i=r.get(n),i||(i=new Map,r.set(n,i));if(i.has(e))return i;for(i.set(e,null),n=n.getElementsByTagName(e),r=0;r<n.length;r++){var o=n[r];if(!(o[Di]||o[Ee]||e==="link"&&o.getAttribute("rel")==="stylesheet")&&o.namespaceURI!=="http://www.w3.org/2000/svg"){var a=o.getAttribute(t)||"";a=e+a;var s=i.get(a);s?s.push(o):i.set(a,[o])}}return i}function Zd(e,t,n){e=e.ownerDocument||e,e.head.insertBefore(n,t==="title"?e.querySelector("head > title"):null)}function Ug(e,t,n){if(n===1||t.itemProp!=null)return!1;switch(e){case"meta":case"title":return!0;case"style":if(typeof t.precedence!="string"||typeof t.href!="string"||t.href==="")break;return!0;case"link":if(typeof t.rel!="string"||typeof t.href!="string"||t.href===""||t.onLoad||t.onError)break;return t.rel==="stylesheet"?(e=t.disabled,typeof t.precedence=="string"&&e==null):!0;case"script":if(t.async&&typeof t.async!="function"&&typeof t.async!="symbol"&&!t.onLoad&&!t.onError&&t.src&&typeof t.src=="string")return!0}return!1}function ep(e){return!(e.type==="stylesheet"&&(e.state.loading&3)===0)}function qg(e,t,n,i){if(n.type==="stylesheet"&&(typeof i.media!="string"||matchMedia(i.media).matches!==!1)&&(n.state.loading&4)===0){if(n.instance===null){var r=Li(i.href),o=t.querySelector(gr(r));if(o){t=o._p,t!==null&&typeof t=="object"&&typeof t.then=="function"&&(e.count++,e=Do.bind(e),t.then(e,e)),n.state.loading|=4,n.instance=o,Le(o);return}o=t.ownerDocument||t,i=Yd(i),(r=ht.get(r))&&Ys(i,r),o=o.createElement("link"),Le(o);var a=o;a._p=new Promise(function(s,l){a.onload=s,a.onerror=l}),Re(o,"link",i),n.instance=o}e.stylesheets===null&&(e.stylesheets=new Map),e.stylesheets.set(n,t),(t=n.state.preload)&&(n.state.loading&3)===0&&(e.count++,n=Do.bind(e),t.addEventListener("load",n),t.addEventListener("error",n))}}var Xs=0;function Bg(e,t){return e.stylesheets&&e.count===0&&Oo(e,e.stylesheets),0<e.count||0<e.imgCount?function(n){var i=setTimeout(function(){if(e.stylesheets&&Oo(e,e.stylesheets),e.unsuspend){var o=e.unsuspend;e.unsuspend=null,o()}},6e4+t);0<e.imgBytes&&Xs===0&&(Xs=62500*Cg());var r=setTimeout(function(){if(e.waitingForImages=!1,e.count===0&&(e.stylesheets&&Oo(e,e.stylesheets),e.unsuspend)){var o=e.unsuspend;e.unsuspend=null,o()}},(e.imgBytes>Xs?50:800)+t);return e.unsuspend=n,function(){e.unsuspend=null,clearTimeout(i),clearTimeout(r)}}:null}function Do(){if(this.count--,this.count===0&&(this.imgCount===0||!this.waitingForImages)){if(this.stylesheets)Oo(this,this.stylesheets);else if(this.unsuspend){var e=this.unsuspend;this.unsuspend=null,e()}}}var Po=null;function Oo(e,t){e.stylesheets=null,e.unsuspend!==null&&(e.count++,Po=new Map,t.forEach(zg,e),Po=null,Do.call(e))}function zg(e,t){if(!(t.state.loading&4)){var n=Po.get(e);if(n)var i=n.get(null);else{n=new Map,Po.set(e,n);for(var r=e.querySelectorAll("link[data-precedence],style[data-precedence]"),o=0;o<r.length;o++){var a=r[o];(a.nodeName==="LINK"||a.getAttribute("media")!=="not all")&&(n.set(a.dataset.precedence,a),i=a)}i&&n.set(null,i)}r=t.instance,a=r.getAttribute("data-precedence"),o=n.get(a)||i,o===i&&n.set(null,r),n.set(a,r),this.count++,i=Do.bind(this),r.addEventListener("load",i),r.addEventListener("error",i),o?o.parentNode.insertBefore(r,o.nextSibling):(e=e.nodeType===9?e.head:e,e.insertBefore(r,e.firstChild)),t.state.loading|=4}}var hr={$$typeof:Pe,Provider:null,Consumer:null,_currentValue:O,_currentValue2:O,_threadCount:0};function Gg(e,t,n,i,r,o,a,s,l){this.tag=1,this.containerInfo=e,this.pingCache=this.current=this.pendingChildren=null,this.timeoutHandle=-1,this.callbackNode=this.next=this.pendingContext=this.context=this.cancelPendingCommit=null,this.callbackPriority=0,this.expirationTimes=Qo(-1),this.entangledLanes=this.shellSuspendCounter=this.errorRecoveryDisabledLanes=this.expiredLanes=this.warmLanes=this.pingedLanes=this.suspendedLanes=this.pendingLanes=0,this.entanglements=Qo(0),this.hiddenUpdates=Qo(null),this.identifierPrefix=i,this.onUncaughtError=r,this.onCaughtError=o,this.onRecoverableError=a,this.pooledCache=null,this.pooledCacheLanes=0,this.formState=l,this.incompleteTransitions=new Map}function tp(e,t,n,i,r,o,a,s,l,m,v,S){return e=new Gg(e,t,n,a,l,m,v,S,s),t=1,o===!0&&(t|=24),o=Ze(3,null,null,t),e.current=o,o.stateNode=e,t=Da(),t.refCount++,e.pooledCache=t,t.refCount++,o.memoizedState={element:i,isDehydrated:n,cache:t},Na(o),e}function np(e){return e?(e=ni,e):ni}function ip(e,t,n,i,r,o){r=np(r),i.context===null?i.context=r:i.pendingContext=r,i=on(t),i.payload={element:n},o=o===void 0?null:o,o!==null&&(i.callback=o),n=an(e,i,t),n!==null&&(Qe(n,e,t),Ki(n,e,t))}function rp(e,t){if(e=e.memoizedState,e!==null&&e.dehydrated!==null){var n=e.retryLane;e.retryLane=n!==0&&n<t?n:t}}function Zs(e,t){rp(e,t),(e=e.alternate)&&rp(e,t)}function op(e){if(e.tag===13||e.tag===31){var t=In(e,67108864);t!==null&&Qe(t,e,67108864),Zs(e,67108864)}}function ap(e){if(e.tag===13||e.tag===31){var t=rt();t=Ko(t);var n=In(e,t);n!==null&&Qe(n,e,t),Zs(e,t)}}var xo=!0;function Hg(e,t,n,i){var r=f.T;f.T=null;var o=w.p;try{w.p=2,el(e,t,n,i)}finally{w.p=o,f.T=r}}function jg(e,t,n,i){var r=f.T;f.T=null;var o=w.p;try{w.p=8,el(e,t,n,i)}finally{w.p=o,f.T=r}}function el(e,t,n,i){if(xo){var r=tl(i);if(r===null)zs(e,t,i,No,n),lp(e,i);else if(_g(r,e,t,n,i))i.stopPropagation();else if(lp(e,i),t&4&&-1<Fg.indexOf(e)){for(;r!==null;){var o=_n(r);if(o!==null)switch(o.tag){case 3:if(o=o.stateNode,o.current.memoizedState.isDehydrated){var a=Ln(o.pendingLanes);if(a!==0){var s=o;for(s.pendingLanes|=2,s.entangledLanes|=2;a;){var l=1<<31-Je(a);s.entanglements[1]|=l,a&=~l}Wt(o),(ee&6)===0&&(vo=$e()+500,ur(0))}}break;case 31:case 13:s=In(o,2),s!==null&&Qe(s,o,2),Co(),Zs(o,2)}if(o=tl(i),o===null&&zs(e,t,i,No,n),o===r)break;r=o}r!==null&&i.stopPropagation()}else zs(e,t,i,null,n)}}function tl(e){return e=ia(e),nl(e)}var No=null;function nl(e){if(No=null,e=Fn(e),e!==null){var t=F(e);if(t===null)e=null;else{var n=t.tag;if(n===13){if(e=Y(t),e!==null)return e;e=null}else if(n===31){if(e=Z(t),e!==null)return e;e=null}else if(n===3){if(t.stateNode.current.memoizedState.isDehydrated)return t.tag===3?t.stateNode.containerInfo:null;e=null}else t!==e&&(e=null)}}return No=e,null}function sp(e){switch(e){case"beforetoggle":case"cancel":case"click":case"close":case"contextmenu":case"copy":case"cut":case"auxclick":case"dblclick":case"dragend":case"dragstart":case"drop":case"focusin":case"focusout":case"input":case"invalid":case"keydown":case"keypress":case"keyup":case"mousedown":case"mouseup":case"paste":case"pause":case"play":case"pointercancel":case"pointerdown":case"pointerup":case"ratechange":case"reset":case"resize":case"seeked":case"submit":case"toggle":case"touchcancel":case"touchend":case"touchstart":case"volumechange":case"change":case"selectionchange":case"textInput":case"compositionstart":case"compositionend":case"compositionupdate":case"beforeblur":case"afterblur":case"beforeinput":case"blur":case"fullscreenchange":case"focus":case"hashchange":case"popstate":case"select":case"selectstart":return 2;case"drag":case"dragenter":case"dragexit":case"dragleave":case"dragover":case"mousemove":case"mouseout":case"mouseover":case"pointermove":case"pointerout":case"pointerover":case"scroll":case"touchmove":case"wheel":case"mouseenter":case"mouseleave":case"pointerenter":case"pointerleave":return 8;case"message":switch(Ip()){case yl:return 2;case hl:return 8;case wr:case Rp:return 32;case vl:return 268435456;default:return 32}default:return 32}}var il=!1,vn=null,fn=null,Cn=null,vr=new Map,fr=new Map,bn=[],Fg="mousedown mouseup touchcancel touchend touchstart auxclick dblclick pointercancel pointerdown pointerup dragend dragstart drop compositionend compositionstart keydown keypress keyup input textInput copy cut paste click change contextmenu reset".split(" ");function lp(e,t){switch(e){case"focusin":case"focusout":vn=null;break;case"dragenter":case"dragleave":fn=null;break;case"mouseover":case"mouseout":Cn=null;break;case"pointerover":case"pointerout":vr.delete(t.pointerId);break;case"gotpointercapture":case"lostpointercapture":fr.delete(t.pointerId)}}function Cr(e,t,n,i,r,o){return e===null||e.nativeEvent!==o?(e={blockedOn:t,domEventName:n,eventSystemFlags:i,nativeEvent:o,targetContainers:[r]},t!==null&&(t=_n(t),t!==null&&op(t)),e):(e.eventSystemFlags|=i,t=e.targetContainers,r!==null&&t.indexOf(r)===-1&&t.push(r),e)}function _g(e,t,n,i,r){switch(t){case"focusin":return vn=Cr(vn,e,t,n,i,r),!0;case"dragenter":return fn=Cr(fn,e,t,n,i,r),!0;case"mouseover":return Cn=Cr(Cn,e,t,n,i,r),!0;case"pointerover":var o=r.pointerId;return vr.set(o,Cr(vr.get(o)||null,e,t,n,i,r)),!0;case"gotpointercapture":return o=r.pointerId,fr.set(o,Cr(fr.get(o)||null,e,t,n,i,r)),!0}return!1}function cp(e){var t=Fn(e.target);if(t!==null){var n=F(t);if(n!==null){if(t=n.tag,t===13){if(t=Y(n),t!==null){e.blockedOn=t,wl(e.priority,function(){ap(n)});return}}else if(t===31){if(t=Z(n),t!==null){e.blockedOn=t,wl(e.priority,function(){ap(n)});return}}else if(t===3&&n.stateNode.current.memoizedState.isDehydrated){e.blockedOn=n.tag===3?n.stateNode.containerInfo:null;return}}}e.blockedOn=null}function Mo(e){if(e.blockedOn!==null)return!1;for(var t=e.targetContainers;0<t.length;){var n=tl(e.nativeEvent);if(n===null){n=e.nativeEvent;var i=new n.constructor(n.type,n);na=i,n.target.dispatchEvent(i),na=null}else return t=_n(n),t!==null&&op(t),e.blockedOn=n,!1;t.shift()}return!0}function up(e,t,n){Mo(e)&&n.delete(t)}function Vg(){il=!1,vn!==null&&Mo(vn)&&(vn=null),fn!==null&&Mo(fn)&&(fn=null),Cn!==null&&Mo(Cn)&&(Cn=null),vr.forEach(up),fr.forEach(up)}function Uo(e,t){e.blockedOn===t&&(e.blockedOn=null,il||(il=!0,T.unstable_scheduleCallback(T.unstable_NormalPriority,Vg)))}var qo=null;function dp(e){qo!==e&&(qo=e,T.unstable_scheduleCallback(T.unstable_NormalPriority,function(){qo===e&&(qo=null);for(var t=0;t<e.length;t+=3){var n=e[t],i=e[t+1],r=e[t+2];if(typeof i!="function"){if(nl(i||n)===null)continue;break}var o=_n(n);o!==null&&(e.splice(t,3),t-=3,ts(o,{pending:!0,data:r,method:n.method,action:i},i,r))}}))}function Ei(e){function t(l){return Uo(l,e)}vn!==null&&Uo(vn,e),fn!==null&&Uo(fn,e),Cn!==null&&Uo(Cn,e),vr.forEach(t),fr.forEach(t);for(var n=0;n<bn.length;n++){var i=bn[n];i.blockedOn===e&&(i.blockedOn=null)}for(;0<bn.length&&(n=bn[0],n.blockedOn===null);)cp(n),n.blockedOn===null&&bn.shift();if(n=(e.ownerDocument||e).$$reactFormReplay,n!=null)for(i=0;i<n.length;i+=3){var r=n[i],o=n[i+1],a=r[Ge]||null;if(typeof o=="function")a||dp(n);else if(a){var s=null;if(o&&o.hasAttribute("formAction")){if(r=o,a=o[Ge]||null)s=a.formAction;else if(nl(r)!==null)continue}else s=a.action;typeof s=="function"?n[i+1]=s:(n.splice(i,3),i-=3),dp(n)}}}function pp(){function e(o){o.canIntercept&&o.info==="react-transition"&&o.intercept({handler:function(){return new Promise(function(a){return r=a})},focusReset:"manual",scroll:"manual"})}function t(){r!==null&&(r(),r=null),i||setTimeout(n,20)}function n(){if(!i&&!navigation.transition){var o=navigation.currentEntry;o&&o.url!=null&&navigation.navigate(o.url,{state:o.getState(),info:"react-transition",history:"replace"})}}if(typeof navigation=="object"){var i=!1,r=null;return navigation.addEventListener("navigate",e),navigation.addEventListener("navigatesuccess",t),navigation.addEventListener("navigateerror",t),setTimeout(n,100),function(){i=!0,navigation.removeEventListener("navigate",e),navigation.removeEventListener("navigatesuccess",t),navigation.removeEventListener("navigateerror",t),r!==null&&(r(),r=null)}}}function rl(e){this._internalRoot=e}Bo.prototype.render=rl.prototype.render=function(e){var t=this._internalRoot;if(t===null)throw Error(y(409));var n=t.current,i=rt();ip(n,i,e,t,null,null)},Bo.prototype.unmount=rl.prototype.unmount=function(){var e=this._internalRoot;if(e!==null){this._internalRoot=null;var t=e.containerInfo;ip(e.current,2,null,e,null,null),Co(),t[jn]=null}};function Bo(e){this._internalRoot=e}Bo.prototype.unstable_scheduleHydration=function(e){if(e){var t=Al();e={blockedOn:null,target:e,priority:t};for(var n=0;n<bn.length&&t!==0&&t<bn[n].priority;n++);bn.splice(n,0,e),n===0&&cp(e)}};var mp=ue.version;if(mp!=="19.2.4")throw Error(y(527,mp,"19.2.4"));w.findDOMNode=function(e){var t=e._reactInternals;if(t===void 0)throw typeof e.render=="function"?Error(y(188)):(e=Object.keys(e).join(","),Error(y(268,e)));return e=b(t),e=e!==null?B(e):null,e=e===null?null:e.stateNode,e};var Qg={bundleType:0,version:"19.2.4",rendererPackageName:"react-dom",currentDispatcherRef:f,reconcilerVersion:"19.2.4"};if(typeof __REACT_DEVTOOLS_GLOBAL_HOOK__<"u"){var zo=__REACT_DEVTOOLS_GLOBAL_HOOK__;if(!zo.isDisabled&&zo.supportsFiber)try{ki=zo.inject(Qg),Ye=zo}catch{}}return Sr.createRoot=function(e,t){if(!N(e))throw Error(y(299));var n=!1,i="",r=bu,o=Su,a=Au;return t!=null&&(t.unstable_strictMode===!0&&(n=!0),t.identifierPrefix!==void 0&&(i=t.identifierPrefix),t.onUncaughtError!==void 0&&(r=t.onUncaughtError),t.onCaughtError!==void 0&&(o=t.onCaughtError),t.onRecoverableError!==void 0&&(a=t.onRecoverableError)),t=tp(e,1,!1,null,null,n,i,null,r,o,a,pp),e[jn]=t.current,Bs(e),new rl(t)},Sr.hydrateRoot=function(e,t,n){if(!N(e))throw Error(y(299));var i=!1,r="",o=bu,a=Su,s=Au,l=null;return n!=null&&(n.unstable_strictMode===!0&&(i=!0),n.identifierPrefix!==void 0&&(r=n.identifierPrefix),n.onUncaughtError!==void 0&&(o=n.onUncaughtError),n.onCaughtError!==void 0&&(a=n.onCaughtError),n.onRecoverableError!==void 0&&(s=n.onRecoverableError),n.formState!==void 0&&(l=n.formState)),t=tp(e,1,!0,t,n??null,i,r,l,o,a,s,pp),t.context=np(null),n=t.current,i=rt(),i=Ko(i),r=on(i),r.callback=null,an(n,r,i),n=i,t.current.lanes=n,Ri(t,n),Wt(t),e[jn]=t.current,Bs(e),new Bo(t)},Sr.version="19.2.4",Sr}var wp;function iy(){if(wp)return sl.exports;wp=1;function T(){if(!(typeof __REACT_DEVTOOLS_GLOBAL_HOOK__>"u"||typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.checkDCE!="function"))try{__REACT_DEVTOOLS_GLOBAL_HOOK__.checkDCE(T)}catch(ue){console.error(ue)}}return T(),sl.exports=ny(),sl.exports}var ry=iy();const oy="modulepreload",ay=function(T){return"/"+T},Lp={},Tp=function(ue,j,y){let N=Promise.resolve();if(j&&j.length>0){let I=function(b){return Promise.all(b.map(B=>Promise.resolve(B).then(D=>({status:"fulfilled",value:D}),D=>({status:"rejected",reason:D}))))};document.getElementsByTagName("link");const Y=document.querySelector("meta[property=csp-nonce]"),Z=Y?.nonce||Y?.getAttribute("nonce");N=I(j.map(b=>{if(b=ay(b),b in Lp)return;Lp[b]=!0;const B=b.endsWith(".css"),D=B?'[rel="stylesheet"]':"";if(document.querySelector(`link[href="${b}"]${D}`))return;const $=document.createElement("link");if($.rel=B?"stylesheet":oy,B||($.as="script"),$.crossOrigin="",$.href=b,Z&&$.setAttribute("nonce",Z),document.head.appendChild($),B)return new Promise((xe,De)=>{$.addEventListener("load",xe),$.addEventListener("error",()=>De(new Error(`Unable to preload CSS for ${b}`)))})}))}function F(Y){const Z=new Event("vite:preloadError",{cancelable:!0});if(Z.payload=Y,window.dispatchEvent(Z),!Z.defaultPrevented)throw Y}return N.then(Y=>{for(const Z of Y||[])Z.status==="rejected"&&F(Z.reason);return ue().catch(F)})},sy={id:"js-basics",name:"Basics",questions:[{id:"q1",question:"What are the different data types in JavaScript?",answer:"JavaScript has 8 data types: Number, String, Boolean, Null, Undefined, Symbol, BigInt, and Object. Primitive types are immutable, while objects are mutable reference types.",codeSnippets:[{language:"javascript",code:`// Primitive types
const num = 42;
const str = "Hello";
const bool = true;
const sym = Symbol("id");
const bigInt = 123n;
const nul = null;
const undef = undefined;

// Non-primitive (Reference types)
const obj = { name: "John" };
const arr = [1, 2, 3];
const func = () => {}; // Functions are objects`}]},{id:"q2",question:"What is the difference between var, let, and const?",answer:"var is function-scoped and hoisted. let and const are block-scoped and not hoisted. const cannot be reassigned, but object properties can be modified.",codeSnippets:[{language:"javascript",code:`// var - function scoped, hoisted
function test() {
  if (true) {
    var x = 1;
  }
  console.log(x); // 1
}

// let - block scoped, temporal dead zone
function test2() {
  console.log(y); // ReferenceError: Cannot access 'y' before initialization
  let y = 2;
}

// const - block scoped, cannot reassign
const z = 3;
z = 4; // TypeError: Assignment to constant variable
const obj = { a: 1 };
obj.a = 2; // OK - object properties can change`}]},{id:"q3",question:"What is hoisting in JavaScript?",answer:"Hoisting is JavaScript's behavior of moving declarations to the top of their scope before code execution. Variables declared with var are hoisted and initialized with undefined, while let and const are hoisted but not initialized.",codeSnippets:[{language:"javascript",code:`// var hoisting
console.log(x); // undefined (hoisted but not initialized)
var x = 5;

// let/const hoisting with temporal dead zone
console.log(y); // ReferenceError
let y = 10;

// Function hoisting
sayHi(); // "Hello" - function works before declaration
function sayHi() {
  console.log("Hello");
}

// Function expression not hoisted
greet(); // TypeError: greet is not a function
const greet = () => console.log("Hi");`}]},{id:"q4",question:"What is the difference between == and ===?",answer:"== performs type coercion before comparison, while === compares both value and type without coercion. Use === in production code to avoid unexpected results.",codeSnippets:[{language:"javascript",code:`// == (loose equality) - type coercion
0 == false;        // true
"0" == 0;          // true
null == undefined; // true
"5" == 5;          // true

// === (strict equality) - no type coercion
0 === false;       // false
"0" === 0;         // false
null === undefined;// false
"5" === 5;         // false

// Best practice: Always use ===
if (value === null) { }
if (value === undefined) { }
if (value === true) { }`}]},{id:"q5",question:"What is NaN and how to check for it?",answer:"NaN (Not-a-Number) is a special value representing an undefined or unrepresentable mathematical result. Use Number.isNaN() or Object.is() for checking, not the global isNaN().",codeSnippets:[{language:"javascript",code:`// NaN creation
const result = parseInt("hello"); // NaN
const calc = 0 / 0;              // NaN

// WRONG way to check
isNaN("hello");  // true (coerces to number first)
NaN === NaN;     // false (NaN is not equal to itself)

// CORRECT ways to check
Number.isNaN(result);   // true
Object.is(result, NaN); // true
typeof result === 'number' && isNaN(result);

// Safe arithmetic
const num = 0 / 0;
if (Number.isNaN(num)) {
  console.log("Invalid calculation");
}`}]}]},ly={id:"js-async",name:"Asynchronous Programming",questions:[{id:"q6",question:"What is a Promise in JavaScript?",answer:"A Promise is an object representing the eventual completion (or failure) of an asynchronous operation and its resulting value. It has three states: pending, fulfilled, or rejected.",codeSnippets:[{language:"javascript",code:`const promise = new Promise((resolve, reject) => {
  setTimeout(() => {
    const success = Math.random() > 0.5;
    if (success) {
      resolve("Success!");
    } else {
      reject("Failed!");
    }
  }, 1000);
});

promise
  .then(result => console.log(result))
  .catch(error => console.log(error))
  .finally(() => console.log("Done"));`}]},{id:"q7",question:"What is async/await?",answer:"Async/await is syntactic sugar over promises that allows you to write asynchronous code that looks synchronous. async functions always return a Promise.",codeSnippets:[{language:"javascript",code:`// async/await example
async function fetchUserData(userId) {
  try {
    const response = await fetch(\`/api/users/\${userId}\`);
    if (!response.ok) throw new Error('Not found');
    const data = await response.json();
    return data;
  } catch (error) {
    console.log('Error:', error.message);
    throw error;
  }
}

// Using async function
const user = await fetchUserData(1);
console.log(user);

// Parallel requests
const [users, posts] = await Promise.all([
  fetch('/api/users').then(r => r.json()),
  fetch('/api/posts').then(r => r.json())
]);`}]},{id:"q8",question:"What is the difference between Promise.all, Promise.race, and Promise.allSettled?",answer:"Promise.all waits for all promises to resolve or any to reject. Promise.race returns the first settled promise. Promise.allSettled waits for all to settle regardless of outcome.",codeSnippets:[{language:"javascript",code:`const p1 = Promise.resolve(1);
const p2 = new Promise(r => setTimeout(() => r(2), 100));
const p3 = Promise.reject("error");

// Promise.all - rejects if any promise rejects
Promise.all([p1, p2])
  .then(results => console.log(results)) // [1, 2]
  .catch(err => console.log("Error:", err));

// Promise.race - returns first settled
Promise.race([p1, p2])
  .then(result => console.log(result)); // 1

// Promise.allSettled - waits for all
Promise.allSettled([p1, p2, p3])
  .then(results => console.log(results));
  // [
  //   { status: 'fulfilled', value: 1 },
  //   { status: 'fulfilled', value: 2 },
  //   { status: 'rejected', reason: 'error' }
  // ]`}]},{id:"q9",question:"What is the event loop in JavaScript?",answer:"The event loop is JavaScript's mechanism for handling asynchronous operations. It monitors the call stack and callback queue, executing callbacks when the stack is empty.",codeSnippets:[{language:"javascript",code:`console.log('Start');

setTimeout(() => {
  console.log('Timeout');
}, 0);

Promise.resolve()
  .then(() => console.log('Promise'));

console.log('End');

// Output:
// Start
// End
// Promise (microtask queue runs before macrotask queue)
// Timeout

// Macrotasks: setTimeout, setInterval, setImmediate
// Microtasks: Promise, MutationObserver, queueMicrotask`}]},{id:"q10",question:"What are callbacks and what is callback hell?",answer:"Callbacks are functions passed as arguments to other functions. Callback hell (pyramid of doom) occurs with deeply nested callbacks, making code hard to read and maintain.",codeSnippets:[{language:"javascript",code:`// Callback Hell - hard to read and maintain
getData(id, function(err, data) {
  if (err) {
    console.error(err);
  } else {
    getUser(data.userId, function(err, user) {
      if (err) {
        console.error(err);
      } else {
        getPosts(user.id, function(err, posts) {
          if (err) {
            console.error(err);
          } else {
            console.log(posts);
          }
        });
      }
    });
  }
});

// Better approach with Promises
getData(id)
  .then(data => getUser(data.userId))
  .then(user => getPosts(user.id))
  .then(posts => console.log(posts))
  .catch(err => console.error(err));

// Best approach with async/await
async function displayPosts(id) {
  try {
    const data = await getData(id);
    const user = await getUser(data.userId);
    const posts = await getPosts(user.id);
    console.log(posts);
  } catch (err) {
    console.error(err);
  }
}`}]}]},cy={id:"js-closures",name:"Closures & Scope",questions:[{id:"q23",question:"What is a closure in JavaScript?",answer:"A closure is a function that has access to variables in its outer scope even after the outer function has returned. Functions form closures around the data they need.",codeSnippets:[{language:"javascript",code:`// Simple closure
function outer() {
  const message = 'Hello'; // Variable in outer scope

  function inner() {
    console.log(message); // inner has access to message
  }

  return inner;
}

const fn = outer();
fn(); // 'Hello' - closure retains access to message

// Practical example: Counter
function createCounter() {
  let count = 0;

  return {
    increment: () => ++count,
    decrement: () => --count,
    getCount: () => count
  };
}

const counter = createCounter();
counter.increment(); // 1
counter.increment(); // 2
counter.decrement(); // 1
console.log(counter.getCount()); // 1

// count is private and only accessible through returned methods
// This is data encapsulation through closure

// Closure in loops
const functions = [];
for (var i = 0; i < 3; i++) {
  functions.push(() => console.log(i));
}
functions[0](); // 3 (var is function-scoped)
functions[1](); // 3
functions[2](); // 3

// Fix with closure
const functions2 = [];
for (let i = 0; i < 3; i++) {
  functions2.push(() => console.log(i));
}
functions2[0](); // 0 (let is block-scoped)
functions2[1](); // 1
functions2[2](); // 2`}]},{id:"q24",question:"What is scope and how many types of scope are there?",answer:"Scope determines where variables are accessible. Types: Global scope (whole program), Function scope (inside function), Block scope (inside {}, for, if), and Lexical scope (inner functions access outer variables).",codeSnippets:[{language:"javascript",code:`// Global scope
const global = 'I am global';

function functionScope() {
  // Function scope
  const local = 'I am local';
  
  if (true) {
    // Block scope
    const blockLocal = 'I am block scoped';
    console.log(blockLocal); // Accessible
  }
  
  console.log(blockLocal); // ReferenceError - not accessible
  console.log(global); // Accessible - lexical scope
}

console.log(local); // ReferenceError - not accessible outside function

// Lexical scope example
function outer() {
  const x = 10;

  function middle() {
    const y = 20;

    function inner() {
      const z = 30;
      console.log(x, y, z); // 10 20 30 - access parent scopes
    }

    inner();
  }

  middle();
}

// Scope chain - JavaScript looks up the scope chain
// inner -> middle -> outer -> global`}]}]},uy={id:"js-this",name:"'this' Binding & Objects",questions:[{id:"q25",question:"What is 'this' in JavaScript and how is it determined?",answer:"'this' is a keyword that refers to the object context. Its value is determined by HOW a function is called: as method (object), function, constructor, or with call/apply/bind.",codeSnippets:[{language:"javascript",code:`// 1. Method call - 'this' is the object
const obj = {
  name: 'Alice',
  greet() {
    console.log('Hello, ' + this.name);
  }
};
obj.greet(); // 'Hello, Alice'

// 2. Regular function call - 'this' is undefined (strict) or global
function sayName() {
  console.log(this.name);
}
sayName(); // undefined or window.name

// 3. Constructor call - 'this' is the new object
function Person(name) {
  this.name = name;
}
const person = new Person('Bob');
console.log(person.name); // 'Bob'

// 4. call/apply/bind - explicitly set 'this'
function introduce() {
  console.log('I am ' + this.name);
}
const user = { name: 'Charlie' };
introduce.call(user); // 'I am Charlie'
introduce.apply(user); // 'I am Charlie'

const bound = introduce.bind(user);
bound(); // 'I am Charlie'

// 5. Arrow function - 'this' from enclosing scope
const team = {
  name: 'Dev Team',
  members: ['Alice', 'Bob'],
  list() {
    this.members.forEach(member => {
      console.log(this.name + ': ' + member); // 'this' is team
    });
  }
};
team.list();`}]},{id:"q26",question:"What is the difference between call, apply, and bind?",answer:"call and apply invoke the function immediately and set 'this'. call takes arguments separately, apply takes an array. bind returns a new function with 'this' set but doesn't invoke it.",codeSnippets:[{language:"javascript",code:`function introduce(greeting, punctuation) {
  return greeting + ', ' + this.name + punctuation;
}

const person = { name: 'Alice' };

// call - invoke immediately, args separated
introduce.call(person, 'Hello', '!');
// 'Hello, Alice!'

// apply - invoke immediately, args in array
introduce.apply(person, ['Hi', '?']);
// 'Hi, Alice?'

// bind - return new function, doesn't invoke
const boundIntroduce = introduce.bind(person, 'Hey');
boundIntroduce('!!!');
// 'Hey, Alice!!!'

// Real-world example: Borrowing methods
const array = [1, 2, 3];
const arrayLike = { 0: 'a', 1: 'b', 2: 'c', length: 3 };

// Borrow Array.prototype.join
Array.prototype.join.call(arrayLike, '-');
// 'a-b-c'

// Borrow Array.prototype.forEach
Array.prototype.forEach.call(arrayLike, item => console.log(item));`}]}]},dy={id:"js-prototypes",name:"Prototypes & Inheritance",questions:[{id:"q27",question:"What are prototypes in JavaScript?",answer:"Prototypes are objects that other objects can inherit properties and methods from. Every object has a prototype ([[Prototype]]). Objects delegate to their prototype when a property is not found.",codeSnippets:[{language:"javascript",code:`// Prototype chain
const person = {
  greet() {
    console.log('Hello');
  }
};

const alice = Object.create(person);
alice.name = 'Alice';

alice.greet(); // 'Hello' - inherited from prototype

// Constructor function and prototype
function Animal(name) {
  this.name = name;
}

Animal.prototype.speak = function() {
  console.log(this.name + ' speaks');
};

const dog = new Animal('Dog');
dog.speak(); // 'Dog speaks'

// Prototype chain lookup
console.log(dog.hasOwnProperty('name')); // true - own property
console.log(dog.hasOwnProperty('speak')); // false - on prototype
console.log('speak' in dog); // true - found in chain

// Check prototype
console.log(Object.getPrototypeOf(dog) === Animal.prototype); // true
console.log(dog instanceof Animal); // true

// Modify prototype
Animal.prototype.move = function() {
  console.log(this.name + ' moves');
};
dog.move(); // 'Dog moves' - new method available`}]},{id:"q28",question:"What is the difference between inheritance with prototypes and classes?",answer:"Prototypal inheritance uses prototype objects and Object.create. Class inheritance uses the class syntax (ES6), which is syntactic sugar over prototypal inheritance.",codeSnippets:[{language:"javascript",code:`// Prototypal Inheritance
function Animal(name) {
  this.name = name;
}
Animal.prototype.speak = function() {
  console.log(this.name + ' speaks');
};

function Dog(name, breed) {
  Animal.call(this, name); // Call parent constructor
  this.breed = breed;
}
Dog.prototype = Object.create(Animal.prototype);
Dog.prototype.constructor = Dog;
Dog.prototype.bark = function() {
  console.log(this.name + ' barks');
};

const dog = new Dog('Rex', 'Labrador');
dog.speak(); // 'Rex speaks'
dog.bark();  // 'Rex barks'

// Class Inheritance (ES6 - much cleaner!)
class Animal {
  constructor(name) {
    this.name = name;
  }
  
  speak() {
    console.log(this.name + ' speaks');
  }
}

class Dog extends Animal {
  constructor(name, breed) {
    super(name); // Call parent constructor
    this.breed = breed;
  }
  
  bark() {
    console.log(this.name + ' barks');
  }
}

const dog = new Dog('Rex', 'Labrador');
dog.speak(); // 'Rex speaks'
dog.bark();  // 'Rex barks'

// Both are equivalent - classes are syntactic sugar over prototypes`}]}]},py={id:"js-copy-methods",name:"Shallow & Deep Copy",questions:[{id:"q1",question:"What is the difference between Shallow Copy and Deep Copy in JavaScript?",answer:`Shallow Copy creates a new object but only copies the first level of properties. Nested objects/arrays are still references to the original. Deep Copy creates a completely independent clone where all nested objects are also copied.

Shallow Copy:
 Copies only the first level of properties
 Nested objects share the same reference
 Changes to nested objects affect both copies
 Faster and uses less memory

Deep Copy:
 Recursively copies all nested objects
 Creates completely independent clone
 Changes don't affect the original
 Slower and uses more memory

When to use:
 Shallow Copy: When you have flat objects or don't need to modify nested properties
 Deep Copy: When you need complete independence from the original object`,codeSnippets:[{language:"javascript",code:`// Original object with nested data
const original = {
  name: "John",
  age: 30,
  address: {
    city: "New York",
    zip: "10001"
  },
  hobbies: ["reading", "gaming"]
};

// SHALLOW COPY - nested objects are still references
const shallowCopy = { ...original };

shallowCopy.name = "Jane";           //  Only changes copy
shallowCopy.address.city = "Boston"; //  Changes BOTH!

console.log(original.name);          // "John" (unchanged)
console.log(original.address.city);  // "Boston" (changed!)

// DEEP COPY - completely independent
const deepCopy = JSON.parse(JSON.stringify(original));

deepCopy.address.city = "Chicago";   //  Only changes copy
console.log(original.address.city);  // "Boston" (unchanged)`}]},{id:"q2",question:"What are all the ways to create a Shallow Copy in JavaScript?",answer:`There are several methods to create shallow copies in JavaScript:

1. Spread Operator (...) - Most common and readable
2. Object.assign() - Classic method, good browser support
3. Array.slice() - For arrays only
4. Array.from() - For arrays and array-like objects
5. Array.prototype.concat() - For arrays

All these methods only copy the first level of properties. Nested objects and arrays remain as references to the original.`,codeSnippets:[{language:"javascript",code:`const original = {
  name: "John",
  scores: [90, 85, 88],
  details: { role: "admin" }
};

// 1. Spread Operator (ES6+) - Recommended
const copy1 = { ...original };

// 2. Object.assign()
const copy2 = Object.assign({}, original);

// 3. For arrays - spread
const arrOriginal = [1, 2, { a: 1 }];
const arrCopy1 = [...arrOriginal];

// 4. Array.slice()
const arrCopy2 = arrOriginal.slice();

// 5. Array.from()
const arrCopy3 = Array.from(arrOriginal);

// 6. Array.concat()
const arrCopy4 = [].concat(arrOriginal);

// All shallow copies share nested references!
copy1.details.role = "user";
console.log(original.details.role); // "user" - also changed!

arrCopy1[2].a = 999;
console.log(arrOriginal[2].a); // 999 - also changed!`}]},{id:"q3",question:"What are all the ways to create a Deep Copy in JavaScript?",answer:`Methods to create deep copies:

1. JSON.parse(JSON.stringify()) - Simple but has limitations
2. structuredClone() - Modern built-in method (ES2022)
3. Lodash _.cloneDeep() - Library method, handles edge cases
4. Custom recursive function - Full control

Limitations of JSON method:
 Loses functions, undefined, Symbol
 Doesn't handle circular references
 Converts Date to string
 Loses prototype chain

structuredClone() handles most cases but not functions or DOM nodes.`,codeSnippets:[{language:"javascript",code:`const original = {
  name: "John",
  date: new Date(),
  nested: { deep: { value: 42 } },
  arr: [1, 2, [3, 4]]
};

// 1. JSON.parse/stringify - Simple cases only
const copy1 = JSON.parse(JSON.stringify(original));
//  Date becomes string, loses functions/undefined

// 2. structuredClone() - Modern & Recommended (ES2022)
const copy2 = structuredClone(original);
//  Handles Date, Map, Set, ArrayBuffer, circular refs
//  Can't clone functions, DOM nodes, or Error objects

// 3. Lodash (if using library)
// import _ from 'lodash';
// const copy3 = _.cloneDeep(original);

// Verify deep independence
copy2.nested.deep.value = 100;
console.log(original.nested.deep.value); // 42 (unchanged!)

copy2.arr[2][0] = 999;
console.log(original.arr[2][0]); // 3 (unchanged!)`},{language:"javascript",code:`// 4. Custom Deep Clone Function
function deepClone(obj, hash = new WeakMap()) {
  // Handle primitives and null
  if (obj === null || typeof obj !== 'object') {
    return obj;
  }
  
  // Handle circular references
  if (hash.has(obj)) {
    return hash.get(obj);
  }
  
  // Handle Date
  if (obj instanceof Date) {
    return new Date(obj.getTime());
  }
  
  // Handle Array
  if (Array.isArray(obj)) {
    const arrCopy = [];
    hash.set(obj, arrCopy);
    obj.forEach((item, index) => {
      arrCopy[index] = deepClone(item, hash);
    });
    return arrCopy;
  }
  
  // Handle Map
  if (obj instanceof Map) {
    const mapCopy = new Map();
    hash.set(obj, mapCopy);
    obj.forEach((value, key) => {
      mapCopy.set(deepClone(key, hash), deepClone(value, hash));
    });
    return mapCopy;
  }
  
  // Handle Set
  if (obj instanceof Set) {
    const setCopy = new Set();
    hash.set(obj, setCopy);
    obj.forEach(value => {
      setCopy.add(deepClone(value, hash));
    });
    return setCopy;
  }
  
  // Handle Object
  const objCopy = Object.create(Object.getPrototypeOf(obj));
  hash.set(obj, objCopy);
  
  for (const key of Reflect.ownKeys(obj)) {
    objCopy[key] = deepClone(obj[key], hash);
  }
  
  return objCopy;
}

// Usage
const complex = {
  date: new Date(),
  map: new Map([['key', 'value']]),
  set: new Set([1, 2, 3]),
  nested: { a: { b: { c: 1 } } }
};

const cloned = deepClone(complex);
cloned.nested.a.b.c = 999;
console.log(complex.nested.a.b.c); // 1 (unchanged!)`}]},{id:"q4",question:"How do you handle circular references when deep copying?",answer:`Circular references occur when an object references itself directly or indirectly. JSON.stringify() fails with circular refs, throwing 'Converting circular structure to JSON' error.

Solutions:
1. structuredClone() - Handles circular refs automatically
2. WeakMap tracking - Track visited objects in custom function
3. Lodash _.cloneDeep() - Handles circular refs

The WeakMap approach stores each object as it's cloned, and if encountered again, returns the already-cloned version instead of recursing infinitely.`,codeSnippets:[{language:"javascript",code:`// Object with circular reference
const obj = {
  name: "Circular",
  data: { value: 42 }
};
obj.self = obj;           // Points to itself
obj.data.parent = obj;    // Nested circular ref

//  JSON.stringify fails!
try {
  JSON.parse(JSON.stringify(obj));
} catch (e) {
  console.log(e.message); // "Converting circular structure to JSON"
}

//  structuredClone handles it
const copy1 = structuredClone(obj);
console.log(copy1.self === copy1); // true (circular ref preserved)
console.log(copy1.self === obj);   // false (independent copy)

//  Custom function with WeakMap
function deepCloneWithCircular(obj, visited = new WeakMap()) {
  if (obj === null || typeof obj !== 'object') return obj;
  
  // Return cached copy if already visited (handles circular)
  if (visited.has(obj)) {
    return visited.get(obj);
  }
  
  const copy = Array.isArray(obj) ? [] : {};
  visited.set(obj, copy); // Cache before recursing
  
  for (const key in obj) {
    if (obj.hasOwnProperty(key)) {
      copy[key] = deepCloneWithCircular(obj[key], visited);
    }
  }
  
  return copy;
}

const copy2 = deepCloneWithCircular(obj);
console.log(copy2.self === copy2);    // true
console.log(copy2.data.parent === copy2); // true`}]},{id:"q5",question:"What are the limitations of JSON.parse(JSON.stringify()) for deep copying?",answer:`JSON.parse(JSON.stringify()) has several limitations:

1. Functions are lost (become undefined)
2. undefined values are lost
3. Symbol keys/values are lost
4. Date objects become ISO strings
5. Map, Set become empty objects {}
6. RegExp becomes empty object {}
7. Infinity, NaN become null
8. Circular references throw error
9. Prototype chain is lost
10. Non-enumerable properties are lost
11. BigInt throws error

Use structuredClone() or custom functions for complex objects.`,codeSnippets:[{language:"javascript",code:`const original = {
  //  Works correctly
  string: "hello",
  number: 42,
  boolean: true,
  null: null,
  array: [1, 2, 3],
  object: { nested: true },
  
  //  Problems with these:
  func: function() { return "hi"; },  // Lost!
  arrow: () => "hi",                   // Lost!
  undefined: undefined,                // Lost!
  symbol: Symbol("id"),                // Lost!
  date: new Date("2024-01-01"),       // Becomes string
  map: new Map([["a", 1]]),           // Becomes {}
  set: new Set([1, 2, 3]),            // Becomes {}
  regex: /pattern/gi,                  // Becomes {}
  infinity: Infinity,                  // Becomes null
  nan: NaN,                            // Becomes null
  // bigint: 123n,                     // Throws error!
};

const copy = JSON.parse(JSON.stringify(original));

console.log(copy.func);      // undefined
console.log(copy.undefined); // key doesn't exist
console.log(copy.symbol);    // undefined
console.log(copy.date);      // "2024-01-01T00:00:00.000Z" (string!)
console.log(copy.map);       // {}
console.log(copy.set);       // {}
console.log(copy.regex);     // {}
console.log(copy.infinity);  // null
console.log(copy.nan);       // null

// Comparing with structuredClone
const better = structuredClone({
  date: new Date("2024-01-01"),
  map: new Map([["a", 1]]),
  set: new Set([1, 2, 3]),
});

console.log(better.date instanceof Date);  // true 
console.log(better.map instanceof Map);    // true 
console.log(better.set instanceof Set);    // true `}]},{id:"q6",question:"How does Object.assign() differ from spread operator for copying?",answer:`Both Object.assign() and spread operator (...) create shallow copies, but they have subtle differences:

Similarities:
 Both create shallow copies
 Both copy enumerable own properties
 Both can merge multiple sources

Differences:
 Object.assign() modifies target object, spread creates new one
 Spread is more readable and concise
 Object.assign() can target existing objects
 Spread can't be used with non-object targets
 Object.assign() triggers setters, spread doesn't
 Performance is nearly identical in modern engines`,codeSnippets:[{language:"javascript",code:`const source1 = { a: 1, b: 2 };
const source2 = { b: 3, c: 4 };

// Spread - Always creates NEW object
const spread = { ...source1, ...source2 };
console.log(spread); // { a: 1, b: 3, c: 4 }

// Object.assign - Modifies FIRST argument
const target = { x: 0 };
const assigned = Object.assign(target, source1, source2);
console.log(assigned); // { x: 0, a: 1, b: 3, c: 4 }
console.log(target === assigned); // true (same reference!)

// Key difference: Setter behavior
const objWithSetter = {
  _value: 0,
  set value(v) {
    console.log('Setter called with:', v);
    this._value = v;
  }
};

// Object.assign triggers setters
Object.assign(objWithSetter, { value: 42 });
// Logs: "Setter called with: 42"

// Spread does NOT trigger setters (creates new object)
const spreadCopy = { ...objWithSetter, value: 100 };
// No setter log - it's a new property on new object

// Merging patterns
const defaults = { theme: 'light', lang: 'en' };
const userPrefs = { theme: 'dark' };

// Both work for merging
const merged1 = { ...defaults, ...userPrefs };
const merged2 = Object.assign({}, defaults, userPrefs);
// Both: { theme: 'dark', lang: 'en' }`}]},{id:"q7",question:"How do you deep copy objects with special types like Date, Map, Set, and RegExp?",answer:`Special types require custom handling because JSON methods lose their type information:

 Date: Use new Date(original.getTime())
 Map: Create new Map and clone entries
 Set: Create new Set and clone values
 RegExp: Use new RegExp(source, flags)
 ArrayBuffer: Use slice()
 TypedArray: Use slice() or new constructor

structuredClone() handles most of these automatically except RegExp and functions.`,codeSnippets:[{language:"javascript",code:`// Deep clone function handling special types
function deepCloneSpecial(value, visited = new WeakMap()) {
  // Primitives
  if (value === null || typeof value !== 'object') {
    return value;
  }
  
  // Circular reference check
  if (visited.has(value)) {
    return visited.get(value);
  }
  
  let clone;
  
  // Date
  if (value instanceof Date) {
    return new Date(value.getTime());
  }
  
  // RegExp
  if (value instanceof RegExp) {
    return new RegExp(value.source, value.flags);
  }
  
  // Map
  if (value instanceof Map) {
    clone = new Map();
    visited.set(value, clone);
    value.forEach((v, k) => {
      clone.set(
        deepCloneSpecial(k, visited),
        deepCloneSpecial(v, visited)
      );
    });
    return clone;
  }
  
  // Set
  if (value instanceof Set) {
    clone = new Set();
    visited.set(value, clone);
    value.forEach(v => {
      clone.add(deepCloneSpecial(v, visited));
    });
    return clone;
  }
  
  // ArrayBuffer
  if (value instanceof ArrayBuffer) {
    return value.slice(0);
  }
  
  // TypedArray (Int8Array, Uint8Array, etc.)
  if (ArrayBuffer.isView(value)) {
    return new value.constructor(value);
  }
  
  // Array
  if (Array.isArray(value)) {
    clone = [];
    visited.set(value, clone);
    value.forEach((item, index) => {
      clone[index] = deepCloneSpecial(item, visited);
    });
    return clone;
  }
  
  // Object
  clone = Object.create(Object.getPrototypeOf(value));
  visited.set(value, clone);
  
  for (const key of Reflect.ownKeys(value)) {
    clone[key] = deepCloneSpecial(value[key], visited);
  }
  
  return clone;
}

// Test
const original = {
  date: new Date('2024-06-15'),
  regex: /hello/gi,
  map: new Map([['name', 'John'], ['age', 30]]),
  set: new Set([1, 2, 3]),
  buffer: new ArrayBuffer(8),
  nested: { arr: [1, { x: 2 }] }
};

const cloned = deepCloneSpecial(original);

// Verify independence
cloned.date.setFullYear(2025);
cloned.map.set('name', 'Jane');
cloned.nested.arr[1].x = 999;

console.log(original.date.getFullYear()); // 2024 
console.log(original.map.get('name'));    // "John" 
console.log(original.nested.arr[1].x);    // 2 `}]}]},my={id:"javascript",name:"JavaScript",icon:"",topics:[sy,ly,cy,uy,dy,py]},gy={id:"react-basics",name:"Basics",questions:[{id:"q11",question:"What are React hooks?",answer:"Hooks are functions that let you use state and other React features in functional components. Common hooks are useState, useEffect, useContext, and useReducer.",codeSnippets:[{language:"jsx",code:`import { useState, useEffect } from 'react';

function Counter() {
  const [count, setCount] = useState(0);

  useEffect(() => {
    document.title = \`Count: \${count}\`;
    return () => {
      // Cleanup
    };
  }, [count]);

  return (
    <div>
      <p>Count: {count}</p>
      <button onClick={() => setCount(count + 1)}>
        Increment
      </button>
    </div>
  );
}`}]},{id:"q12",question:"What is the virtual DOM?",answer:"The virtual DOM is a lightweight JavaScript representation of the real DOM. React compares virtual DOM trees to identify changes and updates only the necessary parts in the real DOM.",codeSnippets:[{language:"javascript",code:`// Simplified virtual DOM concept
const vdom = {
  type: 'div',
  props: { className: 'container' },
  children: [
    {
      type: 'h1',
      props: {},
      children: 'Hello World'
    }
  ]
};

// React's reconciliation algorithm:
// 1. Create new VDOM
// 2. Compare with old VDOM (diffing)
// 3. Identify changes
// 4. Update only changed parts in real DOM (patching)
// This makes updates efficient!`}],diagrams:[{title:"Virtual DOM Process",imageUrl:"https://via.placeholder.com/500x300?text=Virtual+DOM+Flow",description:"Shows how Virtual DOM compares changes and updates the real DOM"}]},{id:"q13",question:"What is JSX?",answer:"JSX is a syntax extension to JavaScript that looks like HTML. It gets compiled to JavaScript function calls (React.createElement) by Babel.",codeSnippets:[{language:"jsx",code:`// JSX syntax
const element = (
  <div className="greeting">
    <h1>Hello {name}</h1>
    <p>Welcome to React</p>
  </div>
);

// Compiled to:
const element = React.createElement(
  'div',
  { className: 'greeting' },
  React.createElement('h1', null, 'Hello ', name),
  React.createElement('p', null, 'Welcome to React')
);

// JSX is NOT valid JavaScript
// It needs to be transpiled by Babel`}]},{id:"q14",question:"What is the difference between state and props?",answer:"Props are read-only inputs passed from parent to child components. State is mutable data managed within a component and can be changed using setState or hooks.",codeSnippets:[{language:"jsx",code:`// Parent component
function App() {
  const [message, setMessage] = useState('Hello');

  return (
    <>
      <Greeting message={message} name="John" />
      <button onClick={() => setMessage('Hi')}>
        Update Message
      </button>
    </>
  );
}

// Child component
function Greeting({ message, name }) {
  // Props are read-only
  // message and name cannot be changed here
  
  return (
    <div>
      <p>{message}, {name}!</p>
      {/* This would cause error: */}
      {/* message = 'Goodbye'; //  Wrong! */}
    </div>
  );
}

// Props are passed down
// State is local to component
// Use props for parent-to-child communication`}]},{id:"q15",question:"What are the different lifecycle methods in class components?",answer:"Lifecycle methods are special methods that run at different stages: mounting (constructor, render, componentDidMount), updating (componentDidUpdate), and unmounting (componentWillUnmount).",codeSnippets:[{language:"jsx",code:`class MyComponent extends React.Component {
  constructor(props) {
    super(props);
    this.state = { count: 0 };
    // Mounting phase
  }

  componentDidMount() {
    // Called after component mounts
    // Good place for API calls
  }

  componentDidUpdate(prevProps, prevState) {
    // Called after update
    // Runs on every state/prop change
  }

  componentWillUnmount() {
    // Called before component removes
    // Good place for cleanup
  }

  shouldComponentUpdate(nextProps, nextState) {
    // Return true to render, false to skip
    return nextState.count !== this.state.count;
  }

  render() {
    return <div>Count: {this.state.count}</div>;
  }
}

// Modern approach with hooks:
function MyComponent() {
  useEffect(() => {
    // componentDidMount & componentDidUpdate
    return () => {
      // componentWillUnmount
    };
  }, []);
}`}]}]},yy={id:"react-hooks",name:"Hooks Deep Dive",questions:[{id:"q16",question:"What is the useState hook and how does it work?",answer:"useState is a React hook that lets you add state to functional components. It returns an array with the current state value and a function to update it.",codeSnippets:[{language:"jsx",code:`import { useState } from 'react';

function Counter() {
  const [count, setCount] = useState(0);
  const [name, setName] = useState('');

  const increment = () => {
    setCount(count + 1); // Simple update
  };

  const decrementIfEven = () => {
    setCount(prevCount => {
      // Use previous state when new state depends on old state
      if (prevCount % 2 === 0) {
        return prevCount - 1;
      }
      return prevCount;
    });
  };

  return (
    <div>
      <p>Count: {count}</p>
      <input 
        value={name} 
        onChange={e => setName(e.target.value)} 
      />
      <button onClick={increment}>+</button>
      <button onClick={decrementIfEven}>- (if even)</button>
    </div>
  );
}`}]},{id:"q17",question:"What is the useEffect hook?",answer:"useEffect is a hook that performs side effects (data fetching, subscriptions, DOM updates). It runs after render and accepts a dependency array to control when it runs.",codeSnippets:[{language:"jsx",code:`import { useEffect, useState } from 'react';

function DataFetcher() {
  const [data, setData] = useState(null);
  const [loading, setLoading] = useState(true);

  // Runs after every render
  useEffect(() => {
    console.log('Runs after every render');
  });

  // Runs only on mount (empty dependency array)
  useEffect(() => {
    console.log('Runs once on mount');
    
    fetchData().then(result => {
      setData(result);
      setLoading(false);
    });
  }, []);

  // Runs when dependencies change
  useEffect(() => {
    console.log('Runs when id changes');
    fetchUserData(id);
  }, [id]); // Dependency array

  // Cleanup function - runs before unmount or before re-running effect
  useEffect(() => {
    const subscription = subscribe();
    
    return () => {
      // Cleanup
      subscription.unsubscribe();
    };
  }, []);

  if (loading) return <p>Loading...</p>;
  return <div>{JSON.stringify(data)}</div>;
}`}]},{id:"q18",question:"What is the useContext hook?",answer:"useContext allows you to consume context values without prop drilling. It takes a context object and returns the current context value.",codeSnippets:[{language:"jsx",code:`import { createContext, useContext } from 'react';

// Create context
const ThemeContext = createContext();

// Provider
function ThemeProvider({ children }) {
  const [theme, setTheme] = useState('light');
  
  return (
    <ThemeContext.Provider value={{ theme, setTheme }}>
      {children}
    </ThemeContext.Provider>
  );
}

// Consume context - without prop drilling
function Button() {
  const { theme, setTheme } = useContext(ThemeContext);
  
  return (
    <button 
      onClick={() => setTheme(theme === 'light' ? 'dark' : 'light')}
      style={{ 
        background: theme === 'light' ? '#fff' : '#222',
        color: theme === 'light' ? '#222' : '#fff'
      }}
    >
      Toggle Theme
    </button>
  );
}

// App
function App() {
  return (
    <ThemeProvider>
      <Button />
    </ThemeProvider>
  );
}`}]},{id:"q19",question:"What is the useReducer hook?",answer:"useReducer is a hook for managing complex state logic. It takes a reducer function and initial state, returning current state and a dispatch function.",codeSnippets:[{language:"jsx",code:`import { useReducer } from 'react';

const initialState = { count: 0 };

function reducer(state, action) {
  switch (action.type) {
    case 'INCREMENT':
      return { count: state.count + 1 };
    case 'DECREMENT':
      return { count: state.count - 1 };
    case 'RESET':
      return { count: 0 };
    default:
      return state;
  }
}

function Counter() {
  const [state, dispatch] = useReducer(reducer, initialState);

  return (
    <div>
      <p>Count: {state.count}</p>
      <button onClick={() => dispatch({ type: 'INCREMENT' })}>
        +
      </button>
      <button onClick={() => dispatch({ type: 'DECREMENT' })}>
        -
      </button>
      <button onClick={() => dispatch({ type: 'RESET' })}>
        Reset
      </button>
    </div>
  );
}

// useReducer is better than useState when:
// - State has multiple sub-values
// - Next state depends on previous state
// - You have complex state transitions`}]},{id:"q20",question:"What are custom hooks?",answer:"Custom hooks are JavaScript functions that use other hooks. They let you extract component logic into reusable functions. Their names must start with 'use'.",codeSnippets:[{language:"jsx",code:`// Custom hook for fetching data
function useFetch(url) {
  const [data, setData] = useState(null);
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState(null);

  useEffect(() => {
    fetch(url)
      .then(res => res.json())
      .then(data => {
        setData(data);
        setLoading(false);
      })
      .catch(err => {
        setError(err);
        setLoading(false);
      });
  }, [url]);

  return { data, loading, error };
}

// Using custom hook
function UserProfile({ userId }) {
  const { data: user, loading, error } = useFetch(\`/api/users/\${userId}\`);

  if (loading) return <p>Loading...</p>;
  if (error) return <p>Error: {error.message}</p>;
  
  return <div>{user.name}</div>;
}

// Another custom hook for form handling
function useForm(initialValues, onSubmit) {
  const [values, setValues] = useState(initialValues);

  const handleChange = (e) => {
    const { name, value } = e.target;
    setValues(prev => ({ ...prev, [name]: value }));
  };

  const handleSubmit = (e) => {
    e.preventDefault();
    onSubmit(values);
  };

  return { values, handleChange, handleSubmit };
}`}]}]},hy={id:"react-performance",name:"Performance Optimization",questions:[{id:"q21",question:"What is React.memo and when should you use it?",answer:"React.memo is a higher-order component that memoizes a component. It prevents re-renders if props haven't changed. Use it for expensive components that receive same props frequently.",codeSnippets:[{language:"jsx",code:`// Without memo - re-renders even if props are same
function Button({ label, onClick }) {
  console.log('Button rendered');
  return <button onClick={onClick}>{label}</button>;
}

// With memo - only re-renders if props change
const MemoButton = React.memo(function Button({ label, onClick }) {
  console.log('Button rendered');
  return <button onClick={onClick}>{label}</button>;
});

// Parent component
function App() {
  const [count, setCount] = useState(0);
  
  // Without memo, MemoButton re-renders even though its props didn't change
  // With memo, it doesn't re-render
  return (
    <>
      <p>Count: {count}</p>
      <MemoButton label="Click me" onClick={() => setCount(count + 1)} />
    </>
  );
}

// Custom comparison function
const ExpensiveComponent = React.memo(
  function Component({ data, count }) {
    return <div>{data.name}</div>;
  },
  (prevProps, nextProps) => {
    // Return true if props are equal (don't re-render)
    // Return false if props are different (re-render)
    return prevProps.data.id === nextProps.data.id;
  }
);`}]},{id:"q22",question:"What is useMemo and useCallback?",answer:"useMemo memoizes expensive calculations. useCallback memoizes function references. Both take a dependency array and recompute only when dependencies change.",codeSnippets:[{language:"jsx",code:`import { useMemo, useCallback } from 'react';

function ExpensiveComponent({ items }) {
  // useMemo - memoize expensive calculation
  const expensiveValue = useMemo(() => {
    console.log('Computing expensive value');
    return items.reduce((sum, item) => sum + item.price, 0);
  }, [items]); // Only recompute when items change

  // useCallback - memoize function reference
  const handleClick = useCallback((id) => {
    console.log('Item clicked:', id);
    // Do something with id
  }, []); // No dependencies - same function always

  // With dependencies
  const handleDelete = useCallback((id) => {
    deleteItem(id);
    setItems(prev => prev.filter(item => item.id !== id));
  }, []); // Empty because deleteItem and setItems don't change

  return (
    <div>
      <p>Total: {expensiveValue}</p>
      <List items={items} onClickItem={handleClick} />
      <List items={items} onClickItem={handleDelete} />
    </div>
  );
}

// When to use:
// useMemo - expensive calculations, array/object that affects child renders
// useCallback - function passed to memoized child components`}]}]},vy={id:"react-unit-testing",name:"Unit Testing",questions:[{id:"q31",question:"What is React Testing Library and how does it differ from Enzyme?",answer:"React Testing Library is a modern testing utility that encourages testing components from a user's perspective. It queries the DOM using user-facing selectors (text, roles, labels). Enzyme tests component internals (state, props) and implementation details. React Testing Library is now the recommended approach as it prevents testing implementation details and ensures your tests resemble actual user interactions.",codeSnippets:[{language:"javascript",code:`// React Testing Library - User-centric approach
import { render, screen } from '@testing-library/react';
import userEvent from '@testing-library/user-event';

test('should display and update counter', async () => {
  render(<Counter />);
  const button = screen.getByRole('button', { name: /increment/i });
  
  expect(screen.getByText('Count: 0')).toBeInTheDocument();
  
  await userEvent.click(button);
  expect(screen.getByText('Count: 1')).toBeInTheDocument();
});`},{language:"javascript",code:`// Enzyme - Component implementation testing (less recommended)
import { shallow } from 'enzyme';

test('should update state on button click', () => {
  const wrapper = shallow(<Counter />);
  wrapper.find('button').simulate('click');
  expect(wrapper.state('count')).toBe(1);
});`}]},{id:"q32",question:"How do you test asynchronous operations in React components?",answer:"Use async/await with React Testing Library. Import waitFor to wait for elements to appear or changes to complete. Use screen queries like getByText or getByRole with waitFor for elements that appear after async operations.",codeSnippets:[{language:"javascript",code:`import { render, screen, waitFor } from '@testing-library/react';
import userEvent from '@testing-library/user-event';

test('should fetch and display user data', async () => {
  render(<UserProfile userId="123" />);
  
  // Component starts loading
  expect(screen.getByText('Loading...')).toBeInTheDocument();
  
  // Wait for the user name to appear
  await waitFor(() => {
    expect(screen.getByText('John Doe')).toBeInTheDocument();
  });
});

// Alternative with findBy
test('should display user name', async () => {
  render(<UserProfile userId="123" />);
  
  // findBy automatically waits for element
  const userName = await screen.findByText('John Doe');
  expect(userName).toBeInTheDocument();
});`}]},{id:"q33",question:"What are some best practices for writing React component tests?",answer:"1) Test user behavior, not implementation details. 2) Use semantic queries (getByRole, getByLabelText) over getByTestId. 3) Avoid testing internal state directly. 4) Test component interactions like clicks and form submissions. 5) Mock external dependencies (APIs, timers). 6) Keep tests focused and readable. 7) Use beforeEach for setup and afterEach for cleanup. 8) Test accessibility with proper roles and labels.",codeSnippets:[{language:"javascript",code:`import { render, screen, waitFor } from '@testing-library/react';
import userEvent from '@testing-library/user-event';

// Good: Test user interactions
test('should submit form with user data', async () => {
  render(<LoginForm />);
  
  const emailInput = screen.getByLabelText(/email/i);
  const passwordInput = screen.getByLabelText(/password/i);
  const submitButton = screen.getByRole('button', { name: /login/i });
  
  await userEvent.type(emailInput, 'user@example.com');
  await userEvent.type(passwordInput, 'password123');
  await userEvent.click(submitButton);
  
  await waitFor(() => {
    expect(screen.getByText(/welcome/i)).toBeInTheDocument();
  });
});

// Bad: Testing implementation details
test('should set state', () => {
  const wrapper = shallow(<LoginForm />);
  wrapper.setState({ email: 'user@example.com' });
  expect(wrapper.state('email')).toBe('user@example.com');
});`}]},{id:"q34",question:"How do you mock API calls in React tests?",answer:"Use jest.mock() to mock modules, or use libraries like MSW (Mock Service Worker) for API mocking. You can mock fetch or axios globally, or mock specific modules. For testing hooks that fetch data, mock the fetch/axios call and test the component's response to the mocked data.",codeSnippets:[{language:"javascript",code:`// Using jest.mock
jest.mock('axios');

test('should display fetched posts', async () => {
  const mockPosts = [
    { id: 1, title: 'Post 1' },
    { id: 2, title: 'Post 2' }
  ];
  
  axios.get.mockResolvedValue({ data: mockPosts });
  
  render(<PostList />);
  
  await waitFor(() => {
    expect(screen.getByText('Post 1')).toBeInTheDocument();
    expect(screen.getByText('Post 2')).toBeInTheDocument();
  });
  
  expect(axios.get).toHaveBeenCalledWith('/api/posts');
});

// Using Mock Service Worker (MSW)
import { setupServer } from 'msw/node';
import { rest } from 'msw';

const server = setupServer(
  rest.get('/api/posts', (req, res, ctx) => {
    return res(ctx.json([
      { id: 1, title: 'Post 1' },
      { id: 2, title: 'Post 2' }
    ]));
  })
);

beforeAll(() => server.listen());
afterEach(() => server.resetHandlers());
afterAll(() => server.close());`}]},{id:"q35",question:"How do you test custom React hooks?",answer:"Use the renderHook utility from @testing-library/react-hooks (or @testing-library/react in v13+). This allows you to test hooks in isolation without rendering a component. Use act() to wrap state updates and waitFor() to test async behavior.",codeSnippets:[{language:"javascript",code:`import { renderHook, act, waitFor } from '@testing-library/react';
import { useCounter } from './useCounter';

test('should increment counter', () => {
  const { result } = renderHook(() => useCounter());
  
  expect(result.current.count).toBe(0);
  
  act(() => {
    result.current.increment();
  });
  
  expect(result.current.count).toBe(1);
});

test('should fetch data', async () => {
  const { result } = renderHook(() => useFetchUser('123'));
  
  expect(result.current.loading).toBe(true);
  
  await waitFor(() => {
    expect(result.current.loading).toBe(false);
    expect(result.current.user.name).toBe('John');
  });
});`}]},{id:"q36",question:"What is snapshot testing and when should you use it?",answer:"Snapshot testing captures the rendered output of a component and stores it. On future runs, new output is compared against the snapshot. It's useful for detecting unintended UI changes but should not be the primary testing strategy. Use sparingly for stable, large components. Always review snapshot changes carefully before updating them, as they can hide real bugs.",codeSnippets:[{language:"javascript",code:`import { render } from '@testing-library/react';

test('should match snapshot', () => {
  const { container } = render(<Button variant="primary">Click Me</Button>);
  expect(container.firstChild).toMatchSnapshot();
});

/* Generated snapshot file:
exports[\`should match snapshot\`] = \`
<button class="btn btn-primary">
  Click Me
</button>
\`;
*/

// Update snapshot when intentional change is made
// Run: jest --updateSnapshot or jest -u`}]},{id:"q37",question:"How do you test context providers in React?",answer:"Wrap the component under test with the context provider. You can create a wrapper component for renderHook or render to reduce boilerplate. This allows testing components that consume context without directly testing the context object.",codeSnippets:[{language:"javascript",code:`import { render, screen } from '@testing-library/react';
import { ThemeProvider } from './ThemeContext';

// Option 1: Wrap component directly
test('should use theme from context', () => {
  render(
    <ThemeProvider initialTheme="dark">
      <ThemedComponent />
    </ThemeProvider>
  );
  
  expect(screen.getByTestId('theme-value')).toHaveTextContent('dark');
});

// Option 2: Create reusable wrapper
const renderWithTheme = (component, initialTheme = 'light') => {
  return render(
    <ThemeProvider initialTheme={initialTheme}>
      {component}
    </ThemeProvider>
  );
};

test('should update theme on button click', async () => {
  renderWithTheme(<ThemedComponent />);
  const button = screen.getByRole('button', { name: /toggle/i });
  
  await userEvent.click(button);
  
  expect(screen.getByTestId('theme-value')).toHaveTextContent('dark');
});`}]},{id:"q38",question:"What are the differences between getByXxx, queryByXxx, and findByXxx?",answer:"getByXxx: Returns element or throws error if not found. Use for elements that should exist immediately. queryByXxx: Returns element, null if not found, or throws error if multiple match. Use to assert element is NOT in document. findByXxx: Returns promise that resolves to element. Waits for element to appear. Use for async rendering or after user interactions.",codeSnippets:[{language:"javascript",code:`import { render, screen } from '@testing-library/react';

test('query method examples', () => {
  render(<Component />);
  
  // getByRole - throws if not found
  const button = screen.getByRole('button', { name: /submit/i });
  
  // queryByText - returns null if not found
  const loading = screen.queryByText('Loading...');
  expect(loading).not.toBeInTheDocument();
  
  // findByText - returns promise, waits for element
  const result = await screen.findByText('Success!');
  expect(result).toBeInTheDocument();
});`}]}]},fy={id:"react-router",name:"React Router & Navigation",questions:[{id:"q1",question:"What is React Router and how does it work?",answer:`React Router is a library that enables client-side routing in React applications. It allows you to build single-page applications (SPAs) with multiple views without full page reloads.

Key concepts:
 BrowserRouter: Wrapper component that provides routing context
 Routes: Container for Route components
 Route: Maps URL paths to components
 Link/NavLink: Navigation without full page reload
 useNavigate: Hook for programmatic navigation
 Dynamic routing: Routes can be defined based on conditions
 Lazy loading: Code splitting with React.lazy and Suspense
 Nested routes: Routes within routes for hierarchical navigation

How it works:
1. BrowserRouter listens to URL changes in browser
2. Routes component checks current URL against defined routes
3. Matching component is rendered
4. Navigation updates URL without page reload
5. Browser history is maintained for back/forward buttons`,codeSnippets:[{language:"javascript",code:`// Basic React Router Setup
import { BrowserRouter, Routes, Route, Link } from 'react-router-dom';

function App() {
  return (
    <BrowserRouter>
      <nav>
        <Link to="/">Home</Link>
        <Link to="/about">About</Link>
        <Link to="/products">Products</Link>
      </nav>

      <Routes>
        <Route path="/" element={<Home />} />
        <Route path="/about" element={<About />} />
        <Route path="/products" element={<Products />} />
        <Route path="*" element={<NotFound />} />
      </Routes>
    </BrowserRouter>
  );
}

function Home() { return <div>Welcome to Home</div>; }
function About() { return <div>About Us</div>; }
function Products() { return <div>Products List</div>; }
function NotFound() { return <div>404 - Page Not Found</div>; }`},{language:"javascript",code:`// Dynamic Routing with URL Parameters
import { useParams, useSearchParams } from 'react-router-dom';

// Route definition
<Route path="/product/:id" element={<ProductDetail />} />

function ProductDetail() {
  const { id } = useParams(); // Get path parameter
  const [searchParams] = useSearchParams(); // Get query parameters
  const category = searchParams.get('category');

  return (
    <div>
      <h1>Product {id}</h1>
      <p>Category: {category}</p>
    </div>
  );
}

// Navigation examples
// /product/123
// /product/123?category=electronics&sort=price`},{language:"javascript",code:`// Nested Routes and Layout Patterns
import { Outlet } from 'react-router-dom';

<Routes>
  <Route path="/" element={<Layout />}>
    <Route index element={<Home />} />
    <Route path="dashboard" element={<Dashboard />} />
    <Route path="settings" element={<Settings />} />
  </Route>
</Routes>

function Layout() {
  return (
    <div>
      <header>Header</header>
      <aside>Sidebar</aside>
      <main>
        <Outlet /> {/* Child routes render here */}
      </main>
      <footer>Footer</footer>
    </div>
  );
}`}]},{id:"q2",question:"How do you implement lazy loading and code splitting with React Router?",answer:`Lazy loading allows you to split your bundle and load components on demand, improving initial load time. React provides React.lazy() for code splitting.

Implementation:
1. Use React.lazy() to wrap component import
2. Use Suspense to handle loading state
3. Provide fallback UI while component loads
4. Routes load only when accessed

Benefits:
 Reduced initial bundle size
 Faster initial page load
 Improved performance on slow networks
 Better resource utilization

Best practices:
 Lazy load route components, not utilities
 Provide meaningful loading UI (spinner, skeleton)
 Handle error boundaries
 Use preloading for predictable navigation
 Monitor bundle sizes with webpack analysis`,codeSnippets:[{language:"javascript",code:`// Lazy Loading with React.lazy and Suspense
import { lazy, Suspense } from 'react';
import { Routes, Route } from 'react-router-dom';

const Home = lazy(() => import('./pages/Home'));
const About = lazy(() => import('./pages/About'));
const Products = lazy(() => import('./pages/Products'));
const Admin = lazy(() => import('./pages/Admin'));

function App() {
  return (
    <Routes>
      <Route path="/" element={<Suspense fallback={<Loading />}><Home /></Suspense>} />
      <Route path="/about" element={<Suspense fallback={<Loading />}><About /></Suspense>} />
      <Route path="/products" element={<Suspense fallback={<Loading />}><Products /></Suspense>} />
      <Route path="/admin" element={<ProtectedRoute><Suspense fallback={<Loading />}><Admin /></Suspense></ProtectedRoute>} />
    </Routes>
  );
}

function Loading() {
  return <div className="spinner">Loading...</div>;
}`},{language:"javascript",code:`// Custom Loading Component with Suspense
function App() {
  return (
    <Suspense fallback={<Skeleton />}>
      <Routes>
        <Route path="/" element={<lazy.Home />} />
        <Route path="/dashboard" element={<lazy.Dashboard />} />
      </Routes>
    </Suspense>
  );
}

function Skeleton() {
  return (
    <div className="skeleton-container">
      <div className="skeleton skeleton-header"></div>
      <div className="skeleton skeleton-content"></div>
      <div className="skeleton skeleton-content"></div>
    </div>
  );
}

// CSS for skeleton loading
const skeletonCSS = \`
.skeleton {
  background: linear-gradient(90deg, #f0f0f0 25%, #e0e0e0 50%, #f0f0f0 75%);
  background-size: 200% 100%;
  animation: loading 1.5s infinite;
}

@keyframes loading {
  0% { background-position: 200% 0; }
  100% { background-position: -200% 0; }
}
\`;`},{language:"javascript",code:`// Error Boundary with Lazy Loading
class ErrorBoundary extends React.Component {
  constructor(props) {
    super(props);
    this.state = { hasError: false };
  }

  static getDerivedStateFromError(error) {
    return { hasError: true };
  }

  componentDidCatch(error, errorInfo) {
    console.error('Error caught:', error, errorInfo);
  }

  render() {
    if (this.state.hasError) {
      return <div>Failed to load component. Please refresh.</div>;
    }
    return this.props.children;
  }
}

function App() {
  return (
    <ErrorBoundary>
      <Routes>
        <Route path="/admin" element={<Suspense fallback={<Loading />}><Admin /></Suspense>} />
      </Routes>
    </ErrorBoundary>
  );
}`}]},{id:"q3",question:"How do you implement protected/private routes in React Router?",answer:`Protected routes restrict access to certain pages based on authentication status, user roles, or permissions. They redirect unauthorized users to login or error pages.

Implementation approaches:
1. Route wrapper component: Create ProtectedRoute component
2. Check authentication status in wrapper
3. Redirect to login if not authenticated
4. Check user permissions/roles
5. Handle role-based access control (RBAC)

Common patterns:
 Authentication check: Verify user is logged in
 Role-based access: Check user permissions
 Token validation: Verify JWT token validity
 Redirect to login: Send unauthorized users to auth page
 Loading state: Handle auth check in progress

Best practices:
 Validate on both client and server
 Don't expose sensitive routes to unauthorized users
 Provide clear error messages
 Implement proper logout handling
 Refresh tokens before expiry`,codeSnippets:[{language:"javascript",code:`// Protected Route Component
import { Navigate } from 'react-router-dom';
import { useAuth } from './hooks/useAuth';

function ProtectedRoute({ children }) {
  const { isAuthenticated, loading } = useAuth();

  if (loading) {
    return <div>Loading...</div>;
  }

  if (!isAuthenticated) {
    return <Navigate to="/login" replace />;
  }

  return children;
}

// Usage in Routes
<Routes>
  <Route path="/login" element={<Login />} />
  <Route path="/dashboard" element={<ProtectedRoute><Dashboard /></ProtectedRoute>} />
  <Route path="/profile" element={<ProtectedRoute><Profile /></ProtectedRoute>} />
</Routes>`},{language:"javascript",code:`// Role-Based Protected Route
function RoleProtectedRoute({ children, requiredRole }) {
  const { isAuthenticated, user, loading } = useAuth();

  if (loading) {
    return <div>Loading...</div>;
  }

  if (!isAuthenticated) {
    return <Navigate to="/login" replace />;
  }

  if (!user.roles.includes(requiredRole)) {
    return <Navigate to="/unauthorized" replace />;
  }

  return children;
}

// Usage
<Routes>
  <Route path="/admin" element={<RoleProtectedRoute requiredRole="admin"><AdminPanel /></RoleProtectedRoute>} />
  <Route path="/editor" element={<RoleProtectedRoute requiredRole="editor"><EditorPanel /></RoleProtectedRoute>} />
</Routes>`},{language:"javascript",code:`// Advanced Protected Route with Token Validation
async function validateToken(token) {
  try {
    const response = await fetch('/api/validate-token', {
      headers: { Authorization: \`Bearer \${token}\` }
    });
    return response.ok;
  } catch (error) {
    return false;
  }
}

function ProtectedRoute({ children }) {
  const [authStatus, setAuthStatus] = useState('loading');
  const token = localStorage.getItem('authToken');

  useEffect(() => {
    if (!token) {
      setAuthStatus('unauthenticated');
      return;
    }

    validateToken(token).then(isValid => {
      setAuthStatus(isValid ? 'authenticated' : 'unauthenticated');
    });
  }, [token]);

  if (authStatus === 'loading') {
    return <Spinner />;
  }

  if (authStatus === 'unauthenticated') {
    return <Navigate to="/login" state={{ from: location }} replace />;
  }

  return children;
}`}]}]},Cy={id:"react-custom-hooks",name:"Custom Hooks & Advanced Patterns",questions:[{id:"q1",question:"What are Custom Hooks and how do you create them?",answer:`Custom Hooks are JavaScript functions that use React Hooks (useState, useEffect, etc.) to extract component logic into reusable functions. They allow you to reuse stateful logic without component duplication.

Rules for Custom Hooks:
1. Must be functions that call other hooks
2. Name must start with 'use' (e.g., useFetch, useForm)
3. Can only be called from React components or other hooks
4. Each hook call gets its own state

Benefits:
 Code reusability across components
 Separation of concerns (logic vs UI)
 Reduced component complexity
 Easier testing of business logic
 Share logic without render props or HOCs

Common patterns:
 Data fetching hooks (useFetch)
 Form handling hooks (useForm)
 Local storage hooks (useLocalStorage)
 Window size hooks (useWindowSize)
 Debounce/throttle hooks (useDebounce)
 Previous value hooks (usePrevious)`,codeSnippets:[{language:"javascript",code:`// Basic Custom Hook - useFetch
function useFetch(url) {
  const [data, setData] = useState(null);
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState(null);

  useEffect(() => {
    let isMounted = true;

    const fetchData = async () => {
      try {
        const response = await fetch(url);
        if (!response.ok) throw new Error('Failed to fetch');
        const result = await response.json();
        
        if (isMounted) {
          setData(result);
          setError(null);
        }
      } catch (err) {
        if (isMounted) {
          setError(err.message);
          setData(null);
        }
      } finally {
        if (isMounted) setLoading(false);
      }
    };

    fetchData();

    return () => { isMounted = false; }; // Cleanup
  }, [url]);

  return { data, loading, error };
}

// Usage
function UserProfile({ userId }) {
  const { data: user, loading, error } = useFetch(\`/api/users/\${userId}\`);

  if (loading) return <div>Loading...</div>;
  if (error) return <div>Error: {error}</div>;
  return <div>{user.name}</div>;
}`},{language:"javascript",code:`// Custom Hook - useForm for Form Handling
function useForm(initialValues, onSubmit) {
  const [values, setValues] = useState(initialValues);
  const [errors, setErrors] = useState({});
  const [touched, setTouched] = useState({});
  const [isSubmitting, setIsSubmitting] = useState(false);

  const handleChange = (e) => {
    const { name, value, type, checked } = e.target;
    setValues(prev => ({
      ...prev,
      [name]: type === 'checkbox' ? checked : value
    }));
  };

  const handleBlur = (e) => {
    const { name } = e.target;
    setTouched(prev => ({ ...prev, [name]: true }));
  };

  const handleSubmit = async (e) => {
    e.preventDefault();
    setIsSubmitting(true);
    try {
      await onSubmit(values);
    } finally {
      setIsSubmitting(false);
    }
  };

  const reset = () => {
    setValues(initialValues);
    setErrors({});
    setTouched({});
  };

  return { values, errors, touched, isSubmitting, handleChange, handleBlur, handleSubmit, reset, setValues };
}

// Usage
function LoginForm() {
  const { values, handleChange, handleSubmit } = useForm(
    { email: '', password: '' },
    async (values) => {
      await fetch('/api/login', { method: 'POST', body: JSON.stringify(values) });
    }
  );

  return (
    <form onSubmit={handleSubmit}>
      <input name="email" value={values.email} onChange={handleChange} />
      <input name="password" type="password" value={values.password} onChange={handleChange} />
      <button type="submit">Login</button>
    </form>
  );
}`},{language:"javascript",code:`// Custom Hook - useLocalStorage
function useLocalStorage(key, initialValue) {
  const [storedValue, setStoredValue] = useState(() => {
    try {
      const item = window.localStorage.getItem(key);
      return item ? JSON.parse(item) : initialValue;
    } catch (error) {
      console.error(error);
      return initialValue;
    }
  });

  const setValue = (value) => {
    try {
      const valueToStore = value instanceof Function ? value(storedValue) : value;
      setStoredValue(valueToStore);
      window.localStorage.setItem(key, JSON.stringify(valueToStore));
    } catch (error) {
      console.error(error);
    }
  };

  return [storedValue, setValue];
}

// Usage
function UserPreferences() {
  const [theme, setTheme] = useLocalStorage('theme', 'light');
  const [fontSize, setFontSize] = useLocalStorage('fontSize', 14);

  return (
    <div>
      <button onClick={() => setTheme(theme === 'light' ? 'dark' : 'light')}>
        Toggle Theme: {theme}
      </button>
      <input type="number" value={fontSize} onChange={(e) => setFontSize(Number(e.target.value))} />
    </div>
  );
}`}]},{id:"q2",question:"How do you compose multiple custom hooks together?",answer:`Hook composition allows you to build complex functionality by combining multiple custom hooks. This is similar to function composition in functional programming.

Patterns:
1. Sequential hooks: Call multiple hooks one after another
2. Conditional hooks: Logic that depends on previous hooks
3. Hook factories: Functions that return hooks
4. Hook wrappers: Hooks that enhance other hooks

Best practices:
 Keep hooks focused on single responsibility
 Return values that consumers need
 Handle loading/error states
 Clean up resources properly
 Consider performance implications
 Document hook dependencies`,codeSnippets:[{language:"javascript",code:`// Composed Hooks - Fetch with Pagination
function usePaginatedFetch(baseUrl, itemsPerPage = 10) {
  const [page, setPage] = useState(1);
  const url = \`\${baseUrl}?page=\${page}&limit=\${itemsPerPage}\`;
  
  // Compose multiple hooks
  const { data, loading, error } = useFetch(url);
  const debouncedPage = useDebounce(page, 500);

  const goToPage = useCallback((newPage) => {
    setPage(Math.max(1, newPage));
  }, []);

  const nextPage = useCallback(() => {
    setPage(prev => prev + 1);
  }, []);

  const prevPage = useCallback(() => {
    setPage(prev => Math.max(1, prev - 1));
  }, []);

  return { data, loading, error, page, nextPage, prevPage, goToPage };
}

// Usage
function ProductList() {
  const { data: items, loading, nextPage, prevPage, page } = usePaginatedFetch('/api/products', 20);

  return (
    <div>
      {items?.map(item => <div key={item.id}>{item.name}</div>)}
      <button onClick={prevPage}>Previous</button>
      <span>Page {page}</span>
      <button onClick={nextPage}>Next</button>
    </div>
  );
}`},{language:"javascript",code:`// Hook Factory - Create Custom Hooks Dynamically
function createAsyncHook(asyncFn) {
  return function useAsync(...args) {
    const [state, setState] = useState({ status: 'idle', data: null, error: null });

    useEffect(() => {
      let cancelled = false;
      setState({ status: 'pending', data: null, error: null });

      asyncFn(...args)
        .then(data => {
          if (!cancelled) setState({ status: 'success', data, error: null });
        })
        .catch(error => {
          if (!cancelled) setState({ status: 'error', data: null, error });
        });

      return () => { cancelled = true; };
    }, args);

    return state;
  };
}

// Create specific hooks from the factory
const useFetchUser = createAsyncHook(async (userId) => {
  const res = await fetch(\`/api/users/\${userId}\`);
  return res.json();
});

const useFetchPosts = createAsyncHook(async (userId) => {
  const res = await fetch(\`/api/users/\${userId}/posts\`);
  return res.json();
});

// Usage
function UserDashboard({ userId }) {
  const userState = useFetchUser(userId);
  const postsState = useFetchPosts(userId);

  return (
    <div>
      {userState.status === 'success' && <h1>{userState.data.name}</h1>}
      {postsState.status === 'success' && <div>{postsState.data.length} posts</div>}
    </div>
  );
}`},{language:"javascript",code:`// Hook Composition - useFetchWithCache
function useFetchWithCache(url) {
  const cache = useRef({});
  const { data, loading, error } = useFetch(url);

  const cachedData = useMemo(() => {
    if (!data) return null;
    cache.current[url] = data;
    return data;
  }, [data, url]);

  const getCachedData = useCallback(() => {
    return cache.current[url] || cachedData;
  }, [url, cachedData]);

  const clearCache = useCallback(() => {
    cache.current = {};
  }, []);

  return { data: cachedData || getCachedData(), loading, error, clearCache };
}

// Usage
function API Integration() {
  const { data, loading, clearCache } = useFetchWithCache('/api/data');

  return (
    <div>
      {data && <pre>{JSON.stringify(data, null, 2)}</pre>}
      <button onClick={clearCache}>Clear Cache</button>
    </div>
  );
}`}]},{id:"q3",question:"What are common patterns and best practices for custom hooks?",answer:`Custom hooks follow specific patterns and best practices to ensure they're reusable, maintainable, and performant.

Key patterns:
1. Separation of concerns: Logic vs UI
2. Single responsibility: One hook does one thing
3. Composition over inheritance
4. Proper cleanup and memory management
5. Error handling and loading states

Best practices:
 Use 'use' prefix for custom hooks
 Document hook parameters and return values
 Handle edge cases (empty data, errors, etc.)
 Optimize dependencies in useEffect
 Avoid creating hooks inside components
 Test hooks independently
 Consider performance with useMemo/useCallback
 Provide reset/clear functions when appropriate
 Handle async operations properly (cleanup)
 Return consistent data structures`,codeSnippets:[{language:"javascript",code:`// Best Practice: useAsync Hook Pattern
function useAsync(asyncFunction, immediate = true, dependencies = []) {
  const [status, setStatus] = useState('idle');
  const [data, setData] = useState(null);
  const [error, setError] = useState(null);

  const execute = useCallback(async () => {
    setStatus('pending');
    setData(null);
    setError(null);

    try {
      const response = await asyncFunction();
      setData(response);
      setStatus('success');
      return response;
    } catch (err) {
      setError(err);
      setStatus('error');
      throw err;
    }
  }, dependencies);

  useEffect(() => {
    if (immediate) {
      execute();
    }
  }, [execute, immediate]);

  return { execute, status, data, error };
}

// Usage with proper typing and documentation
/**
 * useAsync Hook
 * @param {Function} asyncFunction - Async function to execute
 * @param {Boolean} immediate - Execute immediately on mount
 * @param {Array} dependencies - Re-execute when deps change
 * @returns {Object} { execute, status, data, error }
 */
function DataFetcher() {
  const { status, data, error, execute } = useAsync(
    async () => {
      const res = await fetch('/api/data');
      return res.json();
    },
    true,
    []
  );

  if (status === 'pending') return <div>Loading...</div>;
  if (status === 'error') return <div>Error: {error?.message}</div>;
  return <div>{JSON.stringify(data)}</div>;
}`},{language:"javascript",code:`// Best Practice: useDebounce Hook
function useDebounce(value, delay) {
  const [debouncedValue, setDebouncedValue] = useState(value);

  useEffect(() => {
    const handler = setTimeout(() => {
      setDebouncedValue(value);
    }, delay);

    return () => clearTimeout(handler);
  }, [value, delay]);

  return debouncedValue;
}

// Usage: Search with Debounce
function SearchUsers() {
  const [searchTerm, setSearchTerm] = useState('');
  const debouncedSearchTerm = useDebounce(searchTerm, 500);
  const { data: results } = useFetch(
    \`/api/users/search?q=\${debouncedSearchTerm}\`
  );

  return (
    <div>
      <input 
        value={searchTerm} 
        onChange={(e) => setSearchTerm(e.target.value)}
        placeholder="Search users..."
      />
      <ul>
        {results?.map(user => <li key={user.id}>{user.name}</li>)}
      </ul>
    </div>
  );
}`},{language:"javascript",code:`// Best Practice: useReducer for Complex State
function useComplexState(initialState, reducer = null) {
  const defaultReducer = (state, action) => {
    switch (action.type) {
      case 'SET': return action.payload;
      case 'UPDATE': return { ...state, ...action.payload };
      case 'RESET': return initialState;
      default: return state;
    }
  };

  const [state, dispatch] = useReducer(
    reducer || defaultReducer,
    initialState
  );

  const setState = useCallback((value) => {
    dispatch({ type: 'SET', payload: value });
  }, []);

  const updateState = useCallback((updates) => {
    dispatch({ type: 'UPDATE', payload: updates });
  }, []);

  const resetState = useCallback(() => {
    dispatch({ type: 'RESET' });
  }, []);

  return [state, { setState, updateState, resetState }];
}

// Usage
function FormComponent() {
  const [formData, { updateState, resetState }] = useComplexState({
    name: '',
    email: '',
    message: ''
  });

  return (
    <form>
      <input 
        value={formData.name}
        onChange={(e) => updateState({ name: e.target.value })}
      />
      <button onClick={resetState}>Reset Form</button>
    </form>
  );
}`}]}]},by={id:"react-context-state-management",name:"Context API & State Management",questions:[{id:"q1",question:"What is Context API and how does it solve prop drilling?",answer:`Context API is a built-in React feature for managing and sharing state across components without prop drilling. It allows you to pass data through the component tree without explicitly passing props at each level.

Prop drilling problem:
 Passing props through multiple nested components
 Middle components don't use the props
 Makes code hard to maintain
 Increases component coupling

Context API solution:
1. Create context: React.createContext()
2. Create provider component to wrap tree
3. Provide state value
4. Consume context in any nested component with useContext()

Components:
 Context: Created with createContext()
 Provider: Wraps components and provides value
 Consumer: Accesses context value (hooks or render props)

Use cases:
 Theme management (dark/light mode)
 Authentication state
 User preferences
 Global notifications
 Multi-language support
 App configuration`,codeSnippets:[{language:"javascript",code:`// Creating and Using Context
import { createContext, useContext, useState } from 'react';

// 1. Create Context
const ThemeContext = createContext();

// 2. Create Provider Component
function ThemeProvider({ children }) {
  const [theme, setTheme] = useState('light');

  const toggleTheme = () => {
    setTheme(prev => prev === 'light' ? 'dark' : 'light');
  };

  const value = { theme, toggleTheme };

  return (
    <ThemeContext.Provider value={value}>
      {children}
    </ThemeContext.Provider>
  );
}

// 3. Custom Hook to Use Context
function useTheme() {
  const context = useContext(ThemeContext);
  if (!context) {
    throw new Error('useTheme must be used within ThemeProvider');
  }
  return context;
}

// 4. Application Setup
function App() {
  return (
    <ThemeProvider>
      <Header />
      <MainContent />
      <Footer />
    </ThemeProvider>
  );
}

// 5. Consume Context in Components
function Header() {
  const { theme, toggleTheme } = useTheme();

  return (
    <header style={{ background: theme === 'light' ? '#fff' : '#333' }}>
      <button onClick={toggleTheme}>Toggle Theme</button>
      <p>Current theme: {theme}</p>
    </header>
  );
}

function MainContent() {
  const { theme } = useTheme();

  return (
    <main style={{ color: theme === 'light' ? '#000' : '#fff' }}>
      <p>Content here</p>
    </main>
  );
}`},{language:"javascript",code:`// Complex Context: Authentication
const AuthContext = createContext();

function AuthProvider({ children }) {
  const [user, setUser] = useState(null);
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState(null);

  const login = async (email, password) => {
    setLoading(true);
    setError(null);
    try {
      const res = await fetch('/api/login', {
        method: 'POST',
        body: JSON.stringify({ email, password })
      });
      const data = await res.json();
      setUser(data.user);
      localStorage.setItem('authToken', data.token);
    } catch (err) {
      setError(err.message);
    } finally {
      setLoading(false);
    }
  };

  const logout = () => {
    setUser(null);
    localStorage.removeItem('authToken');
  };

  const value = { user, loading, error, login, logout };

  return (
    <AuthContext.Provider value={value}>
      {children}
    </AuthContext.Provider>
  );
}

function useAuth() {
  const context = useContext(AuthContext);
  if (!context) {
    throw new Error('useAuth must be used within AuthProvider');
  }
  return context;
}

// Usage
function Dashboard() {
  const { user, logout } = useAuth();

  return (
    <div>
      <h1>Welcome, {user?.name}</h1>
      <button onClick={logout}>Logout</button>
    </div>
  );
}`},{language:"javascript",code:`// Multiple Contexts Composition
const ThemeContext = createContext();
const LanguageContext = createContext();
const NotificationContext = createContext();

function AppProviders({ children }) {
  return (
    <ThemeProvider>
      <LanguageProvider>
        <NotificationProvider>
          {children}
        </NotificationProvider>
      </LanguageProvider>
    </ThemeProvider>
  );
}

// Usage in App
function App() {
  return (
    <AppProviders>
      <MainApp />
    </AppProviders>
  );
}

function MainApp() {
  const { theme } = useTheme();
  const { language } = useLanguage();
  const { notify } = useNotification();

  return (
    <div style={{ theme: theme }}>
      <button onClick={() => notify('Hello!')}>Notify</button>
    </div>
  );
}`}]},{id:"q2",question:"How do you optimize Context API to prevent unnecessary re-renders?",answer:`When context value changes, all consumers re-render even if they don't use the changed part. Optimization strategies prevent unnecessary re-renders and improve performance.

Optimization techniques:
1. Split contexts: Separate state and dispatch
2. Memoize context value: useMemo() for complex values
3. Use useCallback: Memoize callback functions
4. Context selectors: Use libraries or custom hooks
5. Multiple providers: Separate concerns
6. Combine with useReducer: For complex state

When to use each:
 Small apps: Simple Context API works
 Medium apps: Optimize with memoization
 Large apps: Consider Redux or Zustand

Best practices:
 Don't put too much state in one context
 Keep context value stable
 Use dev tools to monitor re-renders
 Profile performance with React DevTools`,codeSnippets:[{language:"javascript",code:`// Non-Optimized: Causes Unnecessary Re-renders
function ThemeProvider({ children }) {
  const [theme, setTheme] = useState('light');
  const [notifications, setNotifications] = useState([]);

  // This object is recreated on every render
  const value = {
    theme,
    setTheme,
    notifications,
    setNotifications
  };

  return (
    <ThemeContext.Provider value={value}>
      {children}
    </ThemeContext.Provider>
  );
}

// Optimized: Using useMemo
function ThemeProvider({ children }) {
  const [theme, setTheme] = useState('light');
  const [notifications, setNotifications] = useState([]);

  const toggleTheme = useCallback(() => {
    setTheme(prev => prev === 'light' ? 'dark' : 'light');
  }, []);

  const addNotification = useCallback((message) => {
    setNotifications(prev => [...prev, message]);
  }, []);

  // Memoize context value to prevent re-renders
  const value = useMemo(() => ({
    theme,
    toggleTheme,
    notifications,
    addNotification
  }), [theme, toggleTheme, notifications, addNotification]);

  return (
    <ThemeContext.Provider value={value}>
      {children}
    </ThemeContext.Provider>
  );
}`},{language:"javascript",code:`// Split Contexts: State and Dispatch
const ThemeStateContext = createContext();
const ThemeDispatchContext = createContext();

function ThemeProvider({ children }) {
  const [theme, setTheme] = useState('light');

  const stateValue = useMemo(() => ({ theme }), [theme]);
  
  const dispatchValue = useMemo(() => ({
    toggleTheme: () => setTheme(prev => prev === 'light' ? 'dark' : 'light')
  }), []);

  return (
    <ThemeStateContext.Provider value={stateValue}>
      <ThemeDispatchContext.Provider value={dispatchValue}>
        {children}
      </ThemeDispatchContext.Provider>
    </ThemeStateContext.Provider>
  );
}

function useThemeState() {
  return useContext(ThemeStateContext);
}

function useThemeDispatch() {
  return useContext(ThemeDispatchContext);
}

// Usage: Component only re-renders if theme changes, not if dispatch changes
function Component1() {
  const { theme } = useThemeState(); // Re-renders on theme change
  return <div>Theme: {theme}</div>;
}

function Component2() {
  const { toggleTheme } = useThemeDispatch(); // Never re-renders
  return <button onClick={toggleTheme}>Toggle</button>;
}`},{language:"javascript",code:`// Context with useReducer for Complex State
const AppStateContext = createContext();
const AppDispatchContext = createContext();

function appReducer(state, action) {
  switch (action.type) {
    case 'SET_THEME': return { ...state, theme: action.payload };
    case 'SET_LANGUAGE': return { ...state, language: action.payload };
    case 'SET_USER': return { ...state, user: action.payload };
    default: return state;
  }
}

function AppProvider({ children }) {
  const initialState = { theme: 'light', language: 'en', user: null };
  const [state, dispatch] = useReducer(appReducer, initialState);

  const stateValue = useMemo(() => state, [state]);
  const dispatchValue = useMemo(() => dispatch, []);

  return (
    <AppStateContext.Provider value={stateValue}>
      <AppDispatchContext.Provider value={dispatchValue}>
        {children}
      </AppDispatchContext.Provider>
    </AppStateContext.Provider>
  );
}

function useAppState() {
  return useContext(AppStateContext);
}

function useAppDispatch() {
  return useContext(AppDispatchContext);
}

// Usage
function App() {
  const { theme } = useAppState();
  const dispatch = useAppDispatch();

  return (
    <div>
      <button onClick={() => dispatch({ type: 'SET_THEME', payload: 'dark' })}>
        Change Theme
      </button>
    </div>
  );
}`}]},{id:"q3",question:"What are the differences between Context API, Redux, and other state management solutions?",answer:`Different state management solutions have different trade-offs. Choose based on app complexity and requirements.

Context API:
 Pros: Built-in, simple, no dependencies
 Cons: Can cause re-renders, limited DevTools, not optimized for complex state
 Best for: Small to medium apps, global settings

Redux:
 Pros: Predictable state, excellent DevTools, time-travel debugging
 Cons: Boilerplate, steep learning curve, overkill for simple apps
 Best for: Large apps, team projects, complex state logic

MobX:
 Pros: Minimal boilerplate, reactive, great performance
 Cons: Less popular, less predictable than Redux
 Best for: Complex state with lots of computations

Zustand:
 Pros: Lightweight, simple API, good DevTools
 Cons: Smaller ecosystem than Redux
 Best for: Medium to large apps seeking simplicity

Recoil/Jotai:
 Pros: Atomic state, granular reactivity
 Cons: Still experimental
 Best for: Fine-grained reactivity needs`,codeSnippets:[{language:"javascript",code:`// Context API Example
const AppContext = createContext();

function AppProvider({ children }) {
  const [state, setState] = useState(initialState);
  const value = useMemo(() => [state, setState], [state]);
  return <AppContext.Provider value={value}>{children}</AppContext.Provider>;
}

function useApp() {
  const [state, setState] = useContext(AppContext);
  return { state, setState };
}

// Usage: Simple but no middleware, DevTools, or time-travel
function Component() {
  const { state, setState } = useApp();
  return <button onClick={() => setState(newState)}>Update</button>;
}`},{language:"javascript",code:`// Redux Example (simplified)
import { createStore, connect } from 'redux';

const initialState = { count: 0 };

function counterReducer(state = initialState, action) {
  switch (action.type) {
    case 'INCREMENT': return { ...state, count: state.count + 1 };
    case 'DECREMENT': return { ...state, count: state.count - 1 };
    default: return state;
  }
}

const store = createStore(counterReducer);

function Counter({ count, increment, decrement }) {
  return (
    <div>
      <p>Count: {count}</p>
      <button onClick={increment}>+</button>
      <button onClick={decrement}>-</button>
    </div>
  );
}

const mapStateToProps = (state) => ({ count: state.count });
const mapDispatchToProps = (dispatch) => ({
  increment: () => dispatch({ type: 'INCREMENT' }),
  decrement: () => dispatch({ type: 'DECREMENT' })
});

export default connect(mapStateToProps, mapDispatchToProps)(Counter);`},{language:"javascript",code:`// Zustand Example
import create from 'zustand';

const useStore = create((set) => ({
  count: 0,
  theme: 'light',
  user: null,
  
  increment: () => set((state) => ({ count: state.count + 1 })),
  decrement: () => set((state) => ({ count: state.count - 1 })),
  setTheme: (theme) => set({ theme }),
  setUser: (user) => set({ user }),
  reset: () => set({ count: 0, theme: 'light', user: null })
}));

// Usage: Simple and clean
function Counter() {
  const { count, increment, decrement } = useStore();
  return (
    <div>
      <p>Count: {count}</p>
      <button onClick={increment}>+</button>
      <button onClick={decrement}>-</button>
    </div>
  );
}

// Selectors to optimize re-renders
function Theme() {
  const theme = useStore((state) => state.theme);
  const setTheme = useStore((state) => state.setTheme);
  
  return (
    <button onClick={() => setTheme(theme === 'light' ? 'dark' : 'light')}>
      Theme: {theme}
    </button>
  );
}`}]}]},Sy={id:"react-virtual-dom-advanced",name:"Virtual DOM, Shadow DOM & Advanced Concepts",questions:[{id:"q1",question:"What is the Virtual DOM and how does React use it for rendering?",answer:`Virtual DOM is an in-memory representation of the actual DOM. React uses it to optimize rendering performance by comparing changes and only updating the necessary parts of the real DOM.

How it works:
1. Render component  Creates Virtual DOM tree
2. Compare new Virtual DOM with previous version (diffing)
3. Calculate minimal changes (reconciliation)
4. Update only changed parts in real DOM (patching)

Diffing algorithm:
 Compares elements at same level
 If element type changed, recreates entire subtree
 If element type same, updates attributes
 Uses keys for list items to maintain identity

Reconciliation process:
1. Traverse both trees simultaneously
2. Mark differences
3. Batch updates for efficiency
4. Apply batch to real DOM

Benefits:
 Faster than direct DOM manipulation
 Reduces layout thrashing
 Batches updates
 Abstracts browser differences
 Enables cross-platform rendering`,codeSnippets:[{language:"javascript",code:`// Virtual DOM Concept Illustration
// Initial render
function App() {
  return (
    <div className="container">
      <h1>Hello</h1>
      <ul>
        <li key="1">Item 1</li>
        <li key="2">Item 2</li>
      </ul>
    </div>
  );
}

// First render: Creates Virtual DOM
/* Virtual DOM Tree:
{
  type: 'div',
  props: { className: 'container' },
  children: [
    { type: 'h1', props: {}, children: ['Hello'] },
    {
      type: 'ul',
      props: {},
      children: [
        { type: 'li', props: { key: '1' }, children: ['Item 1'] },
        { type: 'li', props: { key: '2' }, children: ['Item 2'] }
      ]
    }
  ]
}
*/

// After state change: New Virtual DOM created
function App() {
  return (
    <div className="container">
      <h1>Hello World</h1> {/* Changed text */}
      <ul>
        <li key="1">Item 1</li>
        <li key="2">Item 2 Updated</li> {/* Changed text */}
        <li key="3">Item 3</li> {/* New item */}
      </ul>
    </div>
  );
}

// React diffs and finds:
// 1. h1 text changed from "Hello" to "Hello World"
// 2. li with key="2" text changed
// 3. New li with key="3" added
// Real DOM updates only these 3 elements`},{language:"javascript",code:`// Why Keys are Important in Lists
// Without keys: React compares by position
function BadList() {
  const [items, setItems] = useState(['A', 'B', 'C']);

  return (
    <div>
      {items.map((item, index) => (
        <div key={index}> {/* DON'T USE INDEX AS KEY */}
          <input placeholder={item} />
        </div>
      ))}
      <button onClick={() => setItems(['X', ...items])}>Add Item</button>
    </div>
  );
}
// Problem: When adding 'X', React thinks:
// Position 0: 'A' -> 'X' (update input value)
// Position 1: 'B' -> 'A' (update input value)
// Position 2: 'C' -> 'B' (update input value)
// Position 3: (empty) -> 'C' (add new)
// Input focus and state gets mixed up!

// With stable keys: React tracks identity
function GoodList() {
  const [items, setItems] = useState([
    { id: 1, name: 'A' },
    { id: 2, name: 'B' },
    { id: 3, name: 'C' }
  ]);

  return (
    <div>
      {items.map((item) => (
        <div key={item.id}> {/* Stable key */}
          <input placeholder={item.name} />
        </div>
      ))}
      <button onClick={() => setItems([{ id: 0, name: 'X' }, ...items])}>
        Add Item
      </button>
    </div>
  );
}
// React correctly identifies:
// ID 0: New item 'X' (add new input)
// ID 1: 'A' stays in same position
// ID 2: 'B' stays in same position
// ID 3: 'C' stays in same position`},{language:"javascript",code:`// Understanding Reconciliation
import React from 'react';

// Old render
<div>
  <Component key="a" id={1} />
  <Component key="b" id={2} />
</div>

// New render (props changed)
<div>
  <Component key="a" id={1} /> {/* Props: id=1 */}
  <Component key="b" id={3} /> {/* Props: id changed to 3 */}
</div>

// Reconciliation process:
// 1. Key 'a': Same key, same component type -> Update props (id stayed 1)
// 2. Key 'b': Same key, same component type -> Update props (id changed from 2 to 3)
// Result: 2 updates, 0 unmounts/remounts

// Compare with no keys:
<div>
  <Component id={1} />
  <Component id={2} />
</div>

<div>
  <Component id={1} />
  <Component id={3} />
</div>

// Without keys, React compares by position:
// Position 0: id={1} -> id={1} (props match, no update)
// Position 1: id={2} -> id={3} (props changed, update)
// Same result but less efficient when reordering`}]},{id:"q2",question:"What is Shadow DOM and how does it differ from Virtual DOM?",answer:`Shadow DOM and Virtual DOM are completely different concepts, often confused because of similar names.

Virtual DOM:
 JavaScript representation of UI
 Created by React for rendering optimization
 Not actual DOM
 Used for diffing and reconciliation
 Part of React's implementation

Shadow DOM:
 Actual DOM API (Web Components standard)
 Encapsulated subtree of real DOM
 Provides style and DOM encapsulation
 Prevents style leakage
 Allows creating reusable components
 Browser feature, not framework-specific

Use cases:
 Virtual DOM: Framework rendering optimization
 Shadow DOM: Component encapsulation and reusability

Comparison:
| Feature | Virtual DOM | Shadow DOM |
|---------|-------------|----------|
| What is it | JS abstraction | Real DOM |
| Purpose | Optimization | Encapsulation |
| Framework | React-specific | Browser API |
| Performance | Improves rendering | No direct impact |
| CSS scoping | No | Yes |
| DOM traversal | Not accessible | Encapsulated |

They can work together: React can render into Shadow DOM`,codeSnippets:[{language:"javascript",code:`// Shadow DOM: Web Components Example
class CustomButton extends HTMLElement {
  constructor() {
    super();
    // Attach shadow DOM
    this.attachShadow({ mode: 'open' });
  }

  connectedCallback() {
    this.render();
  }

  render() {
    this.shadowRoot.innerHTML = \`
      <style>
        button {
          background-color: blue;
          color: white;
          padding: 10px 20px;
          border: none;
          border-radius: 4px;
        }
        
        button:hover {
          background-color: darkblue;
        }
      </style>
      <button>
        <slot></slot> {/* Placeholder for slotted content */}
      </button>
    \`;

    const button = this.shadowRoot.querySelector('button');
    button.addEventListener('click', () => {
      this.dispatchEvent(new CustomEvent('button-clicked', { bubbles: true }));
    });
  }
}

customElements.define('custom-button', CustomButton);

// Usage: CSS doesn't leak in or out
\`
<custom-button>Click me</custom-button>

<style>
  button { color: red; } /* Doesn't affect custom-button */
</style>
\``},{language:"javascript",code:`// Shadow DOM Style Encapsulation Benefits
// Regular HTML/CSS (no encapsulation)
function RegularComponent() {
  return (
    <div className="component">
      <button className="btn">Click</button>
      <style>{css\`
        .btn { background: blue; } /* Affects all .btn globally */
      \`}</style>
    </div>
  );
}

// Problem: Global style conflicts
// If parent also has .btn style, they conflict!

// Shadow DOM (encapsulated)
class EncapsulatedComponent extends HTMLElement {
  connectedCallback() {
    const shadow = this.attachShadow({ mode: 'open' });
    shadow.innerHTML = \`
      <style>
        .btn { background: blue; } /* Only affects this component's button */
      </style>
      <button class="btn">Click</button>
    \`;
  }
}

// Benefit: Styles are scoped
// .btn in parent document doesn't affect this component
// .btn in this component doesn't affect parent`},{language:"javascript",code:`// React with Shadow DOM
function ReactWebComponent() {
  const containerRef = useRef(null);

  useEffect(() => {
    const host = containerRef.current;
    const shadow = host.attachShadow({ mode: 'open' });

    // Render React into shadow DOM
    const root = ReactDOM.createRoot(shadow);
    root.render(
      <>
        <style>{\`
          :host {
            display: block;
            padding: 20px;
            border: 1px solid #ccc;
          }
          
          h1 { color: blue; }
          p { color: gray; }
        \`}</style>
        <h1>Encapsulated Component</h1>
        <p>Content is isolated</p>
      </>
    );

    return () => root.unmount();
  }, []);

  return <div ref={containerRef} />;
}

// Usage: Styles and DOM are encapsulated
\`
<ReactWebComponent></ReactWebComponent>

<style>
  h1 { color: red; } /* Doesn't affect ReactWebComponent's h1 */
</style>
\``}]},{id:"q3",question:"What are React Fibers and how do they improve rendering?",answer:`React Fibers are the internal architecture that powers React's reconciliation algorithm. They enable incremental rendering, prioritized updates, and better performance.

What are Fibers:
 Lightweight JavaScript objects representing work units
 Each component instance gets a fiber
 Fibers form a tree structure
 Contain information about component and its work

How Fibers improve rendering:
1. Incremental rendering: Split work into small chunks
2. Prioritized updates: High-priority updates first (user input)
3. Pausable: Can pause/resume rendering
4. Reclaimable: Can restart rendering if needed
5. Yielding: Yield to browser for frame work

Before Fibers (Stack Reconciler):
 Rendered entire tree synchronously
 Blocking the main thread
 Could cause frame drops and janky UI

With Fibers (Fiber Reconciler):
 Renders incrementally
 Works within frame budgets
 Prioritizes important updates
 Smooth 60 FPS possible

Key Fiber features:
 Time slicing: Break work into time slices
 Suspense: Pause rendering while data loads
 Priority levels: Different update priorities
 Error boundaries: Catch errors during render`,codeSnippets:[{language:"javascript",code:`// Fiber Update Priorities
import { useState } from 'react';

function PriorityDemo() {
  const [count, setCount] = useState(0);
  const [text, setText] = useState('');

  const handleUrgentUpdate = () => {
    // High priority: User input (clicks, typing)
    // Fiber prioritizes this
    setCount(prev => prev + 1);
  };

  const handleDeferredUpdate = () => {
    // Low priority: Non-urgent updates
    // Fiber can defer this
    setText('This can wait');
  };

  return (
    <div>
      <button onClick={handleUrgentUpdate}>
        Urgent: {count}
      </button>
      <button onClick={handleDeferredUpdate}>
        Deferred
      </button>
      <p>{text}</p>
      {/* Expensive render: Fiber breaks into chunks */}
      {Array.from({ length: 1000 }).map((_, i) => (
        <div key={i} style={{ height: '1px' }}></div>
      ))}
    </div>
  );
}

// React Fiber priority levels:
// 1. Immediate (user input, layout)
// 2. User-blocking (animations within 250ms)
// 3. Normal (updates without specific timing)
// 4. Low (deferred work)
// 5. Idle (non-urgent background work)`},{language:"javascript",code:`// Time Slicing with Fibers
function ExpensiveList({ items }) {
  // Rendering 10000 items synchronously = janky UI
  // With Fibers: React renders in time slices
  
  return (
    <div>
      <h1>Items: {items.length}</h1>
      <ul>
        {items.map((item, i) => (
          <li key={i}>
            <ExpensiveComponent item={item} />
          </li>
        ))}
      </ul>
    </div>
  );
}

function ExpensiveComponent({ item }) {
  // Simulate expensive computation
  let sum = 0;
  for (let i = 0; i < 1000000; i++) {
    sum += i;
  }

  return <span>{item.name}: {sum}</span>;
}

// Without Fibers: Blocks main thread, dropping frames
// With Fibers: 
// - Fiber breaks rendering into chunks (~5ms each)
// - After each chunk, yields to browser
// - Browser can handle user input
// - Smooth UI despite expensive rendering`},{language:"javascript",code:`// Concurrent Features with Fibers
import { Suspense, useState, useTransition } from 'react';

function ConcurrentDemo() {
  const [input, setInput] = useState('');
  const [isPending, startTransition] = useTransition();

  const handleChange = (e) => {
    // High priority: Update input immediately
    setInput(e.target.value);

    // Low priority: Search results (deferred update)
    startTransition(() => {
      // This update is lower priority
      // If urgent updates come in, this can be interrupted
      performSearch(e.target.value);
    });
  };

  return (
    <div>
      <input 
        value={input}
        onChange={handleChange}
        placeholder="Search..."
      />
      
      {isPending && <span>Searching...</span>}
      
      <Suspense fallback={<div>Loading results...</div>}>
        <SearchResults query={input} />
      </Suspense>
    </div>
  );
}

// Fiber allows:
// 1. Input to update immediately (user sees typing)
// 2. Search to run in background (lower priority)
// 3. Results to load with Suspense (pause rendering if needed)
// 4. Smooth experience despite multiple concurrent updates`}]}]},Ay={id:"react-api-integration",name:"API Integration with Axios & Fetch",questions:[{id:"q1",question:"How do you fetch data in React using Fetch API and Axios?",answer:`Fetching data from APIs is a core part of React applications. Both Fetch API and Axios are common approaches with different advantages.

Fetch API:
 Built-in browser API
 No dependencies
 Lower-level control
 Requires manual JSON parsing
 More verbose error handling

Axios:
 Third-party library
 Higher-level abstraction
 Automatic JSON serialization
 Request/response interceptors
 Better error handling
 Request cancellation built-in

Common patterns:
1. Fetch on component mount
2. Handle loading/error states
3. Clean up on unmount
4. Prevent race conditions
5. Handle timeouts
6. Retry logic

Best practices:
 Use useEffect for data fetching
 Set loading state
 Handle errors properly
 Clean up requests on unmount
 Use AbortController for cancellation
 Avoid fetching in render
 Consider custom hooks for reusability`,codeSnippets:[{language:"javascript",code:`// Fetch API Example
import { useState, useEffect } from 'react';

function UserProfile({ userId }) {
  const [user, setUser] = useState(null);
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState(null);

  useEffect(() => {
    const controller = new AbortController();

    const fetchUser = async () => {
      try {
        setLoading(true);
        const response = await fetch(\`/api/users/\${userId}\`, {
          signal: controller.signal
        });

        if (!response.ok) {
          throw new Error(\`Error: \${response.status}\`);
        }

        const data = await response.json();
        setUser(data);
        setError(null);
      } catch (err) {
        if (err.name !== 'AbortError') {
          setError(err.message);
          setUser(null);
        }
      } finally {
        setLoading(false);
      }
    };

    fetchUser();

    // Cleanup: Cancel request on unmount
    return () => controller.abort();
  }, [userId]);

  if (loading) return <div>Loading...</div>;
  if (error) return <div>Error: {error}</div>;
  return <div>{user?.name}</div>;
}`},{language:"javascript",code:`// Axios Example
import { useState, useEffect } from 'react';
import axios from 'axios';

function UserProfile({ userId }) {
  const [user, setUser] = useState(null);
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState(null);

  useEffect(() => {
    const fetchUser = async () => {
      try {
        const { data } = await axios.get(\`/api/users/\${userId}\`);
        setUser(data);
        setError(null);
      } catch (err) {
        setError(err.message);
        setUser(null);
      } finally {
        setLoading(false);
      }
    };

    fetchUser();
  }, [userId]);

  if (loading) return <div>Loading...</div>;
  if (error) return <div>Error: {error}</div>;
  return <div>{user?.name}</div>;
}

// Axios is cleaner: No need for manual JSON parsing`},{language:"javascript",code:`// Axios with Request Interceptor
import axios from 'axios';

// Create instance
const apiClient = axios.create({
  baseURL: 'https://api.example.com',
  timeout: 5000
});

// Request interceptor: Add auth token
apiClient.interceptors.request.use(
  (config) => {
    const token = localStorage.getItem('authToken');
    if (token) {
      config.headers.Authorization = \`Bearer \${token}\`;
    }
    return config;
  },
  (error) => Promise.reject(error)
);

// Response interceptor: Handle token refresh
apiClient.interceptors.response.use(
  (response) => response,
  async (error) => {
    const originalRequest = error.config;

    if (error.response?.status === 401 && !originalRequest._retry) {
      originalRequest._retry = true;

      try {
        const { data } = await axios.post('/refresh-token');
        localStorage.setItem('authToken', data.token);
        originalRequest.headers.Authorization = \`Bearer \${data.token}\`;
        return apiClient(originalRequest);
      } catch (refreshError) {
        window.location.href = '/login';
        return Promise.reject(refreshError);
      }
    }

    return Promise.reject(error);
  }
);

// Usage: Token automatically added and refreshed
export default apiClient;`}]},{id:"q2",question:"How do you handle loading states, errors, and race conditions in API calls?",answer:`Proper handling of async operations is crucial for robust React applications. Race conditions, loading states, and error handling must be managed carefully.

Common issues:
1. Race conditions: Multiple simultaneous requests
2. Memory leaks: Setting state after unmount
3. Network errors: No internet or server down
4. Timeouts: Slow or unresponsive servers
5. Stale data: Using outdated cached results

Solutions:
 AbortController: Cancel outdated requests
 Cleanup functions: Prevent memory leaks
 Error boundaries: Catch component errors
 Retry logic: Handle temporary failures
 Caching: Reduce unnecessary requests
 Loading states: Provide user feedback
 Debounce/throttle: Limit request frequency

Best practices:
 Always cleanup in useEffect
 Check isMounted before setState
 Use AbortController for cancellation
 Implement proper error UI
 Add request timeout
 Show loading indicator
 Handle edge cases`,codeSnippets:[{language:"javascript",code:`// Handling Race Conditions
function SearchUsers({ query }) {
  const [results, setResults] = useState([]);
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState(null);

  useEffect(() => {
    // If query is empty, don't fetch
    if (!query) {
      setResults([]);
      return;
    }

    let isMounted = true;
    const controller = new AbortController();

    const searchUsers = async () => {
      setLoading(true);
      try {
        const response = await fetch(\`/api/users/search?q=\${query}\`, {
          signal: controller.signal
        });
        
        const data = await response.json();

        // Only update if this is the latest request
        // Prevents race condition where newer request finishes before older one
        if (isMounted) {
          setResults(data);
          setError(null);
        }
      } catch (err) {
        if (err.name !== 'AbortError' && isMounted) {
          setError(err.message);
          setResults([]);
        }
      } finally {
        if (isMounted) setLoading(false);
      }
    };

    searchUsers();

    // Cleanup: Cancel outdated requests
    return () => {
      isMounted = false;
      controller.abort();
    };
  }, [query]); // Re-fetch when query changes

  return (
    <div>
      {loading && <span>Searching...</span>}
      {error && <div className="error">{error}</div>}
      <ul>
        {results.map(user => <li key={user.id}>{user.name}</li>)}
      </ul>
    </div>
  );
}`},{language:"javascript",code:`// Retry Logic with Exponential Backoff
async function fetchWithRetry(url, options = {}, retries = 3) {
  const delay = (ms) => new Promise(resolve => setTimeout(resolve, ms));
  let lastError;

  for (let i = 0; i < retries; i++) {
    try {
      const response = await fetch(url, options);
      if (!response.ok) {
        throw new Error(\`HTTP \${response.status}\`);
      }
      return response.json();
    } catch (error) {
      lastError = error;
      if (i < retries - 1) {
        // Exponential backoff: 1s, 2s, 4s
        const backoffMs = Math.pow(2, i) * 1000;
        await delay(backoffMs);
      }
    }
  }

  throw new Error(\`Failed after \${retries} retries: \${lastError.message}\`);
}

function DataFetcher() {
  const [data, setData] = useState(null);
  const [status, setStatus] = useState('idle');

  const loadData = async () => {
    setStatus('loading');
    try {
      const result = await fetchWithRetry('/api/data', {}, 3);
      setData(result);
      setStatus('success');
    } catch (error) {
      setStatus('error');
      console.error('Failed to fetch:', error);
    }
  };

  return (
    <div>
      <button onClick={loadData}>Load Data</button>
      {status === 'loading' && <span>Loading...</span>}
      {status === 'success' && <pre>{JSON.stringify(data)}</pre>}
      {status === 'error' && <span>Failed to load data</span>}
    </div>
  );
}`},{language:"javascript",code:`// Request Debouncing to Prevent Race Conditions
function useDebounce(value, delay) {
  const [debouncedValue, setDebouncedValue] = useState(value);

  useEffect(() => {
    const handler = setTimeout(() => {
      setDebouncedValue(value);
    }, delay);

    return () => clearTimeout(handler);
  }, [value, delay]);

  return debouncedValue;
}

function SearchWithDebounce() {
  const [searchTerm, setSearchTerm] = useState('');
  const [results, setResults] = useState([]);
  const [loading, setLoading] = useState(false);

  // Debounce search term (wait 500ms after user stops typing)
  const debouncedSearchTerm = useDebounce(searchTerm, 500);

  useEffect(() => {
    if (!debouncedSearchTerm) {
      setResults([]);
      return;
    }

    const controller = new AbortController();
    let isMounted = true;

    const search = async () => {
      setLoading(true);
      try {
        const response = await fetch(
          \`/api/search?q=\${debouncedSearchTerm}\`,
          { signal: controller.signal }
        );
        const data = await response.json();
        
        if (isMounted) {
          setResults(data);
        }
      } catch (error) {
        if (error.name !== 'AbortError') {
          console.error('Search failed:', error);
        }
      } finally {
        if (isMounted) setLoading(false);
      }
    };

    search();

    return () => {
      isMounted = false;
      controller.abort();
    };
  }, [debouncedSearchTerm]); // Only fetch when debounced term changes

  return (
    <div>
      <input 
        value={searchTerm}
        onChange={(e) => setSearchTerm(e.target.value)}
        placeholder="Search..."
      />
      {loading && <span>Searching...</span>}
      <ul>
        {results.map((result, i) => <li key={i}>{result}</li>)}
      </ul>
    </div>
  );
}`}]},{id:"q3",question:"What are best practices for API integration in production React apps?",answer:`Production applications require robust API integration with proper error handling, caching, performance optimization, and security.

Key practices:
1. Environment configuration: Separate endpoints for dev/prod
2. Request interceptors: Add auth, logging, error handling
3. Response caching: Reduce API calls
4. Error handling: User-friendly error messages
5. Loading states: Skeleton screens, spinners
6. Request timeout: Prevent hanging requests
7. Circuit breaker: Fail fast on repeated failures
8. Monitoring: Log errors and analytics
9. Rate limiting: Respect API limits
10. Security: HTTPS, token management, CORS

Authentication:
 Store tokens securely (not localStorage)
 Refresh token before expiry
 Handle 401 responses
 Logout on auth failure

Performance:
 Lazy load data
 Pagination for large datasets
 Batch requests when possible
 Use request deduplication
 Implement caching strategies

Testing:
 Mock API responses
 Test error scenarios
 Test loading states
 Test race conditions
 Test retry logic`,codeSnippets:[{language:"javascript",code:`// Production API Client Setup
import axios from 'axios';

const apiClient = axios.create({
  baseURL: process.env.REACT_APP_API_URL || 'https://api.example.com',
  timeout: 10000,
  headers: {
    'Content-Type': 'application/json'
  }
});

// Request interceptor
apiClient.interceptors.request.use(
  (config) => {
    // Add auth token
    const token = localStorage.getItem('authToken');
    if (token) {
      config.headers.Authorization = \`Bearer \${token}\`;
    }

    // Log request in development
    if (process.env.NODE_ENV === 'development') {
      console.log(\`[API Request] \${config.method.toUpperCase()} \${config.url}\`);
    }

    return config;
  },
  (error) => Promise.reject(error)
);

// Response interceptor
apiClient.interceptors.response.use(
  (response) => {
    if (process.env.NODE_ENV === 'development') {
      console.log(\`[API Response] \${response.status} \${response.config.url}\`);
    }
    return response;
  },
  async (error) => {
    const originalRequest = error.config;

    // Handle 401: Try to refresh token
    if (error.response?.status === 401 && !originalRequest._retry) {
      originalRequest._retry = true;

      try {
        const { data } = await axios.post(
          \`\${process.env.REACT_APP_API_URL}/refresh-token\`,
          { refreshToken: localStorage.getItem('refreshToken') }
        );

        localStorage.setItem('authToken', data.token);
        originalRequest.headers.Authorization = \`Bearer \${data.token}\`;
        return apiClient(originalRequest);
      } catch (refreshError) {
        // Refresh failed: logout user
        localStorage.clear();
        window.location.href = '/login';
        return Promise.reject(refreshError);
      }
    }

    // Handle other errors
    if (process.env.NODE_ENV === 'development') {
      console.error('[API Error]', error.response?.data || error.message);
    }

    return Promise.reject(error);
  }
);

export default apiClient;`},{language:"javascript",code:`// Request Caching Layer
class APICache {
  constructor(ttl = 5 * 60 * 1000) { // 5 minutes default
    this.cache = new Map();
    this.ttl = ttl;
  }

  set(key, value) {
    this.cache.set(key, {
      value,
      timestamp: Date.now()
    });
  }

  get(key) {
    const item = this.cache.get(key);
    if (!item) return null;

    if (Date.now() - item.timestamp > this.ttl) {
      this.cache.delete(key);
      return null;
    }

    return item.value;
  }

  clear() {
    this.cache.clear();
  }
}

const cache = new APICache();

async function cachedFetch(url) {
  // Check cache first
  const cached = cache.get(url);
  if (cached) {
    console.log('Cache hit:', url);
    return cached;
  }

  // Fetch if not cached
  const response = await fetch(url);
  const data = await response.json();

  // Cache response
  cache.set(url, data);

  return data;
}

// Usage in hook
function useCachedData(url) {
  const [data, setData] = useState(null);
  const [loading, setLoading] = useState(true);

  useEffect(() => {
    cachedFetch(url)
      .then(setData)
      .finally(() => setLoading(false));
  }, [url]);

  return { data, loading };
}`},{language:"javascript",code:`// Circuit Breaker Pattern
class CircuitBreaker {
  constructor(threshold = 5, timeout = 60000) {
    this.failureCount = 0;
    this.threshold = threshold;
    this.timeout = timeout;
    this.state = 'CLOSED'; // CLOSED, OPEN, HALF_OPEN
    this.nextAttempt = Date.now();
  }

  async call(fn) {
    if (this.state === 'OPEN') {
      if (Date.now() < this.nextAttempt) {
        throw new Error('Circuit breaker is OPEN');
      }
      this.state = 'HALF_OPEN';
    }

    try {
      const result = await fn();
      this.onSuccess();
      return result;
    } catch (error) {
      this.onFailure();
      throw error;
    }
  }

  onSuccess() {
    this.failureCount = 0;
    this.state = 'CLOSED';
  }

  onFailure() {
    this.failureCount++;
    if (this.failureCount >= this.threshold) {
      this.state = 'OPEN';
      this.nextAttempt = Date.now() + this.timeout;
    }
  }
}

const breaker = new CircuitBreaker(5, 30000);

function useCircuitBreakerAPI(url) {
  const [data, setData] = useState(null);
  const [error, setError] = useState(null);
  const [loading, setLoading] = useState(true);

  useEffect(() => {
    breaker.call(() => fetch(url).then(r => r.json()))
      .then(setData)
      .catch(setError)
      .finally(() => setLoading(false));
  }, [url]);

  return { data, error, loading };
}`}]}]},wy={id:"react",name:"React",icon:"",topics:[gy,yy,hy,vy,fy,Cy,by,Sy,Ay]},Ly={id:"angular-basics",name:"Basics",questions:[{id:"q1",question:"What is Angular and how is it different from AngularJS?",answer:"Angular is a TypeScript-based framework for building web applications. Unlike AngularJS (Angular 1.x), Angular uses component-based architecture, TypeScript, improved performance, mobile support, and modern tooling. AngularJS used controllers and scope, while Angular uses components and services.",codeSnippets:[{language:"typescript",code:`// Angular Component (Angular 2+)
import { Component } from '@angular/core';

@Component({
  selector: 'app-hello',
  template: '<h1>{{ title }}</h1>',
  styleUrls: ['./hello.component.css']
})
export class HelloComponent {
  title = 'Hello Angular';
}

// AngularJS Controller (Angular 1.x) - OLD
angular.module('app').controller('HelloController', 
  function($scope) {
    $scope.title = 'Hello AngularJS';
  }
);`}]},{id:"q2",question:"What are Angular modules (NgModules)?",answer:"NgModules are containers for cohesive blocks of code. They organize an application into functional units. Every Angular app has at least one module (AppModule). Modules can import other modules and declare components, directives, and pipes.",codeSnippets:[{language:"typescript",code:`import { NgModule } from '@angular/core';
import { BrowserModule } from '@angular/platform-browser';
import { FormsModule } from '@angular/forms';
import { AppComponent } from './app.component';
import { UserComponent } from './user/user.component';

@NgModule({
  declarations: [
    AppComponent,    // Components, directives, pipes
    UserComponent
  ],
  imports: [
    BrowserModule,   // Other modules
    FormsModule
  ],
  providers: [],     // Services
  bootstrap: [AppComponent]  // Root component
})
export class AppModule { }`}]},{id:"q3",question:"What is the Angular CLI and what are its benefits?",answer:"Angular CLI is a command-line interface tool for initializing, developing, and maintaining Angular applications. It automates project setup, generates components/services, runs tests, builds for production, and follows best practices.",codeSnippets:[{language:"bash",code:`# Create new Angular application
ng new my-app

# Generate component
ng generate component user

# Generate service
ng generate service data

# Serve application (development)
ng serve

# Build for production
ng build --prod

# Run tests
ng test

# Generate module
ng generate module feature`}]},{id:"q4",question:"What is data binding in Angular?",answer:"Data binding is the synchronization between the component's data and the view. Angular supports four types: Interpolation (one-way from component to view), Property binding (one-way to view), Event binding (one-way from view to component), and Two-way binding (using [(ngModel)]).",codeSnippets:[{language:"typescript",code:`import { Component } from '@angular/core';

@Component({
  selector: 'app-binding',
  template: \`
    <!-- 1. Interpolation {{}} -->
    <h1>{{ title }}</h1>
    
    <!-- 2. Property Binding [] -->
    <img [src]="imageUrl" [alt]="imageAlt">
    <button [disabled]="isDisabled">Click</button>
    
    <!-- 3. Event Binding () -->
    <button (click)="handleClick()">Click Me</button>
    <input (keyup)="onKeyUp($event)">
    
    <!-- 4. Two-way Binding [(ngModel)] -->
    <input [(ngModel)]="username">
    <p>Hello, {{ username }}!</p>
  \`
})
export class BindingComponent {
  title = 'Data Binding Demo';
  imageUrl = 'assets/logo.png';
  imageAlt = 'Logo';
  isDisabled = false;
  username = '';

  handleClick() {
    console.log('Button clicked!');
  }

  onKeyUp(event: KeyboardEvent) {
    console.log('Key pressed:', event.key);
  }
}`}]},{id:"q5",question:"What are Angular decorators?",answer:"Decorators are functions that modify classes or class members. Angular provides decorators like @Component, @NgModule, @Injectable, @Input, @Output, etc. They add metadata that Angular uses to understand how to process the class.",codeSnippets:[{language:"typescript",code:`import { Component, Input, Output, EventEmitter } from '@angular/core';
import { Injectable } from '@angular/core';

// @Component decorator
@Component({
  selector: 'app-user',
  templateUrl: './user.component.html',
  styleUrls: ['./user.component.css']
})
export class UserComponent {
  // @Input decorator - receives data from parent
  @Input() userName: string = '';
  
  // @Output decorator - sends data to parent
  @Output() userDeleted = new EventEmitter<string>();

  deleteUser() {
    this.userDeleted.emit(this.userName);
  }
}

// @Injectable decorator
@Injectable({
  providedIn: 'root'  // Available app-wide
})
export class UserService {
  getUsers() {
    return ['Alice', 'Bob', 'Charlie'];
  }
}`}]},{id:"q6",question:"What is the Angular lifecycle and what are lifecycle hooks?",answer:"Angular creates, updates, and destroys components. Lifecycle hooks are methods that let you tap into key moments in this lifecycle. Common hooks: ngOnInit (after component initialization), ngOnChanges (when input properties change), ngOnDestroy (before component destruction).",codeSnippets:[{language:"typescript",code:`import { Component, OnInit, OnChanges, OnDestroy, 
         Input, SimpleChanges } from '@angular/core';

@Component({
  selector: 'app-lifecycle',
  template: '<p>{{ message }}</p>'
})
export class LifecycleComponent implements OnInit, OnChanges, OnDestroy {
  @Input() data: string = '';
  message = '';
  private intervalId: any;

  // Called before ngOnInit, when input properties change
  ngOnChanges(changes: SimpleChanges) {
    console.log('ngOnChanges:', changes);
    if (changes['data']) {
      this.message = \`Data changed to: \${changes['data'].currentValue}\`;
    }
  }

  // Called once after component initialization
  ngOnInit() {
    console.log('ngOnInit: Component initialized');
    this.intervalId = setInterval(() => {
      console.log('Interval running');
    }, 1000);
  }

  // Called before component destruction
  ngOnDestroy() {
    console.log('ngOnDestroy: Cleaning up');
    if (this.intervalId) {
      clearInterval(this.intervalId);
    }
  }

  // Other hooks:
  // ngDoCheck, ngAfterContentInit, ngAfterContentChecked,
  // ngAfterViewInit, ngAfterViewChecked
}`}]}]},Ty={id:"angular-components",name:"Components",questions:[{id:"q1",question:"What is a component in Angular?",answer:"A component controls a portion of the screen (view). It consists of a TypeScript class (logic), an HTML template (view), and CSS styles. Components are the building blocks of Angular applications and use the @Component decorator.",codeSnippets:[{language:"typescript",code:`import { Component } from '@angular/core';

@Component({
  selector: 'app-user-card',
  templateUrl: './user-card.component.html',
  styleUrls: ['./user-card.component.css']
  // Alternative inline:
  // template: '<div>{{ userName }}</div>',
  // styles: ['div { color: blue; }']
})
export class UserCardComponent {
  userName = 'John Doe';
  age = 30;
  
  greet() {
    return \`Hello, I'm \${this.userName}\`;
  }
}`}]},{id:"q2",question:"What is @Input() and how does parent-child communication work?",answer:"@Input() decorator allows a parent component to pass data to a child component. The child declares an @Input() property, and the parent binds to it using property binding [propertyName].",codeSnippets:[{language:"typescript",code:`// Child Component
import { Component, Input } from '@angular/core';

@Component({
  selector: 'app-child',
  template: \`
    <div>
      <h3>{{ title }}</h3>
      <p>Count: {{ count }}</p>
      <p>User: {{ user?.name }}</p>
    </div>
  \`
})
export class ChildComponent {
  @Input() title: string = '';
  @Input() count: number = 0;
  @Input() user?: { name: string; age: number };
  
  // With alias
  @Input('userName') displayName: string = '';
}

// Parent Component
@Component({
  selector: 'app-parent',
  template: \`
    <app-child 
      [title]="parentTitle"
      [count]="parentCount"
      [user]="currentUser"
      [userName]="name">
    </app-child>
  \`
})
export class ParentComponent {
  parentTitle = 'Child Component';
  parentCount = 42;
  currentUser = { name: 'Alice', age: 25 };
  name = 'Bob';
}`}]},{id:"q3",question:"What is @Output() and EventEmitter?",answer:"@Output() decorator allows a child component to emit events to its parent. It uses EventEmitter to send data upwards. The parent listens using event binding (eventName).",codeSnippets:[{language:"typescript",code:`// Child Component
import { Component, Output, EventEmitter } from '@angular/core';

@Component({
  selector: 'app-child',
  template: \`
    <button (click)="sendMessage()">Send Message</button>
    <button (click)="increment()">Increment</button>
  \`
})
export class ChildComponent {
  @Output() messageEvent = new EventEmitter<string>();
  @Output() countChanged = new EventEmitter<number>();
  
  private count = 0;
  
  sendMessage() {
    this.messageEvent.emit('Hello from child!');
  }
  
  increment() {
    this.count++;
    this.countChanged.emit(this.count);
  }
}

// Parent Component
@Component({
  selector: 'app-parent',
  template: \`
    <app-child 
      (messageEvent)="receiveMessage($event)"
      (countChanged)="onCountChanged($event)">
    </app-child>
    <p>{{ message }}</p>
    <p>Count: {{ totalCount }}</p>
  \`
})
export class ParentComponent {
  message = '';
  totalCount = 0;
  
  receiveMessage(msg: string) {
    this.message = msg;
  }
  
  onCountChanged(count: number) {
    this.totalCount = count;
  }
}`}]},{id:"q4",question:"What is ViewChild and how do you access child components?",answer:"@ViewChild allows a parent to access child component instances, DOM elements, or template reference variables. It provides direct access to child component properties and methods after the view initializes.",codeSnippets:[{language:"typescript",code:`// Child Component
import { Component } from '@angular/core';

@Component({
  selector: 'app-child',
  template: '<p>{{ message }}</p>'
})
export class ChildComponent {
  message = 'Child message';
  
  childMethod() {
    return 'Called from parent!';
  }
}

// Parent Component
import { Component, ViewChild, AfterViewInit, ElementRef } from '@angular/core';

@Component({
  selector: 'app-parent',
  template: \`
    <app-child #childComp></app-child>
    <input #myInput type="text">
    <button (click)="accessChild()">Access Child</button>
  \`
})
export class ParentComponent implements AfterViewInit {
  // Access child component
  @ViewChild('childComp') childComponent!: ChildComponent;
  
  // Access DOM element
  @ViewChild('myInput') inputElement!: ElementRef<HTMLInputElement>;
  
  ngAfterViewInit() {
    // Available after view initialization
    console.log(this.childComponent.message);
    this.inputElement.nativeElement.focus();
  }
  
  accessChild() {
    const result = this.childComponent.childMethod();
    console.log(result);
    this.childComponent.message = 'Updated from parent';
  }
}`}]},{id:"q5",question:"What is content projection (ng-content)?",answer:"Content projection allows you to insert content from a parent component into a child component's template using <ng-content>. It's similar to React's children prop or Vue's slots. Supports single-slot and multi-slot projection.",codeSnippets:[{language:"typescript",code:`// Card Component (Reusable Container)
@Component({
  selector: 'app-card',
  template: \`
    <div class="card">
      <div class="card-header">
        <ng-content select="[header]"></ng-content>
      </div>
      <div class="card-body">
        <ng-content></ng-content>
      </div>
      <div class="card-footer">
        <ng-content select="[footer]"></ng-content>
      </div>
    </div>
  \`,
  styles: [\`.card { border: 1px solid #ccc; padding: 16px; }\`]
})
export class CardComponent { }

// Parent Component Usage
@Component({
  selector: 'app-parent',
  template: \`
    <app-card>
      <h2 header>User Profile</h2>
      
      <p>This is the main content area</p>
      <p>Multiple elements can go here</p>
      
      <button footer>Close</button>
    </app-card>
  \`
})
export class ParentComponent { }`}]},{id:"q6",question:"What is the difference between ViewChild and ContentChild?",answer:"@ViewChild accesses elements in the component's own template. @ContentChild accesses elements projected into the component via <ng-content>. ViewChild is available in ngAfterViewInit, ContentChild in ngAfterContentInit.",codeSnippets:[{language:"typescript",code:`// Button Component
@Component({
  selector: 'app-button',
  template: '<button>{{ label }}</button>'
})
export class ButtonComponent {
  @Input() label = 'Click';
}

// Container Component
import { Component, ViewChild, ContentChild, 
         AfterViewInit, AfterContentInit } from '@angular/core';

@Component({
  selector: 'app-container',
  template: \`
    <div>
      <h3>Container</h3>
      <app-button #viewButton label="View Button"></app-button>
      <ng-content></ng-content>
    </div>
  \`
})
export class ContainerComponent implements AfterViewInit, AfterContentInit {
  // Accesses button in own template
  @ViewChild('viewButton') viewBtn!: ButtonComponent;
  
  // Accesses projected button
  @ContentChild('contentButton') contentBtn!: ButtonComponent;
  
  ngAfterViewInit() {
    console.log('ViewChild:', this.viewBtn.label);
  }
  
  ngAfterContentInit() {
    console.log('ContentChild:', this.contentBtn?.label);
  }
}

// Parent Usage
@Component({
  selector: 'app-parent',
  template: \`
    <app-container>
      <app-button #contentButton label="Content Button"></app-button>
    </app-container>
  \`
})
export class ParentComponent { }`}]}]},Ey={id:"angular-services-di",name:"Services & Dependency Injection",questions:[{id:"q1",question:"What is a service in Angular?",answer:"A service is a class with a specific purpose, typically used for sharing data, implementing business logic, or communicating with external resources. Services are singleton instances that can be injected into components and other services using dependency injection.",codeSnippets:[{language:"typescript",code:`import { Injectable } from '@angular/core';

@Injectable({
  providedIn: 'root'  // Available throughout the app
})
export class UserService {
  private users = [
    { id: 1, name: 'Alice' },
    { id: 2, name: 'Bob' }
  ];

  getUsers() {
    return this.users;
  }

  getUserById(id: number) {
    return this.users.find(user => user.id === id);
  }

  addUser(name: string) {
    const newUser = { 
      id: this.users.length + 1, 
      name 
    };
    this.users.push(newUser);
    return newUser;
  }
}

// Using the service in a component
import { Component, OnInit } from '@angular/core';

@Component({
  selector: 'app-user-list',
  template: \`
    <div *ngFor="let user of users">
      {{ user.name }}
    </div>
  \`
})
export class UserListComponent implements OnInit {
  users: any[] = [];

  // Inject service via constructor
  constructor(private userService: UserService) { }

  ngOnInit() {
    this.users = this.userService.getUsers();
  }
}`}]},{id:"q2",question:"What is Dependency Injection (DI)?",answer:"Dependency Injection is a design pattern where dependencies are provided to a class rather than the class creating them. Angular's DI framework manages the creation and lifecycle of service instances, automatically providing them when needed.",codeSnippets:[{language:"typescript",code:`// Without DI (tightly coupled - BAD)
class UserComponent {
  userService: UserService;
  
  constructor() {
    this.userService = new UserService();  // Creates its own dependency
  }
}

// With DI (loosely coupled - GOOD)
import { Component } from '@angular/core';
import { UserService } from './user.service';

@Component({
  selector: 'app-user',
  template: '<div>{{ users.length }} users</div>'
})
export class UserComponent {
  users: any[] = [];
  
  // Angular provides the instance
  constructor(private userService: UserService) {
    this.users = this.userService.getUsers();
  }
}

// Benefits of DI:
// 1. Testability - easy to mock dependencies
// 2. Reusability - same service instance across components
// 3. Maintainability - loose coupling
// 4. Flexibility - easy to swap implementations`}]},{id:"q3",question:"What are the different provider scopes in Angular?",answer:"Angular provides three scopes for services: 1) Root (providedIn: 'root') - singleton app-wide, 2) Module - one instance per module, 3) Component - new instance per component. The scope determines service lifetime and sharing.",codeSnippets:[{language:"typescript",code:`// 1. Root Level (Singleton - App-wide)
@Injectable({
  providedIn: 'root'  // Recommended for most services
})
export class GlobalService {
  // Single instance shared across entire app
}

// 2. Module Level
@NgModule({
  providers: [ModuleService]  // One instance per module
})
export class FeatureModule { }

@Injectable()
export class ModuleService {
  // New instance for each module that provides it
}

// 3. Component Level
@Component({
  selector: 'app-user',
  providers: [ComponentService]  // New instance per component
})
export class UserComponent {
  constructor(private service: ComponentService) { }
  // Each component instance gets its own service instance
}

@Injectable()
export class ComponentService {
  count = 0;  // Each component has separate count
}`}]},{id:"q4",question:"How do you inject one service into another?",answer:"To inject a service into another service, both must have the @Injectable decorator. The receiving service declares the dependency in its constructor, just like in components.",codeSnippets:[{language:"typescript",code:`// Logger Service
@Injectable({
  providedIn: 'root'
})
export class LoggerService {
  log(message: string) {
    console.log(\`[LOG] \${new Date().toISOString()}: \${message}\`);
  }
  
  error(message: string) {
    console.error(\`[ERROR] \${new Date().toISOString()}: \${message}\`);
  }
}

// User Service depends on Logger Service
@Injectable({
  providedIn: 'root'
})
export class UserService {
  private users = [];

  // Inject LoggerService
  constructor(private logger: LoggerService) {
    this.logger.log('UserService initialized');
  }

  addUser(name: string) {
    this.users.push({ id: Date.now(), name });
    this.logger.log(\`User added: \${name}\`);
  }

  deleteUser(id: number) {
    const index = this.users.findIndex(u => u.id === id);
    if (index > -1) {
      this.users.splice(index, 1);
      this.logger.log(\`User deleted: \${id}\`);
    } else {
      this.logger.error(\`User not found: \${id}\`);
    }
  }
}`}]},{id:"q5",question:"What is the purpose of @Injectable decorator?",answer:"@Injectable marks a class as available for dependency injection. It tells Angular's DI system that the class can have dependencies injected into it. While optional for services without dependencies, it's best practice to always use it.",codeSnippets:[{language:"typescript",code:`// Without @Injectable - only works if service has no dependencies
export class SimpleService {
  getData() {
    return ['data1', 'data2'];
  }
}

// With @Injectable - can receive dependencies
import { Injectable } from '@angular/core';
import { HttpClient } from '@angular/common/http';

@Injectable({
  providedIn: 'root'  // Modern way - tree-shakeable
})
export class DataService {
  // Can inject dependencies
  constructor(private http: HttpClient) { }

  fetchData() {
    return this.http.get('api/data');
  }
}

// Best practice: Always use @Injectable
@Injectable({
  providedIn: 'root'
})
export class BestPracticeService {
  // Even without dependencies, use @Injectable
  // Makes it easier to add dependencies later
  // Enables tree shaking
}`}]},{id:"q6",question:"What is HttpClient and how do you use it?",answer:"HttpClient is Angular's service for making HTTP requests. It returns Observables, supports request/response interceptors, automatic JSON parsing, and error handling. Must import HttpClientModule to use it.",codeSnippets:[{language:"typescript",code:`// 1. Import HttpClientModule in app.module.ts
import { HttpClientModule } from '@angular/common/http';

@NgModule({
  imports: [HttpClientModule],
  // ...
})
export class AppModule { }

// 2. Create a service using HttpClient
import { Injectable } from '@angular/core';
import { HttpClient, HttpHeaders, HttpParams } from '@angular/common/http';
import { Observable } from 'rxjs';
import { catchError, retry } from 'rxjs/operators';

interface User {
  id: number;
  name: string;
  email: string;
}

@Injectable({
  providedIn: 'root'
})
export class ApiService {
  private apiUrl = 'https://api.example.com';

  constructor(private http: HttpClient) { }

  // GET request
  getUsers(): Observable<User[]> {
    return this.http.get<User[]>(\`\${this.apiUrl}/users\`);
  }

  // GET with parameters
  getUserById(id: number): Observable<User> {
    return this.http.get<User>(\`\${this.apiUrl}/users/\${id}\`);
  }

  // GET with query params
  searchUsers(term: string): Observable<User[]> {
    const params = new HttpParams()
      .set('q', term)
      .set('limit', '10');
    
    return this.http.get<User[]>(\`\${this.apiUrl}/users\`, { params });
  }

  // POST request
  createUser(user: Partial<User>): Observable<User> {
    const headers = new HttpHeaders({
      'Content-Type': 'application/json'
    });
    
    return this.http.post<User>(
      \`\${this.apiUrl}/users\`,
      user,
      { headers }
    ).pipe(
      retry(2),  // Retry failed requests
      catchError(this.handleError)
    );
  }

  // PUT request
  updateUser(id: number, user: Partial<User>): Observable<User> {
    return this.http.put<User>(\`\${this.apiUrl}/users/\${id}\`, user);
  }

  // DELETE request
  deleteUser(id: number): Observable<void> {
    return this.http.delete<void>(\`\${this.apiUrl}/users/\${id}\`);
  }

  private handleError(error: any): Observable<never> {
    console.error('API Error:', error);
    throw error;
  }
}

// 3. Use in component
@Component({
  selector: 'app-users',
  template: \`
    <div *ngFor="let user of users">{{ user.name }}</div>
  \`
})
export class UsersComponent implements OnInit {
  users: User[] = [];

  constructor(private apiService: ApiService) { }

  ngOnInit() {
    this.apiService.getUsers().subscribe({
      next: (data) => this.users = data,
      error: (err) => console.error('Error loading users', err)
    });
  }
}`}]}]},Wy={id:"angular-routing",name:"Routing & Navigation",questions:[{id:"q1",question:"What is Angular Router and how do you configure it?",answer:"Angular Router enables navigation between views/components based on URL paths. It's configured by defining routes (path-component mappings) in a Routes array and importing RouterModule. Supports lazy loading, guards, and nested routes.",codeSnippets:[{language:"typescript",code:`// app-routing.module.ts
import { NgModule } from '@angular/core';
import { RouterModule, Routes } from '@angular/router';
import { HomeComponent } from './home/home.component';
import { AboutComponent } from './about/about.component';
import { UserComponent } from './user/user.component';
import { NotFoundComponent } from './not-found/not-found.component';

const routes: Routes = [
  { path: '', component: HomeComponent },  // Default route
  { path: 'about', component: AboutComponent },
  { path: 'user/:id', component: UserComponent },  // Route with parameter
  { path: '**', component: NotFoundComponent }  // Wildcard for 404
];

@NgModule({
  imports: [RouterModule.forRoot(routes)],
  exports: [RouterModule]
})
export class AppRoutingModule { }

// app.component.html
// <router-outlet></router-outlet>  // Renders matched component

// app.module.ts
import { AppRoutingModule } from './app-routing.module';

@NgModule({
  imports: [AppRoutingModule],
  // ...
})
export class AppModule { }`}]},{id:"q2",question:"How do you navigate programmatically in Angular?",answer:"Use the Router service's navigate() or navigateByUrl() methods. navigate() takes an array of path segments and can include route parameters. navigateByUrl() takes a complete URL string.",codeSnippets:[{language:"typescript",code:`import { Component } from '@angular/core';
import { Router } from '@angular/router';

@Component({
  selector: 'app-home',
  template: \`
    <button (click)="goToAbout()">Go to About</button>
    <button (click)="goToUser(42)">Go to User 42</button>
    <button (click)="goToSearch()">Search</button>
  \`
})
export class HomeComponent {
  constructor(private router: Router) { }

  // Method 1: navigate() with array
  goToAbout() {
    this.router.navigate(['/about']);
  }

  // Navigate with parameters
  goToUser(userId: number) {
    this.router.navigate(['/user', userId]);
    // Results in: /user/42
  }

  // Navigate with query parameters
  goToSearch() {
    this.router.navigate(['/search'], {
      queryParams: { q: 'angular', page: 1 }
    });
    // Results in: /search?q=angular&page=1
  }

  // Method 2: navigateByUrl() with string
  goToProfile() {
    this.router.navigateByUrl('/profile');
  }

  // Relative navigation
  goToRelative() {
    this.router.navigate(['../sibling'], { 
      relativeTo: this.route  // Need ActivatedRoute injected
    });
  }
}`}]},{id:"q3",question:"How do you access route parameters and query parameters?",answer:"Use ActivatedRoute service to access route parameters (e.g., /user/:id) via params observable or snapshot.params. Query parameters (e.g., /search?q=test) are accessed via queryParams observable or snapshot.queryParams.",codeSnippets:[{language:"typescript",code:`import { Component, OnInit } from '@angular/core';
import { ActivatedRoute, ParamMap } from '@angular/router';

// Route: /user/:id
@Component({
  selector: 'app-user',
  template: \`
    <h2>User ID: {{ userId }}</h2>
    <p>Query: {{ query }}</p>
  \`
})
export class UserComponent implements OnInit {
  userId: string = '';
  query: string = '';

  constructor(private route: ActivatedRoute) { }

  ngOnInit() {
    // Method 1: Using Observable (recommended for dynamic changes)
    this.route.paramMap.subscribe((params: ParamMap) => {
      this.userId = params.get('id') || '';
      console.log('User ID changed:', this.userId);
    });

    // Query parameters observable
    this.route.queryParamMap.subscribe(params => {
      this.query = params.get('q') || '';
    });

    // Method 2: Using Snapshot (for initial values only)
    const id = this.route.snapshot.paramMap.get('id');
    const query = this.route.snapshot.queryParamMap.get('q');
    console.log('Initial:', id, query);

    // Alternative: Direct access
    this.route.params.subscribe(params => {
      this.userId = params['id'];
    });

    this.route.queryParams.subscribe(params => {
      this.query = params['q'];
    });
  }
}`}]},{id:"q4",question:"What are Route Guards and what types are available?",answer:"Route Guards control navigation to/from routes. Types: CanActivate (allow access), CanActivateChild (child routes), CanDeactivate (leaving route), CanLoad (lazy loading), Resolve (pre-fetch data). Guards return boolean or Observable<boolean>.",codeSnippets:[{language:"typescript",code:`// auth.guard.ts - CanActivate Guard
import { Injectable } from '@angular/core';
import { 
  CanActivate, 
  ActivatedRouteSnapshot, 
  RouterStateSnapshot, 
  Router 
} from '@angular/router';
import { AuthService } from './auth.service';

@Injectable({
  providedIn: 'root'
})
export class AuthGuard implements CanActivate {
  constructor(
    private authService: AuthService,
    private router: Router
  ) { }

  canActivate(
    route: ActivatedRouteSnapshot,
    state: RouterStateSnapshot
  ): boolean {
    if (this.authService.isLoggedIn()) {
      return true;  // Allow navigation
    }
    
    // Redirect to login
    this.router.navigate(['/login'], {
      queryParams: { returnUrl: state.url }
    });
    return false;  // Block navigation
  }
}

// unsaved-changes.guard.ts - CanDeactivate Guard
export interface CanComponentDeactivate {
  canDeactivate: () => boolean | Observable<boolean>;
}

@Injectable({
  providedIn: 'root'
})
export class UnsavedChangesGuard implements CanDeactivate<CanComponentDeactivate> {
  canDeactivate(
    component: CanComponentDeactivate
  ): boolean | Observable<boolean> {
    return component.canDeactivate ? 
      component.canDeactivate() : true;
  }
}

// form.component.ts
@Component({
  selector: 'app-form',
  template: '<form>...</form>'
})
export class FormComponent implements CanComponentDeactivate {
  hasUnsavedChanges = false;

  canDeactivate(): boolean {
    if (this.hasUnsavedChanges) {
      return confirm('You have unsaved changes. Leave anyway?');
    }
    return true;
  }
}

// app-routing.module.ts - Apply guards
const routes: Routes = [
  {
    path: 'profile',
    component: ProfileComponent,
    canActivate: [AuthGuard]  // Protect route
  },
  {
    path: 'form',
    component: FormComponent,
    canDeactivate: [UnsavedChangesGuard]  // Warn before leaving
  }
];`}]},{id:"q5",question:"What is lazy loading and how do you implement it?",answer:"Lazy loading loads feature modules on-demand rather than at startup, reducing initial bundle size and improving performance. Use loadChildren in routes to specify the module path. Requires separate routing module for the feature.",codeSnippets:[{language:"typescript",code:`// app-routing.module.ts
const routes: Routes = [
  { path: '', component: HomeComponent },
  {
    path: 'admin',
    loadChildren: () => import('./admin/admin.module')
      .then(m => m.AdminModule)  // Lazy load module
  },
  {
    path: 'users',
    loadChildren: () => import('./users/users.module')
      .then(m => m.UsersModule),
    canLoad: [AuthGuard]  // Guard lazy loading
  }
];

// admin/admin-routing.module.ts
const routes: Routes = [
  { path: '', component: AdminDashboardComponent },
  { path: 'users', component: AdminUsersComponent },
  { path: 'settings', component: AdminSettingsComponent }
];

@NgModule({
  imports: [RouterModule.forChild(routes)],  // forChild for lazy module
  exports: [RouterModule]
})
export class AdminRoutingModule { }

// admin/admin.module.ts
@NgModule({
  declarations: [
    AdminDashboardComponent,
    AdminUsersComponent,
    AdminSettingsComponent
  ],
  imports: [
    CommonModule,
    AdminRoutingModule
  ]
})
export class AdminModule { }

// Result: 
// - /admin routes to AdminDashboardComponent
// - /admin/users routes to AdminUsersComponent
// - Module only loaded when /admin/* is accessed`}]},{id:"q6",question:"How do you create child/nested routes?",answer:"Child routes are defined using the children property in a route configuration. The parent component must include a <router-outlet> where child components render. Useful for layouts with nested navigation.",codeSnippets:[{language:"typescript",code:`// app-routing.module.ts
const routes: Routes = [
  {
    path: 'products',
    component: ProductsComponent,  // Parent component
    children: [
      { path: '', component: ProductListComponent },  // /products
      { path: ':id', component: ProductDetailComponent },  // /products/123
      { path: ':id/edit', component: ProductEditComponent }  // /products/123/edit
    ]
  },
  {
    path: 'dashboard',
    component: DashboardComponent,
    children: [
      { path: 'overview', component: OverviewComponent },
      { path: 'stats', component: StatsComponent },
      { path: '', redirectTo: 'overview', pathMatch: 'full' }
    ]
  }
];

// products.component.ts (Parent)
@Component({
  selector: 'app-products',
  template: \`
    <div class="products-layout">
      <h1>Products</h1>
      <nav>
        <a routerLink="/">All Products</a>
        <a routerLink="/products/1">Product 1</a>
      </nav>
      
      <!-- Child components render here -->
      <router-outlet></router-outlet>
    </div>
  \`
})
export class ProductsComponent { }

// product-detail.component.ts (Child)
@Component({
  selector: 'app-product-detail',
  template: \`
    <h2>Product Details</h2>
    <p>Product ID: {{ productId }}</p>
  \`
})
export class ProductDetailComponent implements OnInit {
  productId: string = '';

  constructor(private route: ActivatedRoute) { }

  ngOnInit() {
    this.productId = this.route.snapshot.paramMap.get('id') || '';
  }
}`}]}]},ky={id:"angular-forms",name:"Forms",questions:[{id:"q1",question:"What are the two types of forms in Angular?",answer:"Angular has Template-driven forms (simpler, uses directives in template) and Reactive forms (more powerful, programmatic approach with FormControl/FormGroup). Template-driven is good for simple forms, Reactive is better for complex validation and dynamic forms.",codeSnippets:[{language:"typescript",code:`// Template-driven Forms
import { Component } from '@angular/core';

@Component({
  selector: 'app-template-form',
  template: \`
    <form #myForm="ngForm" (ngSubmit)="onSubmit(myForm)">
      <input 
        type="text" 
        name="username" 
        [(ngModel)]="user.username" 
        required
        #username="ngModel">
      <div *ngIf="username.invalid && username.touched">
        Username is required
      </div>
      
      <input 
        type="email" 
        name="email" 
        [(ngModel)]="user.email" 
        required 
        email>
      
      <button [disabled]="myForm.invalid">Submit</button>
    </form>
  \`
})
export class TemplateFormComponent {
  user = { username: '', email: '' };

  onSubmit(form: any) {
    console.log('Form value:', form.value);
    console.log('User model:', this.user);
  }
}

// Need FormsModule in app.module.ts
import { FormsModule } from '@angular/forms';

@NgModule({
  imports: [FormsModule]
})
export class AppModule { }`}]},{id:"q2",question:"How do you create a Reactive Form?",answer:"Reactive forms use FormControl, FormGroup, and FormBuilder. Define form structure in component class, not template. Provides better testing, validation, and dynamic form manipulation. Requires ReactiveFormsModule.",codeSnippets:[{language:"typescript",code:`import { Component, OnInit } from '@angular/core';
import { FormBuilder, FormGroup, FormControl, Validators } from '@angular/forms';

@Component({
  selector: 'app-reactive-form',
  template: \`
    <form [formGroup]="userForm" (ngSubmit)="onSubmit()">
      <div>
        <label>Username:</label>
        <input formControlName="username">
        <div *ngIf="userForm.get('username')?.invalid && 
                    userForm.get('username')?.touched">
          <small *ngIf="userForm.get('username')?.errors?.['required']">
            Username is required
          </small>
          <small *ngIf="userForm.get('username')?.errors?.['minlength']">
            Min 3 characters
          </small>
        </div>
      </div>

      <div>
        <label>Email:</label>
        <input formControlName="email">
        <div *ngIf="userForm.get('email')?.invalid && 
                    userForm.get('email')?.touched">
          Invalid email
        </div>
      </div>

      <div>
        <label>Age:</label>
        <input type="number" formControlName="age">
      </div>

      <button [disabled]="userForm.invalid">Submit</button>
    </form>

    <p>Form Status: {{ userForm.status }}</p>
    <p>Form Value: {{ userForm.value | json }}</p>
  \`
})
export class ReactiveFormComponent implements OnInit {
  userForm!: FormGroup;

  // Method 1: Without FormBuilder
  constructor(private fb: FormBuilder) { }

  ngOnInit() {
    // Method 1: Manual FormControl creation
    this.createFormManually();

    // Method 2: Using FormBuilder (recommended)
    // this.createFormWithBuilder();
  }

  createFormManually() {
    this.userForm = new FormGroup({
      username: new FormControl('', [
        Validators.required,
        Validators.minLength(3)
      ]),
      email: new FormControl('', [
        Validators.required,
        Validators.email
      ]),
      age: new FormControl(null, [
        Validators.min(18),
        Validators.max(100)
      ])
    });
  }

  createFormWithBuilder() {
    this.userForm = this.fb.group({
      username: ['', [Validators.required, Validators.minLength(3)]],
      email: ['', [Validators.required, Validators.email]],
      age: [null, [Validators.min(18), Validators.max(100)]]
    });
  }

  onSubmit() {
    if (this.userForm.valid) {
      console.log('Form submitted:', this.userForm.value);
      this.userForm.reset();  // Reset form
    }
  }
}

// app.module.ts
import { ReactiveFormsModule } from '@angular/forms';

@NgModule({
  imports: [ReactiveFormsModule]
})
export class AppModule { }`}]},{id:"q3",question:"What are FormArray and how do you use them?",answer:"FormArray manages dynamic arrays of FormControls, FormGroups, or other FormArrays. Useful for dynamic forms where users can add/remove fields. Provides methods like push(), removeAt(), and at().",codeSnippets:[{language:"typescript",code:`import { Component, OnInit } from '@angular/core';
import { FormBuilder, FormGroup, FormArray, Validators } from '@angular/forms';

@Component({
  selector: 'app-dynamic-form',
  template: \`
    <form [formGroup]="orderForm" (ngSubmit)="onSubmit()">
      <div>
        <label>Customer Name:</label>
        <input formControlName="customerName">
      </div>

      <div formArrayName="items">
        <h3>Order Items</h3>
        <div *ngFor="let item of items.controls; let i = index" 
             [formGroupName]="i">
          <div class="item-group">
            <input formControlName="name" placeholder="Item name">
            <input type="number" formControlName="quantity" placeholder="Qty">
            <input type="number" formControlName="price" placeholder="Price">
            <button type="button" (click)="removeItem(i)">Remove</button>
          </div>
        </div>
      </div>

      <button type="button" (click)="addItem()">Add Item</button>
      <button [disabled]="orderForm.invalid">Submit Order</button>
    </form>

    <pre>{{ orderForm.value | json }}</pre>
  \`
})
export class DynamicFormComponent implements OnInit {
  orderForm!: FormGroup;

  constructor(private fb: FormBuilder) { }

  ngOnInit() {
    this.orderForm = this.fb.group({
      customerName: ['', Validators.required],
      items: this.fb.array([
        this.createItem()  // Initial item
      ])
    });
  }

  // Getter for FormArray
  get items(): FormArray {
    return this.orderForm.get('items') as FormArray;
  }

  // Create FormGroup for single item
  createItem(): FormGroup {
    return this.fb.group({
      name: ['', Validators.required],
      quantity: [1, [Validators.required, Validators.min(1)]],
      price: [0, [Validators.required, Validators.min(0)]]
    });
  }

  // Add new item
  addItem() {
    this.items.push(this.createItem());
  }

  // Remove item at index
  removeItem(index: number) {
    this.items.removeAt(index);
  }

  onSubmit() {
    if (this.orderForm.valid) {
      console.log('Order:', this.orderForm.value);
      
      // Calculate total
      const total = this.items.value.reduce((sum: number, item: any) => {
        return sum + (item.quantity * item.price);
      }, 0);
      
      console.log('Total:', total);
    }
  }
}`}]},{id:"q4",question:"How do you create custom validators?",answer:"Custom validators are functions that return a ValidationErrors object or null. They can be synchronous or asynchronous. Implement ValidatorFn interface for reusable validators. Can access FormControl value and return error object.",codeSnippets:[{language:"typescript",code:`import { AbstractControl, ValidationErrors, ValidatorFn } from '@angular/forms';

// 1. Simple custom validator
export function forbiddenNameValidator(forbidden: string): ValidatorFn {
  return (control: AbstractControl): ValidationErrors | null => {
    const isForbidden = control.value?.toLowerCase() === forbidden.toLowerCase();
    return isForbidden ? { forbiddenName: { value: control.value } } : null;
  };
}

// 2. Password match validator (cross-field)
export function passwordMatchValidator(): ValidatorFn {
  return (control: AbstractControl): ValidationErrors | null => {
    const password = control.get('password');
    const confirmPassword = control.get('confirmPassword');

    if (!password || !confirmPassword) {
      return null;
    }

    return password.value === confirmPassword.value 
      ? null 
      : { passwordMismatch: true };
  };
}

// 3. Async validator (e.g., checking username availability)
import { Injectable } from '@angular/core';
import { AsyncValidatorFn, AbstractControl } from '@angular/forms';
import { Observable, of } from 'rxjs';
import { map, delay, catchError } from 'rxjs/operators';
import { HttpClient } from '@angular/common/http';

@Injectable({ providedIn: 'root' })
export class UsernameValidator {
  constructor(private http: HttpClient) { }

  usernameExists(): AsyncValidatorFn {
    return (control: AbstractControl): Observable<ValidationErrors | null> => {
      if (!control.value) {
        return of(null);
      }

      return this.http.get<boolean>(\`/api/check-username/\${control.value}\`)
        .pipe(
          delay(500),  // Debounce
          map(exists => exists ? { usernameTaken: true } : null),
          catchError(() => of(null))
        );
    };
  }
}

// Using custom validators in component
@Component({
  selector: 'app-register',
  template: \`
    <form [formGroup]="registerForm" (ngSubmit)="onSubmit()">
      <div>
        <input formControlName="username" placeholder="Username">
        <div *ngIf="registerForm.get('username')?.invalid && 
                    registerForm.get('username')?.touched">
          <small *ngIf="registerForm.get('username')?.errors?.['required']">
            Required
          </small>
          <small *ngIf="registerForm.get('username')?.errors?.['forbiddenName']">
            This name is forbidden
          </small>
          <small *ngIf="registerForm.get('username')?.errors?.['usernameTaken']">
            Username already taken
          </small>
        </div>
      </div>

      <div formGroupName="passwords">
        <input type="password" formControlName="password">
        <input type="password" formControlName="confirmPassword">
        <div *ngIf="registerForm.get('passwords')?.errors?.['passwordMismatch']">
          Passwords don't match
        </div>
      </div>

      <button [disabled]="registerForm.invalid">Register</button>
    </form>
  \`
})
export class RegisterComponent implements OnInit {
  registerForm!: FormGroup;

  constructor(
    private fb: FormBuilder,
    private usernameValidator: UsernameValidator
  ) { }

  ngOnInit() {
    this.registerForm = this.fb.group({
      username: ['',
        [Validators.required, forbiddenNameValidator('admin')],
        [this.usernameValidator.usernameExists()]  // Async validator
      ],
      passwords: this.fb.group({
        password: ['', [Validators.required, Validators.minLength(8)]],
        confirmPassword: ['', Validators.required]
      }, { validators: passwordMatchValidator() })  // Group validator
    });
  }

  onSubmit() {
    if (this.registerForm.valid) {
      console.log('Registered:', this.registerForm.value);
    }
  }
}`}]},{id:"q5",question:"How do you handle form submission and validation states?",answer:"Forms have status properties (valid, invalid, pending, pristine, dirty, touched, untouched). Access via form.status or control.status. Use these to disable submit buttons, show error messages conditionally, or track user interaction.",codeSnippets:[{language:"typescript",code:`import { Component, OnInit } from '@angular/core';
import { FormBuilder, FormGroup, Validators } from '@angular/forms';

@Component({
  selector: 'app-user-form',
  template: \`
    <form [formGroup]="userForm" (ngSubmit)="onSubmit()">
      <div>
        <label>Name:</label>
        <input formControlName="name">
        
        <!-- Show errors only when touched and invalid -->
        <div *ngIf="name.invalid && (name.dirty || name.touched)" 
             class="error">
          <div *ngIf="name.errors?.['required']">Name is required</div>
          <div *ngIf="name.errors?.['minlength']">
            Name must be at least 
            {{ name.errors?.['minlength'].requiredLength }} characters
          </div>
        </div>
      </div>

      <div>
        <label>Email:</label>
        <input formControlName="email">
        
        <!-- Different error states -->
        <div *ngIf="email.invalid && email.touched" class="error">
          <div *ngIf="email.errors?.['required']">Email is required</div>
          <div *ngIf="email.errors?.['email']">Invalid email format</div>
        </div>
      </div>

      <!-- Submit button disabled if form invalid -->
      <button 
        type="submit" 
        [disabled]="userForm.invalid || submitting">
        {{ submitting ? 'Submitting...' : 'Submit' }}
      </button>

      <!-- Reset button -->
      <button 
        type="button" 
        (click)="onReset()"
        [disabled]="userForm.pristine">
        Reset
      </button>
    </form>

    <!-- Debug info -->
    <div class="debug">
      <p>Form Status: {{ userForm.status }}</p>
      <p>Form Valid: {{ userForm.valid }}</p>
      <p>Form Pristine: {{ userForm.pristine }}</p>
      <p>Form Touched: {{ userForm.touched }}</p>
      <p>Name Status: {{ name.status }}</p>
      <p>Name Errors: {{ name.errors | json }}</p>
    </div>
  \`
})
export class UserFormComponent implements OnInit {
  userForm!: FormGroup;
  submitting = false;
  submitted = false;

  constructor(private fb: FormBuilder) { }

  ngOnInit() {
    this.userForm = this.fb.group({
      name: ['', [Validators.required, Validators.minLength(3)]],
      email: ['', [Validators.required, Validators.email]]
    });

    // Listen to form value changes
    this.userForm.valueChanges.subscribe(value => {
      console.log('Form changed:', value);
    });

    // Listen to status changes
    this.userForm.statusChanges.subscribe(status => {
      console.log('Status changed:', status);
    });

    // Listen to specific field
    this.name.valueChanges.subscribe(value => {
      console.log('Name changed:', value);
    });
  }

  // Convenience getters for form controls
  get name() {
    return this.userForm.get('name')!;
  }

  get email() {
    return this.userForm.get('email')!;
  }

  onSubmit() {
    this.submitted = true;

    // Mark all as touched to show errors
    this.userForm.markAllAsTouched();

    if (this.userForm.valid) {
      this.submitting = true;

      // Simulate API call
      setTimeout(() => {
        console.log('Form submitted:', this.userForm.value);
        this.submitting = false;
        this.userForm.reset();
        this.submitted = false;
      }, 2000);
    } else {
      console.log('Form is invalid');
    }
  }

  onReset() {
    this.userForm.reset();
    this.submitted = false;
  }

  // Manually set values
  populateForm() {
    this.userForm.patchValue({
      name: 'John Doe'
      // email not set
    });

    // Or set all values
    this.userForm.setValue({
      name: 'John Doe',
      email: 'john@example.com'
    });
  }
}`}]}]},Iy={id:"angular-rxjs",name:"RxJS & Observables",questions:[{id:"q1",question:"What are Observables in Angular?",answer:"Observables are lazy collections of multiple values over time. They're part of RxJS library. Unlike Promises (single value), Observables can emit multiple values, can be cancelled, and support operators for transformation. Angular uses them extensively for HTTP, routing, forms, and events.",codeSnippets:[{language:"typescript",code:`import { Observable, of, from } from 'rxjs';

// Creating Observables
const observable1 = new Observable(subscriber => {
  subscriber.next(1);
  subscriber.next(2);
  subscriber.next(3);
  subscriber.complete();
});

// Using 'of' operator
const observable2 = of(1, 2, 3);

// From array
const observable3 = from([1, 2, 3]);

// Subscribing to Observable
observable1.subscribe({
  next: (value) => console.log('Received:', value),
  error: (err) => console.error('Error:', err),
  complete: () => console.log('Completed')
});

// Observable vs Promise
const promise = new Promise((resolve) => {
  resolve('one value');  // Single value
});

const observable = new Observable(subscriber => {
  subscriber.next('value 1');
  subscriber.next('value 2');  // Multiple values
  subscriber.next('value 3');
});

// Observables are lazy (only execute when subscribed)
const lazy = new Observable(subscriber => {
  console.log('Observable executed!');
  subscriber.next(Math.random());
});

// Nothing happens here
const obs = lazy;

// Executes now
obs.subscribe(val => console.log('First:', val));
obs.subscribe(val => console.log('Second:', val));  // Different value`}]},{id:"q2",question:"What are common RxJS operators and how do you use them?",answer:"RxJS operators transform, filter, or combine Observables. Common operators: map (transform values), filter (conditional emission), tap (side effects), switchMap (switch to new observable), mergeMap, concatMap, catchError (error handling), debounceTime (delay), take (limit emissions).",codeSnippets:[{language:"typescript",code:`import { Component, OnInit } from '@angular/core';
import { Observable, of, interval, fromEvent } from 'rxjs';
import { 
  map, filter, tap, take, debounceTime, 
  switchMap, catchError, distinctUntilChanged 
} from 'rxjs/operators';

@Component({
  selector: 'app-rxjs-demo',
  template: \`
    <input #searchInput type="text" placeholder="Search...">
    <div *ngFor="let result of searchResults">{{ result }}</div>
  \`
})
export class RxjsDemoComponent implements OnInit {
  searchResults: string[] = [];

  ngOnInit() {
    // 1. map - transform values
    of(1, 2, 3).pipe(
      map(x => x * 10)
    ).subscribe(val => console.log('Mapped:', val));
    // Output: 10, 20, 30

    // 2. filter - emit only certain values
    of(1, 2, 3, 4, 5).pipe(
      filter(x => x % 2 === 0)
    ).subscribe(val => console.log('Filtered:', val));
    // Output: 2, 4

    // 3. tap - side effects (logging, debugging)
    of(1, 2, 3).pipe(
      tap(x => console.log('Before map:', x)),
      map(x => x * 10),
      tap(x => console.log('After map:', x))
    ).subscribe();

    // 4. take - limit emissions
    interval(1000).pipe(
      take(5)
    ).subscribe(val => console.log('Interval:', val));
    // Emits 0, 1, 2, 3, 4 then completes

    // 5. debounceTime - delay emissions
    fromEvent(document.getElementById('searchInput')!, 'input').pipe(
      debounceTime(500),  // Wait 500ms after last keystroke
      map((event: any) => event.target.value),
      distinctUntilChanged()  // Only if value changed
    ).subscribe(value => console.log('Search:', value));

    // 6. switchMap - switch to new observable (cancel previous)
    // Useful for search/autocomplete
    this.search('angular');
  }

  search(term: string): void {
    of(term).pipe(
      debounceTime(300),
      distinctUntilChanged(),
      switchMap(searchTerm => this.performSearch(searchTerm)),
      catchError(error => {
        console.error('Search error:', error);
        return of([]);  // Return empty array on error
      })
    ).subscribe(results => {
      this.searchResults = results;
    });
  }

  performSearch(term: string): Observable<string[]> {
    // Simulated API call
    return of(['Result 1', 'Result 2', 'Result 3']);
  }
}

// More operator examples
export class MoreOperators {
  example1() {
    // mergeMap - process all emissions in parallel
    of('user1', 'user2').pipe(
      mergeMap(userId => this.fetchUser(userId))
    ).subscribe(user => console.log('User:', user));
  }

  example2() {
    // concatMap - process emissions in order (wait for previous)
    of('user1', 'user2').pipe(
      concatMap(userId => this.fetchUser(userId))
    ).subscribe(user => console.log('User:', user));
  }

  fetchUser(id: string): Observable<any> {
    return of({ id, name: \`User \${id}\` });
  }
}`}]},{id:"q3",question:"What is the difference between Subject, BehaviorSubject, and ReplaySubject?",answer:"Subject is an Observable that can multicast to multiple observers. BehaviorSubject requires initial value and emits current value to new subscribers. ReplaySubject replays specified number of emissions to new subscribers. AsyncSubject emits only last value on completion.",codeSnippets:[{language:"typescript",code:`import { Subject, BehaviorSubject, ReplaySubject, AsyncSubject } from 'rxjs';

// 1. Subject - no initial value, late subscribers miss previous emissions
const subject = new Subject<number>();

subject.subscribe(val => console.log('Sub 1:', val));
subject.next(1);  // Sub 1: 1
subject.next(2);  // Sub 1: 2

subject.subscribe(val => console.log('Sub 2:', val));
// Sub 2 doesn't receive 1 or 2
subject.next(3);  // Sub 1: 3, Sub 2: 3

// 2. BehaviorSubject - has initial value, emits current value to new subscribers
const behavior = new BehaviorSubject<number>(0);  // Initial value

behavior.subscribe(val => console.log('Behavior 1:', val));  // 0
behavior.next(1);  // 1
behavior.next(2);  // 2

behavior.subscribe(val => console.log('Behavior 2:', val));  // 2 (current)
behavior.next(3);  // Both get 3

console.log('Current value:', behavior.value);  // Can access current value

// 3. ReplaySubject - replays N previous emissions to new subscribers
const replay = new ReplaySubject<number>(2);  // Buffer size: 2

replay.next(1);
replay.next(2);
replay.next(3);

replay.subscribe(val => console.log('Replay 1:', val));
// Outputs: 2, 3 (last 2 values)

replay.next(4);  // 4

replay.subscribe(val => console.log('Replay 2:', val));
// Outputs: 3, 4 (last 2 values)

// 4. AsyncSubject - emits only last value when completed
const async = new AsyncSubject<number>();

async.subscribe(val => console.log('Async:', val));
async.next(1);
async.next(2);
async.next(3);
// No output yet

async.complete();  // Now outputs: 3 (only last value)

// Practical use case: Shared data service
import { Injectable } from '@angular/core';

@Injectable({ providedIn: 'root' })
export class DataService {
  // BehaviorSubject for current user
  private currentUserSubject = new BehaviorSubject<any>(null);
  currentUser$ = this.currentUserSubject.asObservable();

  // Subject for notifications
  private notificationSubject = new Subject<string>();
  notifications$ = this.notificationSubject.asObservable();

  setUser(user: any) {
    this.currentUserSubject.next(user);
  }

  getCurrentUser() {
    return this.currentUserSubject.value;  // Synchronous access
  }

  sendNotification(message: string) {
    this.notificationSubject.next(message);
  }
}

// Component usage
@Component({
  selector: 'app-user-profile',
  template: '<h1>{{ (currentUser$ | async)?.name }}</h1>'
})
export class UserProfileComponent implements OnInit {
  currentUser$: Observable<any>;

  constructor(private dataService: DataService) {
    this.currentUser$ = this.dataService.currentUser$;
  }

  ngOnInit() {
    // Immediately receives current user (if any)
    this.currentUser$.subscribe(user => {
      console.log('Current user:', user);
    });
  }
}`}]},{id:"q4",question:"What is the async pipe and why should you use it?",answer:"The async pipe subscribes to Observables/Promises in templates and automatically unsubscribes on component destruction. It prevents memory leaks, reduces boilerplate, and handles subscription lifecycle automatically. Returns the latest emitted value.",codeSnippets:[{language:"typescript",code:`import { Component, OnInit } from '@angular/core';
import { Observable, interval } from 'rxjs';
import { map } from 'rxjs/operators';

// Without async pipe (BAD - manual subscription management)
@Component({
  selector: 'app-without-async',
  template: \`
    <h2>Users</h2>
    <div *ngFor="let user of users">{{ user.name }}</div>
  \`
})
export class WithoutAsyncComponent implements OnInit, OnDestroy {
  users: any[] = [];
  private subscription: any;

  constructor(private userService: UserService) { }

  ngOnInit() {
    // Must manually subscribe
    this.subscription = this.userService.getUsers().subscribe(
      users => this.users = users
    );
  }

  ngOnDestroy() {
    // Must manually unsubscribe to prevent memory leak
    if (this.subscription) {
      this.subscription.unsubscribe();
    }
  }
}

// With async pipe (GOOD - automatic subscription management)
@Component({
  selector: 'app-with-async',
  template: \`
    <h2>Users</h2>
    
    <!-- Observable with async pipe -->
    <div *ngFor="let user of users$ | async">
      {{ user.name }}
    </div>

    <!-- Loading state -->
    <div *ngIf="(users$ | async) === null">Loading...</div>

    <!-- Using as syntax for single subscription -->
    <div *ngIf="users$ | async as users">
      <p>Total: {{ users.length }}</p>
      <div *ngFor="let user of users">{{ user.name }}</div>
    </div>

    <!-- Multiple async pipes (creates multiple subscriptions) -->
    <p>Count: {{ (users$ | async)?.length }}</p>
    <div *ngFor="let user of users$ | async">...</div>
  \`
})
export class WithAsyncComponent implements OnInit {
  users$!: Observable<any[]>;
  // No OnDestroy needed!

  constructor(private userService: UserService) { }

  ngOnInit() {
    // Just assign the Observable
    this.users$ = this.userService.getUsers();
    // async pipe handles subscribe/unsubscribe automatically
  }
}

// Better pattern: single subscription with 'as'
@Component({
  selector: 'app-optimized',
  template: \`
    <ng-container *ngIf="data$ | async as data">
      <h2>{{ data.title }}</h2>
      <p>{{ data.description }}</p>
      <ul>
        <li *ngFor="let item of data.items">{{ item }}</li>
      </ul>
    </ng-container>
  \`
})
export class OptimizedComponent {
  data$: Observable<any>;

  constructor(private dataService: DataService) {
    this.data$ = this.dataService.getData();
  }
}

// Async pipe with loading and error states
@Component({
  selector: 'app-advanced',
  template: \`
    <div [ngSwitch]="(users$ | async)">
      <div *ngSwitchCase="null">Loading...</div>
      <div *ngSwitchCase="[]">No users found</div>
      <div *ngSwitchDefault>
        <div *ngFor="let user of users$ | async">
          {{ user.name }}
        </div>
      </div>
    </div>
  \`
})
export class AdvancedAsyncComponent {
  users$: Observable<any[]>;

  constructor(private userService: UserService) {
    this.users$ = this.userService.getUsers();
  }
}`}]},{id:"q5",question:"How do you handle errors in Observables?",answer:"Use catchError operator to handle errors gracefully. It receives the error and returns a new Observable (replacement or empty). Can also use retry operator to retry failed operations. Use finalize for cleanup regardless of success/error.",codeSnippets:[{language:"typescript",code:`import { Component } from '@angular/core';
import { HttpClient } from '@angular/common/http';
import { Observable, throwError, of } from 'rxjs';
import { catchError, retry, finalize, tap } from 'rxjs/operators';

@Injectable({ providedIn: 'root' })
export class ApiService {
  constructor(private http: HttpClient) { }

  // 1. Basic error handling with catchError
  getUsers(): Observable<any[]> {
    return this.http.get<any[]>('/api/users').pipe(
      catchError(error => {
        console.error('Error loading users:', error);
        return of([]); // Return empty array as fallback
      })
    );
  }

  // 2. Retry failed requests
  getUsersWithRetry(): Observable<any[]> {
    return this.http.get<any[]>('/api/users').pipe(
      retry(3),  // Retry up to 3 times
      catchError(error => {
        console.error('Failed after 3 retries:', error);
        return of([]);
      })
    );
  }

  // 3. Re-throw error after handling
  getUsersRethrow(): Observable<any[]> {
    return this.http.get<any[]>('/api/users').pipe(
      catchError(error => {
        console.error('Error occurred:', error);
        
        // Log to error service
        this.logError(error);
        
        // Re-throw error
        return throwError(() => new Error('Failed to load users'));
      })
    );
  }

  // 4. Different error handling based on status
  getUsersAdvanced(): Observable<any[]> {
    return this.http.get<any[]>('/api/users').pipe(
      catchError(error => {
        if (error.status === 404) {
          console.log('Users not found');
          return of([]);
        } else if (error.status === 401) {
          console.log('Unauthorized');
          // Redirect to login
          return throwError(() => new Error('Unauthorized'));
        } else {
          console.error('Unknown error:', error);
          return of([]);
        }
      })
    );
  }

  // 5. Using finalize for cleanup
  getUsersWithCleanup(): Observable<any[]> {
    let loading = true;
    
    return this.http.get<any[]>('/api/users').pipe(
      tap(() => console.log('Request started')),
      finalize(() => {
        // Always executes (success or error)
        loading = false;
        console.log('Request completed');
      }),
      catchError(error => {
        console.error('Error:', error);
        return of([]);
      })
    );
  }

  private logError(error: any): void {
    // Send to logging service
  }
}

// Component with error handling
@Component({
  selector: 'app-users',
  template: \`
    <div *ngIf="loading">Loading...</div>
    <div *ngIf="error" class="error">{{ error }}</div>
    <div *ngIf="!loading && !error">
      <div *ngFor="let user of users">{{ user.name }}</div>
    </div>
  \`
})
export class UsersComponent implements OnInit {
  users: any[] = [];
  loading = false;
  error: string | null = null;

  constructor(private apiService: ApiService) { }

  ngOnInit() {
    this.loadUsers();
  }

  loadUsers() {
    this.loading = true;
    this.error = null;

    this.apiService.getUsersAdvanced().pipe(
      finalize(() => this.loading = false)
    ).subscribe({
      next: (users) => {
        this.users = users;
      },
      error: (err) => {
        this.error = err.message || 'An error occurred';
        console.error('Error in component:', err);
      }
    });
  }

  // Retry mechanism
  retry() {
    this.loadUsers();
  }
}`}]},{id:"q6",question:"What is the difference between mergeMap, switchMap, and concatMap?",answer:"All three flatten nested Observables, but differ in behavior: switchMap cancels previous inner observables (for searches), mergeMap processes all in parallel (for independent requests), concatMap processes sequentially in order (for ordered operations).",codeSnippets:[{language:"typescript",code:`import { Component } from '@angular/core';
import { fromEvent, interval, of } from 'rxjs';
import { 
  switchMap, mergeMap, concatMap, 
  map, take, delay 
} from 'rxjs/operators';

@Component({
  selector: 'app-operators-demo',
  template: '<div>Check console for output</div>'
})
export class OperatorsDemoComponent {
  
  // 1. switchMap - Cancels previous, keeps only latest
  // USE FOR: Search, autocomplete, GET requests
  demonstrateSwitchMap() {
    const clicks = fromEvent(document, 'click');
    
    clicks.pipe(
      switchMap(() => interval(1000).pipe(take(5)))
    ).subscribe(val => console.log('switchMap:', val));
    
    // If you click again, previous interval is CANCELLED
    // Only the latest interval runs
  }

  // 2. mergeMap - Processes all in parallel
  // USE FOR: Independent operations, batch operations
  demonstrateMergeMap() {
    of('user1', 'user2', 'user3').pipe(
      mergeMap(userId => 
        this.fetchUser(userId).pipe(
          map(user => ({ userId, user }))
        )
      )
    ).subscribe(result => console.log('mergeMap:', result));
    
    // All fetchUser calls run in parallel
    // Results may arrive in any order
  }

  // 3. concatMap - Processes sequentially (wait for previous)
  // USE FOR: Ordered operations, dependent requests
  demonstrateConcatMap() {
    of('user1', 'user2', 'user3').pipe(
      concatMap(userId => 
        this.fetchUser(userId).pipe(
          map(user => ({ userId, user }))
        )
      )
    ).subscribe(result => console.log('concatMap:', result));
    
    // Fetches users one at a time, in order
    // Waits for each to complete before starting next
  }

  // Practical examples
  
  // Search with switchMap (cancels previous search)
  searchUsers(searchTerm: string) {
    return of(searchTerm).pipe(
      switchMap(term => this.apiSearch(term))
    );
    // If user types fast, only last search executes
  }

  // Batch update with mergeMap (parallel)
  updateMultipleUsers(userIds: string[]) {
    return of(...userIds).pipe(
      mergeMap(id => this.updateUser(id))
    );
    // All updates happen simultaneously
  }

  // Sequential operations with concatMap
  processQueueInOrder(tasks: any[]) {
    return of(...tasks).pipe(
      concatMap(task => this.processTask(task))
    );
    // Tasks processed one by one, maintaining order
  }

  // Helper methods
  private fetchUser(userId: string) {
    return of({ id: userId, name: \`User \${userId}\` }).pipe(
      delay(Math.random() * 1000)  // Random delay
    );
  }

  private apiSearch(term: string) {
    return of([{ name: term }]).pipe(delay(500));
  }

  private updateUser(id: string) {
    return of({ id, updated: true }).pipe(delay(300));
  }

  private processTask(task: any) {
    return of({ task, processed: true }).pipe(delay(1000));
  }
}

// Visual comparison
/**
 * INPUT: [A, B, C] (emitted over time)
 * 
 * switchMap:
 * A-----X (cancelled when B arrives)
 * B-----X (cancelled when C arrives)  
 * C-----result
 * 
 * mergeMap:
 * A-----resultA
 * B-----resultB
 * C-----resultC
 * (all run in parallel, any order)
 * 
 * concatMap:
 * A-----resultA
 *       B-----resultB
 *             C-----resultC
 * (sequential, ordered)
 */`}]}]},Ry={id:"angular",name:"Angular",icon:"",topics:[Ly,Ty,Ey,Wy,ky,Iy]},Dy={id:"csharp-creational",name:"Creational Patterns",questions:[{id:"q1",question:"What is the Singleton pattern and how do you implement it in C#?",answer:"The Singleton pattern ensures a class has only one instance and provides a global point of access to it. It's useful for centralized management of resources like database connections, logging, or configuration. There are multiple implementation approaches with different thread-safety guarantees.",codeSnippets:[{language:"csharp",code:`// Eager initialization - Thread-safe
public class Singleton
{
    private static readonly Singleton _instance = new Singleton();
    
    private Singleton() { }
    
    public static Singleton Instance => _instance;
}

// Lazy initialization - Thread-safe with Lazy<T>
public class SingletonLazy
{
    private static readonly Lazy<SingletonLazy> _instance = 
        new Lazy<SingletonLazy>(() => new SingletonLazy());
    
    private SingletonLazy() { }
    
    public static SingletonLazy Instance => _instance.Value;
}

// Usage
var singleton1 = Singleton.Instance;
var singleton2 = Singleton.Instance;
Console.WriteLine(ReferenceEquals(singleton1, singleton2)); // true`}]},{id:"q2",question:"Explain the Factory Method pattern with a C# example.",answer:"The Factory Method pattern defines an interface for creating objects, but lets subclasses decide which class to instantiate. It promotes loose coupling by eliminating the need to bind application-specific classes into the code.",codeSnippets:[{language:"csharp",code:`// Abstract Creator
public abstract class DatabaseFactory
{
    public abstract IDatabase CreateDatabase();
    
    public void InitializeDatabase()
    {
        var db = CreateDatabase();
        db.Connect();
    }
}

// Concrete Creators
public class SqlServerFactory : DatabaseFactory
{
    public override IDatabase CreateDatabase() => new SqlServerDatabase();
}

public class MySqlFactory : DatabaseFactory
{
    public override IDatabase CreateDatabase() => new MySqlDatabase();
}

// Product Interface
public interface IDatabase
{
    void Connect();
    void ExecuteQuery(string query);
}

// Concrete Products
public class SqlServerDatabase : IDatabase
{
    public void Connect() => Console.WriteLine("Connected to SQL Server");
    public void ExecuteQuery(string query) => Console.WriteLine($"Executing: {query}");
}

public class MySqlDatabase : IDatabase
{
    public void Connect() => Console.WriteLine("Connected to MySQL");
    public void ExecuteQuery(string query) => Console.WriteLine($"Executing: {query}");
}

// Usage
DatabaseFactory factory = new SqlServerFactory();
factory.InitializeDatabase();`}]},{id:"q3",question:"What is the Abstract Factory pattern and when should you use it?",answer:"The Abstract Factory pattern provides an interface for creating families of related or dependent objects without specifying their concrete classes. Use it when you need to create multiple related objects that must work together, such as UI elements for different platforms (Windows, macOS) or database providers with different drivers.",codeSnippets:[{language:"csharp",code:`// Abstract Factory
public interface IUIFactory
{
    IButton CreateButton();
    ITextBox CreateTextBox();
}

// Product Interfaces
public interface IButton { void Click(); }
public interface ITextBox { void Type(string text); }

// Concrete Factories
public class WindowsUIFactory : IUIFactory
{
    public IButton CreateButton() => new WindowsButton();
    public ITextBox CreateTextBox() => new WindowsTextBox();
}

public class MacUIFactory : IUIFactory
{
    public IButton CreateButton() => new MacButton();
    public ITextBox CreateTextBox() => new MacTextBox();
}

// Concrete Products
public class WindowsButton : IButton { public void Click() => Console.WriteLine("Windows Button clicked"); }
public class MacButton : IButton { public void Click() => Console.WriteLine("Mac Button clicked"); }
public class WindowsTextBox : ITextBox { public void Type(string text) => Console.WriteLine($"Windows TextBox: {text}"); }
public class MacTextBox : ITextBox { public void Type(string text) => Console.WriteLine($"Mac TextBox: {text}"); }

// Client Code
public class Application
{
    private IButton _button;
    private ITextBox _textBox;
    
    public Application(IUIFactory factory)
    {
        _button = factory.CreateButton();
        _textBox = factory.CreateTextBox();
    }
    
    public void Run()
    {
        _button.Click();
        _textBox.Type("Hello");
    }
}

// Usage
IUIFactory factory = Environment.OSVersion.Platform == PlatformID.Win32NT 
    ? new WindowsUIFactory() : new MacUIFactory();
var app = new Application(factory);
app.Run();`}]},{id:"q4",question:"What is the Builder pattern and why is it useful?",answer:"The Builder pattern separates the construction of a complex object from its representation, allowing the same construction process to create different representations. It's useful for objects with many optional parameters and makes code more readable than multiple constructor overloads.",codeSnippets:[{language:"csharp",code:`// Product
public class Computer
{
    public string CPU { get; set; }
    public string RAM { get; set; }
    public string Storage { get; set; }
    public string GPU { get; set; }
    public bool HasWiFi { get; set; }
    
    public override string ToString()
    {
        return $"CPU: {CPU}, RAM: {RAM}, Storage: {Storage}, GPU: {GPU}, WiFi: {HasWiFi}";
    }
}

// Builder
public class ComputerBuilder
{
    private Computer _computer = new Computer();
    
    public ComputerBuilder WithCPU(string cpu)
    {
        _computer.CPU = cpu;
        return this;
    }
    
    public ComputerBuilder WithRAM(string ram)
    {
        _computer.RAM = ram;
        return this;
    }
    
    public ComputerBuilder WithStorage(string storage)
    {
        _computer.Storage = storage;
        return this;
    }
    
    public ComputerBuilder WithGPU(string gpu)
    {
        _computer.GPU = gpu;
        return this;
    }
    
    public ComputerBuilder WithWiFi(bool hasWiFi = true)
    {
        _computer.HasWiFi = hasWiFi;
        return this;
    }
    
    public Computer Build() => _computer;
}

// Usage
var computer = new ComputerBuilder()
    .WithCPU("Intel i7")
    .WithRAM("16GB")
    .WithStorage("512GB SSD")
    .WithGPU("RTX 3080")
    .WithWiFi()
    .Build();
    
Console.WriteLine(computer);`}]},{id:"q5",question:"Explain the Prototype pattern in C#.",answer:"The Prototype pattern creates new objects by cloning an existing object rather than creating from scratch. It's useful when object creation is expensive or complex. In C#, you implement the ICloneable interface or use a Clone method.",codeSnippets:[{language:"csharp",code:`// Prototype interface
public interface IPrototype
{
    IPrototype Clone();
}

// Concrete Prototype
public class User : IPrototype
{
    public int Id { get; set; }
    public string Name { get; set; }
    public List<string> Roles { get; set; }
    
    public IPrototype Clone()
    {
        return new User
        {
            Id = this.Id,
            Name = this.Name,
            Roles = new List<string>(this.Roles) // Deep copy
        };
    }
}

// Usage
var originalUser = new User 
{ 
    Id = 1, 
    Name = "John", 
    Roles = new List<string> { "Admin", "User" } 
};

var clonedUser = (User)originalUser.Clone();
clonedUser.Name = "Jane";
clonedUser.Roles.Add("Manager");

Console.WriteLine($"Original: {originalUser.Name}, Roles: {string.Join(", ", originalUser.Roles)}");
Console.WriteLine($"Cloned: {clonedUser.Name}, Roles: {string.Join(", ", clonedUser.Roles)}");`}]}]},Py={id:"csharp-structural",name:"Structural Patterns",questions:[{id:"q6",question:"What is the Adapter pattern and provide a C# example.",answer:"The Adapter pattern converts the interface of a class into another interface clients expect. It lets classes work together that couldn't otherwise because of incompatible interfaces. It's useful for integrating legacy code or third-party libraries.",codeSnippets:[{language:"csharp",code:`// Existing interface (third-party)
public interface ILegacySystem
{
    string GetData();
}

// Legacy implementation
public class LegacySystem : ILegacySystem
{
    public string GetData() => "Data from legacy system";
}

// New interface we want to use
public interface IModernSystem
{
    object FetchData();
}

// Adapter
public class LegacyToModernAdapter : IModernSystem
{
    private ILegacySystem _legacySystem;
    
    public LegacyToModernAdapter(ILegacySystem legacySystem)
    {
        _legacySystem = legacySystem;
    }
    
    public object FetchData()
    {
        return new { data = _legacySystem.GetData(), timestamp = DateTime.Now };
    }
}

// Usage
ILegacySystem legacy = new LegacySystem();
IModernSystem modern = new LegacyToModernAdapter(legacy);
var result = modern.FetchData(); // Works seamlessly`}]},{id:"q7",question:"Explain the Decorator pattern in C#.",answer:"The Decorator pattern attaches additional responsibilities to an object dynamically, providing a flexible alternative to subclassing for extending functionality. It lets you wrap objects in decorators to add features without modifying original classes.",codeSnippets:[{language:"csharp",code:`// Component interface
public interface ICoffee
{
    string GetDescription();
    decimal GetCost();
}

// Concrete Component
public class SimpleCoffee : ICoffee
{
    public string GetDescription() => "Simple Coffee";
    public decimal GetCost() => 2.00m;
}

// Decorators
public abstract class CoffeeDecorator : ICoffee
{
    protected ICoffee _coffee;
    
    public CoffeeDecorator(ICoffee coffee)
    {
        _coffee = coffee;
    }
    
    public virtual string GetDescription() => _coffee.GetDescription();
    public virtual decimal GetCost() => _coffee.GetCost();
}

public class MilkDecorator : CoffeeDecorator
{
    public MilkDecorator(ICoffee coffee) : base(coffee) { }
    
    public override string GetDescription() => _coffee.GetDescription() + ", Milk";
    public override decimal GetCost() => _coffee.GetCost() + 0.50m;
}

public class ChocolateDecorator : CoffeeDecorator
{
    public ChocolateDecorator(ICoffee coffee) : base(coffee) { }
    
    public override string GetDescription() => _coffee.GetDescription() + ", Chocolate";
    public override decimal GetCost() => _coffee.GetCost() + 0.75m;
}

// Usage
ICoffee coffee = new SimpleCoffee();
coffee = new MilkDecorator(coffee);
coffee = new ChocolateDecorator(coffee);

Console.WriteLine(\`\${coffee.GetDescription()}: \${coffee.GetCost()}\`);
// Output: Simple Coffee, Milk, Chocolate: $3.25`}]},{id:"q8",question:"What is the Facade pattern and when do you use it?",answer:"The Facade pattern provides a unified, simplified interface to a set of interfaces in a subsystem. It hides the complexity of the subsystem and makes it easier for clients to use. Use it when you have a complex subsystem and want to provide a simple interface.",codeSnippets:[{language:"csharp",code:`// Complex subsystem
public class DatabaseService
{
    public void Connect(string connectionString) => Console.WriteLine("Database connected");
    public void Authenticate(string username, string password) => Console.WriteLine("User authenticated");
}

public class CacheService
{
    public void Initialize() => Console.WriteLine("Cache initialized");
}

public class LoggingService
{
    public void Log(string message) => Console.WriteLine($"Log: {message}");
}

// Facade
public class ApplicationFacade
{
    private DatabaseService _db;
    private CacheService _cache;
    private LoggingService _logger;
    
    public ApplicationFacade()
    {
        _db = new DatabaseService();
        _cache = new CacheService();
        _logger = new LoggingService();
    }
    
    public void InitializeApplication(string connectionString, string user, string password)
    {
        _logger.Log("Initializing application...");
        _db.Connect(connectionString);
        _db.Authenticate(user, password);
        _cache.Initialize();
        _logger.Log("Application initialized successfully");
    }
}

// Usage - Simple!
var facade = new ApplicationFacade();
facade.InitializeApplication("Server=localhost", "admin", "password");`}]},{id:"q9",question:"Explain the Proxy pattern in C#.",answer:"The Proxy pattern provides a substitute or placeholder for another object to control access to it. It can add behavior like lazy initialization, logging, access control, or caching without changing the original object.",codeSnippets:[{language:"csharp",code:`// Subject interface
public interface IDataService
{
    string FetchData(int id);
}

// Real subject - expensive to create/use
public class RealDataService : IDataService
{
    public string FetchData(int id)
    {
        System.Threading.Thread.Sleep(2000); // Simulate delay
        return $"Data for ID: {id}";
    }
}

// Proxy with caching
public class DataServiceProxy : IDataService
{
    private RealDataService _realService;
    private Dictionary<int, string> _cache = new Dictionary<int, string>();
    
    public string FetchData(int id)
    {
        if (_cache.ContainsKey(id))
        {
            Console.WriteLine($"Cache hit for ID: {id}");
            return _cache[id];
        }
        
        Console.WriteLine($"Cache miss for ID: {id}, fetching from real service...");
        _realService ??= new RealDataService();
        
        var data = _realService.FetchData(id);
        _cache[id] = data;
        return data;
    }
}

// Usage
IDataService service = new DataServiceProxy();
Console.WriteLine(service.FetchData(1)); // Slow - fetches from real service
Console.WriteLine(service.FetchData(1)); // Fast - from cache
Console.WriteLine(service.FetchData(2)); // Slow - fetches from real service`}]},{id:"q10",question:"What is the Bridge pattern?",answer:"The Bridge pattern decouples an abstraction from its implementation so they can vary independently. It's useful when you want to avoid permanent binding between abstraction and implementation, allowing both to vary without affecting each other.",codeSnippets:[{language:"csharp",code:`// Implementor
public interface IRenderer
{
    void RenderCircle(float x, float y, float radius);
}

// Concrete Implementors
public class RasterRenderer : IRenderer
{
    public void RenderCircle(float x, float y, float radius)
        => Console.WriteLine($"Raster rendering circle at ({x}, {y}) with radius {radius}");
}

public class VectorRenderer : IRenderer
{
    public void RenderCircle(float x, float y, float radius)
        => Console.WriteLine($"Vector rendering circle at ({x}, {y}) with radius {radius}");
}

// Abstraction
public abstract class Shape
{
    protected IRenderer _renderer;
    
    public Shape(IRenderer renderer)
    {
        _renderer = renderer;
    }
    
    public abstract void Draw();
}

// Refined Abstraction
public class Circle : Shape
{
    private float _x, _y, _radius;
    
    public Circle(float x, float y, float radius, IRenderer renderer) : base(renderer)
    {
        _x = x;
        _y = y;
        _radius = radius;
    }
    
    public override void Draw() => _renderer.RenderCircle(_x, _y, _radius);
}

// Usage
Circle vectorCircle = new Circle(10, 20, 5, new VectorRenderer());
Circle rasterCircle = new Circle(10, 20, 5, new RasterRenderer());

vectorCircle.Draw(); // Vector rendering circle...
rasterCircle.Draw(); // Raster rendering circle...`}]}]},Oy={id:"csharp-behavioral",name:"Behavioral Patterns",questions:[{id:"q11",question:"What is the Observer pattern and how do you implement it in C#?",answer:"The Observer pattern defines a one-to-many dependency between objects so that when one object changes state, all its dependents are notified automatically. In C#, you can use delegates, events, or implement IObserver/IObservable.",codeSnippets:[{language:"csharp",code:`// Using Events and Delegates
public class StockPrice
{
    private decimal _price;
    
    public decimal Price
    {
        get => _price;
        set
        {
            if (_price != value)
            {
                _price = value;
                OnPriceChanged(_price);
            }
        }
    }
    
    // Event
    public event EventHandler<PriceChangedEventArgs> PriceChanged;
    
    protected virtual void OnPriceChanged(decimal newPrice)
    {
        PriceChanged?.Invoke(this, new PriceChangedEventArgs { NewPrice = newPrice });
    }
}

public class PriceChangedEventArgs : EventArgs
{
    public decimal NewPrice { get; set; }
}

// Observer
public class Investor
{
    public string Name { get; set; }
    
    public void OnPriceChanged(object sender, PriceChangedEventArgs e)
    {
        Console.WriteLine($"{Name} received notification: Price changed to {e.NewPrice}");
    }
}

// Usage
var stock = new StockPrice();
var investor1 = new Investor { Name = "Alice" };
var investor2 = new Investor { Name = "Bob" };

stock.PriceChanged += investor1.OnPriceChanged;
stock.PriceChanged += investor2.OnPriceChanged;

stock.Price = 100.50m; // Both investors are notified`}]},{id:"q12",question:"Explain the Strategy pattern in C#.",answer:"The Strategy pattern defines a family of algorithms, encapsulates each one, and makes them interchangeable. It lets the algorithm vary independently from clients that use it, making code flexible and testable.",codeSnippets:[{language:"csharp",code:`// Strategy interface
public interface IPaymentStrategy
{
    void Pay(decimal amount);
}

// Concrete Strategies
public class CreditCardStrategy : IPaymentStrategy
{
    private string _cardNumber;
    
    public CreditCardStrategy(string cardNumber) => _cardNumber = cardNumber;
    
    public void Pay(decimal amount)
        => Console.WriteLine(\`Paid \${amount} using Credit Card \${_cardNumber}\`);
}

public class PayPalStrategy : IPaymentStrategy
{
    private string _email;
    
    public PayPalStrategy(string email) => _email = email;
    
    public void Pay(decimal amount)
        => Console.WriteLine(\`Paid \${amount} using PayPal account \${_email}\`);
}

public class CryptoStrategy : IPaymentStrategy
{
    private string _walletAddress;
    
    public CryptoStrategy(string walletAddress) => _walletAddress = walletAddress;
    
    public void Pay(decimal amount)
        => Console.WriteLine(\`Paid \${amount} using Crypto wallet \${_walletAddress}\`);
}

// Context
public class ShoppingCart
{
    private IPaymentStrategy _paymentStrategy;
    
    public void SetPaymentStrategy(IPaymentStrategy strategy)
        => _paymentStrategy = strategy;
    
    public void Checkout(decimal total)
        => _paymentStrategy.Pay(total);
}

// Usage
var cart = new ShoppingCart();

cart.SetPaymentStrategy(new CreditCardStrategy("1234-5678-9012-3456"));
cart.Checkout(99.99m);

cart.SetPaymentStrategy(new PayPalStrategy("user@example.com"));
cart.Checkout(49.99m);`}]},{id:"q13",question:"What is the Command pattern and when should you use it?",answer:"The Command pattern encapsulates a request as an object, allowing you to parameterize clients with different requests, queue requests, and support undoable operations. Use it for undo/redo, task scheduling, or request logging.",codeSnippets:[{language:"csharp",code:`// Command interface
public interface ICommand
{
    void Execute();
    void Undo();
}

// Receiver
public class TextEditor
{
    private string _content = "";
    
    public void InsertText(string text)
    {
        _content += text;
        Console.WriteLine($"Content: {_content}");
    }
    
    public void DeleteText(int length)
    {
        if (_content.Length >= length)
        {
            _content = _content.Substring(0, _content.Length - length);
            Console.WriteLine($"Content: {_content}");
        }
    }
    
    public string GetContent() => _content;
}

// Concrete Commands
public class InsertCommand : ICommand
{
    private TextEditor _editor;
    private string _text;
    
    public InsertCommand(TextEditor editor, string text)
    {
        _editor = editor;
        _text = text;
    }
    
    public void Execute() => _editor.InsertText(_text);
    public void Undo() => _editor.DeleteText(_text.Length);
}

// Invoker
public class CommandHistory
{
    private Stack<ICommand> _history = new Stack<ICommand>();
    
    public void Execute(ICommand command)
    {
        command.Execute();
        _history.Push(command);
    }
    
    public void Undo()
    {
        if (_history.Count > 0)
        {
            var command = _history.Pop();
            command.Undo();
        }
    }
}

// Usage
var editor = new TextEditor();
var history = new CommandHistory();

history.Execute(new InsertCommand(editor, "Hello "));
history.Execute(new InsertCommand(editor, "World"));
history.Undo(); // Undo "World"
history.Undo(); // Undo "Hello "`}]},{id:"q14",question:"Explain the State pattern in C#.",answer:"The State pattern allows an object to alter its behavior when its internal state changes. The object will appear to change its class. It's useful for objects with state-dependent behavior.",codeSnippets:[{language:"csharp",code:`// State interface
public interface ILightState
{
    void TurnOn(Light light);
    void TurnOff(Light light);
}

// Concrete States
public class OnState : ILightState
{
    public void TurnOn(Light light) => Console.WriteLine("Light is already on");
    public void TurnOff(Light light)
    {
        Console.WriteLine("Turning light off");
        light.SetState(new OffState());
    }
}

public class OffState : ILightState
{
    public void TurnOn(Light light)
    {
        Console.WriteLine("Turning light on");
        light.SetState(new OnState());
    }
    
    public void TurnOff(Light light) => Console.WriteLine("Light is already off");
}

// Context
public class Light
{
    private ILightState _state;
    
    public Light() => _state = new OffState();
    
    public void SetState(ILightState state) => _state = state;
    
    public void TurnOn() => _state.TurnOn(this);
    public void TurnOff() => _state.TurnOff(this);
}

// Usage
var light = new Light();
light.TurnOn();  // Turning light on
light.TurnOn();  // Light is already on
light.TurnOff(); // Turning light off
light.TurnOff(); // Light is already off`}]},{id:"q15",question:"What is the Chain of Responsibility pattern?",answer:"The Chain of Responsibility pattern allows passing requests along a chain of handlers. Each handler decides whether to process the request or pass it to the next handler. It's useful for request handling, logging, validation pipelines.",codeSnippets:[{language:"csharp",code:`// Handler interface
public abstract class ApprovalHandler
{
    protected ApprovalHandler _nextHandler;
    
    public void SetNext(ApprovalHandler next) => _nextHandler = next;
    
    public abstract void Handle(ExpenseRequest request);
}

// Concrete Handlers
public class ManagerApproval : ApprovalHandler
{
    public override void Handle(ExpenseRequest req)
    {
        if (req.Amount <= 1000)
        {
            Console.WriteLine(\`Manager approved expense of \${req.Amount}\`);
        }
        else if (_nextHandler != null)
        {
            _nextHandler.Handle(req);
        }
    }
}

public class DirectorApproval : ApprovalHandler
{
    public override void Handle(ExpenseRequest req)
    {
        if (req.Amount <= 5000)
        {
            Console.WriteLine(\`Director approved expense of \${req.Amount}\`);
        }
        else if (_nextHandler != null)
        {
            _nextHandler.Handle(req);
        }
    }
}

public class CEOApproval : ApprovalHandler
{
    public override void Handle(ExpenseRequest req)
    {
        if (req.Amount <= 100000)
        {
            Console.WriteLine(\`CEO approved expense of \${req.Amount}\`);
        }
        else
        {
            Console.WriteLine(\`Expense of \${req.Amount} rejected\`);
        }
    }
}

public class ExpenseRequest
{
    public decimal Amount { get; set; }
    public string Description { get; set; }
}

// Usage
var manager = new ManagerApproval();
var director = new DirectorApproval();
var ceo = new CEOApproval();

manager.SetNext(director);
director.SetNext(ceo);

manager.Handle(new ExpenseRequest { Amount = 500 });   // Manager approves
manager.Handle(new ExpenseRequest { Amount = 3000 });  // Director approves
manager.Handle(new ExpenseRequest { Amount = 50000 }); // CEO approves`}]}]},xy={id:"csharp",name:"C# Design Patterns",icon:"",topics:[Dy,Py,Oy]},Ny={id:"microservices-communication",name:"Service Communication",questions:[{id:"q1",question:"What is the API Gateway pattern and why is it important in microservices?",answer:"The API Gateway pattern provides a single entry point for all client requests to a microservices architecture. It handles request routing, protocol translation, authentication, rate limiting, and response aggregation. It simplifies client code and provides a facade over complex microservices.",codeSnippets:[{language:"csharp",code:`// API Gateway using middleware
public class ApiGateway
{
    private readonly IServiceProvider _serviceProvider;
    
    public ApiGateway(IServiceProvider serviceProvider)
    {
        _serviceProvider = serviceProvider;
    }
    
    public async Task<ApiResponse> RouteRequest(ApiRequest request)
    {
        // Route to appropriate microservice
        return request.Path switch
        {
            "/users/*" => await RouteToUserService(request),
            "/orders/*" => await RouteToOrderService(request),
            "/products/*" => await RouteToProductService(request),
            _ => new ApiResponse { StatusCode = 404, Body = "Not Found" }
        };
    }
    
    private async Task<ApiResponse> RouteToUserService(ApiRequest request)
    {
        var userService = _serviceProvider.GetRequiredService<IUserService>();
        return await userService.HandleRequest(request);
    }
    
    private async Task<ApiResponse> RouteToOrderService(ApiRequest request)
    {
        var orderService = _serviceProvider.GetRequiredService<IOrderService>();
        return await orderService.HandleRequest(request);
    }
    
    private async Task<ApiResponse> RouteToProductService(ApiRequest request)
    {
        var productService = _serviceProvider.GetRequiredService<IProductService>();
        return await productService.HandleRequest(request);
    }
}

// ASP.NET Core Implementation
app.Use(async (context, next) =>
{
    var path = context.Request.Path.Value;
    
    if (path.StartsWith("/api/users"))
        context.Items["service"] = "UserService";
    else if (path.StartsWith("/api/orders"))
        context.Items["service"] = "OrderService";
    
    // Add authentication, rate limiting, logging
    await next();
});`}]},{id:"q2",question:"Explain the Saga pattern for distributed transactions in microservices.",answer:"The Saga pattern manages data consistency across multiple microservices without distributed transactions. It's a sequence of local transactions coordinated by a saga coordinator. Two approaches: Choreography (event-driven) and Orchestration (centralized coordinator).",codeSnippets:[{language:"csharp",code:`// Orchestration-based Saga
public class OrderSaga
{
    private readonly IOrderService _orderService;
    private readonly IPaymentService _paymentService;
    private readonly IInventoryService _inventoryService;
    private readonly IEventBus _eventBus;
    
    public async Task<bool> ExecuteOrderSaga(Order order)
    {
        try
        {
            // Step 1: Create order
            var orderCreated = await _orderService.CreateOrder(order);
            if (!orderCreated) throw new Exception("Order creation failed");
            
            // Step 2: Process payment
            var paymentProcessed = await _paymentService.ProcessPayment(order.Id, order.Amount);
            if (!paymentProcessed)
            {
                await _orderService.CancelOrder(order.Id);
                throw new Exception("Payment failed");
            }
            
            // Step 3: Reserve inventory
            var inventoryReserved = await _inventoryService.ReserveInventory(order.Items);
            if (!inventoryReserved)
            {
                await _paymentService.RefundPayment(order.Id);
                await _orderService.CancelOrder(order.Id);
                throw new Exception("Inventory reservation failed");
            }
            
            // Publish order completed event
            await _eventBus.PublishAsync(new OrderCompletedEvent { OrderId = order.Id });
            return true;
        }
        catch (Exception ex)
        {
            // Compensating transactions already handled in try-catch
            await _eventBus.PublishAsync(new OrderFailedEvent { OrderId = order.Id, Reason = ex.Message });
            return false;
        }
    }
}

// Choreography-based Saga with Events
public class OrderService
{
    private readonly IEventBus _eventBus;
    
    public async Task CreateOrder(Order order)
    {
        // Create order
        await SaveOrder(order);
        
        // Publish event - other services subscribe and act
        await _eventBus.PublishAsync(new OrderCreatedEvent { OrderId = order.Id });
    }
}

public class PaymentService
{
    private readonly IEventBus _eventBus;
    
    [EventHandler]
    public async Task HandleOrderCreated(OrderCreatedEvent @event)
    {
        var order = await GetOrder(@event.OrderId);
        var success = await ProcessPayment(order);
        
        if (success)
            await _eventBus.PublishAsync(new PaymentProcessedEvent { OrderId = @event.OrderId });
        else
            await _eventBus.PublishAsync(new PaymentFailedEvent { OrderId = @event.OrderId });
    }
}`}]},{id:"q3",question:"What is the Event Sourcing pattern and its benefits?",answer:"Event Sourcing stores the state of an entity as a sequence of immutable events rather than storing the current state. Benefits include complete audit trail, ability to rebuild state at any point, and temporal queries. Challenges include handling eventual consistency and complex queries.",codeSnippets:[{language:"csharp",code:`// Event Sourcing Implementation
public abstract class Event
{
    public Guid AggregateId { get; set; }
    public long Version { get; set; }
    public DateTime Timestamp { get; set; }
}

public class AccountCreatedEvent : Event
{
    public string AccountHolder { get; set; }
    public decimal InitialBalance { get; set; }
}

public class MoneyDepositedEvent : Event
{
    public decimal Amount { get; set; }
}

public class MoneyWithdrawnEvent : Event
{
    public decimal Amount { get; set; }
}

// Aggregate Root
public class BankAccount
{
    public Guid Id { get; set; }
    public string AccountHolder { get; set; }
    public decimal Balance { get; private set; }
    public long Version { get; private set; }
    
    private List<Event> _uncommittedEvents = new();
    
    // Recreate account from events
    public static BankAccount FromHistory(IEnumerable<Event> events)
    {
        var account = new BankAccount();
        foreach (var @event in events)
        {
            account.ApplyEvent(@event);
        }
        return account;
    }
    
    public void Deposit(decimal amount)
    {
        var @event = new MoneyDepositedEvent
        {
            AggregateId = this.Id,
            Amount = amount,
            Version = this.Version + 1,
            Timestamp = DateTime.UtcNow
        };
        ApplyEvent(@event);
        _uncommittedEvents.Add(@event);
    }
    
    public void Withdraw(decimal amount)
    {
        if (this.Balance < amount)
            throw new InvalidOperationException("Insufficient funds");
        
        var @event = new MoneyWithdrawnEvent
        {
            AggregateId = this.Id,
            Amount = amount,
            Version = this.Version + 1,
            Timestamp = DateTime.UtcNow
        };
        ApplyEvent(@event);
        _uncommittedEvents.Add(@event);
    }
    
    private void ApplyEvent(Event @event)
    {
        switch (@event)
        {
            case AccountCreatedEvent acc:
                this.Id = acc.AggregateId;
                this.AccountHolder = acc.AccountHolder;
                this.Balance = acc.InitialBalance;
                break;
            case MoneyDepositedEvent dep:
                this.Balance += dep.Amount;
                break;
            case MoneyWithdrawnEvent wd:
                this.Balance -= wd.Amount;
                break;
        }
        this.Version = @event.Version;
    }
    
    public IEnumerable<Event> GetUncommittedEvents() => _uncommittedEvents;
}

// Event Store
public interface IEventStore
{
    Task SaveEventsAsync(Guid aggregateId, IEnumerable<Event> events);
    Task<IEnumerable<Event>> GetEventsAsync(Guid aggregateId);
}`}]},{id:"q4",question:"What is the CQRS (Command Query Responsibility Segregation) pattern?",answer:"CQRS separates read and write models. Commands handle writes (state changes), while queries handle reads (retrieving data). Enables independent scaling, different storage mechanisms for reads/writes, and better performance through optimized read models.",codeSnippets:[{language:"csharp",code:`// Commands - Write Model
public abstract class Command
{
    public Guid CommandId { get; } = Guid.NewGuid();
}

public class CreateOrderCommand : Command
{
    public Guid CustomerId { get; set; }
    public List<OrderItem> Items { get; set; }
}

public class UpdateOrderStatusCommand : Command
{
    public Guid OrderId { get; set; }
    public OrderStatus NewStatus { get; set; }
}

// Queries - Read Model
public abstract class Query<TResult>
{
}

public class GetOrderByIdQuery : Query<OrderDto>
{
    public Guid OrderId { get; set; }
}

public class GetCustomerOrdersQuery : Query<List<OrderSummaryDto>>
{
    public Guid CustomerId { get; set; }
}

// Command Handler
public class OrderCommandHandler
{
    private readonly IEventBus _eventBus;
    private readonly IRepository<Order> _repository;
    
    public async Task Handle(CreateOrderCommand command)
    {
        var order = new Order
        {
            Id = Guid.NewGuid(),
            CustomerId = command.CustomerId,
            Items = command.Items,
            CreatedAt = DateTime.UtcNow
        };
        
        await _repository.SaveAsync(order);
        
        // Publish event for read model update
        await _eventBus.PublishAsync(new OrderCreatedEvent 
        { 
            OrderId = order.Id,
            CustomerId = command.CustomerId 
        });
    }
}

// Query Handler
public class OrderQueryHandler
{
    private readonly IReadModelRepository _readRepository;
    
    public async Task<OrderDto> Handle(GetOrderByIdQuery query)
    {
        // Query optimized read model (denormalized data)
        return await _readRepository.GetOrderAsync(query.OrderId);
    }
    
    public async Task<List<OrderSummaryDto>> Handle(GetCustomerOrdersQuery query)
    {
        // Quick read from denormalized read model
        return await _readRepository.GetCustomerOrdersAsync(query.CustomerId);
    }
}

// CQRS Bus
public class CqrsBus
{
    private readonly IServiceProvider _serviceProvider;
    
    public async Task<TResult> SendQuery<TResult>(Query<TResult> query)
    {
        var handlerType = typeof(IQueryHandler<,>).MakeGenericType(query.GetType(), typeof(TResult));
        var handler = _serviceProvider.GetService(handlerType);
        var method = handlerType.GetMethod("Handle");
        return await (Task<TResult>)method.Invoke(handler, new object[] { query });
    }
    
    public async Task SendCommand<T>(T command) where T : Command
    {
        var handlerType = typeof(ICommandHandler<>).MakeGenericType(command.GetType());
        var handler = _serviceProvider.GetService(handlerType);
        var method = handlerType.GetMethod("Handle");
        await (Task)method.Invoke(handler, new object[] { command });
    }
}`}]},{id:"q5",question:"Explain the Message Queue pattern in microservices architecture.",answer:"The Message Queue pattern enables asynchronous communication between microservices through a message broker. Services produce messages to a queue and consumers process them independently. Benefits: decoupling, reliability, and handling temporary failures.",codeSnippets:[{language:"csharp",code:`// Message interface
public interface IMessage
{
    string MessageType { get; }
    DateTime CreatedAt { get; }
}

public class OrderPlacedMessage : IMessage
{
    public string MessageType => "OrderPlaced";
    public DateTime CreatedAt { get; set; } = DateTime.UtcNow;
    public Guid OrderId { get; set; }
    public List<OrderItem> Items { get; set; }
}

// Message Producer
public class OrderService
{
    private readonly IMessageQueue _messageQueue;
    
    public async Task PlaceOrder(Order order)
    {
        // Save order
        await SaveOrder(order);
        
        // Publish message to queue
        var message = new OrderPlacedMessage
        {
            OrderId = order.Id,
            Items = order.Items
        };
        
        await _messageQueue.PublishAsync("orders.placed", message);
    }
}

// Message Consumer
public class NotificationService
{
    private readonly IMessageQueue _messageQueue;
    
    public async Task StartProcessing()
    {
        await _messageQueue.SubscribeAsync("orders.placed", HandleOrderPlaced);
    }
    
    private async Task HandleOrderPlaced(OrderPlacedMessage message)
    {
        try
        {
            // Send notification to customer
            await SendEmailNotification(message.OrderId);
        }
        catch (Exception ex)
        {
            // Message will be retried or moved to dead-letter queue
            throw;
        }
    }
}

// Message Queue Implementation with RabbitMQ
public class RabbitMQMessageQueue : IMessageQueue
{
    private readonly IConnection _connection;
    
    public async Task PublishAsync<T>(string queueName, T message) where T : IMessage
    {
        using (var channel = _connection.CreateModel())
        {
            channel.QueueDeclare(queue: queueName, durable: true);
            
            var json = JsonConvert.SerializeObject(message);
            var body = Encoding.UTF8.GetBytes(json);
            
            channel.BasicPublish(exchange: "", routingKey: queueName, body: body);
        }
    }
    
    public async Task SubscribeAsync<T>(string queueName, Func<T, Task> handler) where T : IMessage
    {
        using (var channel = _connection.CreateModel())
        {
            channel.QueueDeclare(queue: queueName, durable: true);
            var consumer = new EventingBasicConsumer(channel);
            
            consumer.Received += async (model, ea) =>
            {
                try
                {
                    var json = Encoding.UTF8.GetString(ea.Body.ToArray());
                    var message = JsonConvert.DeserializeObject<T>(json);
                    await handler(message);
                    channel.BasicAck(ea.DeliveryTag, false);
                }
                catch (Exception ex)
                {
                    channel.BasicNack(ea.DeliveryTag, false, true); // Requeue
                }
            };
            
            channel.BasicConsume(queue: queueName, autoAck: false, consumer: consumer);
        }
    }
}`}]}]},My={id:"microservices-resilience",name:"Resilience Patterns",questions:[{id:"q1",question:"What is the Circuit Breaker pattern and how does it prevent cascading failures?",answer:"The Circuit Breaker pattern monitors for failures and temporarily stops requests to a failing service. It has three states: Closed (normal), Open (blocking requests), and Half-Open (testing recovery). Prevents cascading failures and allows services to recover gracefully.",codeSnippets:[{language:"csharp",code:`// Circuit Breaker Implementation
public enum CircuitState
{
    Closed,      // Normal operation
    Open,        // Blocking requests
    HalfOpen     // Testing recovery
}

public class CircuitBreaker
{
    private CircuitState _state = CircuitState.Closed;
    private DateTime _lastFailureTime;
    private int _failureCount;
    private int _failureThreshold = 5;
    private TimeSpan _timeout = TimeSpan.FromSeconds(30);
    private readonly object _lock = new();
    
    public async Task<T> ExecuteAsync<T>(Func<Task<T>> operation)
    {
        lock (_lock)
        {
            if (_state == CircuitState.Open)
            {
                if (DateTime.UtcNow - _lastFailureTime > _timeout)
                {
                    _state = CircuitState.HalfOpen;
                    _failureCount = 0;
                }
                else
                {
                    throw new CircuitBreakerOpenException("Circuit breaker is open");
                }
            }
        }
        
        try
        {
            var result = await operation();
            OnSuccess();
            return result;
        }
        catch (Exception ex)
        {
            OnFailure();
            throw;
        }
    }
    
    private void OnSuccess()
    {
        lock (_lock)
        {
            _failureCount = 0;
            if (_state == CircuitState.HalfOpen)
            {
                _state = CircuitState.Closed;
            }
        }
    }
    
    private void OnFailure()
    {
        lock (_lock)
        {
            _failureCount++;
            _lastFailureTime = DateTime.UtcNow;
            
            if (_failureCount >= _failureThreshold)
            {
                _state = CircuitState.Open;
            }
        }
    }
    
    public CircuitState GetState() => _state;
}

// Using Polly library (recommended)
using Polly;
using Polly.CircuitBreaker;

public class PollyCircuitBreakerExample
{
    public static IAsyncPolicy<HttpResponseMessage> GetCircuitBreakerPolicy()
    {
        return Policy
            .HandleResult<HttpResponseMessage>(r => !r.IsSuccessStatusCode)
            .Or<HttpRequestException>()
            .CircuitBreakerAsync<HttpResponseMessage>(
                handledEventsAllowedBeforeBreaking: 3,
                durationOfBreak: TimeSpan.FromSeconds(30),
                onBreak: (outcome, timespan) =>
                {
                    Console.WriteLine(\`Circuit breaker opened for {	imespan.TotalSeconds} seconds\`);
                },
                onReset: () =>
                {
                    Console.WriteLine("Circuit breaker reset");
                }
            );
    }
}`}]},{id:"q2",question:"Explain the Retry pattern with exponential backoff in microservices.",answer:"The Retry pattern automatically retries failed requests with exponential backoff to handle transient failures. Exponential backoff increases delay between retries to avoid overwhelming a recovering service. Includes jitter to prevent thundering herd problem.",codeSnippets:[{language:"csharp",code:`// Retry with Exponential Backoff
public class RetryPolicy
{
    private int _maxRetries = 3;
    private double _backoffMultiplier = 2.0;
    private int _initialDelayMs = 100;
    
    public async Task<T> ExecuteAsync<T>(Func<Task<T>> operation)
    {
        int retryCount = 0;
        
        while (true)
        {
            try
            {
                return await operation();
            }
            catch (Exception ex) when (ShouldRetry(ex) && retryCount < _maxRetries)
            {
                retryCount++;
                var delayMs = CalculateDelay(retryCount);
                Console.WriteLine(\`Retry attempt {retryCount} after {delayMs}ms\`);
                await Task.Delay(delayMs);
            }
        }
    }
    
    private int CalculateDelay(int attemptNumber)
    {
        // Exponential backoff: initialDelay * (backoffMultiplier ^ attemptNumber)
        var exponentialDelay = _initialDelayMs * Math.Pow(_backoffMultiplier, attemptNumber - 1);
        
        // Add jitter to prevent thundering herd
        var jitter = new Random().NextDouble() * 0.1 * exponentialDelay;
        
        return (int)(exponentialDelay + jitter);
    }
    
    private bool ShouldRetry(Exception ex)
    {
        // Retry on transient errors
        return ex is HttpRequestException || 
               ex is TimeoutException ||
               (ex is InvalidOperationException && ex.Message.Contains("transient"));
    }
}

// Using Polly
var retryPolicy = Policy
    .Handle<HttpRequestException>()
    .Or<TimeoutException>()
    .WaitAndRetryAsync(
        retryCount: 3,
        sleepDurationProvider: attempt => TimeSpan.FromMilliseconds(
            Math.Pow(2, attempt) * 100 + new Random().Next(0, 100)
        ),
        onRetry: (outcome, timespan, retryCount, context) =>
        {
            Console.WriteLine(\`Retry {retryCount} after {timespan.TotalMilliseconds}ms\`);
        }
    );

// Execute with retry
var response = await retryPolicy.ExecuteAsync(() => 
    httpClient.GetAsync("https://api.example.com/data")
);`}]},{id:"q3",question:"What is the Bulkhead pattern and how does it prevent resource exhaustion?",answer:"The Bulkhead pattern isolates resources (threads, connections) for different operations to prevent one failing operation from exhausting all resources. Named after compartments in ships that contain flooding. Limits concurrency and prevents cascading failures.",codeSnippets:[{language:"csharp",code:`// Bulkhead Pattern Implementation
public class BulkheadIsolation
{
    private readonly SemaphoreSlim _semaphore;
    private readonly string _name;
    
    public BulkheadIsolation(string name, int maxConcurrency)
    {
        _name = name;
        _semaphore = new SemaphoreSlim(maxConcurrency);
    }
    
    public async Task<T> ExecuteAsync<T>(Func<Task<T>> operation)
    {
        if (!await _semaphore.WaitAsync(TimeSpan.FromSeconds(5)))
        {
            throw new BulkheadException($"Bulkhead '{_name}' is at capacity");
        }
        
        try
        {
            return await operation();
        }
        finally
        {
            _semaphore.Release();
        }
    }
}

// Usage
public class PaymentServiceClient
{
    private readonly BulkheadIsolation _bulkhead;
    private readonly HttpClient _httpClient;
    
    public PaymentServiceClient(HttpClient httpClient)
    {
        _httpClient = httpClient;
        // Limit to 10 concurrent requests to payment service
        _bulkhead = new BulkheadIsolation("PaymentService", maxConcurrency: 10);
    }
    
    public async Task<PaymentResult> ProcessPaymentAsync(Payment payment)
    {
        return await _bulkhead.ExecuteAsync(async () =>
        {
            var response = await _httpClient.PostAsJsonAsync(
                "https://payment-api.example.com/process",
                payment
            );
            return await response.Content.ReadAsAsync<PaymentResult>();
        });
    }
}

// Using Polly Bulkhead
var bulkheadPolicy = Policy.BulkheadAsync(
    maxParallelization: 10,
    maxQueuingActions: 5,
    onBulkheadRejectedAsync: context =>
    {
        Console.WriteLine("Bulkhead at capacity - request rejected");
        return Task.CompletedTask;
    }
);

// Using separate thread pools
public class ThreadPoolBulkhead
{
    private readonly TaskScheduler _taskScheduler;
    
    public ThreadPoolBulkhead(int maxDegreeOfParallelism)
    {
        _taskScheduler = new LimitedConcurrencyLevelTaskScheduler(maxDegreeOfParallelism);
    }
    
    public async Task<T> ExecuteAsync<T>(Func<Task<T>> operation)
    {
        var task = operation();
        var schedulerTask = Task.Factory.StartNew(
            async () => await task,
            CancellationToken.None,
            TaskCreationOptions.DenyChildAttach,
            _taskScheduler
        );
        
        return await await schedulerTask;
    }
}`}]},{id:"q4",question:"What is the Timeout pattern and its importance in distributed systems?",answer:"The Timeout pattern sets maximum waiting time for operations to complete. Prevents hanging requests and resource leaks. Critical in distributed systems where network issues can cause indefinite waits. Combined with retries and circuit breakers for resilience.",codeSnippets:[{language:"csharp",code:`// Timeout Pattern
public class TimeoutPolicy
{
    public async Task<T> ExecuteWithTimeoutAsync<T>(
        Func<Task<T>> operation, 
        TimeSpan timeout)
    {
        using (var cts = new CancellationTokenSource(timeout))
        {
            try
            {
                return await operation();
            }
            catch (OperationCanceledException)
            {
                throw new TimeoutException($"Operation exceeded timeout of {timeout.TotalSeconds}s");
            }
        }
    }
}

// HTTP Client with Timeout
public class ResilientHttpClient
{
    private readonly HttpClient _httpClient;
    private readonly TimeSpan _timeout = TimeSpan.FromSeconds(10);
    
    public ResilientHttpClient()
    {
        _httpClient = new HttpClient();
        _httpClient.Timeout = _timeout;
    }
    
    public async Task<T> GetAsync<T>(string url)
    {
        try
        {
            var response = await _httpClient.GetAsync(url);
            response.EnsureSuccessStatusCode();
            return await response.Content.ReadAsAsync<T>();
        }
        catch (TaskCanceledException ex)
        {
            throw new TimeoutException($"Request to {url} timed out", ex);
        }
    }
}

// Polly Timeout Policy
var timeoutPolicy = Policy
    .TimeoutAsync<HttpResponseMessage>(
        timeout: TimeSpan.FromSeconds(10),
        timeoutStrategy: TimeoutStrategy.Aggressive
    );

// Combining multiple policies
var combinedPolicy = Policy.WrapAsync(
    timeoutPolicy,
    circuitBreakerPolicy,
    retryPolicy
);

// Usage
var result = await combinedPolicy.ExecuteAsync(async () =>
{
    return await httpClient.GetAsync("https://api.example.com/data");
});`}]},{id:"q5",question:"What is the Fallback pattern and how does it improve user experience?",answer:"The Fallback pattern provides alternative behavior when primary operations fail. Examples: return cached data, default values, or graceful degradation. Improves user experience by avoiding complete failures and maintaining partial functionality.",codeSnippets:[{language:"csharp",code:`// Fallback Pattern
public class FallbackPolicy
{
    public async Task<T> ExecuteWithFallbackAsync<T>(
        Func<Task<T>> primaryOperation,
        Func<Task<T>> fallbackOperation)
    {
        try
        {
            return await primaryOperation();
        }
        catch (Exception ex)
        {
            Console.WriteLine($"Primary operation failed: {ex.Message}. Using fallback.");
            return await fallbackOperation();
        }
    }
}

// Product Service with Cache Fallback
public class ProductService
{
    private readonly HttpClient _httpClient;
    private readonly IDistributedCache _cache;
    
    public async Task<Product> GetProductAsync(int productId)
    {
        try
        {
            // Primary: Call remote service
            var response = await _httpClient.GetAsync(
                $"https://products-api.example.com/{productId}"
            );
            response.EnsureSuccessStatusCode();
            return await response.Content.ReadAsAsync<Product>();
        }
        catch (Exception ex)
        {
            Console.WriteLine($"Failed to fetch from remote service: {ex.Message}");
            
            // Fallback: Return cached data
            var cachedProduct = await _cache.GetAsync<Product>($"product:{productId}");
            if (cachedProduct != null)
                return cachedProduct;
            
            // Final fallback: Return default/empty product
            return new Product { Id = productId, Name = "Product Unavailable" };
        }
    }
}

// Using Polly Fallback
var fallbackPolicy = Policy
    .Handle<HttpRequestException>()
    .Or<TimeoutException>()
    .FallbackAsync<UserProfile>(async context =>
    {
        // Return default/cached profile
        return new UserProfile 
        { 
            Id = Guid.NewGuid(),
            Name = "Guest User",
            IsDefault = true 
        };
    });

// Combining with other policies
var combinedPolicy = Policy.WrapAsync(
    timeoutPolicy,
    retryPolicy,
    fallbackPolicy
);`}]}]},Uy={id:"microservices-data",name:"Data Management",questions:[{id:"q1",question:"What is the Database per Service pattern and its advantages/disadvantages?",answer:"The Database per Service pattern assigns each microservice its own database, ensuring loose coupling and independent scaling. Advantages: autonomy, technology flexibility, easier scaling. Disadvantages: distributed transactions, data consistency challenges, cross-service queries.",codeSnippets:[{language:"C#",code:`// Database per Service Pattern
// OrderService - PostgreSQL
public class OrderService
{
    private readonly IOrderRepository _orderRepository;
    
    public async Task<Order> CreateOrderAsync(CreateOrderRequest request)
    {
        var order = new Order
        {
            Id = Guid.NewGuid(),
            CustomerId = request.CustomerId,
            Items = request.Items,
            Total = CalculateTotal(request.Items)
        };
        
        // Order service manages its own database
        return await _orderRepository.SaveAsync(order);
    }
}

// UserService - MongoDB
public class UserService
{
    private readonly IMongoCollection<User> _userCollection;
    
    public async Task<User> GetUserAsync(Guid userId)
    {
        // User service uses different database technology
        return await _userCollection.Find(u => u.Id == userId).FirstOrDefaultAsync();
    }
}

// InventoryService - Redis
public class InventoryService
{
    private readonly IConnectionMultiplexer _redis;
    
    public async Task<Stock> GetStockAsync(string productId)
    {
        // Inventory uses Redis for fast access
        var db = _redis.GetDatabase();
        var stock = await db.StringGetAsync($"stock:{productId}");
        return JsonConvert.DeserializeObject<Stock>(stock.ToString());
    }
}

// Cross-Service Communication
public class OrderProcessingService
{
    private readonly IOrderServiceClient _orderServiceClient;
    private readonly IUserServiceClient _userServiceClient;
    private readonly IInventoryServiceClient _inventoryServiceClient;
    
    public async Task ProcessOrderAsync(Guid orderId)
    {
        // Get order from OrderService
        var order = await _orderServiceClient.GetOrderAsync(orderId);
        
        // Get user from UserService (different database)
        var user = await _userServiceClient.GetUserAsync(order.CustomerId);
        
        // Check inventory from InventoryService (different database)
        var stock = await _inventoryServiceClient.GetStockAsync(order.Items[0].ProductId);
        
        // Combine data from multiple services
        var orderDetails = new OrderDetails
        {
            Order = order,
            Customer = user,
            AvailableStock = stock.Quantity
        };
    }
}

// Challenges: Distributed Transactions
public class TransactionalOrderService
{
    private readonly IOrderRepository _orderRepository;
    private readonly IEventBus _eventBus;
    
    public async Task CreateOrderWithSagaAsync(CreateOrderRequest request)
    {
        var order = new Order { Id = Guid.NewGuid() };
        
        // Step 1: Save order in OrderService database
        await _orderRepository.SaveAsync(order);
        
        // Step 2: Publish event for other services to handle
        await _eventBus.PublishAsync(new OrderCreatedEvent { OrderId = order.Id });
        
        // Each service updates its own database independently
        // Saga pattern manages distributed transaction
    }
}`}]},{id:"q2",question:"What is the CQRS pattern specifically for data management in microservices?",answer:"CQRS (Command Query Responsibility Segregation) for microservices separates write and read data models. Commands write to operational database, queries read from denormalized read model. Enables different storage solutions for writes vs reads, independent scaling, and optimized performance.",codeSnippets:[{language:"csharp",code:`// CQRS Pattern for Data Management
// Write Model (Operational Data Store)
public class OrderWriteModel
{
    public Guid Id { get; set; }
    public Guid CustomerId { get; set; }
    public List<OrderItem> Items { get; set; }
    public decimal Total { get; set; }
    public OrderStatus Status { get; set; }
    public DateTime CreatedAt { get; set; }
}

// Read Model (Denormalized)
public class OrderReadModel
{
    public Guid Id { get; set; }
    public string CustomerName { get; set; }
    public string CustomerEmail { get; set; }
    public int ItemCount { get; set; }
    public decimal Total { get; set; }
    public string Status { get; set; }
    public DateTime CreatedAt { get; set; }
    public List<string> ItemDescriptions { get; set; }
}

// Write Repository
public class OrderWriteRepository
{
    private readonly DbContext _writeDb;
    
    public async Task SaveAsync(OrderWriteModel order)
    {
        // Write to operational database
        _writeDb.Orders.Add(order);
        await _writeDb.SaveChangesAsync();
    }
}

// Read Repository (using different storage)
public class OrderReadRepository
{
    private readonly IElasticsearchClient _elasticsearch;
    
    public async Task<OrderReadModel> GetOrderAsync(Guid orderId)
    {
        // Query from denormalized read model in Elasticsearch
        var response = await _elasticsearch.SearchAsync<OrderReadModel>(s => s
            .Query(q => q.Term(t => t.Id, orderId))
        );
        
        return response.Documents.FirstOrDefault();
    }
    
    public async Task<List<OrderReadModel>> SearchOrdersAsync(string customerName)
    {
        // Optimized search across denormalized data
        var response = await _elasticsearch.SearchAsync<OrderReadModel>(s => s
            .Query(q => q.Match(m => m.Field(f => f.CustomerName).Query(customerName)))
        );
        
        return response.Documents.ToList();
    }
}

// Synchronization: Event-driven update of read model
public class OrderReadModelUpdater
{
    private readonly OrderReadRepository _readRepository;
    private readonly UserServiceClient _userServiceClient;
    private readonly IEventBus _eventBus;
    
    [EventSubscriber(EventType = "OrderCreated")]
    public async Task OnOrderCreatedAsync(OrderCreatedEvent @event)
    {
        // Get customer details from UserService
        var customer = await _userServiceClient.GetUserAsync(@event.CustomerId);
        
        // Build denormalized read model
        var readModel = new OrderReadModel
        {
            Id = @event.OrderId,
            CustomerName = customer.Name,
            CustomerEmail = customer.Email,
            ItemCount = @event.Items.Count,
            Total = @event.Total,
            Status = "Created",
            CreatedAt = @event.CreatedAt,
            ItemDescriptions = @event.Items.Select(i => i.Description).ToList()
        };
        
        // Update read model
        await _readRepository.SaveAsync(readModel);
    }
}

// CQRS Command Handler
public class CreateOrderCommandHandler
{
    private readonly OrderWriteRepository _writeRepository;
    private readonly IEventBus _eventBus;
    
    public async Task HandleAsync(CreateOrderCommand command)
    {
        var order = new OrderWriteModel
        {
            Id = Guid.NewGuid(),
            CustomerId = command.CustomerId,
            Items = command.Items,
            Status = OrderStatus.Pending
        };
        
        await _writeRepository.SaveAsync(order);
        
        // Publish event to trigger read model update
        await _eventBus.PublishAsync(new OrderCreatedEvent 
        { 
            OrderId = order.Id,
            CustomerId = order.CustomerId,
            Items = order.Items
        });
    }
}

// CQRS Query Handler
public class GetOrderDetailsQueryHandler
{
    private readonly OrderReadRepository _readRepository;
    
    public async Task<OrderReadModel> HandleAsync(GetOrderDetailsQuery query)
    {
        // Fast read from denormalized read model
        return await _readRepository.GetOrderAsync(query.OrderId);
    }
}`}]},{id:"q3",question:"What is Event Sourcing and how does it solve data consistency issues?",answer:"Event Sourcing stores all state changes as immutable events instead of current state. Provides audit trail, enables temporal queries, and simplifies data consistency. Challenges: eventual consistency handling, complex queries, storage of all events.",codeSnippets:[{language:"csharp",code:`// Event Sourcing for Data Management
// Domain Events
public abstract class DomainEvent
{
    public Guid AggregateId { get; set; }
    public long EventVersion { get; set; }
    public DateTime Timestamp { get; set; }
}

public class OrderCreatedEvent : DomainEvent
{
    public Guid CustomerId { get; set; }
    public List<OrderItem> Items { get; set; }
    public decimal Total { get; set; }
}

public class OrderShippedEvent : DomainEvent
{
    public string TrackingNumber { get; set; }
    public DateTime ShipDate { get; set; }
}

public class OrderCancelledEvent : DomainEvent
{
    public string Reason { get; set; }
}

// Event Store
public interface IEventStore
{
    Task AppendEventAsync(DomainEvent @event);
    Task<IEnumerable<DomainEvent>> GetEventsAsync(Guid aggregateId);
    Task<IEnumerable<DomainEvent>> GetAllEventsAsync();
}

public class EventStoreRepository : IEventStore
{
    private readonly DbContext _context;
    
    public async Task AppendEventAsync(DomainEvent @event)
    {
        var eventEntity = new EventEntity
        {
            Id = Guid.NewGuid(),
            AggregateId = @event.AggregateId,
            EventType = @event.GetType().Name,
            EventData = JsonConvert.SerializeObject(@event),
            Timestamp = DateTime.UtcNow
        };
        
        _context.Events.Add(eventEntity);
        await _context.SaveChangesAsync();
    }
    
    public async Task<IEnumerable<DomainEvent>> GetEventsAsync(Guid aggregateId)
    {
        var events = await _context.Events
            .Where(e => e.AggregateId == aggregateId)
            .OrderBy(e => e.Id)
            .ToListAsync();
        
        return events.Select(DeserializeEvent);
    }
    
    private DomainEvent DeserializeEvent(EventEntity entity)
    {
        return entity.EventType switch
        {
            nameof(OrderCreatedEvent) => JsonConvert.DeserializeObject<OrderCreatedEvent>(entity.EventData),
            nameof(OrderShippedEvent) => JsonConvert.DeserializeObject<OrderShippedEvent>(entity.EventData),
            nameof(OrderCancelledEvent) => JsonConvert.DeserializeObject<OrderCancelledEvent>(entity.EventData),
            _ => throw new InvalidOperationException($"Unknown event type: {entity.EventType}")
        };
    }
}

// Aggregate: Order
public class Order
{
    public Guid Id { get; set; }
    public Guid CustomerId { get; set; }
    public List<OrderItem> Items { get; set; }
    public OrderStatus Status { get; set; }
    public decimal Total { get; set; }
    
    private List<DomainEvent> _uncommittedEvents = new();
    
    // Rebuild from events
    public static Order FromHistory(IEnumerable<DomainEvent> events)
    {
        var order = new Order { Items = new List<OrderItem>() };
        
        foreach (var @event in events)
        {
            order.ApplyEvent(@event);
        }
        
        return order;
    }
    
    public void PlaceOrder(Guid customerId, List<OrderItem> items)
    {
        var @event = new OrderCreatedEvent
        {
            AggregateId = this.Id,
            CustomerId = customerId,
            Items = items,
            Total = items.Sum(i => i.Price * i.Quantity)
        };
        
        ApplyEvent(@event);
        _uncommittedEvents.Add(@event);
    }
    
    public void Ship(string trackingNumber)
    {
        if (this.Status != OrderStatus.Confirmed)
            throw new InvalidOperationException("Only confirmed orders can be shipped");
        
        var @event = new OrderShippedEvent
        {
            AggregateId = this.Id,
            TrackingNumber = trackingNumber,
            ShipDate = DateTime.UtcNow
        };
        
        ApplyEvent(@event);
        _uncommittedEvents.Add(@event);
    }
    
    private void ApplyEvent(DomainEvent @event)
    {
        switch (@event)
        {
            case OrderCreatedEvent created:
                this.Id = created.AggregateId;
                this.CustomerId = created.CustomerId;
                this.Items = created.Items;
                this.Total = created.Total;
                this.Status = OrderStatus.Pending;
                break;
            case OrderShippedEvent shipped:
                this.Status = OrderStatus.Shipped;
                break;
            case OrderCancelledEvent cancelled:
                this.Status = OrderStatus.Cancelled;
                break;
        }
    }
    
    public IEnumerable<DomainEvent> GetUncommittedEvents() => _uncommittedEvents;
}

// Order Repository using Event Store
public class OrderRepository
{
    private readonly IEventStore _eventStore;
    
    public async Task SaveAsync(Order order)
    {
        foreach (var @event in order.GetUncommittedEvents())
        {
            await _eventStore.AppendEventAsync(@event);
        }
    }
    
    public async Task<Order> GetByIdAsync(Guid orderId)
    {
        var events = await _eventStore.GetEventsAsync(orderId);
        return Order.FromHistory(events);
    }
    
    // Temporal query: Get order state at specific point in time
    public async Task<Order> GetByIdAtTimeAsync(Guid orderId, DateTime timestamp)
    {
        var events = await _eventStore.GetEventsAsync(orderId);
        var eventsAtTime = events.Where(e => e.Timestamp <= timestamp);
        return Order.FromHistory(eventsAtTime);
    }
}`}]},{id:"q4",question:"What is the API Composition pattern for querying data across microservices?",answer:"The API Composition pattern queries multiple microservices and aggregates results at the client or gateway level. Client makes multiple requests and combines results. Alternative to database joins in monoliths. Challenges: network latency, handling partial failures, N+1 queries.",codeSnippets:[{language:"csharp",code:`// API Composition Pattern
// Individual Service Clients
public interface IOrderServiceClient
{
    Task<OrderDto> GetOrderAsync(Guid orderId);
}

public interface IUserServiceClient
{
    Task<UserDto> GetUserAsync(Guid userId);
}

public interface IProductServiceClient
{
    Task<ProductDto> GetProductAsync(string productId);
}

// API Composition: Aggregate data from multiple services
public class OrderCompositionService
{
    private readonly IOrderServiceClient _orderServiceClient;
    private readonly IUserServiceClient _userServiceClient;
    private readonly IProductServiceClient _productServiceClient;
    private readonly ILogger<OrderCompositionService> _logger;
    
    public async Task<OrderDetailDto> GetOrderDetailsAsync(Guid orderId)
    {
        try
        {
            // Get order details
            var order = await _orderServiceClient.GetOrderAsync(orderId);
            
            // Parallel calls to other services
            var userTask = _userServiceClient.GetUserAsync(order.CustomerId);
            var productTasks = order.Items.Select(item => 
                _productServiceClient.GetProductAsync(item.ProductId)
            );
            
            await Task.WhenAll(userTask, Task.WhenAll(productTasks));
            
            var user = await userTask;
            var products = await Task.WhenAll(productTasks);
            
            // Compose the response
            return new OrderDetailDto
            {
                OrderId = order.Id,
                CustomerName = user.Name,
                CustomerEmail = user.Email,
                Items = order.Items.Select((item, index) => new OrderItemDetailDto
                {
                    ProductName = products[index].Name,
                    ProductDescription = products[index].Description,
                    Quantity = item.Quantity,
                    UnitPrice = item.Price
                }).ToList(),
                Total = order.Total
            };
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, $"Failed to compose order details for {orderId}");
            throw;
        }
    }
}

// Optimized composition with caching
public class CachedOrderCompositionService
{
    private readonly IOrderServiceClient _orderServiceClient;
    private readonly IUserServiceClient _userServiceClient;
    private readonly IProductServiceClient _productServiceClient;
    private readonly IDistributedCache _cache;
    
    public async Task<OrderDetailDto> GetOrderDetailsAsync(Guid orderId)
    {
        var cacheKey = $"order:{orderId}";
        
        // Try to get from cache
        var cached = await _cache.GetAsync<OrderDetailDto>(cacheKey);
        if (cached != null)
            return cached;
        
        // Compose from services
        var order = await _orderServiceClient.GetOrderAsync(orderId);
        var user = await _userServiceClient.GetUserAsync(order.CustomerId);
        
        // Get products in parallel
        var products = await Task.WhenAll(
            order.Items.Select(item => _productServiceClient.GetProductAsync(item.ProductId))
        );
        
        var result = new OrderDetailDto
        {
            OrderId = order.Id,
            CustomerName = user.Name,
            Items = order.Items.Select((item, i) => new OrderItemDetailDto
            {
                ProductName = products[i].Name,
                Quantity = item.Quantity,
                UnitPrice = item.Price
            }).ToList()
        };
        
        // Cache for 1 hour
        await _cache.SetAsync(cacheKey, result, TimeSpan.FromHours(1));
        
        return result;
    }
}

// Timeout and fallback handling
public class ResilientOrderCompositionService
{
    private readonly IOrderServiceClient _orderServiceClient;
    private readonly IUserServiceClient _userServiceClient;
    private readonly IDistributedCache _cache;
    
    public async Task<OrderDetailDto> GetOrderDetailsAsync(Guid orderId)
    {
        var cts = new CancellationTokenSource(TimeSpan.FromSeconds(5));
        
        try
        {
            var order = await _orderServiceClient.GetOrderAsync(orderId);
            var user = await _userServiceClient.GetUserAsync(order.CustomerId);
            
            return new OrderDetailDto
            {
                OrderId = order.Id,
                CustomerName = user.Name,
                Items = order.Items
            };
        }
        catch (OperationCanceledException)
        {
            // Timeout: return partial data from cache
            var cachedOrder = await _cache.GetAsync<OrderDto>($"order:{orderId}");
            if (cachedOrder != null)
            {
                return new OrderDetailDto
                {
                    OrderId = cachedOrder.Id,
                    CustomerName = "Unknown",
                    Items = cachedOrder.Items
                };
            }
            throw;
        }
    }
}`}]},{id:"q5",question:"What is the Command Query Responsibility Segregation and Event Sourcing integration?",answer:"Combining CQRS with Event Sourcing provides powerful data management: events drive the system, commands modify events, read models derive from events. Enables independent scaling of reads/writes, audit trail, temporal queries, and eventual consistency.",codeSnippets:[{language:"csharp",code:`// CQRS + Event Sourcing Integration
// Command (Write)
public abstract class Command
{
    public Guid CommandId { get; } = Guid.NewGuid();
    public DateTime CreatedAt { get; } = DateTime.UtcNow;
}

public class CreateOrderCommand : Command
{
    public Guid CustomerId { get; set; }
    public List<OrderLineItem> Items { get; set; }
}

// Domain Event (Source of Truth)
public class OrderCreatedEvent : DomainEvent
{
    public Guid CustomerId { get; set; }
    public List<OrderLineItem> Items { get; set; }
    public decimal Total { get; set; }
}

// Command Handler: Generates Events
public class OrderCommandHandler
{
    private readonly IEventStore _eventStore;
    private readonly IEventBus _eventBus;
    
    public async Task HandleAsync(CreateOrderCommand command)
    {
        var orderId = Guid.NewGuid();
        var total = command.Items.Sum(i => i.Price * i.Quantity);
        
        var @event = new OrderCreatedEvent
        {
            AggregateId = orderId,
            CustomerId = command.CustomerId,
            Items = command.Items,
            Total = total,
            Timestamp = DateTime.UtcNow
        };
        
        // Save to event store
        await _eventStore.AppendEventAsync(@event);
        
        // Publish event for subscribers
        await _eventBus.PublishAsync(@event);
    }
}

// Event Handlers: Update Read Models
public class OrderReadModelEventHandler
{
    private readonly IOrderReadRepository _readRepository;
    private readonly IUserServiceClient _userServiceClient;
    
    [EventSubscriber]
    public async Task OnOrderCreatedAsync(OrderCreatedEvent @event)
    {
        var customer = await _userServiceClient.GetUserAsync(@event.CustomerId);
        
        var readModel = new OrderReadModel
        {
            Id = @event.AggregateId,
            CustomerName = customer.Name,
            CustomerEmail = customer.Email,
            ItemCount = @event.Items.Count,
            Total = @event.Total,
            CreatedAt = @event.Timestamp
        };
        
        // Update read model in optimized store (Elasticsearch, etc.)
        await _readRepository.SaveAsync(readModel);
    }
}

// Query (Read)
public abstract class Query<TResult>
{
}

public class GetOrderDetailsQuery : Query<OrderDetailsDto>
{
    public Guid OrderId { get; set; }
}

// Query Handler: Reads from Read Model
public class OrderQueryHandler
{
    private readonly IOrderReadRepository _readRepository;
    
    public async Task<OrderDetailsDto> HandleAsync(GetOrderDetailsQuery query)
    {
        // Fast read from denormalized read model
        return await _readRepository.GetOrderDetailsAsync(query.OrderId);
    }
}

// Full Architecture: Command-Event-Query Flow
public class OrderService
{
    private readonly ICommandBus _commandBus;
    private readonly IQueryBus _queryBus;
    private readonly IEventBus _eventBus;
    
    // Write Operation
    public async Task<Guid> CreateOrderAsync(CreateOrderRequest request)
    {
        var command = new CreateOrderCommand
        {
            CustomerId = request.CustomerId,
            Items = request.Items
        };
        
        // Send command to handler
        // Handler creates OrderCreatedEvent
        // Event is stored and published
        // Read models updated via event handlers
        await _commandBus.SendAsync(command);
        
        return Guid.NewGuid(); // Return order ID
    }
    
    // Read Operation
    public async Task<OrderDetailsDto> GetOrderDetailsAsync(Guid orderId)
    {
        var query = new GetOrderDetailsQuery { OrderId = orderId };
        
        // Query reads from optimized read model
        return await _queryBus.SendAsync(query);
    }
    
    // Temporal Query: Get order state at specific time
    public async Task<OrderDetailsDto> GetOrderDetailsAtTimeAsync(Guid orderId, DateTime timestamp)
    {
        // Rebuild from event store at specific timestamp
        var events = await _eventStore.GetEventsAsync(orderId);
        var relevantEvents = events.Where(e => e.Timestamp <= timestamp);
        
        var order = Order.FromHistory(relevantEvents);
        
        return new OrderDetailsDto { /* ... */ };
    }
}

// Eventual Consistency Handling
public class EventProjectionService : IHostedService
{
    private readonly IEventStore _eventStore;
    private readonly IOrderReadRepository _readRepository;
    
    public async Task StartAsync(CancellationToken cancellationToken)
    {
        // Continuously project new events to read models
        while (!cancellationToken.IsCancellationRequested)
        {
            var newEvents = await _eventStore.GetUnprocessedEventsAsync();
            
            foreach (var @event in newEvents)
            {
                // Update read model for this event
                await ProjectEventToReadModelAsync(@event);
                await _eventStore.MarkAsProcessedAsync(@event.Id);
            }
            
            await Task.Delay(TimeSpan.FromSeconds(1), cancellationToken);
        }
    }
    
    private async Task ProjectEventToReadModelAsync(DomainEvent @event)
    {
        switch (@event)
        {
            case OrderCreatedEvent orderCreated:
                // Update order read model
                break;
            case OrderShippedEvent orderShipped:
                // Update order read model status
                break;
        }
    }
    
    public Task StopAsync(CancellationToken cancellationToken) => Task.CompletedTask;
}`}]}]},qy={id:"microservices",name:"Microservices",icon:"",topics:[Ny,My,Uy]},By={id:"csharp-oops-concepts",name:"OOPs Concepts",questions:[{id:"q1",question:"What are the four pillars of OOP and explain each one briefly?",answer:"The four pillars are: (1) Encapsulation - bundling data and methods, hiding internals with access modifiers. (2) Inheritance - deriving new classes from existing ones, reusing code. (3) Polymorphism - objects can take many forms, same method name different behavior. (4) Abstraction - hiding complexity, exposing only essential features through interfaces/abstract classes.",codeSnippets:[{language:"csharp",code:`using System;

// 1. ENCAPSULATION - Hide internals, expose through properties
public class BankAccount
{
    private decimal balance; // Hidden
    
    public decimal Balance
    {
        get { return balance; }
        private set { balance = value; } // Only internal access
    }
    
    public void Deposit(decimal amount)
    {
        if (amount > 0)
            balance += amount; // Controlled modification
    }
    
    public bool Withdraw(decimal amount)
    {
        if (amount <= balance)
        {
            balance -= amount;
            return true;
        }
        return false;
    }
}

// Usage
var account = new BankAccount();
account.Deposit(1000);
Console.WriteLine(account.Balance); // 1000
account.Withdraw(200); // Verified before withdrawal
// account.balance = -999; // ERROR: Can't access private field

// 2. INHERITANCE - Derive from base class
public class Animal
{
    public string Name { get; set; }
    
    public virtual void MakeSound()
    {
        Console.WriteLine("Generic animal sound");
    }
}

public class Dog : Animal // Inherits from Animal
{
    public override void MakeSound()
    {
        Console.WriteLine("Woof!");
    }
}

public class Cat : Animal
{
    public override void MakeSound()
    {
        Console.WriteLine("Meow!");
    }
}

// Usage
Animal dog = new Dog { Name = "Buddy" };
dog.MakeSound(); // Woof! (Dog's implementation)

// 3. POLYMORPHISM - Same interface, different behavior
public void AnimalSounds()
{
    var animals = new Animal[]
    {
        new Dog { Name = "Buddy" },
        new Cat { Name = "Whiskers" },
        new Animal { Name = "Generic" }
    };
    
    foreach (var animal in animals)
    {
        animal.MakeSound(); // Calls appropriate implementation
        // Woof!
        // Meow!
        // Generic animal sound
    }
}

// 4. ABSTRACTION - Hide complexity, show only what's needed
public abstract class Vehicle
{
    public abstract void Start(); // Must be implemented
    public abstract void Stop();
    
    public void Drive()
    {
        Start();
        Console.WriteLine("Driving...");
        Stop();
    }
}

public class Car : Vehicle
{
    public override void Start()
    {
        Console.WriteLine("Engine started");
    }
    
    public override void Stop()
    {
        Console.WriteLine("Engine stopped");
    }
}

// Usage - User doesn't need to know how Start/Stop work
var car = new Car();
car.Drive(); // Abstracted logic`}]},{id:"q2",question:"What is the difference between abstraction and encapsulation? Are they the same?",answer:"No, they're different. Encapsulation is about hiding implementation details and controlling access using access modifiers (private, public, protected). Abstraction is about hiding complexity and showing only essential features through abstract classes or interfaces. Encapsulation is HOW you hide (access modifiers), abstraction is WHAT you hide (complexity).",codeSnippets:[{language:"csharp",code:`using System;

// ENCAPSULATION - HOW to hide (using access modifiers)
public class Person
{
    // Private - hidden from outside
    private string socialSecurityNumber;
    private decimal salary;
    
    // Public property with validation
    public string Name { get; set; }
    
    public decimal Salary
    {
        get { return salary; }
        set 
        { 
            if (value >= 0)
                salary = value; // Controlled access
        }
    }
    
    public bool VerifySocialSecurityNumber(string ssn)
    {
        return socialSecurityNumber == ssn; // Only method can access
    }
}

// ABSTRACTION - WHAT to hide (using abstract classes/interfaces)
// Hides how different shapes calculate area
public abstract class Shape
{
    public abstract double GetArea(); // User doesn't need to know how
}

public class Circle : Shape
{
    private double radius;
    
    public Circle(double r) { radius = r; }
    
    public override double GetArea()
    {
        return Math.PI * radius * radius; // Complex calculation hidden
    }
}

public class Rectangle : Shape
{
    private double width, height;
    
    public Rectangle(double w, double h) 
    { 
        width = w; 
        height = h; 
    }
    
    public override double GetArea()
    {
        return width * height; // Different calculation
    }
}

// Usage - Client doesn't care how area is calculated
public void CalculateAreas()
{
    Shape circle = new Circle(5);
    Shape rectangle = new Rectangle(4, 6);
    
    Console.WriteLine(circle.GetArea()); // *5*5 (calculation hidden)
    Console.WriteLine(rectangle.GetArea()); // 4*6 (calculation hidden)
}

// Real-world comparison
// ENCAPSULATION: BankAccount hides balance with private field
// ABSTRACTION: IPaymentProcessor hides how payments are processed

public interface IPaymentProcessor
{
    bool ProcessPayment(decimal amount); // What it does
    // Client doesn't know if it uses Stripe, PayPal, or bank transfer
}

public class StripePaymentProcessor : IPaymentProcessor
{
    public bool ProcessPayment(decimal amount)
    {
        // Complex Stripe API calls hidden here
        Console.WriteLine($"Processing {amount} via Stripe");
        return true;
    }
}

public class PayPalPaymentProcessor : IPaymentProcessor
{
    public bool ProcessPayment(decimal amount)
    {
        // Complex PayPal API calls hidden here
        Console.WriteLine($"Processing {amount} via PayPal");
        return true;
    }
}

// Key differences:
// ENCAPSULATION                           ABSTRACTION
// Hide data/implementation               Hide complexity
// Use: private, protected, public        Use: abstract, interface
// Achieved with: fields, properties      Achieved with: abstract class, interface
// Controls: Access to data               Controls: Interface/contract
// "How" something works                  "What" something does`}]},{id:"q3",question:"What is the difference between Abstract Class and Interface? When to use each?",answer:"Abstract class can have implementation, state (fields), constructors, access modifiers. Interface only declares contracts, no implementation (except default methods in modern C#). Use abstract class for related classes sharing code, use interface for unrelated classes sharing behavior. A class can implement multiple interfaces but inherit from one abstract class.",codeSnippets:[{language:"csharp",code:`using System;

// ABSTRACT CLASS - Partial implementation, shared state
public abstract class Employee
{
    // Fields (state) - Abstract class can have
    protected string name;
    protected decimal salary;
    
    // Constructor - Abstract class can have
    protected Employee(string name, decimal salary)
    {
        this.name = name;
        this.salary = salary;
    }
    
    // Concrete method - Abstract class can have implementation
    public void PrintDetails()
    {
        Console.WriteLine($"Name: {name}");
    }
    
    // Abstract method - Must be implemented by derived class
    public abstract decimal CalculateBonus();
    
    // Virtual method - Can be overridden
    public virtual void Work()
    {
        Console.WriteLine($"{name} is working");
    }
}

public class Manager : Employee
{
    private int teamSize;
    
    public Manager(string name, decimal salary, int team) 
        : base(name, salary)
    {
        teamSize = team;
    }
    
    public override decimal CalculateBonus()
    {
        return salary * 0.2m; // 20% bonus
    }
    
    public override void Work()
    {
        Console.WriteLine($"{name} is managing {teamSize} people");
    }
}

// INTERFACE - Contract only, no implementation
public interface IPayable
{
    decimal GetSalary();
    void Pay();
}

public interface IManageable
{
    int GetTeamSize();
    void Manage();
}

// One class can implement multiple interfaces
public class Contractor : IPayable, IManageable
{
    private decimal hourlyRate;
    private int hoursWorked;
    private int teamSize;
    
    public Contractor(decimal rate, int hours, int team)
    {
        hourlyRate = rate;
        hoursWorked = hours;
        teamSize = team;
    }
    
    public decimal GetSalary()
    {
        return hourlyRate * hoursWorked;
    }
    
    public void Pay()
    {
        Console.WriteLine($"Paying contractor: {GetSalary()}");
    }
    
    public int GetTeamSize()
    {
        return teamSize;
    }
    
    public void Manage()
    {
        Console.WriteLine($"Managing {teamSize} contractors");
    }
}

// Comparison
Console.WriteLine("ABSTRACT CLASS vs INTERFACE:");
Console.WriteLine("Feature              Abstract Class      Interface");
Console.WriteLine("Implementation       Can have            None (C#7) or default");
Console.WriteLine("Fields               Yes                 No");
Console.WriteLine("Constructors         Yes                 No");
Console.WriteLine("Access modifiers     public/private      All public");
Console.WriteLine("Inheritance          One abstract class  Multiple interfaces");
Console.WriteLine("When to use          Related classes     Unrelated contract");
Console.WriteLine("Purpose              IS-A relationship   CAN-DO capability");

// Modern C# 8+ - Interfaces can have default implementation
public interface IWorker
{
    void DoWork(); // Abstract
    
    void TakeBreak() // Default implementation
    {
        Console.WriteLine("Taking a break");
    }
}

public class Worker : IWorker
{
    public void DoWork()
    {
        Console.WriteLine("Working");
    }
    
    // Inherits TakeBreak() from interface
}

// When to use Abstract Class
public abstract class Vehicle
{
    // Shared fields
    protected string model;
    protected int year;
    
    // Shared implementation
    public void Register()
    {
        Console.WriteLine("Registering vehicle");
    }
    
    // Abstract method
    public abstract void Drive();
}

public class Car : Vehicle { /* ... */ }
public class Truck : Vehicle { /* ... */ }
// Car and Truck are related through Vehicle

// When to use Interface
public interface IComparable
{
    int CompareTo(object obj);
}

public interface IDrawable
{
    void Draw();
}

public class Circle : IComparable, IDrawable
{
    public int CompareTo(object obj)
    {
        // Implementation
        return 0;
    }
    
    public void Draw()
    {
        // Implementation
    }
}

// Circle doesn't have IS-A relationship with IComparable or IDrawable
// But it CAN compare and CAN draw

// Best practice decision:
// Use Abstract Class when:
// - Classes are closely related
// - Need shared fields/state
// - Need non-public members
// - Need constructors or initialization logic

// Use Interface when:
// - Unrelated classes need same contract
// - Need multiple inheritance of type
// - Defining capability/behavior only
// - Need polymorphic behavior across unrelated types`}]},{id:"q4",question:"What is polymorphism? Explain compile-time (static) and runtime (dynamic) polymorphism.",answer:"Polymorphism means 'many forms'. Compile-time (static) polymorphism is method overloading - multiple methods with same name but different parameters, resolved at compile time. Runtime (dynamic) polymorphism is method overriding - child class overrides parent method, resolved at runtime based on actual object type.",codeSnippets:[{language:"csharp",code:`using System;

// ========== COMPILE-TIME POLYMORPHISM (Method Overloading) ==========
// Same method name, different parameters
public class Calculator
{
    // Add for two integers
    public int Add(int a, int b)
    {
        return a + b;
    }
    
    // Add for three integers (different parameter count)
    public int Add(int a, int b, int c)
    {
        return a + b + c;
    }
    
    // Add for two doubles (different parameter type)
    public double Add(double a, double b)
    {
        return a + b;
    }
    
    // Add for string (different parameter type)
    public string Add(string a, string b)
    {
        return a + b;
    }
}

// Usage - Compiler decides which method to call
var calc = new Calculator();

int result1 = calc.Add(5, 3); // Calls Add(int, int)
int result2 = calc.Add(5, 3, 2); // Calls Add(int, int, int)
double result3 = calc.Add(5.5, 3.2); // Calls Add(double, double)
string result4 = calc.Add("Hello", "World"); // Calls Add(string, string)

// Compile-time polymorphism with different return types
public class Printer
{
    // Overload by parameter type
    public void Print(int value)
    {
        Console.WriteLine($"Printing integer: {value}");
    }
    
    public void Print(string value)
    {
        Console.WriteLine($"Printing string: {value}");
    }
    
    public void Print(double value)
    {
        Console.WriteLine($"Printing double: {value}");
    }
}

// ========== RUNTIME POLYMORPHISM (Method Overriding) ==========
// Base class with virtual method
public abstract class Shape
{
    public string Name { get; set; }
    
    // Virtual method - can be overridden
    public virtual void Draw()
    {
        Console.WriteLine("Drawing generic shape");
    }
    
    public virtual double GetArea()
    {
        return 0;
    }
}

public class Circle : Shape
{
    private double radius;
    
    public Circle(double r) { radius = r; }
    
    // Override - child class implementation
    public override void Draw()
    {
        Console.WriteLine("Drawing circle");
    }
    
    public override double GetArea()
    {
        return Math.PI * radius * radius;
    }
}

public class Rectangle : Shape
{
    private double width, height;
    
    public Rectangle(double w, double h)
    {
        width = w;
        height = h;
    }
    
    public override void Draw()
    {
        Console.WriteLine("Drawing rectangle");
    }
    
    public override double GetArea()
    {
        return width * height;
    }
}

// Runtime polymorphism - type determined at runtime
public void DemoRuntimePolymorphism()
{
    Shape[] shapes = new Shape[]
    {
        new Circle(5),
        new Rectangle(4, 6),
        new Circle(3)
    };
    
    // Runtime decides which implementation to call
    foreach (var shape in shapes)
    {
        shape.Draw(); // Calls correct Draw() based on actual type
        // Drawing circle
        // Drawing rectangle
        // Drawing circle
    }
}

// Key differences
Console.WriteLine("COMPILE-TIME vs RUNTIME POLYMORPHISM:");
Console.WriteLine("Aspect              Compile-Time        Runtime");
Console.WriteLine("Also called         Overloading         Overriding");
Console.WriteLine("When resolved       At compile time     At runtime");
Console.WriteLine("Same method name    Yes, diff params    Yes, same params");
Console.WriteLine("Virtual keyword     Not needed          Required");
Console.WriteLine("Use                 Operator +          shape.Draw()");
Console.WriteLine("Performance         Slightly faster     Slightly slower");

// Compile-time polymorphism example
public void CompileTimeExample()
{
    var printer = new Printer();
    
    // Compiler knows at compile time which Print() to call
    printer.Print(42); // Print(int)
    printer.Print("Hello"); // Print(string)
    printer.Print(3.14); // Print(double)
}

// Runtime polymorphism example
public void RuntimeExample()
{
    Shape circle = new Circle(5); // circle is Shape reference
    Shape rectangle = new Rectangle(4, 6); // rect is Shape reference
    
    // Runtime (not compile time) determines actual type
    circle.Draw(); // Calls Circle.Draw()
    rectangle.Draw(); // Calls Rectangle.Draw()
    
    // This is why virtual keyword is important
    // Without virtual, would always call Shape.Draw()
}

// Non-virtual method - NOT polymorphic
public class Parent
{
    public void Method()
    {
        Console.WriteLine("Parent method");
    }
}

public class Child : Parent
{
    public new void Method() // Uses "new", not "override"
    {
        Console.WriteLine("Child method");
    }
}

var obj = new Parent();
obj.Method(); // Parent method

Parent childRef = new Child();
childRef.Method(); // Still Parent method (NOT polymorphic)
// Because Method() is not virtual

// Virtual method - IS polymorphic
public class Parent2
{
    public virtual void Method()
    {
        Console.WriteLine("Parent method");
    }
}

public class Child2 : Parent2
{
    public override void Method()
    {
        Console.WriteLine("Child method");
    }
}

Parent2 childRef2 = new Child2();
childRef2.Method(); // Child method (IS polymorphic)`}]},{id:"q5",question:"What are access modifiers? Explain public, private, protected, and internal.",answer:"Access modifiers control where code can be accessed. public - accessible everywhere. private - accessible only within same class. protected - accessible in same class and derived classes. internal - accessible within same assembly. private protected - only in same class or derived classes in same assembly.",codeSnippets:[{language:"csharp",code:`using System;

public class AccessModifiersExample
{
    // PUBLIC - Accessible from anywhere
    public string PublicField;
    public void PublicMethod()
    {
        Console.WriteLine("Public method");
    }
    
    // PRIVATE - Accessible only within this class
    private string privateField;
    private void PrivateMethod()
    {
        Console.WriteLine("Private method");
    }
    
    // PROTECTED - Accessible in this class and derived classes
    protected string protectedField;
    protected void ProtectedMethod()
    {
        Console.WriteLine("Protected method");
    }
    
    // INTERNAL - Accessible within same assembly
    internal string internalField;
    internal void InternalMethod()
    {
        Console.WriteLine("Internal method");
    }
    
    // PRIVATE PROTECTED - Same class or derived in same assembly
    private protected string privateProtectedField;
    
    // PROTECTED INTERNAL - This class, derived classes, same assembly
    protected internal string protectedInternalField;
}

// Derived class demonstrates access
public class DerivedClass : AccessModifiersExample
{
    public void TestAccess()
    {
        //  Can access public
        PublicField = "accessible";
        PublicMethod();
        
        //  Cannot access private
        // privateField = "not accessible"; // ERROR
        // PrivateMethod(); // ERROR
        
        //  Can access protected (because we're derived)
        protectedField = "accessible";
        ProtectedMethod();
        
        //  Can access internal (same assembly)
        internalField = "accessible";
        InternalMethod();
        
        //  Can access private protected (derived + same assembly)
        privateProtectedField = "accessible";
    }
}

// Another class in same assembly
public class OtherClass
{
    public void TestAccess()
    {
        var obj = new AccessModifiersExample();
        
        //  Can access public
        obj.PublicField = "accessible";
        obj.PublicMethod();
        
        //  Cannot access private
        // obj.privateField = "not accessible"; // ERROR
        // obj.PrivateMethod(); // ERROR
        
        //  Cannot access protected (not derived)
        // obj.protectedField = "not accessible"; // ERROR
        // obj.ProtectedMethod(); // ERROR
        
        //  Can access internal (same assembly)
        obj.internalField = "accessible";
        obj.InternalMethod();
        
        //  Cannot access private protected (not derived)
        // obj.privateProtectedField = "not accessible"; // ERROR
    }
}

// Encapsulation example - Using private fields with public property
public class BankAccount
{
    private decimal balance; // Private - hidden
    
    public decimal Balance // Public property - controlled access
    {
        get { return balance; }
        private set { balance = value; } // Only internal modification
    }
    
    public void Deposit(decimal amount)
    {
        if (amount > 0)
            balance += amount;
    }
    
    public bool Withdraw(decimal amount)
    {
        if (amount > 0 && amount <= balance)
        {
            balance -= amount;
            return true;
        }
        return false;
    }
}

// Usage
var account = new BankAccount();
account.Deposit(1000);
Console.WriteLine(account.Balance); // Can read: 1000
// account.Balance = -500; // ERROR: Can't set (private setter)
// account.balance = -500; // ERROR: Can't access private field

// Access modifier summary table
Console.WriteLine("Access Modifier Summary:");
Console.WriteLine("Modifier             Same Class  Derived Class  Same Assembly  Different Assembly");
Console.WriteLine("public                                                      ");
Console.WriteLine("protected                                                   ");
Console.WriteLine("internal                                                    ");
Console.WriteLine("private                                                     ");
Console.WriteLine("protected internal                                          ");
Console.WriteLine("private protected                                           ");

// Best practices
public class GoodEncapsulation
{
    // Private fields - hide implementation
    private List<Item> items = new();
    private decimal total;
    
    // Public property - controlled access
    public IReadOnlyList<Item> Items
    {
        get { return items.AsReadOnly(); }
    }
    
    public decimal Total
    {
        get { return total; }
    }
    
    // Public methods - define behavior
    public void AddItem(Item item)
    {
        items.Add(item);
        total += item.Price;
    }
    
    public void Clear()
    {
        items.Clear();
        total = 0;
    }
}

// Protected for derived classes
public abstract class DataAccessBase
{
    protected string connectionString; // Available to derived classes
    
    protected void ExecuteQuery(string sql)
    {
        // Implementation
    }
}

public class UserRepository : DataAccessBase
{
    public List<User> GetAllUsers()
    {
        ExecuteQuery("SELECT * FROM Users"); // Can use protected method
        return new List<User>();
    }
}`}]},{id:"q6",question:"What is the difference between virtual, abstract, and override keywords?",answer:"virtual - base class method can be overridden (optional). abstract - must be overridden in derived class (no implementation). override - implementing the virtual/abstract method in derived class. virtual allows optional override, abstract requires it. Abstract methods have no body, virtual methods do.",codeSnippets:[{language:"csharp",code:`using System;

// ========== VIRTUAL - Optional override ==========
public class Animal
{
    public virtual void MakeSound()
    {
        Console.WriteLine("Some generic sound");
    }
    
    public virtual void Move()
    {
        Console.WriteLine("Moving");
    }
}

public class Dog : Animal
{
    // Override is optional - if not overridden, uses base implementation
    public override void MakeSound()
    {
        Console.WriteLine("Woof!");
    }
    
    // Don't override Move - uses Animal.Move()
}

var dog = new Dog();
dog.MakeSound(); // Woof! (overridden)
dog.Move(); // Moving (not overridden, uses base)

// ========== ABSTRACT - Required override ==========
public abstract class Shape
{
    // Abstract method - NO implementation, must be overridden
    public abstract double GetArea();
    
    // Abstract methods must be overridden by derived class
    public abstract void Draw();
    
    // Can still have concrete methods
    public void Describe()
    {
        Console.WriteLine($"Area: {GetArea()}");
    }
}

public class Circle : Shape
{
    private double radius;
    
    public Circle(double r) { radius = r; }
    
    // MUST override abstract methods
    public override double GetArea()
    {
        return Math.PI * radius * radius;
    }
    
    public override void Draw()
    {
        Console.WriteLine("Drawing circle");
    }
}

// Cannot instantiate abstract class
// var shape = new Shape(); // ERROR

// But can instantiate concrete derived class
var circle = new Circle(5);
circle.Describe(); // Uses Describe() from base

// ========== Comparison Table ==========
Console.WriteLine("VIRTUAL vs ABSTRACT:");
Console.WriteLine("Aspect               Virtual             Abstract");
Console.WriteLine("Implementation       Has body            No body (;)");
Console.WriteLine("Override required    Optional            Required");
Console.WriteLine("Can instantiate      Yes                 No");
Console.WriteLine("Use in               Regular class       Only abstract class");
Console.WriteLine("Keyword combo        virtual             abstract");

// Real-world example: Vehicle hierarchy
public abstract class Vehicle
{
    // Abstract - must override
    public abstract void Start();
    public abstract void Stop();
    
    // Virtual - can override
    public virtual void Drive()
    {
        Start();
        Console.WriteLine("Driving...");
        Stop();
    }
}

public class Car : Vehicle
{
    public override void Start()
    {
        Console.WriteLine("Car engine starts");
    }
    
    public override void Stop()
    {
        Console.WriteLine("Car engine stops");
    }
    
    // Don't override Drive - uses base implementation
}

public class Bicycle : Vehicle
{
    public override void Start()
    {
        Console.WriteLine("Ready to pedal");
    }
    
    public override void Stop()
    {
        Console.WriteLine("Stopped pedaling");
    }
    
    // Override Drive for different behavior
    public override void Drive()
    {
        Console.WriteLine("Pedaling...");
    }
}

// Another example: Payment processors
public abstract class PaymentProcessor
{
    // Abstract - must override
    public abstract bool ValidatePayment(decimal amount);
    
    // Virtual - optional override
    public virtual void RecordTransaction(string description)
    {
        Console.WriteLine($"Recording: {description}");
    }
    
    // Template method using abstract method
    public void ProcessPayment(decimal amount)
    {
        if (ValidatePayment(amount))
        {
            Console.WriteLine("Payment successful");
            RecordTransaction($"Charge: {amount}");
        }
        else
        {
            Console.WriteLine("Payment failed");
        }
    }
}

public class CreditCardProcessor : PaymentProcessor
{
    public override bool ValidatePayment(decimal amount)
    {
        // Credit card specific validation
        return amount > 0 && amount < 100000;
    }
    
    // Don't override RecordTransaction - uses base
}

public class BankTransferProcessor : PaymentProcessor
{
    public override bool ValidatePayment(decimal amount)
    {
        // Bank transfer specific validation
        return amount > 100 && amount < 50000;
    }
    
    // Override for different recording
    public override void RecordTransaction(string description)
    {
        Console.WriteLine($"Recording in bank ledger: {description}");
    }
}

// Usage
PaymentProcessor ccProcessor = new CreditCardProcessor();
ccProcessor.ProcessPayment(500); // Uses CC validation

PaymentProcessor bankProcessor = new BankTransferProcessor();
bankProcessor.ProcessPayment(5000); // Uses bank validation

// Key point: Interface as pure abstraction
public interface ILogger
{
    void Log(string message); // All members are abstract
}

public class ConsoleLogger : ILogger
{
    public void Log(string message)
    {
        Console.WriteLine(message); // Must implement
    }
}

// Sealed keyword - prevents further overriding
public class FinalAnimal : Animal
{
    public sealed override void MakeSound()
    {
        Console.WriteLine("Final sound");
    }
}

// Cannot override FinalAnimal.MakeSound()
// public class BadDog : FinalAnimal
// {
//     public override void MakeSound() // ERROR: sealed
//     {
//     }
// }`}]},{id:"q7",question:"What is method overriding? How is it different from method overloading?",answer:"Method overriding is in derived class with same signature as base class, uses virtual/override keywords, resolved at runtime. Method overloading is in same class with same name but different parameters, resolved at compile time. Overriding is runtime polymorphism, overloading is compile-time polymorphism.",codeSnippets:[{language:"csharp",code:`using System;

// ========== METHOD OVERLOADING (Compile-time) ==========
// Same name, different parameters, SAME CLASS
public class StringUtility
{
    // Convert int to string
    public string ToString(int value)
    {
        return value.ToString();
    }
    
    // Convert double to string
    public string ToString(double value)
    {
        return value.ToString("F2");
    }
    
    // Convert bool to string
    public string ToString(bool value)
    {
        return value.ToString();
    }
    
    // Different parameter count
    public string Concat(string a, string b)
    {
        return a + b;
    }
    
    public string Concat(string a, string b, string c)
    {
        return a + b + c;
    }
}

// Usage - Compiler determines which method at COMPILE TIME
var util = new StringUtility();
var s1 = util.ToString(42); // Calls ToString(int)
var s2 = util.ToString(3.14); // Calls ToString(double)
var s3 = util.ToString(true); // Calls ToString(bool)
var s4 = util.Concat("Hello", "World"); // 2 params
var s5 = util.Concat("A", "B", "C"); // 3 params

// ========== METHOD OVERRIDING (Runtime polymorphism) ==========
// Same name, same parameters, BASE and DERIVED class
public class Animal
{
    public virtual void MakeSound()
    {
        Console.WriteLine("Generic sound");
    }
}

public class Dog : Animal
{
    // Override - same signature, DIFFERENT CLASS
    public override void MakeSound()
    {
        Console.WriteLine("Woof!");
    }
}

public class Cat : Animal
{
    public override void MakeSound()
    {
        Console.WriteLine("Meow!");
    }
}

// Usage - Runtime determines which method based on ACTUAL TYPE
Animal animal1 = new Dog();
Animal animal2 = new Cat();
Animal animal3 = new Animal();

animal1.MakeSound(); // Woof! (Dog's override)
animal2.MakeSound(); // Meow! (Cat's override)
animal3.MakeSound(); // Generic sound (Animal's implementation)

// Detailed comparison
Console.WriteLine("METHOD OVERLOADING vs OVERRIDING:");
Console.WriteLine("Aspect              Overloading         Overriding");
Console.WriteLine("Scope               Same class          Base + derived");
Console.WriteLine("Method name         Same                Same");
Console.WriteLine("Parameters          Different           Same");
Console.WriteLine("Return type         Can differ          Same");
Console.WriteLine("Keywords            None                virtual/override");
Console.WriteLine("When resolved       Compile-time        Runtime");
Console.WriteLine("Inheritance         No                  Yes");
Console.WriteLine("Polymorphism type   Compile-time        Runtime");

// Real example: Overloading
public class DataProcessor
{
    public int Sum(int a, int b)
    {
        return a + b;
    }
    
    public double Sum(double a, double b)
    {
        return a + b;
    }
    
    public int Sum(int a, int b, int c)
    {
        return a + b + c;
    }
}

var dp = new DataProcessor();
int r1 = dp.Sum(5, 3); // Sum(int, int) -> 8
double r2 = dp.Sum(5.5, 3.2); // Sum(double, double) -> 8.7
int r3 = dp.Sum(5, 3, 2); // Sum(int, int, int) -> 10

// Real example: Overriding
public abstract class Shape
{
    public abstract double GetArea();
}

public class Circle : Shape
{
    private double radius;
    
    public Circle(double r) { radius = r; }
    
    public override double GetArea()
    {
        return Math.PI * radius * radius;
    }
}

public class Rectangle : Shape
{
    private double width, height;
    
    public Rectangle(double w, double h) 
    { 
        width = w; 
        height = h; 
    }
    
    public override double GetArea()
    {
        return width * height;
    }
}

// Polymorphism through overriding
Shape[] shapes = new Shape[]
{
    new Circle(5),
    new Rectangle(4, 6)
};

foreach (var shape in shapes)
{
    Console.WriteLine($"Area: {shape.GetArea()}");
    // Area: 78.54 (Circle)
    // Area: 24 (Rectangle)
}

// Cannot override in same class
public class BadExample
{
    public void Display(int x) { }
    // public override void Display(int x) { } // ERROR: No base member to override
    
    // But can overload
    public void Display(string x) { } // OK: Overload
}

// Overloading with different return types - usually not recommended
public class Example
{
    public int GetValue() { return 10; }
    // public string GetValue() { } // ERROR: Return type alone doesn't distinguish
    // Need different parameters
    public string GetValue(int x) { return "test"; } // OK: Different parameter
}

// Common mistake: Hiding instead of overriding
public class Parent
{
    public virtual void Method()
    {
        Console.WriteLine("Parent");
    }
}

public class Child : Parent
{
    public new void Method() // "new" hides parent method
    {
        Console.WriteLine("Child");
    }
}

var child = new Child();
child.Method(); // Child

Parent childRef = new Child();
childRef.Method(); // Parent (WRONG! Should be Child)

// Correct: Use override
public class GoodChild : Parent
{
    public override void Method()
    {
        Console.WriteLine("GoodChild");
    }
}

var goodChild = new GoodChild();
goodChild.Method(); // GoodChild

Parent goodChildRef = new GoodChild();
goodChildRef.Method(); // GoodChild (CORRECT!)`}]},{id:"q8",question:"What is composition vs inheritance? When to use each?",answer:"Inheritance is IS-A relationship (Dog IS-A Animal). Composition is HAS-A relationship (Car HAS-A Engine). Use inheritance for related classes sharing behavior. Use composition for flexibility and avoiding rigid hierarchies. Composition is usually better than deep inheritance chains. Prefer composition over inheritance for code reuse.",codeSnippets:[{language:"csharp",code:`using System;
using System.Collections.Generic;

// ========== INHERITANCE (IS-A) ==========
public abstract class Animal
{
    public string Name { get; set; }
    
    public abstract void MakeSound();
}

public class Dog : Animal
{
    public override void MakeSound()
    {
        Console.WriteLine("Woof!");
    }
}

public class Cat : Animal
{
    public override void MakeSound()
    {
        Console.WriteLine("Meow!");
    }
}

// IS-A: Dog IS-A Animal
var dog = new Dog { Name = "Buddy" };
dog.MakeSound(); // Woof

// Problem with deep inheritance
public class Vehicle { }
public class Car : Vehicle { }
public class SportsCar : Car { }
public class FerrariFf : SportsCar { }
// Rigid hierarchy - hard to change

// ========== COMPOSITION (HAS-A) ==========
public class Engine
{
    public int Horsepower { get; set; }
    
    public void Start()
    {
        Console.WriteLine("Engine started");
    }
}

public class Transmission
{
    public string Type { get; set; }
    
    public void Shift(string gear)
    {
        Console.WriteLine($"Shifting to {gear}");
    }
}

public class ComposedCar
{
    // Car HAS-A Engine
    private Engine engine;
    
    // Car HAS-A Transmission
    private Transmission transmission;
    
    public ComposedCar(Engine engine, Transmission transmission)
    {
        this.engine = engine;
        this.transmission = transmission;
    }
    
    public void Drive()
    {
        engine.Start();
        transmission.Shift("D");
        Console.WriteLine("Driving");
    }
}

// Usage
var engine = new Engine { Horsepower = 200 };
var transmission = new Transmission { Type = "Automatic" };
var car = new ComposedCar(engine, transmission);
car.Drive();

// Can swap components easily
var sportEngine = new Engine { Horsepower = 500 };
var sportCar = new ComposedCar(sportEngine, transmission);

// Comparison
Console.WriteLine("INHERITANCE vs COMPOSITION:");
Console.WriteLine("Aspect           Inheritance         Composition");
Console.WriteLine("Relationship     IS-A                HAS-A");
Console.WriteLine("Flexibility      Rigid               Flexible");
Console.WriteLine("Runtime change   Not possible        Possible");
Console.WriteLine("Complexity       Can be complex      Usually simpler");
Console.WriteLine("Code reuse       Through extension   Through delegation");

// Real-world example: Inheritance (NOT recommended)
public abstract class Employee
{
    public string Name { get; set; }
    
    public abstract decimal CalculateSalary();
}

// Bad: Too specific inheritance
public class Manager : Employee
{
    public override decimal CalculateSalary()
    {
        return 5000;
    }
}

public class Developer : Employee
{
    public override decimal CalculateSalary()
    {
        return 4000;
    }
}

// Problem: What if manager is also developer?
// Can't inherit from both

// Better: Composition
public interface IRole
{
    decimal CalculateCompensation();
}

public class ManagerRole : IRole
{
    public decimal CalculateCompensation() => 2000;
}

public class DeveloperRole : IRole
{
    public decimal CalculateCompensation() => 3000;
}

public class ComposedEmployee
{
    public string Name { get; set; }
    
    private List<IRole> roles = new();
    
    public void AddRole(IRole role)
    {
        roles.Add(role);
    }
    
    public decimal CalculateTotalCompensation()
    {
        decimal total = 0;
        foreach (var role in roles)
        {
            total += role.CalculateCompensation();
        }
        return total;
    }
}

// Usage - Much more flexible!
var employee = new ComposedEmployee { Name = "Alice" };
employee.AddRole(new ManagerRole());
employee.AddRole(new DeveloperRole());
Console.WriteLine(employee.CalculateTotalCompensation()); // 5000

// Real-world: Logger example
// Bad inheritance approach
public class ConsoleWriter
{
    public void WriteLine(string text) => Console.WriteLine(text);
}

public class ConsoleLogger : ConsoleWriter
{
    public void Log(string message)
    {
        WriteLine($"[LOG] {message}");
    }
}

// Problem: Can't change ConsoleWriter at runtime

// Good composition approach
public interface IWriter
{
    void Write(string text);
}

public class ConsoleOutput : IWriter
{
    public void Write(string text) => Console.WriteLine(text);
}

public class FileOutput : IWriter
{
    public void Write(string text)
    {
        // Write to file
    }
}

public class ComposedLogger
{
    private IWriter writer;
    
    public ComposedLogger(IWriter writer)
    {
        this.writer = writer;
    }
    
    public void Log(string message)
    {
        writer.Write($"[LOG] {message}");
    }
}

// Usage - Switch writers at runtime!
var consoleLogger = new ComposedLogger(new ConsoleOutput());
consoleLogger.Log("Hello"); // To console

var fileLogger = new ComposedLogger(new FileOutput());
fileLogger.Log("Hello"); // To file

// When to use Inheritance
public abstract class DatabaseConnection
{
    public abstract void Connect();
    public abstract void Disconnect();
}

// Related classes - use inheritance
public class SqlServerConnection : DatabaseConnection
{
    public override void Connect() => Console.WriteLine("Connecting to SQL Server");
    public override void Disconnect() => Console.WriteLine("Disconnecting from SQL Server");
}

public class MySqlConnection : DatabaseConnection
{
    public override void Connect() => Console.WriteLine("Connecting to MySQL");
    public override void Disconnect() => Console.WriteLine("Disconnecting from MySQL");
}

// When to use Composition
public class DataRepository
{
    private DatabaseConnection connection;
    
    public DataRepository(DatabaseConnection connection)
    {
        this.connection = connection;
    }
    
    public void LoadData()
    {
        connection.Connect();
        // Load data
        connection.Disconnect();
    }
}

// Summary: Prefer composition for flexibility`}]},{id:"q9",question:"What is the difference between == operator and Equals() method?",answer:"== compares references for reference types (unless overloaded). Equals() compares values by default. For value types, == doesn't work without overload. Equals() checks object equality. Best practice: override both == and Equals() together, implement IEquatable<T>.",codeSnippets:[{language:"csharp",code:`using System;

// ========== DEFAULT BEHAVIOR ==========
public class Person
{
    public string Name { get; set; }
}

var person1 = new Person { Name = "Alice" };
var person2 = new Person { Name = "Alice" };

Console.WriteLine(person1 == person2); // false (different references)
Console.WriteLine(person1.Equals(person2)); // false (default: reference comparison)

// For value types
int a = 5;
int b = 5;
Console.WriteLine(a == b); // true (value comparison)
Console.WriteLine(a.Equals(b)); // true (value comparison)

// ========== OVERRIDING EQUALS AND == ==========
public class GoodPerson : IEquatable<GoodPerson>
{
    public string Name { get; set; }
    public int Age { get; set; }
    
    // Override Equals - compare by value
    public override bool Equals(object obj)
    {
        return Equals(obj as GoodPerson);
    }
    
    public bool Equals(GoodPerson other)
    {
        if (other == null) return false;
        return Name == other.Name && Age == other.Age;
    }
    
    // Override GetHashCode - must be consistent with Equals
    public override int GetHashCode()
    {
        unchecked
        {
            int hash = 17;
            hash = hash * 31 + Name?.GetHashCode() ?? 0;
            hash = hash * 31 + Age.GetHashCode();
            return hash;
        }
    }
    
    // Overload == operator
    public static bool operator ==(GoodPerson left, GoodPerson right)
    {
        if (ReferenceEquals(left, right))
            return true;
        if (left is null || right is null)
            return false;
        return left.Equals(right);
    }
    
    // Overload != operator
    public static bool operator !=(GoodPerson left, GoodPerson right)
    {
        return !(left == right);
    }
}

// Usage
var good1 = new GoodPerson { Name = "Alice", Age = 25 };
var good2 = new GoodPerson { Name = "Alice", Age = 25 };
var good3 = new GoodPerson { Name = "Bob", Age = 30 };

Console.WriteLine(good1 == good2); // true (value comparison)
Console.WriteLine(good1.Equals(good2)); // true (value comparison)
Console.WriteLine(good1 != good3); // true

// ========== String example ==========
// Strings override Equals and ==
string str1 = "Hello";
string str2 = "Hello";
string str3 = new string(new[] { 'H', 'e', 'l', 'l', 'o' });

Console.WriteLine(str1 == str2); // true (value comparison)
Console.WriteLine(str1.Equals(str2)); // true (value comparison)
Console.WriteLine(str1 == str3); // true (value comparison)

// ========== Reference vs Value comparison ==========
public class BadPerson
{
    public string Name { get; set; }
    
    // Don't override Equals or ==
}

var bad1 = new BadPerson { Name = "Alice" };
var bad2 = new BadPerson { Name = "Alice" };

Console.WriteLine(bad1 == bad2); // false (reference comparison)
Console.WriteLine(bad1.Equals(bad2)); // false (reference comparison)

// Even though values are same!

// ========== Important: Must override both ==========
public class InconsistentPerson
{
    public string Name { get; set; }
    
    // Overrode Equals but not ==
    public override bool Equals(object obj)
    {
        var other = obj as InconsistentPerson;
        return other?.Name == Name;
    }
    
    public override int GetHashCode()
    {
        return Name?.GetHashCode() ?? 0;
    }
    
    // Forgot to override ==
}

var inc1 = new InconsistentPerson { Name = "Alice" };
var inc2 = new InconsistentPerson { Name = "Alice" };

Console.WriteLine(inc1 == inc2); // false (uses reference comparison)
Console.WriteLine(inc1.Equals(inc2)); // true (uses Equals override)
// INCONSISTENT! BAD!

// ========== Null comparisons ==========
GoodPerson person = null;
GoodPerson other = null;

Console.WriteLine(person == other); // true (both null)
Console.WriteLine(person == new GoodPerson()); // false (one null)

// ========== With collections ==========
var list = new List<GoodPerson>
{
    new GoodPerson { Name = "Alice", Age = 25 },
    new GoodPerson { Name = "Bob", Age = 30 }
};

var target = new GoodPerson { Name = "Alice", Age = 25 };

// Contains uses Equals (which we overrode)
bool found = list.Contains(target); // true!

// Dictionary uses GetHashCode and Equals
var dict = new Dictionary<GoodPerson, string>();
dict[new GoodPerson { Name = "Alice", Age = 25 }] = "Developer";

// Can retrieve with different reference
var value = dict[new GoodPerson { Name = "Alice", Age = 25 }]; // Works!

// ========== Summary Table ==========
Console.WriteLine("EQUALS vs ==:");
Console.WriteLine("Aspect               Equals           ==");
Console.WriteLine("Default behavior     Reference        Reference");
Console.WriteLine("Can override         Yes              Yes");
Console.WriteLine("For strings          Value            Value (overridden)");
Console.WriteLine("For value types      Value            Value (overridden)");
Console.WriteLine("Must implement       IEquatable<T>    Both operators");
Console.WriteLine("Used in              Contains, Dict   Comparisons");

// Best practice template
public class ProperComparison : IEquatable<ProperComparison>
{
    public string Id { get; set; }
    
    public override bool Equals(object obj) => Equals(obj as ProperComparison);
    
    public bool Equals(ProperComparison other)
    {
        if (other == null) return false;
        return Id == other.Id;
    }
    
    public override int GetHashCode() => Id?.GetHashCode() ?? 0;
    
    public static bool operator ==(ProperComparison left, ProperComparison right)
    {
        if (left is null) return right is null;
        return left.Equals(right);
    }
    
    public static bool operator !=(ProperComparison left, ProperComparison right)
    {
        return !(left == right);
    }
}`}]},{id:"q10",question:"What are constructors and destructors? What is the difference between parameterized and default constructors?",answer:"Constructor is a special method called when creating an object, initializes state. Destructor cleans up resources, called when object is garbage collected (rare in C#). Default constructor has no parameters. Parameterized constructor takes parameters to initialize fields. Base class constructor can be called using : base().",codeSnippets:[{language:"csharp",code:`using System;

// ========== DEFAULT CONSTRUCTOR ==========
public class SimpleClass
{
    public string Name { get; set; }
    public int Value { get; set; }
    
    // Default constructor - no parameters
    public SimpleClass()
    {
        Name = "Default";
        Value = 0;
        Console.WriteLine("Default constructor called");
    }
}

var simple = new SimpleClass();
// Output: Default constructor called
Console.WriteLine(simple.Name); // Default

// ========== PARAMETERIZED CONSTRUCTOR ==========
public class Account
{
    public string AccountNumber { get; set; }
    public decimal Balance { get; set; }
    
    // Parameterized constructor
    public Account(string accountNumber, decimal initialBalance)
    {
        AccountNumber = accountNumber;
        Balance = initialBalance;
        Console.WriteLine($"Account {accountNumber} created");
    }
}

var account = new Account("ACC001", 1000);
// Output: Account ACC001 created

// ========== MULTIPLE CONSTRUCTORS (Overloading) ==========
public class Person
{
    public string Name { get; set; }
    public int Age { get; set; }
    public string Email { get; set; }
    
    // Default constructor
    public Person()
    {
        Name = "Unknown";
        Age = 0;
        Email = "unknown@email.com";
    }
    
    // Parameterized - one parameter
    public Person(string name)
    {
        Name = name;
        Age = 0;
        Email = "unknown@email.com";
    }
    
    // Parameterized - two parameters
    public Person(string name, int age)
    {
        Name = name;
        Age = age;
        Email = "unknown@email.com";
    }
    
    // Parameterized - all parameters
    public Person(string name, int age, string email)
    {
        Name = name;
        Age = age;
        Email = email;
    }
}

var p1 = new Person(); // Default
var p2 = new Person("Alice"); // 1 param
var p3 = new Person("Bob", 30); // 2 params
var p4 = new Person("Charlie", 25, "charlie@email.com"); // All params

// ========== USING this() for constructor chaining ==========
public class ImprovedPerson
{
    public string Name { get; set; }
    public int Age { get; set; }
    
    public ImprovedPerson() : this("Unknown", 0)
    {
        // Calls parameterized constructor
    }
    
    public ImprovedPerson(string name) : this(name, 0)
    {
        // Calls other constructor
    }
    
    public ImprovedPerson(string name, int age)
    {
        Name = name;
        Age = age;
        Console.WriteLine($"Person created: {name}, Age {age}");
    }
}

var ip1 = new ImprovedPerson(); // Calls : this()
var ip2 = new ImprovedPerson("Alice"); // Calls : this(string)
var ip3 = new ImprovedPerson("Bob", 30); // Full initialization

// ========== INHERITANCE AND CONSTRUCTORS ==========
public class Animal
{
    public string Name { get; set; }
    
    public Animal(string name)
    {
        Name = name;
        Console.WriteLine($"Animal constructor: {name}");
    }
}

public class Dog : Animal
{
    public string Breed { get; set; }
    
    // Must call base constructor with : base()
    public Dog(string name, string breed) : base(name)
    {
        Breed = breed;
        Console.WriteLine($"Dog constructor: {breed}");
    }
}

var dog = new Dog("Buddy", "Labrador");
// Output:
// Animal constructor: Buddy
// Dog constructor: Labrador

// ========== DESTRUCTORS (Finalizers) ==========
public class ResourceHolder
{
    private IntPtr unmanagedResource;
    
    public ResourceHolder()
    {
        Console.WriteLine("Constructor: Resource allocated");
        unmanagedResource = AllocateUnmanagedResource();
    }
    
    // Destructor - called by garbage collector
    ~ResourceHolder()
    {
        Console.WriteLine("Destructor: Resource freed");
        FreeUnmanagedResource(unmanagedResource);
    }
    
    private IntPtr AllocateUnmanagedResource()
    {
        return new IntPtr(12345); // Simulated
    }
    
    private void FreeUnmanagedResource(IntPtr resource)
    {
        // Cleanup
    }
}

// ========== PROPER RESOURCE MANAGEMENT WITH IDisposable ==========
public class ManagedResource : IDisposable
{
    private bool disposed = false;
    
    public ManagedResource()
    {
        Console.WriteLine("Constructor");
    }
    
    // Implement Dispose for explicit cleanup
    public void Dispose()
    {
        Dispose(true);
        GC.SuppressFinalize(this); // Don't call finalizer
    }
    
    protected virtual void Dispose(bool disposing)
    {
        if (!disposed)
        {
            if (disposing)
            {
                Console.WriteLine("Disposing managed resources");
                // Dispose managed resources
            }
            
            Console.WriteLine("Freeing unmanaged resources");
            // Free unmanaged resources
            
            disposed = true;
        }
    }
    
    // Finalizer as safety net
    ~ManagedResource()
    {
        Dispose(false);
    }
}

// Usage with using statement
using (var resource = new ManagedResource())
{
    // Use resource
} // Dispose called automatically

// Or
var resource2 = new ManagedResource();
try
{
    // Use resource
}
finally
{
    resource2?.Dispose();
}

// ========== STATIC CONSTRUCTOR ==========
public class Configuration
{
    public static string AppName { get; set; }
    public static string Version { get; set; }
    
    // Static constructor - called once when class is first used
    static Configuration()
    {
        AppName = "MyApp";
        Version = "1.0";
        Console.WriteLine("Static constructor called");
    }
}

// Usage
var app1 = new Configuration();
var app2 = new Configuration();
// Static constructor called only ONCE (for all instances)

// ========== COMPARISON ==========
Console.WriteLine("CONSTRUCTOR vs DESTRUCTOR:");
Console.WriteLine("Aspect           Constructor     Destructor");
Console.WriteLine("Purpose          Initialize      Cleanup");
Console.WriteLine("Called when      Object created  Object collected");
Console.WriteLine("Can overload     Yes             No (only one)");
Console.WriteLine("Parameters       Yes             No");
Console.WriteLine("Syntax           public Type()   ~Type()");
Console.WriteLine("Timing           Immediate       Garbage collection");

// ========== BEST PRACTICES ==========
public class GoodPractice
{
    private string resource;
    
    // Clear parameterized constructor
    public GoodPractice(string resource)
    {
        this.resource = resource ?? throw new ArgumentNullException(nameof(resource));
        Console.WriteLine("Initialized with: " + resource);
    }
    
    // Validate input in constructor
    public static implicit operator GoodPractice(string value)
    {
        return new GoodPractice(value);
    }
}

// Use constructor to validate
var good = new GoodPractice("Valid");
// good = new GoodPractice(null); // Throws ArgumentNullException`}]}]},zy={id:"csharp-solid-principles",name:"SOLID Principles",questions:[{id:"q1",question:"What are SOLID principles and why are they important?",answer:"SOLID is an acronym for five design principles (Single Responsibility, Open/Closed, Liskov Substitution, Interface Segregation, Dependency Inversion) that make code more maintainable, scalable, and testable. They help you write clean code that's easy to understand, modify, and extend without breaking existing functionality.",codeSnippets:[{language:"csharp",code:`// BAD - Violates SOLID principles
public class UserManager
{
    // Violates SRP - does too many things
    public void CreateUser(string name, string email) { }
    public void SendEmail(string to, string subject) { }
    public void LogActivity(string message) { }
    public void SaveToDatabase(string data) { }
    public void ValidateEmail(string email) { }
    
    // Hard to test, maintain, and extend
    // Change one thing breaks everything
}

// GOOD - Follows SOLID principles
public class UserService
{
    private readonly IUserRepository userRepository;
    private readonly IEmailService emailService;
    private readonly ILogger logger;
    
    public UserService(
        IUserRepository userRepository,
        IEmailService emailService,
        ILogger logger)
    {
        this.userRepository = userRepository;
        this.emailService = emailService;
        this.logger = logger;
    }
    
    public void CreateUser(User user)
    {
        // Single Responsibility - only manage users
        userRepository.Save(user);
        logger.Log(\`User \${user.Name} created\`);
    }
}

public interface IUserRepository
{
    void Save(User user);
}

public interface IEmailService
{
    void SendEmail(string to, string subject, string body);
}

public interface ILogger
{
    void Log(string message);
}

// Benefits:
// - Easy to test (inject mocks)
// - Easy to extend (implement new repositories)
// - Easy to maintain (each class has one job)
// - Easy to reuse (components are independent)`}]},{id:"q2",question:"What is the Single Responsibility Principle (SRP)?",answer:"A class should have only one reason to change. It should have only one responsibility. This makes classes focused, easier to understand, test, and maintain. If a class has multiple reasons to change, it violates SRP.",codeSnippets:[{language:"csharp",code:`// VIOLATES SRP - Multiple reasons to change
public class Employee
{
    public string Name { get; set; }
    public decimal Salary { get; set; }
    
    // Responsibility 1: Employee data
    public void UpdateName(string name)
    {
        Name = name;
    }
    
    // Responsibility 2: Calculations
    public decimal CalculateBonus()
    {
        return Salary * 0.1m;
    }
    
    // Responsibility 3: Persistence
    public void SaveToDatabase()
    {
        // Save to DB
    }
    
    // Responsibility 4: Reporting
    public string GenerateReport()
    {
        return $"Employee: {Name}, Salary: {Salary}";
    }
    
    // Changes for any reason: pay logic, DB schema, report format, etc.
}

// FOLLOWS SRP - Each class has one reason to change
public class Employee
{
    public string Name { get; set; }
    public decimal Salary { get; set; }
}

public class BonusCalculator
{
    // Only reason to change: bonus calculation logic
    public decimal CalculateBonus(Employee employee)
    {
        return employee.Salary * 0.1m;
    }
}

public class EmployeeRepository
{
    // Only reason to change: database schema or ORM
    public void Save(Employee employee)
    {
        // Save to DB
    }
}

public class EmployeeReporter
{
    // Only reason to change: report format
    public string GenerateReport(Employee employee)
    {
        return $"Employee: {employee.Name}, Salary: {employee.Salary}";
    }
}

// Benefits:
// - Each class is easier to understand
// - Changes are localized (changing bonus logic doesn't affect reporting)
// - Easier to test
// - Easier to reuse

// Usage
var employee = new Employee { Name = "Alice", Salary = 50000 };
var calculator = new BonusCalculator();
var bonus = calculator.CalculateBonus(employee); // $5000`}]},{id:"q3",question:"What is the Open/Closed Principle (OCP)?",answer:"Software entities should be open for extension but closed for modification. You should be able to add new functionality without changing existing code. Achieved through inheritance, abstraction, and polymorphism.",codeSnippets:[{language:"csharp",code:`// VIOLATES OCP - Need to modify for every new report type
public class ReportGenerator
{
    public void Generate(string reportType)
    {
        if (reportType == "PDF")
        {
            // Generate PDF
        }
        else if (reportType == "Excel")
        {
            // Generate Excel
        }
        else if (reportType == "HTML")
        {
            // Generate HTML
        }
        // Must modify this class for every new report type!
    }
}

// FOLLOWS OCP - Use abstraction to extend
public interface IReportFormatter
{
    void Format(ReportData data);
}

public class PdfReportFormatter : IReportFormatter
{
    public void Format(ReportData data)
    {
        // Generate PDF
    }
}

public class ExcelReportFormatter : IReportFormatter
{
    public void Format(ReportData data)
    {
        // Generate Excel
    }
}

public class HtmlReportFormatter : IReportFormatter
{
    public void Format(ReportData data)
    {
        // Generate HTML
    }
}

public class ReportGenerator
{
    // Closed for modification - this doesn't change
    // Open for extension - add new formatters without changing this
    public void Generate(ReportData data, IReportFormatter formatter)
    {
        formatter.Format(data); // Works with any formatter
    }
}

// Adding new report type doesn't require changing ReportGenerator
public class JsonReportFormatter : IReportFormatter
{
    public void Format(ReportData data)
    {
        // Generate JSON
    }
}

// Usage
var generator = new ReportGenerator();
var data = new ReportData();

generator.Generate(data, new PdfReportFormatter());
generator.Generate(data, new ExcelReportFormatter());
generator.Generate(data, new JsonReportFormatter()); // New format!

// Benefits:
// - Existing code is not modified (lower risk of bugs)
// - New functionality can be added by creating new classes
// - Easier to test (mock formatters)
// - Better code organization`}]},{id:"q4",question:"What is the Liskov Substitution Principle (LSP)?",answer:"Derived classes must be substitutable for their base classes. If a class is a subclass of another, it should be usable wherever the parent class is expected without breaking the code. Violating this principle leads to unexpected behavior.",codeSnippets:[{language:"csharp",code:`// VIOLATES LSP - Circle can't be substituted for Rectangle
public class Rectangle
{
    public virtual int Width { get; set; }
    public virtual int Height { get; set; }
    
    public virtual int CalculateArea()
    {
        return Width * Height;
    }
}

public class Circle : Rectangle
{
    // Circle doesn't have Width and Height independently!
    // Setting Width should also set Height (radius)
    
    public override int Width
    {
        get => base.Width;
        set => base.Width = base.Height = value; // Violates expectations
    }
    
    public override int CalculateArea()
    {
        return (int)(Width * Width * 3.14); // Different calculation
    }
}

// Problem: Circle violates Rectangle's contract
public void ProcessRectangle(Rectangle rect)
{
    rect.Width = 5;
    rect.Height = 10;
    
    // Expected area: 5 * 10 = 50
    var area = rect.CalculateArea();
    
    if (rect is Circle)
        // area = 5 * 5 * 3.14  78.5 - BROKEN!
    }
}

// FOLLOWS LSP - Proper inheritance hierarchy
public abstract class Shape
{
    public abstract int CalculateArea();
}

public class Rectangle : Shape
{
    public int Width { get; set; }
    public int Height { get; set; }
    
    public override int CalculateArea()
    {
        return Width * Height;
    }
}

public class Circle : Shape
{
    public int Radius { get; set; }
    
    public override int CalculateArea()
    {
        return (int)(Radius * Radius * 3.14);
    }
}

// Now all shapes can be substituted
public void ProcessShape(Shape shape)
{
    var area = shape.CalculateArea(); // Works correctly for any shape
}

// Usage
var shapes = new List<Shape>
{
    new Rectangle { Width = 5, Height = 10 },
    new Circle { Radius = 3 }
};

foreach (var shape in shapes)
{
    Console.WriteLine(shape.CalculateArea()); // Works correctly
}

// Benefits:
// - Inheritance is meaningful
// - Polymorphism works as expected
// - No surprises when substituting derived classes
// - Easier to reason about code`}]},{id:"q5",question:"What is the Interface Segregation Principle (ISP)?",answer:"Clients should not depend on interfaces they don't use. Create specific, focused interfaces instead of large general-purpose ones. This prevents classes from being forced to implement methods they don't need.",codeSnippets:[{language:"csharp",code:`// VIOLATES ISP - Large interface with many methods
public interface IWorker
{
    void Work();
    void Eat();
    void Sleep();
    void Drive();
    void Code();
}

public class Developer : IWorker
{
    public void Work() { Console.WriteLine("Coding"); }
    public void Eat() { Console.WriteLine("Eating"); }
    public void Sleep() { Console.WriteLine("Sleeping"); }
    public void Drive() { Console.WriteLine("Driving"); }
    public void Code() { Console.WriteLine("Writing code"); }
}

public class Robot : IWorker
{
    public void Work() { Console.WriteLine("Working"); }
    public void Eat() { throw new NotImplementedException(); } // Robot doesn't eat!
    public void Sleep() { throw new NotImplementedException(); } // Robot doesn't sleep!
    public void Drive() { Console.WriteLine("Moving"); }
    public void Code() { throw new NotImplementedException(); } // Robot might not code!
    
    // Forced to implement methods it doesn't need
}

// FOLLOWS ISP - Small, focused interfaces
public interface IWorker
{
    void Work();
}

public interface IEater
{
    void Eat();
}

public interface ISleeper
{
    void Sleep();
}

public interface IDriver
{
    void Drive();
}

public interface IProgrammer
{
    void Code();
}

public class Developer : IWorker, IEater, ISleeper, IDriver, IProgrammer
{
    public void Work() { Console.WriteLine("Working"); }
    public void Eat() { Console.WriteLine("Eating"); }
    public void Sleep() { Console.WriteLine("Sleeping"); }
    public void Drive() { Console.WriteLine("Driving"); }
    public void Code() { Console.WriteLine("Coding"); }
}

public class Robot : IWorker, IDriver, IProgrammer
{
    // Only implements what it actually needs
    public void Work() { Console.WriteLine("Working"); }
    public void Drive() { Console.WriteLine("Moving"); }
    public void Code() { Console.WriteLine("Programming"); }
}

// Usage
var developer = new Developer();
ProcessWorker(developer); // Works

var robot = new Robot();
ProcessWorker(robot); // Works

public void ProcessWorker(IWorker worker)
{
    worker.Work();
}

public void ProcessProgrammer(IProgrammer programmer)
{
    programmer.Code();
}

// Benefits:
// - Classes only depend on what they use
// - No forced implementations of unnecessary methods
// - More flexible and reusable
// - Easier to understand what a class does
// - Changes to one interface don't affect unrelated classes`}]},{id:"q6",question:"What is the Dependency Inversion Principle (DIP)?",answer:"High-level modules should not depend on low-level modules. Both should depend on abstractions. Depend on interfaces/abstractions, not concrete implementations. This decouples code and makes it more testable and flexible.",codeSnippets:[{language:"csharp",code:`// VIOLATES DIP - Direct dependency on concrete classes
public class MySqlDatabase
{
    public void Save(User user)
    {
        // Save to MySQL
    }
}

public class UserService
{
    // High-level module depends on low-level module (MySqlDatabase)
    private MySqlDatabase database = new MySqlDatabase();
    
    public void CreateUser(User user)
    {
        database.Save(user); // Tightly coupled
    }
}

public class UserController
{
    private UserService userService = new UserService();
    
    public void CreateUser(User user)
    {
        userService.CreateUser(user);
    }
}

// Problems:
// - Can't switch databases without changing UserService
// - Hard to test (can't mock MySqlDatabase)
// - Tightly coupled
// - UserService depends on implementation details

// FOLLOWS DIP - Depend on abstractions
public interface IUserRepository
{
    void Save(User user);
}

public class MySqlUserRepository : IUserRepository
{
    public void Save(User user)
    {
        // Save to MySQL
    }
}

public class SqlServerUserRepository : IUserRepository
{
    public void Save(User user)
    {
        // Save to SQL Server
    }
}

public class UserService
{
    // Depends on abstraction, not concrete implementation
    private readonly IUserRepository userRepository;
    
    // Dependency injected through constructor
    public UserService(IUserRepository userRepository)
    {
        this.userRepository = userRepository;
    }
    
    public void CreateUser(User user)
    {
        userRepository.Save(user); // Works with any repository
    }
}

public class UserController
{
    private readonly UserService userService;
    
    public UserController(UserService userService)
    {
        this.userService = userService; // Injected
    }
    
    public void CreateUser(User user)
    {
        userService.CreateUser(user);
    }
}

// Setup (using dependency injection container)
var repository = new MySqlUserRepository();
var service = new UserService(repository);
var controller = new UserController(service);

// Easy to switch databases
var sqlServerRepo = new SqlServerUserRepository();
var serviceWithSqlServer = new UserService(sqlServerRepo);

// Easy to test with mock
public class MockUserRepository : IUserRepository
{
    public void Save(User user) { } // Mock implementation
}

var testService = new UserService(new MockUserRepository());
// Now can test without actual database!

// Benefits:
// - Decoupled code (can swap implementations)
// - Easy to test (use mocks)
// - Follows Open/Closed Principle
// - More flexible and maintainable
// - Can easily add new repository types`}]},{id:"q7",question:"How do SOLID principles relate to each other? Give an example of following all five together.",answer:"SOLID principles work together to create clean, maintainable code. They complement each other: SRP focuses code, OCP extends it, LSP ensures substitution works, ISP segregates interfaces, and DIP decouples dependencies. Following one often encourages following others.",codeSnippets:[{language:"csharp",code:`// Example: E-commerce Order Processing System
// Demonstrates all SOLID principles working together

// 1. Single Responsibility - Each class has one job
public class Order
{
    public int Id { get; set; }
    public List<OrderItem> Items { get; set; }
    public decimal TotalAmount { get; set; }
}

// 2. Interface Segregation - Small, focused interfaces
public interface IOrderRepository
{
    void Save(Order order);
    Order GetById(int id);
}

public interface IPaymentProcessor
{
    bool ProcessPayment(Order order, PaymentMethod method);
}

public interface INotificationService
{
    void SendOrderConfirmation(Order order);
}

public interface IInventoryService
{
    void ReserveItems(Order order);
    void ReleaseReservation(Order order);
}

// 3. Liskov Substitution - Derived classes substitute parents correctly
public abstract class PaymentProcessor : IPaymentProcessor
{
    protected decimal Amount { get; set; }
    
    public virtual bool ProcessPayment(Order order, PaymentMethod method)
    {
        // Common logic
        Amount = order.TotalAmount;
        return ValidateAndProcess(method);
    }
    
    protected abstract bool ValidateAndProcess(PaymentMethod method);
}

public class CreditCardProcessor : PaymentProcessor
{
    protected override bool ValidateAndProcess(PaymentMethod method)
    {
        // Process credit card
        return true;
    }
}

public class PayPalProcessor : PaymentProcessor
{
    protected override bool ValidateAndProcess(PaymentMethod method)
    {
        // Process PayPal
        return true;
    }
}

// 4. Dependency Inversion & Open/Closed - Depend on abstractions
public class OrderService
{
    // Dependencies injected, not hardcoded
    private readonly IOrderRepository orderRepository;
    private readonly IPaymentProcessor paymentProcessor;
    private readonly INotificationService notificationService;
    private readonly IInventoryService inventoryService;
    
    public OrderService(
        IOrderRepository orderRepository,
        IPaymentProcessor paymentProcessor,
        INotificationService notificationService,
        IInventoryService inventoryService)
    {
        this.orderRepository = orderRepository;
        this.paymentProcessor = paymentProcessor;
        this.notificationService = notificationService;
        this.inventoryService = inventoryService;
    }
    
    // Single Responsibility - only handles order processing workflow
    public bool ProcessOrder(Order order, PaymentMethod paymentMethod)
    {
        // Reserve inventory first
        inventoryService.ReserveItems(order);
        
        // Process payment
        bool paymentSuccess = paymentProcessor.ProcessPayment(order, paymentMethod);
        
        if (!paymentSuccess)
        {
            // Release inventory if payment fails
            inventoryService.ReleaseReservation(order);
            return false;
        }
        
        // Save order
        orderRepository.Save(order);
        
        // Send notification
        notificationService.SendOrderConfirmation(order);
        
        return true;
    }
}

// 5. Open/Closed - Easy to extend with new implementations
public class EmailNotificationService : INotificationService
{
    public void SendOrderConfirmation(Order order)
    {
        // Send email notification
    }
}

public class SmsNotificationService : INotificationService
{
    public void SendOrderConfirmation(Order order)
    {
        // Send SMS notification
    }
}

public class SqlOrderRepository : IOrderRepository
{
    public void Save(Order order) { }
    public Order GetById(int id) { return new Order(); }
}

public class MongoOrderRepository : IOrderRepository
{
    public void Save(Order order) { }
    public Order GetById(int id) { return new Order(); }
}

// Usage - easy to compose and change implementations
var orderRepository = new SqlOrderRepository();
var paymentProcessor = new CreditCardProcessor();
var notificationService = new EmailNotificationService();
var inventoryService = new InventoryService();

var orderService = new OrderService(
    orderRepository,
    paymentProcessor,
    notificationService,
    inventoryService);

var order = new Order { Id = 1, TotalAmount = 100 };
orderService.ProcessOrder(order, PaymentMethod.CreditCard);

// Easy to change to different implementations
var orderService2 = new OrderService(
    new MongoOrderRepository(),
    new PayPalProcessor(),
    new SmsNotificationService(),
    inventoryService);

// Benefits of applying all SOLID principles:
// - Maintainable: Each class is focused and independent
// - Testable: Can mock any dependency
// - Extensible: Add new processors, repositories, notifications without changing existing code
// - Flexible: Easy to swap implementations
// - Clear: Code is organized and understandable`}]},{id:"q8",question:"What are common violations of SOLID principles and how to identify them?",answer:"Common violations include: classes doing too much (SRP), needing modification for new features (OCP), broken inheritance (LSP), forced interface implementations (ISP), tight coupling to concrete classes (DIP). Identify by looking for classes with multiple reasons to change, if-else statements for variations, unused method implementations, or direct instantiation of dependencies.",codeSnippets:[{language:"csharp",code:`// Red Flags - Signs of SOLID Violations

// 1. SRP Violation - Class has multiple reasons to change
public class BadUserManager //  Bad name already suggests multiple responsibilities
{
    public void CreateUser(string name) { } // User management
    public void SendWelcomeEmail(string email) { } // Email service
    public void SaveToDatabase(User user) { } // Database service
    public void LogActivity(string message) { } // Logging service
    public void GenerateReport() { } // Reporting service
    
    // Signs:
    // - Class name with "Manager", "Service" (too generic)
    // - Many dependencies
    // - Multiple reasons to modify the class
    // - Hard to unit test
}

// 2. OCP Violation - Need to modify code for new features
public class BadOrderProcessor
{
    public void ProcessOrder(Order order, string paymentType)
    {
        if (paymentType == "CreditCard")
        {
            // Process credit card
        }
        else if (paymentType == "PayPal")
        {
            // Process PayPal
        }
        else if (paymentType == "Bitcoin")
        {
            // Process Bitcoin - NEED TO MODIFY THIS CLASS!
        }
        // Signs:
        // - Many if/else or switch statements
        // - Must modify existing code to add features
        // - Tight coupling to concrete types
    }
}

// 3. LSP Violation - Derived class breaks base contract
public class BadShape
{
    public virtual void Draw() { }
}

public class BadSquareDrawable : BadShape
{
    public override void Draw()
    {
        throw new NotImplementedException("Squares don't draw");
    }
    // Signs:
    // - Throwing NotImplementedException in overrides
    // - Override doesn't fulfill the contract
    // - Base type assumption is broken
}

// 4. ISP Violation - Forces unused methods
public class BadWorkerInterface
{
    public interface IWorker
    {
        void Work();
        void Eat();
        void Sleep();
        void Exercise();
        void GoToSchool();
    }
    
    public class Robot : IWorker
    {
        public void Work() { }
        public void Eat() { throw new NotImplementedException(); } //  Not applicable
        public void Sleep() { throw new NotImplementedException(); } //  Not applicable
        public void Exercise() { throw new NotImplementedException(); } //  Not applicable
        public void GoToSchool() { throw new NotImplementedException(); } //  Not applicable
        
        // Signs:
        // - Throwing NotImplementedException
        // - Empty implementations
        // - Methods that don't make sense for the class
    }
}

// 5. DIP Violation - Tight coupling to concrete classes
public class BadUserService
{
    // Direct instantiation - tight coupling
    private MySqlDatabase database = new MySqlDatabase();
    
    public void CreateUser(User user)
    {
        database.Save(user);
    }
    
    // Signs:
    // - Using 'new' to create dependencies
    // - Can't test without actual objects
    // - Hard to swap implementations
    // - High coupling
}

// How to Refactor (GOOD versions)

// 1. Fix SRP
public class GoodUserService //  Single responsibility
{
    public void CreateUser(User user) { }
}

public class EmailService //  Separate responsibility
{
    public void SendWelcomeEmail(string email) { }
}

// 2. Fix OCP
public interface IPaymentProcessor
{
    void Process(Order order);
}

public class CreditCardProcessor : IPaymentProcessor { }
public class PayPalProcessor : IPaymentProcessor { }
public class BitcoinProcessor : IPaymentProcessor { } // Easy to add

public class GoodOrderProcessor //  Closed for modification
{
    public void ProcessOrder(Order order, IPaymentProcessor processor)
    {
        processor.Process(order); // Works with any processor
    }
}

// 3. Fix LSP
public abstract class GoodShape
{
    public abstract void Draw();
}

public class Circle : GoodShape
{
    public override void Draw() { /* Draw circle */ }
}

public class Square : GoodShape
{
    public override void Draw() { /* Draw square */ }
}

// 4. Fix ISP
public interface IWorker { void Work(); }
public interface IEater { void Eat(); }
public interface ISleeper { void Sleep(); }

public class Person : IWorker, IEater, ISleeper { }
public class Robot : IWorker { } // Only what it needs

// 5. Fix DIP
public class GoodUserService
{
    private readonly IUserRepository repository;
    
    // Dependency injected
    public GoodUserService(IUserRepository repository)
    {
        this.repository = repository;
    }
    
    public void CreateUser(User user)
    {
        repository.Save(user);
    }
}

// Automated Tools to Detect Violations:
// - Code metrics (complexity, coupling)
// - Roslyn analyzers
// - CodeSmell detectors
// - Unit test coverage (hard to test = violation)
// - Regular code reviews

// Key Questions to Ask:
// - Does this class have only one reason to change? (SRP)
// - Can I add new functionality without modifying existing code? (OCP)
// - Can I use derived classes anywhere the base is expected? (LSP)
// - Are all interface methods actually used? (ISP)
// - Can I test this without actual dependencies? (DIP)`}]},{id:"q9",question:"How do design patterns relate to SOLID principles?",answer:"Design patterns are implementations that often encourage following SOLID principles. Strategy pattern follows OCP, Adapter pattern follows ISP, Repository pattern follows DIP. Many design patterns exist specifically to help follow SOLID principles.",codeSnippets:[{language:"csharp",code:`// Relationship between Design Patterns and SOLID

// 1. Strategy Pattern - Follows OCP (Open/Closed)
public interface IPaymentStrategy
{
    void Pay(decimal amount);
}

public class CreditCardPayment : IPaymentStrategy
{
    public void Pay(decimal amount) { }
}

public class PayPalPayment : IPaymentStrategy
{
    public void Pay(decimal amount) { }
}

public class ShoppingCart
{
    public void Checkout(IPaymentStrategy paymentMethod)
    {
        paymentMethod.Pay(GetTotal());
        // Open for extension - add new payment methods
        // Closed for modification - this method doesn't change
    }
}

// 2. Repository Pattern - Follows DIP (Dependency Inversion)
public interface IRepository<T>
{
    void Add(T item);
    T GetById(int id);
}

public class SqlRepository<T> : IRepository<T>
{
    public void Add(T item) { }
    public T GetById(int id) { return default; }
}

public class Service
{
    // Depends on abstraction, not concrete SqlRepository
    private readonly IRepository<User> repository;
    
    public Service(IRepository<User> repository)
    {
        this.repository = repository; // DIP
    }
}

// 3. Adapter Pattern - Follows ISP (Interface Segregation)
public interface IEmailSender
{
    void SendEmail(string to, string message);
}

public class ThirdPartyEmailService
{
    public void Send(string recipient, string body) { }
}

// Adapter to fit interface
public class EmailAdapter : IEmailSender
{
    private readonly ThirdPartyEmailService service;
    
    public void SendEmail(string to, string message)
    {
        service.Send(to, message); // Adapts to our interface
    }
}

// 4. Decorator Pattern - Follows OCP
public interface IComponent
{
    void Operation();
}

public class ConcreteComponent : IComponent
{
    public void Operation() { Console.WriteLine("Base operation"); }
}

public abstract class Decorator : IComponent
{
    protected IComponent component;
    
    public virtual void Operation()
    {
        component.Operation();
    }
}

public class ConcreteDecorator : Decorator
{
    public override void Operation()
    {
        Console.WriteLine("Before");
        base.Operation();
        Console.WriteLine("After");
    }
}

// Usage
IComponent component = new ConcreteComponent();
component = new ConcreteDecorator { component = component };
component.Operation();
// Extends functionality without modifying ConcreteComponent (OCP)

// 5. Factory Pattern - Follows DIP
public interface IProductFactory
{
    Product CreateProduct();
}

public class ConcreteFactory : IProductFactory
{
    public Product CreateProduct()
    {
        return new ConcreteProduct();
    }
}

public class Client
{
    private readonly IProductFactory factory;
    
    public Client(IProductFactory factory)
    {
        this.factory = factory; // DIP - depends on abstraction
    }
    
    public void DoSomething()
    {
        var product = factory.CreateProduct();
    }
}

// 6. Observer Pattern - Follows SRP
public interface IObserver
{
    void Update(string message);
}

public class Subject
{
    private List<IObserver> observers = new();
    
    public void Notify(string message)
    {
        foreach (var observer in observers)
        {
            observer.Update(message); // Each observer has one job
        }
    }
}

// 7. Template Method - Follows OCP and LSP
public abstract class DataProcessor
{
    public void ProcessData(string data)
    {
        ValidateData(data);
        TransformData(data);
        SaveData(data);
    }
    
    protected abstract void ValidateData(string data);
    protected abstract void TransformData(string data);
    protected abstract void SaveData(string data);
}

public class JsonProcessor : DataProcessor
{
    protected override void ValidateData(string data) { }
    protected override void TransformData(string data) { }
    protected override void SaveData(string data) { }
}

// Key Connection Points:
// Pattern          SOLID Principles
// Strategy         OCP (extend without modification)
// Repository       DIP (depend on abstraction)
// Adapter          ISP (create focused interfaces)
// Decorator        OCP (add functionality without modification)
// Factory          DIP (abstract object creation)
// Observer         SRP (each observer has one job)
// Template Method  OCP (extend by overriding methods)
// Singleton        SRP (single instance of one thing)`}]},{id:"q10",question:"How do you test code that follows SOLID principles?",answer:"Code following SOLID principles is naturally testable. Use dependency injection to inject mocks/fakes. Single Responsibility makes unit tests focused. Closed Principle with abstractions allows easy mocking. Interface Segregation enables testing specific behaviors. Dependency Inversion allows test doubles.",codeSnippets:[{language:"csharp",code:`using Xunit;
using Moq;

// Testing code that follows SOLID principles is easy

public interface IEmailService
{
    void SendEmail(string to, string subject, string body);
}

public interface IUserRepository
{
    void Save(User user);
    User GetById(int id);
}

// Service that depends on abstractions (DIP)
public class UserRegistrationService
{
    private readonly IUserRepository userRepository;
    private readonly IEmailService emailService;
    
    public UserRegistrationService(
        IUserRepository userRepository,
        IEmailService emailService)
    {
        this.userRepository = userRepository;
        this.emailService = emailService;
    }
    
    public void RegisterUser(User user)
    {
        userRepository.Save(user);
        emailService.SendEmail(user.Email, "Welcome", "Welcome to our app");
    }
}

// Easy to test - can mock dependencies
public class UserRegistrationServiceTests
{
    [Fact]
    public void RegisterUser_SavesUserToRepository()
    {
        // Arrange
        var mockRepository = new Mock<IUserRepository>();
        var mockEmailService = new Mock<IEmailService>();
        
        var service = new UserRegistrationService(
            mockRepository.Object,
            mockEmailService.Object);
        
        var user = new User { Email = "test@example.com", Name = "Test" };
        
        // Act
        service.RegisterUser(user);
        
        // Assert
        // Verify that Save was called with the correct user
        mockRepository.Verify(r => r.Save(It.Is<User>(u => u.Email == "test@example.com")), Times.Once);
    }
    
    [Fact]
    public void RegisterUser_SendsWelcomeEmail()
    {
        // Arrange
        var mockRepository = new Mock<IUserRepository>();
        var mockEmailService = new Mock<IEmailService>();
        
        var service = new UserRegistrationService(
            mockRepository.Object,
            mockEmailService.Object);
        
        var user = new User { Email = "test@example.com", Name = "Test" };
        
        // Act
        service.RegisterUser(user);
        
        // Assert
        // Verify email was sent
        mockEmailService.Verify(
            e => e.SendEmail(
                It.IsAny<string>(),
                It.IsAny<string>(),
                It.IsAny<string>()),
            Times.Once);
    }
    
    [Fact]
    public void RegisterUser_RepositoryFailure_DoesNotSendEmail()
    {
        // Arrange
        var mockRepository = new Mock<IUserRepository>();
        mockRepository.Setup(r => r.Save(It.IsAny<User>()))
            .Throws(new Exception("DB Error"));
        
        var mockEmailService = new Mock<IEmailService>();
        
        var service = new UserRegistrationService(
            mockRepository.Object,
            mockEmailService.Object);
        
        var user = new User { Email = "test@example.com" };
        
        // Act & Assert
        Assert.Throws<Exception>(() => service.RegisterUser(user));
        
        // Email should not be sent if save fails
        mockEmailService.Verify(e => e.SendEmail(It.IsAny<string>(), It.IsAny<string>(), It.IsAny<string>()), Times.Never);
    }
}

// Testing with fake implementations (alternative to mocks)
public class FakeEmailService : IEmailService
{
    public List<string> SentEmails { get; } = new();
    
    public void SendEmail(string to, string subject, string body)
    {
        SentEmails.Add(to);
    }
}

public class FakeUserRepository : IUserRepository
{
    public List<User> SavedUsers { get; } = new();
    
    public void Save(User user)
    {
        SavedUsers.Add(user);
    }
    
    public User GetById(int id)
    {
        return SavedUsers.FirstOrDefault(u => u.Id == id);
    }
}

public class UserRegistrationServiceFakeTests
{
    [Fact]
    public void RegisterUser_WithFakes()
    {
        // Arrange
        var repository = new FakeUserRepository();
        var emailService = new FakeEmailService();
        
        var service = new UserRegistrationService(repository, emailService);
        var user = new User { Email = "test@example.com", Name = "Test" };
        
        // Act
        service.RegisterUser(user);
        
        // Assert
        Assert.Single(repository.SavedUsers);
        Assert.Single(emailService.SentEmails);
        Assert.Equal("test@example.com", emailService.SentEmails[0]);
    }
}

// Benefits of SOLID for Testing:
// 1. Dependency Injection - inject test doubles
// 2. Small Interfaces - test specific behaviors
// 3. Single Responsibility - focused unit tests
// 4. Open/Closed - extend behavior without changing tests
// 5. Liskov Substitution - substitutes work in tests
// 6. Abstraction - can create mocks and fakes

// Anti-pattern - Hard to test without SOLID
public class BadUserRegistrationService
{
    private MySqlDatabase database = new MySqlDatabase(); // Tight coupling
    private SmtpEmailSender emailService = new SmtpEmailSender(); // Tight coupling
    
    public void RegisterUser(User user)
    {
        database.Save(user); // Can't mock
        emailService.SendEmail(user.Email, "Welcome", "Welcome"); // Can't mock
    }
}

// This requires actual database and email service to test!
// No way to inject mocks`}]}]},Gy={id:"csharp-multi-threading",name:"Multi-threading",questions:[{id:"q1",question:"What is multi-threading and why is it important in C#?",answer:"Multi-threading allows multiple threads to execute within a single process, enabling concurrent execution of code. It's important for improving application responsiveness, better resource utilization, and handling multiple operations simultaneously.",codeSnippets:[{language:"csharp",code:`// Creating and starting threads
Thread thread1 = new Thread(() => Console.WriteLine("Thread 1"));
Thread thread2 = new Thread(() => Console.WriteLine("Thread 2"));

thread1.Start();
thread2.Start();

thread1.Join(); // Wait for thread1 to complete
thread2.Join(); // Wait for thread2 to complete`}]},{id:"q2",question:"What is the difference between Thread and Task in C#?",answer:"Thread is a low-level abstraction representing an OS thread. Task is a higher-level abstraction built on the ThreadPool that represents asynchronous work. Tasks are more efficient, support better composition, and are preferred in modern C#.",codeSnippets:[{language:"csharp",code:`// Using Thread
Thread thread = new Thread(() => Console.WriteLine("Thread"));
thread.Start();

// Using Task
Task task = Task.Run(() => Console.WriteLine("Task"));
task.Wait();

// Using async/await (recommended)
await Task.Run(() => Console.WriteLine("Async Task"));`}]},{id:"q3",question:"What is a lock and how do you use it for synchronization?",answer:"A lock is a synchronization primitive that ensures only one thread can access a critical section of code at a time. It prevents race conditions when multiple threads access shared resources. Use 'lock' keyword with an object.",codeSnippets:[{language:"csharp",code:`private int counter = 0;
private object lockObject = new object();

public void Increment()
{
    lock (lockObject)
    {
        // Only one thread can execute this at a time
        int temp = counter;
        temp++;
        counter = temp;
    }
}

// Thread-safe alternative using Interlocked
public void IncrementAtomic()
{
    Interlocked.Increment(ref counter);
}`}]},{id:"q4",question:"What are mutexes and semaphores? How do they differ?",answer:"Mutex is a mutual exclusion lock that allows only one thread to access a resource. Semaphore is a signaling mechanism that allows a specified number of threads to access a resource. Semaphore with count=1 is similar to a mutex.",codeSnippets:[{language:"csharp",code:`// Using Mutex
Mutex mutex = new Mutex();

mutex.WaitOne(); // Acquire lock
try
{
    // Critical section
}
finally
{
    mutex.ReleaseMutex(); // Release lock
}

// Using Semaphore (allows N threads)
Semaphore semaphore = new Semaphore(3, 3); // Allow 3 threads

semaphore.WaitOne(); // Acquire one slot
try
{
    // Critical section
}
finally
{
    semaphore.Release(); // Release one slot
}`}]},{id:"q5",question:"What is a ReaderWriterLock and when would you use it?",answer:"ReaderWriterLock allows multiple threads to read simultaneously, but only one thread to write. It's useful when reads are frequent and writes are rare, providing better concurrency than a regular lock.",codeSnippets:[{language:"csharp",code:`private ReaderWriterLockSlim rwLock = new ReaderWriterLockSlim();
private string data = "";

public string ReadData()
{
    rwLock.EnterReadLock();
    try
    {
        return data;
    }
    finally
    {
        rwLock.ExitReadLock();
    }
}

public void WriteData(string value)
{
    rwLock.EnterWriteLock();
    try
    {
        data = value;
    }
    finally
    {
        rwLock.ExitWriteLock();
    }
}`}]},{id:"q6",question:"What is the ThreadPool and how does it improve performance?",answer:"ThreadPool is a collection of threads maintained by the system. It reduces overhead by reusing threads instead of creating new ones for each task. Tasks are queued and executed on available threads, improving performance.",codeSnippets:[{language:"csharp",code:`// Queue work to ThreadPool
ThreadPool.QueueUserWorkItem(state =>
{
    Console.WriteLine("Executing on ThreadPool");
    Thread.Sleep(1000);
});

// Using WaitHandle to wait for completion
ManualResetEvent resetEvent = new ManualResetEvent(false);

ThreadPool.QueueUserWorkItem(state =>
{
    Console.WriteLine("Work completed");
    resetEvent.Set();
});

resetEvent.WaitOne(); // Wait for signal`}]},{id:"q7",question:"What is a race condition and how do you prevent it?",answer:"A race condition occurs when multiple threads access shared data concurrently, leading to unpredictable results. Prevent it using synchronization techniques: locks, mutexes, semaphores, or thread-safe collections.",codeSnippets:[{language:"csharp",code:`// BAD - Race condition
private int unsafeCounter = 0;

public void UnsafeIncrement()
{
    unsafeCounter++; // Not atomic
}

// GOOD - Thread-safe
private int safeCounter = 0;
private object lockObj = new object();

public void SafeIncrement()
{
    lock (lockObj)
    {
        safeCounter++;
    }
}

// GOOD - Using Interlocked
public void AtomicIncrement()
{
    Interlocked.Increment(ref unsafeCounter);
}`}]},{id:"q8",question:"What is a deadlock and how can you avoid it?",answer:"A deadlock occurs when two or more threads are blocked waiting for each other to release resources. Avoid it by: acquiring locks in the same order, using timeouts, minimizing lock scope, or using lock-free structures.",codeSnippets:[{language:"csharp",code:`// BAD - Potential Deadlock
object lock1 = new object();
object lock2 = new object();

Thread t1 = new Thread(() =>
{
    lock (lock1) { lock (lock2) { /* work */ } }
});

Thread t2 = new Thread(() =>
{
    lock (lock2) { lock (lock1) { /* work */ } } // Different order!
});

// GOOD - Avoid deadlock with consistent lock ordering
Thread t3 = new Thread(() =>
{
    lock (lock1) { lock (lock2) { /* work */ } }
});

Thread t4 = new Thread(() =>
{
    lock (lock1) { lock (lock2) { /* work */ } } // Same order
});

// GOOD - Using timeout
if (Monitor.TryEnter(lock1, TimeSpan.FromSeconds(1)))
{
    try { /* critical section */ }
    finally { Monitor.Exit(lock1); }
}`}]},{id:"q9",question:"What is async/await and how does it relate to multi-threading?",answer:"async/await is syntactic sugar for Task-based asynchronous programming. It doesn't require a new thread - the same thread can switch between tasks. It's more efficient for I/O-bound operations than creating new threads.",codeSnippets:[{language:"csharp",code:`// Async/await pattern
public async Task<string> FetchDataAsync()
{
    // This doesn't block the thread while waiting
    HttpClient client = new HttpClient();
    string result = await client.GetStringAsync("https://api.example.com/data");
    return result;
}

// Called asynchronously
await FetchDataAsync();

// Contrast with blocking
public string FetchDataSync()
{
    HttpClient client = new HttpClient();
    // This blocks the thread while waiting
    string result = client.GetStringAsync("https://api.example.com/data").Result;
    return result;
}`}]},{id:"q10",question:"What are thread-safe collections in C#?",answer:"Thread-safe collections from System.Collections.Concurrent allow multiple threads to access them without explicit locking. Examples: ConcurrentBag, ConcurrentQueue, ConcurrentDictionary, ConcurrentStack.",codeSnippets:[{language:"csharp",code:`using System.Collections.Concurrent;

// Thread-safe queue
ConcurrentQueue<int> queue = new ConcurrentQueue<int>();
queue.Enqueue(1);
queue.Enqueue(2);
queue.TryDequeue(out int value);

// Thread-safe dictionary
ConcurrentDictionary<string, int> dict = new ConcurrentDictionary<string, int>();
dict.TryAdd("key", 10);
dict.AddOrUpdate("key", 20, (k, v) => v + 20);

// Thread-safe bag
ConcurrentBag<string> bag = new ConcurrentBag<string>();
bag.Add("item1");
bag.TryTake(out string item);`}]}]},Hy={id:"csharp-async-programming",name:"Asynchronous Programming",questions:[{id:"q1",question:"What is asynchronous programming and why is it important in C#?",answer:"Asynchronous programming allows operations to run without blocking the calling thread. It's important for improving application responsiveness, especially for I/O operations like database queries, API calls, and file access. It enables better resource utilization by allowing the thread to work on other tasks while waiting.",codeSnippets:[{language:"csharp",code:`// Synchronous - blocks thread
public string FetchDataSync()
{
    System.Threading.Thread.Sleep(2000); // Simulates I/O operation
    return "Data";
}

// Asynchronous - doesn't block thread
public async Task<string> FetchDataAsync()
{
    await Task.Delay(2000); // Simulates I/O operation
    return "Data";
}

// Usage
string result = FetchDataSync(); // Thread is blocked for 2 seconds

var result = await FetchDataAsync(); // Thread is free to do other work`}]},{id:"q2",question:"What is the difference between Task and async/await?",answer:"Task is the underlying abstraction representing asynchronous work. async/await is syntactic sugar that makes working with Tasks easier and more readable. async methods return Task or Task<T>, and await unwraps the result.",codeSnippets:[{language:"csharp",code:`// Using Task directly
public Task<string> GetDataTask()
{
    return Task.Run(async () => 
    {
        await Task.Delay(1000);
        return "Data";
    });
}

// Using async/await (more readable)
public async Task<string> GetDataAsync()
{
    await Task.Delay(1000);
    return "Data";
}

// Calling Task version
GetDataTask().ContinueWith(task => 
{
    Console.WriteLine(task.Result);
});

// Calling async version (cleaner)
var data = await GetDataAsync();
Console.WriteLine(data);`}]},{id:"q3",question:"What is async/await and how does it work?",answer:"async/await is syntactic sugar for working with Tasks. The 'async' keyword enables the 'await' operator and returns a Task. 'await' suspends execution until the awaited Task completes, allowing other code to run.",codeSnippets:[{language:"csharp",code:`// Async method signature
public async Task<string> FetchDataAsync()
{
    // Method must be async to use await
    var response = await HttpClient.GetAsync("https://api.example.com/data");
    var content = await response.Content.ReadAsStringAsync();
    return content;
}

// Async void (not recommended except for event handlers)
public async void OnButtonClick()
{
    var data = await FetchDataAsync();
}

// Async Task (recommended)
public async Task OnButtonClickAsync()
{
    var data = await FetchDataAsync();
}

// Async Task<T> (with return value)
public async Task<int> CalculateAsync()
{
    await Task.Delay(1000);
    return 42;
}

// Usage
int result = await CalculateAsync();`}]},{id:"q4",question:"What is the relationship between async/await and the thread pool?",answer:"async/await doesn't necessarily use new threads. When you await a Task, the current thread is freed and can handle other work. The Task may use a thread from the ThreadPool, but often I/O operations don't use threads at all.",codeSnippets:[{language:"csharp",code:`public async Task DemonstrateAsync()
{
    Console.WriteLine($"Thread {Thread.CurrentThread.ManagedThreadId} started");
    
    // This doesn't block the thread
    await Task.Delay(1000);
    
    // May run on different thread
    Console.WriteLine($"Thread {Thread.CurrentThread.ManagedThreadId} resumed");
}

// With CPU-bound work
public async Task CpuBoundAsync()
{
    // Run on ThreadPool to avoid blocking
    var result = await Task.Run(() => 
    {
        // Long CPU operation
        return ExpensiveCalculation();
    });
    
    return result;
}

// Key difference:
// I/O operations (HTTP, Database) use completion-based asynchrony
// CPU operations should use Task.Run to avoid blocking the UI thread`}]},{id:"q5",question:"What is the difference between Task.Run and Task.Delay?",answer:"Task.Run executes CPU-bound work on a thread pool thread. Task.Delay creates a Task that completes after a specified time without using a thread. Use Task.Run for CPU work, Task.Delay for timing/I/O operations.",codeSnippets:[{language:"csharp",code:`// Task.Delay - doesn't use a thread
public async Task DelayExample()
{
    await Task.Delay(2000); // Just waits, no thread
    Console.WriteLine("Waited 2 seconds");
}

// Task.Run - uses thread pool thread
public async Task RunExample()
{
    var result = await Task.Run(() =>
    {
        // CPU-intensive work on separate thread
        return ExpensiveCalculation();
    });
    return result;
}

// Real-world example
public async Task<Data> FetchAndProcessAsync(string url)
{
    // I/O operation - no thread needed
    var response = await httpClient.GetAsync(url);
    
    // CPU-intensive operation - use Task.Run
    var processed = await Task.Run(() => ProcessData(response));
    
    return processed;
}`}]},{id:"q6",question:"How do you handle exceptions in async/await?",answer:"Use try-catch blocks around await statements just like synchronous code. Exceptions are captured and re-thrown when the Task is awaited. Use Task.WhenAll to handle multiple exceptions.",codeSnippets:[{language:"csharp",code:`// Try-catch with async/await
public async Task<string> FetchDataAsync()
{
    try
    {
        var response = await httpClient.GetAsync("https://api.example.com/data");
        response.EnsureSuccessStatusCode();
        return await response.Content.ReadAsStringAsync();
    }
    catch (HttpRequestException ex)
    {
        Console.WriteLine($"HTTP error: {ex.Message}");
        throw; // Re-throw or handle
    }
    catch (Exception ex)
    {
        Console.WriteLine($"Error: {ex.Message}");
        throw;
    }
}

// Handle multiple async operations
public async Task<(Data1, Data2)> FetchMultipleAsync()
{
    try
    {
        var task1 = FetchData1Async();
        var task2 = FetchData2Async();
        
        await Task.WhenAll(task1, task2);
        
        return (task1.Result, task2.Result);
    }
    catch (Exception ex)
    {
        // Both exceptions might be in ex.InnerExceptions
        Console.WriteLine($"Error: {ex.Message}");
        throw;
    }
}`}]},{id:"q7",question:"What is deadlock in async/await and how do you prevent it?",answer:"Deadlock occurs when you block on an async operation using .Result or .Wait(). The thread is blocked waiting for the Task, but the Task needs the same context (like UI thread) to complete. Use await instead of .Result or .Wait().",codeSnippets:[{language:"csharp",code:`// DEADLOCK - Bad practice
public void BadMethod()
{
    // If FetchDataAsync needs the UI context, this deadlocks
    var data = FetchDataAsync().Result; // BLOCKS!
}

// Also deadlock risk
public void AnotherBadMethod()
{
    var task = FetchDataAsync();
    task.Wait(); // Blocks thread
    var data = task.Result;
}

// GOOD - Use async all the way
public async Task GoodMethodAsync()
{
    var data = await FetchDataAsync();
    return data;
}

// If you must call async from sync context (rare):
public string SafeMethod()
{
    var task = FetchDataAsync();
    // Don't use Result/Wait - marshal to another thread
    return task.GetAwaiter().GetResult();
}

// Best practice: Make the caller async
public async Task CallerAsync()
{
    var data = await FetchDataAsync();
}`}]},{id:"q8",question:"What is ConfigureAwait and why is it important?",answer:"ConfigureAwait(false) tells the await to not capture the current SynchronizationContext. This improves performance in library code and helps avoid deadlocks in async over sync scenarios. Use it in library code unless you need the original context.",codeSnippets:[{language:"csharp",code:`// Without ConfigureAwait - captures UI context
public async Task<string> FetchWithContextAsync()
{
    var response = await httpClient.GetAsync(url);
    // Resumes on UI thread (slow if it's a library method)
    return await response.Content.ReadAsStringAsync();
}

// With ConfigureAwait - doesn't capture context
public async Task<string> FetchWithoutContextAsync()
{
    var response = await httpClient.GetAsync(url).ConfigureAwait(false);
    // Resumes on any thread (faster)
    return await response.Content.ReadAsStringAsync().ConfigureAwait(false);
}

// Best practice in libraries
public async Task<Data> GetDataAsync()
{
    using var httpClient = new HttpClient();
    
    var response = await httpClient
        .GetAsync("https://api.example.com/data")
        .ConfigureAwait(false);
    
    var content = await response.Content
        .ReadAsStringAsync()
        .ConfigureAwait(false);
    
    return JsonConvert.DeserializeObject<Data>(content);
}

// ConfigureAwait(true) - important to preserve context
public async Task UpdateUIAsync()
{
    var data = await FetchDataAsync().ConfigureAwait(true);
    // Must resume on UI thread to update controls
    myLabel.Text = data;
}`}]},{id:"q9",question:"How do you run multiple async operations concurrently?",answer:"Use Task.WhenAll to wait for multiple Tasks concurrently, or Task.WhenAny to wait for the first one. Start all tasks first, then await together to run concurrently.",codeSnippets:[{language:"csharp",code:`// Sequential - slow
public async Task<(Data1, Data2, Data3)> FetchSequentialAsync()
{
    var data1 = await FetchData1Async();
    var data2 = await FetchData2Async();
    var data3 = await FetchData3Async();
    return (data1, data2, data3);
}

// Concurrent - fast
public async Task<(Data1, Data2, Data3)> FetchConcurrentAsync()
{
    var task1 = FetchData1Async();
    var task2 = FetchData2Async();
    var task3 = FetchData3Async();
    
    await Task.WhenAll(task1, task2, task3);
    
    return (task1.Result, task2.Result, task3.Result);
}

// Task.WhenAny - return first completed
public async Task<Data> FetchFirstAsync()
{
    var task1 = FetchFromServerAsync("server1");
    var task2 = FetchFromServerAsync("server2");
    var task3 = FetchFromServerAsync("server3");
    
    var completedTask = await Task.WhenAny(task1, task2, task3);
    
    return ((Task<Data>)completedTask).Result;
}

// Handle exceptions with WhenAll
public async Task<List<Data>> FetchMultipleAsync(IEnumerable<string> urls)
{
    var tasks = urls.Select(url => FetchAsync(url)).ToList();
    
    try
    {
        var results = await Task.WhenAll(tasks);
        return results.ToList();
    }
    catch (Exception ex)
    {
        // May contain multiple exceptions in InnerExceptions
        throw;
    }
}`}]},{id:"q10",question:"What is async void and when should you use it?",answer:"async void methods have no way to signal completion or report exceptions. They should only be used for event handlers where the caller doesn't need to wait. Use async Task or async Task<T> for all other scenarios.",codeSnippets:[{language:"csharp",code:`// AVOID - async void (except for event handlers)
public async void BadAsyncMethod()
{
    // No way to wait for completion
    // Exceptions will crash the app
    await FetchDataAsync();
}

// GOOD - async Task
public async Task GoodAsyncMethod()
{
    var data = await FetchDataAsync();
    return data;
}

// ACCEPTABLE - async void for event handlers only
public async void OnButtonClick(object sender, EventArgs e)
{
    try
    {
        var data = await FetchDataAsync();
        UpdateUI(data);
    }
    catch (Exception ex)
    {
        MessageBox.Show($"Error: {ex.Message}");
    }
}

// BETTER - Event handler that returns Task
public class MyControl : Control
{
    private async void button_Click(object sender, EventArgs e)
    {
        await HandleClickAsync();
    }
    
    public async Task HandleClickAsync()
    {
        var data = await FetchDataAsync();
        UpdateUI(data);
    }
}

// Rule of thumb
// async void: Only for top-level event handlers
// async Task: For all other methods
// async Task<T>: When you need to return a value`}]}]},jy={id:"csharp-linq",name:"LINQ (Language Integrated Query)",questions:[{id:"q1",question:"What is LINQ and why is it important in C#?",answer:"LINQ (Language Integrated Query) provides a uniform way to query different data sources using C# syntax. It works with objects (LINQ to Objects), databases (LINQ to SQL/Entity Framework), XML (LINQ to XML), and more. It's important because it provides type-safe, readable queries with compile-time checking and IntelliSense support.",codeSnippets:[{language:"csharp",code:`using System;
using System.Linq;
using System.Collections.Generic;

List<int> numbers = new() { 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 };

// LINQ query - filters even numbers
var evenNumbers = numbers.Where(n => n % 2 == 0).ToList();
// Result: [2, 4, 6, 8, 10]

// LINQ with objects
var employees = new List<Employee>
{
    new { Id = 1, Name = "Alice", Salary = 50000 },
    new { Id = 2, Name = "Bob", Salary = 60000 },
    new { Id = 3, Name = "Charlie", Salary = 55000 }
};

// Filter and select - type-safe and readable
var highEarners = employees
    .Where(e => e.Salary > 50000)
    .Select(e => e.Name)
    .ToList();
// Result: ["Bob", "Charlie"]`}]},{id:"q2",question:"What is the difference between query syntax and method syntax in LINQ?",answer:"Query syntax looks like SQL and is translated to method syntax at compile time. Method syntax uses extension methods like Where, Select. Both produce the same IL code. Use query syntax for complex queries, method syntax for simple ones.",codeSnippets:[{language:"csharp",code:`var numbers = new List<int> { 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 };

// Query Syntax (SQL-like)
var resultQuery = from n in numbers
                  where n > 5
                  select n * 2;

// Method Syntax (Lambda expressions)
var resultMethod = numbers
    .Where(n => n > 5)
    .Select(n => n * 2);

// Both produce same result: [12, 14, 16, 18, 20]

// Complex query - query syntax is cleaner
var complexQuery = from emp in employees
                   where emp.Salary > 50000
                   group emp by emp.Department into deptGroup
                   select new
                   {
                       Department = deptGroup.Key,
                       AvgSalary = deptGroup.Average(e => e.Salary)
                   };

// Same with method syntax (more verbose)
var complexMethod = employees
    .Where(emp => emp.Salary > 50000)
    .GroupBy(emp => emp.Department)
    .Select(deptGroup => new
    {
        Department = deptGroup.Key,
        AvgSalary = deptGroup.Average(e => e.Salary)
    });`}]},{id:"q3",question:"What is deferred execution in LINQ?",answer:"Deferred execution means the query doesn't run immediately when defined. It runs when you enumerate the results (call ToList, ForEach, etc.). This allows you to build queries dynamically and only execute when needed.",codeSnippets:[{language:"csharp",code:`var numbers = new List<int> { 1, 2, 3, 4, 5 };

// Deferred execution - query not executed yet
IEnumerable<int> query = numbers.Where(n => n > 2);

// Add more conditions - still not executed
query = query.Select(n => n * 2);

// Now execute - deferred execution happens here
var result = query.ToList();

// Practical example: Building dynamic queries
public List<Employee> GetEmployees(string department = null, decimal? minSalary = null)
{
    IQueryable<Employee> query = _dbContext.Employees;
    
    // Conditions added dynamically - not executed yet
    if (!string.IsNullOrEmpty(department))
        query = query.Where(e => e.Department == department);
    
    if (minSalary.HasValue)
        query = query.Where(e => e.Salary >= minSalary);
    
    // Query executes here when ToList is called
    return query.ToList();
}

// Problem with deferred execution
var list = numbers.Where(n => n > 2);
numbers.Add(6); // Modifying source after query definition

// Enumeration happens here - includes the newly added 6!
foreach(var n in list)
    Console.WriteLine(n); // 3, 4, 5, 6

// Solution: Use ToList to execute immediately
var list2 = numbers.Where(n => n > 2).ToList();
numbers.Add(7); // Adding now doesn't affect list2`}]},{id:"q4",question:"What are common LINQ methods and when to use each?",answer:"Common LINQ methods: Where (filter), Select (transform), FirstOrDefault/Single (get one item), OrderBy (sort), GroupBy (group), Join (combine), Aggregate (calculate), Skip/Take (pagination), Any/All (check conditions).",codeSnippets:[{language:"csharp",code:`var employees = new List<Employee>
{
    new { Id = 1, Name = "Alice", Salary = 50000, Dept = "IT" },
    new { Id = 2, Name = "Bob", Salary = 60000, Dept = "HR" },
    new { Id = 3, Name = "Charlie", Salary = 55000, Dept = "IT" },
    new { Id = 4, Name = "David", Salary = 52000, Dept = "HR" }
};

// WHERE - Filter
var highSalaries = employees.Where(e => e.Salary > 50000);

// SELECT - Transform
var names = employees.Select(e => e.Name);

// FIRST/FIRSTORDEFAULT - Get single item
var first = employees.First();
var firstIT = employees.FirstOrDefault(e => e.Dept == "IT");
var notFound = employees.FirstOrDefault(e => e.Dept == "Finance"); // null

// SINGLE/SINGLEORDEFAULT - Exactly one item
var admin = employees.SingleOrDefault(e => e.Id == 1);

// ORDERBY - Sort
var sortedByName = employees.OrderBy(e => e.Name);
var sortedBySalaryDesc = employees.OrderByDescending(e => e.Salary);
var multiSort = employees.OrderBy(e => e.Dept).ThenByDescending(e => e.Salary);

// GROUPBY - Group items
var byDept = employees.GroupBy(e => e.Dept);
foreach(var group in byDept)
{
    Console.WriteLine($"{group.Key}: {group.Count()} employees");
}

// JOIN - Combine collections
var departments = new List<Department>
{
    new { Id = 1, Name = "IT" },
    new { Id = 2, Name = "HR" }
};

var joined = employees.Join(departments,
    e => e.DeptId,
    d => d.Id,
    (e, d) => new { e.Name, Department = d.Name });

// SKIP/TAKE - Pagination
var page2 = employees.OrderBy(e => e.Id).Skip(2).Take(2);

// ANY/ALL - Check conditions
bool hasHighSalary = employees.Any(e => e.Salary > 60000);
bool allAbove40k = employees.All(e => e.Salary >= 40000);

// AGGREGATE - Calculate
decimal totalSalary = employees.Sum(e => e.Salary);
double avgSalary = employees.Average(e => e.Salary);
int count = employees.Count();
var maxSalary = employees.Max(e => e.Salary);`}]},{id:"q5",question:"What is the difference between LINQ to Objects and LINQ to SQL?",answer:"LINQ to Objects queries in-memory collections using delegates. LINQ to SQL/Entity Framework queries databases and translates C# to SQL. LINQ to Objects executes in-memory, LINQ to SQL on the server. Use LINQ to Objects for collections, LINQ to SQL for databases.",codeSnippets:[{language:"csharp",code:`// LINQ to Objects - In-memory collection
var employees = new List<Employee>
{
    new { Name = "Alice", Salary = 50000 },
    new { Name = "Bob", Salary = 60000 }
};

// Executes in-memory with delegates
var result = employees
    .Where(e => e.Salary > 50000)
    .ToList(); // Filters all data in memory

// LINQ to SQL / Entity Framework - Database
public class EmployeeContext : DbContext
{
    public DbSet<Employee> Employees { get; set; }
}

using (var context = new EmployeeContext())
{
    // Executes on SQL Server - only matching rows returned
    var result = context.Employees
        .Where(e => e.Salary > 50000)
        .ToList(); // Translates to SQL: WHERE Salary > 50000
}

// Key difference in performance
var numbers = Enumerable.Range(1, 1000000).ToList();

// LINQ to Objects - loads all million numbers, filters in memory
var slowQuery = numbers.Where(n => n > 500000).ToList();

// LINQ to SQL - only fetches matching rows from database
using (var context = new DbContext())
{
    var fastQuery = context.Numbers
        .Where(n => n > 500000)
        .ToList();
}

// Important: Only simple operations work in LINQ to SQL
var employees = new List<Employee> { ... };

// Works in LINQ to Objects
var complex = employees
    .Where(e => e.Salary > 50000)
    .Select(e => new { e.Name, Length = e.Name.Length }) // String.Length works
    .ToList();

// May not work with LINQ to SQL - depends on database provider
var dbComplex = context.Employees
    .Where(e => e.Salary > 50000)
    .Select(e => new { e.Name, Length = e.Name.Length }) // Might fail
    .ToList();`}]},{id:"q6",question:"How do you perform a GroupBy operation in LINQ?",answer:"GroupBy groups elements by a key and returns IEnumerable<IGrouping<TKey, TElement>>. Each group can be aggregated. Use for creating summaries, calculations by category, etc.",codeSnippets:[{language:"csharp",code:`var sales = new List<Sale>
{
    new { Product = "Laptop", Quantity = 2, Price = 1000 },
    new { Product = "Mouse", Quantity = 5, Price = 20 },
    new { Product = "Laptop", Quantity = 1, Price = 1000 },
    new { Product = "Keyboard", Quantity = 3, Price = 50 }
};

// Simple GroupBy
var byProduct = sales.GroupBy(s => s.Product);

foreach(var group in byProduct)
{
    Console.WriteLine($"{group.Key}:");
    foreach(var item in group)
        Console.WriteLine($"  Qty: {item.Quantity}, Price: {item.Price}");
}

// GroupBy with aggregation
var productSummary = sales
    .GroupBy(s => s.Product)
    .Select(g => new
    {
        Product = g.Key,
        TotalQuantity = g.Sum(s => s.Quantity),
        TotalRevenue = g.Sum(s => s.Quantity * s.Price),
        Count = g.Count()
    })
    .ToList();

foreach(var summary in productSummary)
{
    Console.WriteLine(\`\${summary.Product}: \${summary.TotalQuantity} units, \${summary.TotalRevenue}\`);
}

// GroupBy multiple keys
var employeeSales = new List<Sale>
{
    new { Employee = "Alice", Product = "A", Amount = 100 },
    new { Employee = "Bob", Product = "A", Amount = 150 },
    new { Employee = "Alice", Product = "B", Amount = 200 }
};

var byEmployeeAndProduct = employeeSales
    .GroupBy(s => new { s.Employee, s.Product })
    .Select(g => new
    {
        Employee = g.Key.Employee,
        Product = g.Key.Product,
        Total = g.Sum(s => s.Amount)
    });

// GroupBy with where clause
var topProducts = sales
    .GroupBy(s => s.Product)
    .Where(g => g.Sum(s => s.Quantity) > 2)
    .Select(g => new
    {
        Product = g.Key,
        Quantity = g.Sum(s => s.Quantity)
    });`}]},{id:"q7",question:"How do you perform a Join operation in LINQ?",answer:"Use Join to combine two collections based on a key. Supports inner join, left join (with DefaultIfEmpty), and right join. Alternative: use query syntax with 'join' keyword.",codeSnippets:[{language:"csharp",code:`var employees = new List<Employee>
{
    new { Id = 1, Name = "Alice", DeptId = 1 },
    new { Id = 2, Name = "Bob", DeptId = 2 },
    new { Id = 3, Name = "Charlie", DeptId = 1 }
};

var departments = new List<Department>
{
    new { Id = 1, Name = "IT" },
    new { Id = 2, Name = "HR" }
};

// Inner Join - Method syntax
var innerJoin = employees.Join(departments,
    e => e.DeptId,          // outer key
    d => d.Id,              // inner key
    (e, d) => new           // result selector
    {
        e.Name,
        Department = d.Name
    });

// Inner Join - Query syntax (cleaner)
var innerJoinQuery = from emp in employees
                     join dept in departments on emp.DeptId equals dept.Id
                     select new { emp.Name, Department = dept.Name };

// Left Join - Include employees without matching department
var leftJoin = employees.GroupJoin(departments,
    e => e.DeptId,
    d => d.Id,
    (e, depts) => new
    {
        e.Name,
        Department = depts.FirstOrDefault()?.Name ?? "No Department"
    });

// Left Join - Query syntax with DefaultIfEmpty
var leftJoinQuery = from emp in employees
                    join dept in departments on emp.DeptId equals dept.Id into deptGroup
                    from d in deptGroup.DefaultIfEmpty()
                    select new
                    {
                        emp.Name,
                        Department = d?.Name ?? "No Department"
                    };

// Multiple joins
var orders = new List<Order>
{
    new { Id = 1, EmployeeId = 1, Amount = 100 },
    new { Id = 2, EmployeeId = 2, Amount = 200 }
};

var multiJoin = from order in orders
                join emp in employees on order.EmployeeId equals emp.Id
                join dept in departments on emp.DeptId equals dept.Id
                select new
                {
                    order.Id,
                    emp.Name,
                    dept.Name,
                    order.Amount
                };`}]},{id:"q8",question:"What are Select and SelectMany? What's the difference?",answer:"Select projects each element to a new form. SelectMany flattens nested collections. Use Select for one-to-one mapping, SelectMany for one-to-many mapping (like SQL CROSS APPLY).",codeSnippets:[{language:"csharp",code:`var students = new List<Student>
{
    new { Name = "Alice", Subjects = new[] { "Math", "English" } },
    new { Name = "Bob", Subjects = new[] { "Math", "Science" } }
};

// SELECT - projects each element (one-to-one)
var names = students.Select(s => s.Name);
// Result: ["Alice", "Bob"]

var enrollments = students.Select(s => new
{
    s.Name,
    SubjectCount = s.Subjects.Length
});
// Result: [{ Name: "Alice", SubjectCount: 2 }, ...]

// SELECTMANY - flattens collections (one-to-many)
var allSubjects = students.SelectMany(s => s.Subjects);
// Result: ["Math", "English", "Math", "Science"]

var studentSubjects = students.SelectMany(
    s => s.Subjects,
    (student, subject) => new
    {
        Student = student.Name,
        Subject = subject
    });
// Result: [
//   { Student: "Alice", Subject: "Math" },
//   { Student: "Alice", Subject: "English" },
//   { Student: "Bob", Subject: "Math" },
//   { Student: "Bob", Subject: "Science" }
// ]

// Query syntax alternative
var flatQuery = from student in students
                from subject in student.Subjects
                select new
                {
                    Student = student.Name,
                    Subject = subject
                };

// SelectMany with orders
var orders = new List<Order>
{
    new { CustomerId = 1, Items = new[] { "A", "B", "C" } },
    new { CustomerId = 2, Items = new[] { "D", "E" } }
};

var orderItems = orders.SelectMany(
    o => o.Items,
    (order, item) => new
    {
        order.CustomerId,
        Item = item
    });`}]},{id:"q9",question:"How do you handle null values and use DefaultIfEmpty in LINQ?",answer:"Use null-coalescing operator (??), null-conditional operator (?.), or DefaultIfEmpty to handle empty sequences. DefaultIfEmpty returns a default value when the sequence is empty, useful for outer joins.",codeSnippets:[{language:"csharp",code:`var employees = new List<Employee>
{
    new { Name = "Alice", ManagerId = null },
    new { Name = "Bob", ManagerId = 1 },
    new { Name = "Charlie", ManagerId = 1 }
};

var managers = new List<Manager>
{
    new { Id = 1, Name = "Alice" }
};

// Null-coalescing operator (??)
var managerNames = employees.Select(e =>
    e.ManagerId.HasValue ? e.ManagerId.ToString() : "No Manager");

// Null-conditional operator (?.)
var result = employees
    .Select(e => new
    {
        e.Name,
        ManagerName = e.Manager?.Name ?? "No Manager" // Safe navigation
    });

// DefaultIfEmpty - left outer join
var leftJoin = from emp in employees
               join mgr in managers on emp.ManagerId equals mgr.Id into managerGroup
               from m in managerGroup.DefaultIfEmpty()
               select new
               {
                   Employee = emp.Name,
                   Manager = m?.Name ?? "No Manager"
               };

// DefaultIfEmpty with custom default
var query = employees
    .Where(e => e.Salary > 100000)
    .DefaultIfEmpty(new Employee { Name = "No results" });

foreach(var emp in query)
    Console.WriteLine(emp.Name); // "No results" if no employees found

// Handling empty collections
var numbers = new List<int>();

// This throws IndexOutOfRangeException
// var first = numbers.First();

// This returns null/default
var safeFirst = numbers.FirstOrDefault();

var customDefault = numbers.FirstOrDefault(() => 0);

// Check before accessing
var hasData = numbers.Any();
if (hasData)
{
    var first = numbers.First();
}

// Safe with null coalescing
var first2 = numbers.FirstOrDefault() ?? 0;`}]},{id:"q10",question:"What is the difference between IEnumerable and IQueryable in LINQ?",answer:"IEnumerable uses delegates (LINQ to Objects) and executes in-memory. IQueryable uses expression trees and can be translated to other query languages (SQL, OData). Use IEnumerable for collections, IQueryable for databases.",codeSnippets:[{language:"csharp",code:`// IEnumerable - In-memory, uses delegates
IEnumerable<Employee> enumerable = employees;
var enumerableResult = enumerable
    .Where(e => e.Salary > 50000)  // Delegates - executes in C#
    .Select(e => e.Name);

// Loads all employees in memory, then filters
foreach(var item in enumerableResult)
    Console.WriteLine(item);

// IQueryable - Deferred, uses expression trees
IQueryable<Employee> queryable = context.Employees.AsQueryable();
var queryableResult = queryable
    .Where(e => e.Salary > 50000)  // Expression tree - translated to SQL
    .Select(e => e.Name);

// Sends SQL to database, returns only matching rows
foreach(var item in queryableResult)
    Console.WriteLine(item);

// Key difference - where clauses
var list = new List<Employee>
{
    new { Id = 1, Name = "Alice", Manager = new Manager { Name = "Bob" } },
    new { Id = 2, Name = "Bob", Manager = null }
};

// IEnumerable - works with any delegate
var ienumResult = list
    .AsEnumerable()
    .Where(e => e.Manager.Name == "Bob") // Works because delegates can use custom C# code
    .ToList();

// IQueryable - must be translatable to SQL
var iqueryResult = list
    .AsQueryable()
    .Where(e => e.Manager.Name == "Bob") // Might fail - can't translate navigation to SQL
    .ToList();

// Solution for IQueryable
var iqueryResult2 = list
    .AsQueryable()
    .Where(e => e.Manager != null && e.Manager.Name == "Bob")
    .ToList();

// Performance difference
// LINQ to Objects - loads all 1 million records
var slow = employees.AsEnumerable()
    .Where(e => e.Salary > 50000)
    .ToList();

// LINQ to SQL - only fetches matching records
var fast = context.Employees
    .Where(e => e.Salary > 50000)
    .ToList();`}]},{id:"q11",question:"How do you write complex LINQ queries with multiple conditions?",answer:"Combine Where, OrderBy, GroupBy, and Select clauses. For complex conditions, use multiple Where calls or build conditions dynamically. Query syntax is often cleaner for complex queries.",codeSnippets:[{language:"csharp",code:`var employees = new List<Employee>
{
    new { Id = 1, Name = "Alice", Dept = "IT", Salary = 70000, YearsExp = 5 },
    new { Id = 2, Name = "Bob", Dept = "HR", Salary = 60000, YearsExp = 3 },
    new { Id = 3, Name = "Charlie", Dept = "IT", Salary = 65000, YearsExp = 4 },
    new { Id = 4, Name = "David", Dept = "Finance", Salary = 75000, YearsExp = 6 }
};

// Complex query with query syntax
var complexQuery = from emp in employees
                   where emp.Salary > 60000 && emp.YearsExp >= 4
                   group emp by emp.Dept into deptGroup
                   where deptGroup.Count() > 1
                   select new
                   {
                       Department = deptGroup.Key,
                       Count = deptGroup.Count(),
                       AvgSalary = deptGroup.Average(e => e.Salary),
                       Employees = deptGroup.Select(e => e.Name).ToList()
                   };

// Same with method syntax (more verbose)
var methodQuery = employees
    .Where(emp => emp.Salary > 60000 && emp.YearsExp >= 4)
    .GroupBy(emp => emp.Dept)
    .Where(g => g.Count() > 1)
    .Select(deptGroup => new
    {
        Department = deptGroup.Key,
        Count = deptGroup.Count(),
        AvgSalary = deptGroup.Average(e => e.Salary),
        Employees = deptGroup.Select(e => e.Name).ToList()
    });

// Multiple Where conditions
var filtered = employees
    .Where(e => e.Salary > 60000)
    .Where(e => e.YearsExp >= 4)
    .Where(e => !string.IsNullOrEmpty(e.Name))
    .OrderByDescending(e => e.Salary)
    .ThenBy(e => e.Name);

// Dynamic query building
public IEnumerable<Employee> SearchEmployees(
    string department = null,
    decimal? minSalary = null,
    int? minExperience = null)
{
    var query = employees.AsEnumerable();
    
    if (!string.IsNullOrEmpty(department))
        query = query.Where(e => e.Dept == department);
    
    if (minSalary.HasValue)
        query = query.Where(e => e.Salary >= minSalary);
    
    if (minExperience.HasValue)
        query = query.Where(e => e.YearsExp >= minExperience);
    
    return query.OrderBy(e => e.Name);
}

// Complex aggregation
var report = employees
    .GroupBy(e => e.Dept)
    .Select(g => new
    {
        Department = g.Key,
        TotalEmployees = g.Count(),
        AvgSalary = g.Average(e => e.Salary),
        MaxSalary = g.Max(e => e.Salary),
        MinSalary = g.Min(e => e.Salary),
        HighEarners = g
            .Where(e => e.Salary > g.Average(x => x.Salary))
            .Select(e => e.Name)
            .ToList()
    })
    .OrderByDescending(r => r.AvgSalary);`}]},{id:"q12",question:"What are performance considerations when using LINQ?",answer:"Avoid N+1 queries with LINQ to SQL. Use Include() for eager loading. Materialize data at appropriate times with ToList(). Use IQueryable for databases, IEnumerable for collections. Filter on the server before bringing data to memory.",codeSnippets:[{language:"csharp",code:`// N+1 Problem - Bad
var employees = context.Employees.ToList(); // Query 1: Gets all employees
foreach(var emp in employees)
{
    var dept = context.Departments.FirstOrDefault(d => d.Id == emp.DeptId); // N queries
    Console.WriteLine($"{emp.Name} - {dept.Name}");
}
// Total queries: 1 + N

// Solution 1: Eager loading with Include
var empWithDepts = context.Employees
    .Include(e => e.Department) // Loads department in same query
    .ToList();

foreach(var emp in empWithDepts)
{
    Console.WriteLine($"{emp.Name} - {emp.Department.Name}");
}
// Total queries: 1

// Solution 2: Join
var joined = from emp in context.Employees
             join dept in context.Departments on emp.DeptId equals dept.Id
             select new { emp.Name, DeptName = dept.Name };

// Materializing at wrong time - Bad
var query = context.Employees
    .Where(e => e.Salary > 50000)
    .ToList() // Materializes all matching employees
    .Where(e => e.Name.StartsWith("A")) // Filters in-memory
    .ToList();

// Better - Filter on database
var better = context.Employees
    .Where(e => e.Salary > 50000 && e.Name.StartsWith("A"))
    .ToList(); // Materializes only filtered results

// Using IQueryable instead of IEnumerable
var slow = GetAllEmployees() // Returns IEnumerable
    .Where(e => e.Salary > 50000)
    .ToList();

var fast = context.Employees.AsQueryable() // IQueryable
    .Where(e => e.Salary > 50000)
    .ToList();

// Avoiding inefficient projections
var bad = context.Employees
    .Select(e => e) // Unnecessary
    .ToList();

var good = context.Employees
    .Select(e => new { e.Id, e.Name })
    .ToList();

// Use AsNoTracking for read-only queries
var tracked = context.Employees
    .Where(e => e.Salary > 50000)
    .ToList(); // Entity Framework tracks changes

var untracked = context.Employees
    .AsNoTracking()
    .Where(e => e.Salary > 50000)
    .ToList(); // Faster - no tracking overhead`}]}]},Fy={id:"csharp-garbage-collection",name:"Garbage Collection",questions:[{id:"q1",question:"What is garbage collection and why is it important?",answer:"Garbage collection is the automatic memory management process that frees memory occupied by objects no longer needed. It's important because it eliminates manual memory management, prevents memory leaks, and reduces the chance of bugs like accessing freed memory or double-freeing.",codeSnippets:[{language:"csharp",code:`// In languages without GC (like C++), you must manage memory manually
// void* ptr = malloc(sizeof(int));
// free(ptr);  // Easy to forget, leading to leaks

// In C#, the garbage collector handles this
public class MyClass
{
    private byte[] data = new byte[1000000]; // 1MB of data
}

// Memory allocated automatically
var obj = new MyClass();

// When 'obj' is no longer reachable, garbage collector
// automatically frees the memory
obj = null; // Object can now be collected
// GC will free the 1MB when it runs

// Benefits:
// 1. No manual memory management needed
// 2. No memory leaks from forgetting to free
// 3. No use-after-free bugs
// 4. No double-free bugs

// Drawback:
// - Unpredictable pause times when GC runs
// - Can't control exactly when memory is freed`}]},{id:"q2",question:"How does .NET garbage collection work?",answer:"The .NET garbage collector uses mark-and-sweep algorithm. It starts from roots (static variables, local variables, registers), marks all reachable objects, and sweaps (frees) unmarked objects. It uses generational collection for performance: most objects die young (Gen 0), rarely collected objects (Gen 2).",codeSnippets:[{language:"csharp",code:`// Garbage Collection Process:
// 1. Pause all threads
// 2. Mark phase: Start from roots, mark all reachable objects
// 3. Sweep phase: Free unmarked objects
// 4. Compact: Move objects together to reduce fragmentation
// 5. Resume threads

public class GCDemo
{
    public void Demonstrate()
    {
        // Local variable (root)
        var obj1 = new MyObject();
        
        // obj1 is reachable from local variable
        // - During GC.Mark: marked as reachable
        
        obj1 = null; // No longer reachable
        // - During next GC: sweep phase will collect this memory
        
        // Reference from another object
        var obj2 = new MyObject();
        var obj3 = new Container { Item = obj2 };
        
        // obj2 is reachable through obj3.Item
        // Even if obj2 local variable goes out of scope,
        // the object still exists because obj3 references it
        
        obj3 = null; // Now obj2 is also unreachable
        // Both will be collected in next GC
    }
}

// Roots are:
// - Local variables in methods
// - Static fields
// - CPU registers holding references
// - GC handles (pinned objects)

public static class RootsExample
{
    private static MyObject staticField; // Root
    
    public void Method()
    {
        var localVar = new MyObject(); // Root
        staticField = new MyObject();   // Root (through static field)
        
        var temp = new MyObject();
        temp = null; // This object becomes unreachable
        // Will be collected next GC cycle
    }
}`}]},{id:"q3",question:"What are generations in garbage collection? Explain Gen 0, Gen 1, and Gen 2.",answer:"Generations are a performance optimization. Gen 0 is for new objects, Gen 1 for survivors, Gen 2 for long-lived objects. Most objects die in Gen 0, reducing GC overhead. Gen 2 is collected less frequently since most collected objects are young.",codeSnippets:[{language:"csharp",code:`// Generational Hypothesis: Most objects die young
// This means frequent full scans are wasteful

// GC Collections:
// Gen 0: Most frequent (every few MB allocated)
// Gen 1: When Gen 0 fills up multiple times
// Gen 2: When Gen 1 fills up

public class GenerationDemo
{
    public void Demonstrate()
    {
        // Initially in Gen 0
        var young = new MyObject(); // Gen 0
        
        // After first GC, survivors move to Gen 1
        GC.Collect(0); // Force Gen 0 collection
        
        // Now if it survived, it's Gen 1
        // Next GC might collect it if it's unreachable
        
        // Objects that survive multiple GC cycles move to Gen 2
        var longLived = new MyObject();
        // Multiple GC cycles later...
        // longLived is in Gen 2 (very old object)
        
        // Benefits:
        // - Gen 0 is fast to scan (small)
        // - Gen 2 scanned infrequently
        // - Improves cache locality
    }
}

// Checking object generation
var obj = new MyObject();
int generation = GC.GetGeneration(obj); // 0 or 1 or 2

// Gen 0 -> Gen 1 -> Gen 2 progression
public void LifeCycleDemo()
{
    var obj = new byte[1024]; // Created in Gen 0
    Console.WriteLine(GC.GetGeneration(obj)); // Output: 0
    
    // Simulate some GCs
    GC.Collect(0);
    GC.WaitForPendingFinalizers();
    
    // Object survived Gen 0 collection
    Console.WriteLine(GC.GetGeneration(obj)); // Output: 1
    
    // More GCs...
    GC.Collect();
    
    // Object is now in Gen 2
    Console.WriteLine(GC.GetGeneration(obj)); // Output: 2
}`}]},{id:"q4",question:"What is IDisposable and what is the Dispose pattern?",answer:"IDisposable is an interface for releasing unmanaged resources (file handles, database connections, unmanaged memory). The Dispose pattern provides a safe way to clean up resources. Implement Dispose() to release resources, and optionally a finalizer for safety.",codeSnippets:[{language:"csharp",code:`// IDisposable interface
public interface IDisposable
{
    void Dispose();
}

// Basic Dispose Pattern
public class FileHandler : IDisposable
{
    private IntPtr fileHandle; // Unmanaged resource
    private bool disposed = false;
    
    public void ReadFile()
    {
        // Use the file handle
    }
    
    // Implement Dispose
    public void Dispose()
    {
        Dispose(true);
        GC.SuppressFinalize(this); // Prevent finalizer from running
    }
    
    // Protected dispose with bool parameter
    protected virtual void Dispose(bool disposing)
    {
        if (disposed)
            return;
        
        if (disposing)
        {
            // Free managed resources
        }
        
        // Free unmanaged resources
        if (fileHandle != IntPtr.Zero)
        {
            // Release the unmanaged resource
            fileHandle = IntPtr.Zero;
        }
        
        disposed = true;
    }
    
    // Finalizer - safety net
    ~FileHandler()
    {
        Dispose(false);
    }
}

// Using Disposable objects
using (var handler = new FileHandler())
{
    handler.ReadFile();
} // Dispose called automatically here

// Modern pattern (C# 8+) - using declaration
{
    using var handler = new FileHandler();
    handler.ReadFile();
} // Dispose called automatically when scope ends

// IAsyncDisposable for async cleanup
public class AsyncFileHandler : IAsyncDisposable
{
    public async ValueTask DisposeAsync()
    {
        await CloseHandleAsync();
    }
    
    private async Task CloseHandleAsync()
    {
        // Async cleanup
    }
}`}]},{id:"q5",question:"What is the difference between Dispose and Finalizer? When should you use each?",answer:"Dispose is called explicitly and should release unmanaged resources immediately. Finalizer (~ClassName) is called by the GC as a safety net but has unpredictable timing. Always implement Dispose for quick cleanup, use Finalizer only as a backup.",codeSnippets:[{language:"csharp",code:`// Finalizer (destructor) - Bad practice alone
public class BadResource
{
    private IntPtr handle;
    
    // Finalizer - called by GC, timing is unpredictable
    ~BadResource()
    {
        // This might run minutes or hours after object created!
        // Not reliable for immediate cleanup
        ReleaseHandle(handle);
    }
}

// Good practice - Dispose + Finalizer
public class GoodResource : IDisposable
{
    private IntPtr handle;
    private bool disposed = false;
    
    // Immediate cleanup when explicitly called
    public void Dispose()
    {
        if (disposed)
            return;
        
        ReleaseHandle(handle);
        disposed = true;
        
        // Tell GC: don't call finalizer, already cleaned up
        GC.SuppressFinalize(this);
    }
    
    // Safety net - cleanup if Dispose wasn't called
    ~GoodResource()
    {
        if (!disposed)
        {
            ReleaseHandle(handle);
        }
    }
    
    private void ReleaseHandle(IntPtr h)
    {
        if (h != IntPtr.Zero)
        {
            // Release resource
        }
    }
}

// Usage - guarantees cleanup
public void ProcessFile()
{
    var resource = new GoodResource();
    try
    {
        // Use resource
    }
    finally
    {
        resource?.Dispose(); // Guaranteed cleanup
    }
}

// Or with using (C# 8+)
public void ProcessFileModern()
{
    using var resource = new GoodResource();
    // Use resource
} // Dispose called automatically

// Costs of finalizers:
// 1. Objects with finalizers go to finalization queue
// 2. Finalizer thread processes them slowly
// 3. Keeps objects alive longer (Gen 2 candidate)
// 4. Performance impact

// Avoid this pattern:
public class BadPattern
{
    private string data; // Managed resource
    
    // DON'T finalize managed objects
    ~BadPattern()
    {
        data = null; // Unnecessary and bad practice
    }
}`}]},{id:"q6",question:"What is the 'using' statement and how does it work with IDisposable?",answer:"The 'using' statement ensures Dispose is called on IDisposable objects, even if an exception occurs. It's syntactic sugar for try-finally. Modern C# 8+ has 'using declaration' which disposes at the end of the scope.",codeSnippets:[{language:"csharp",code:`// Traditional using statement
using (var stream = new FileStream("file.txt", FileMode.Open))
{
    // Use stream
    stream.Read(...);
} // Dispose called automatically, even if exception

// Equivalent to:
FileStream stream = new FileStream("file.txt", FileMode.Open);
try
{
    // Use stream
    stream.Read(...);
}
finally
{
    // Guaranteed to call Dispose
    stream?.Dispose();
}

// Modern using declaration (C# 8+)
void ProcessFile()
{
    using var stream = new FileStream("file.txt", FileMode.Open);
    // Use stream
    stream.Read(...);
} // Dispose called automatically at end of scope

// Multiple resources
using (var stream = File.OpenRead("input.txt"))
using (var writer = new StreamWriter("output.txt"))
{
    // Use both
    var data = stream.ReadToEnd();
    writer.Write(data);
} // Both disposed automatically

// Modern syntax for multiple
void ProcessMultiple()
{
    using var stream = File.OpenRead("input.txt");
    using var writer = new StreamWriter("output.txt");
    
    var data = stream.ReadToEnd();
    writer.Write(data);
} // Both disposed at end of scope

// With exception handling
using var conn = new SqlConnection("connection");
try
{
    conn.Open();
    // Use connection
}
catch (Exception ex)
{
    // Handle error
}
finally
{
    // Using ensures Dispose called in finally
}

// IAsyncDisposable with using
async Task ProcessAsync()
{
    await using var conn = new SqlConnection("connection");
    await conn.OpenAsync();
    // Use connection
} // DisposeAsync called automatically`}]},{id:"q7",question:"How can memory leaks occur in managed code? Give examples.",answer:"Memory leaks in C# occur when objects are unintentionally kept alive through references. Common causes: static references, event handler subscriptions without unsubscribe, circular references in disposable objects, or not disposing unmanaged resources.",codeSnippets:[{language:"csharp",code:`// Memory Leak 1: Static References
public class Cache
{
    private static Dictionary<string, LargeObject> cache
        = new Dictionary<string, LargeObject>();
    
    public void Add(string key, LargeObject obj)
    {
        cache[key] = obj; // Objects never removed from static cache!
        // Memory leak - objects are never freed
    }
}

// Fix: Implement cache eviction
public class BetterCache
{
    private Dictionary<string, LargeObject> cache
        = new Dictionary<string, LargeObject>();
    private int maxSize = 100;
    
    public void Add(string key, LargeObject obj)
    {
        if (cache.Count >= maxSize)
            cache.Remove(cache.First().Key); // Evict old items
        
        cache[key] = obj;
    }
}

// Memory Leak 2: Event Handler Subscription
public class DataProvider : IDisposable
{
    public event EventHandler DataChanged;
}

public class Consumer
{
    private DataProvider provider;
    
    public Consumer(DataProvider provider)
    {
        this.provider = provider;
        // Subscribe to event
        provider.DataChanged += OnDataChanged;
    }
    
    private void OnDataChanged(object sender, EventArgs e)
    {
        // Handle data change
    }
    
    // Memory Leak: Provider kept alive because Consumer subscribed
    // Consumer kept alive because Provider has reference in event
    // Circular reference!
}

// Fix: Unsubscribe in Dispose
public class GoodConsumer : IDisposable
{
    private DataProvider provider;
    
    public GoodConsumer(DataProvider provider)
    {
        this.provider = provider;
        provider.DataChanged += OnDataChanged;
    }
    
    public void Dispose()
    {
        if (provider != null)
            provider.DataChanged -= OnDataChanged; // Unsubscribe
    }
    
    private void OnDataChanged(object sender, EventArgs e) { }
}

// Memory Leak 3: Not Disposing Resources
public void BadMethod()
{
    var stream = new FileStream("file.txt", FileMode.Open);
    var data = stream.ReadToEnd(); // Exception here?
    stream.Dispose(); // Never called if exception
    // File handle leaked!
}

// Fix: Use using
public void GoodMethod()
{
    using var stream = new FileStream("file.txt", FileMode.Open);
    var data = stream.ReadToEnd();
} // Dispose guaranteed even with exception

// Memory Leak 4: Circular References
public class Node
{
    public Node Parent { get; set; }
    public Node Child { get; set; }
}

public void CreateCircularReference()
{
    var parent = new Node();
    var child = new Node();
    
    parent.Child = child;
    child.Parent = parent; // Circular reference
    
    parent = null;
    child = null;
    // Both objects kept alive by circular reference!
    // GC can still collect (it detects cycles), but resources
    // held by these objects won't be freed until GC runs
}

// Prevention strategies:
// 1. Always use 'using' for IDisposable
// 2. Unsubscribe from events
// 3. Clear static collections periodically
// 4. Use weak references for caches
// 5. Implement IDisposable properly
// 6. Use dependency injection instead of static references`}]},{id:"q8",question:"What is GC.Collect? When should you call it and when should you avoid it?",answer:"GC.Collect() forces garbage collection to run immediately. It's generally not recommended because the GC is optimized to run automatically. Only use it in specific scenarios like demonstrating GC behavior or after loading massive data before entering critical sections.",codeSnippets:[{language:"csharp",code:`// GC.Collect() - Forces garbage collection
public class GCDemo
{
    public void BadPractice()
    {
        // BAD - Calling GC.Collect frequently
        for (int i = 0; i < 1000; i++)
        {
            var obj = new byte[1024 * 1024]; // 1MB
            GC.Collect(); // Forces collection every iteration!
            // Massive performance hit - GC is interrupted constantly
        }
    }
    
    public void AvoidThis()
    {
        // Calling GC.Collect after operation
        LoadMillionsOfObjects();
        GC.Collect(); // Let GC manage itself!
        // The GC will run automatically when needed
    }
}

// When it's ACCEPTABLE to call GC.Collect:
public class ProperGCUsage
{
    // Scenario 1: Before critical performance measurement
    public long MeasurePerformance(Action action)
    {
        GC.Collect();
        GC.WaitForPendingFinalizers();
        GC.Collect(); // Clear everything
        
        var sw = Stopwatch.StartNew();
        action();
        sw.Stop();
        
        return sw.ElapsedMilliseconds;
    }
    
    // Scenario 2: After loading data, before game starts
    public void InitializeGame()
    {
        LoadAllAssets(); // Massive allocation
        LoadAllModels();
        
        GC.Collect(); // Clean up temporary allocations
        // Now game starts without GC pauses
    }
    
    // Scenario 3: Demonstrate GC behavior
    public void DemonstrateGC()
    {
        var obj = new object();
        Console.WriteLine(GC.GetGeneration(obj)); // 0
        
        GC.Collect(); // Force collection
        
        Console.WriteLine(GC.GetGeneration(obj)); // 1 (survived)
    }
}

// GC.Collect options
public void CollectionOptions()
{
    GC.Collect(); // Full collection (all generations)
    
    GC.Collect(0); // Collect Gen 0 only
    
    GC.Collect(1); // Collect Gen 0 and Gen 1
    
    GC.Collect(2); // Full collection (Gen 0, 1, and 2)
    
    // Wait for finalizers to complete
    GC.WaitForPendingFinalizers();
    
    // Second collection clears objects finalized
    GC.Collect();
}

// Impact of GC.Collect
public void PerformanceImpact()
{
    var sw = Stopwatch.StartNew();
    for (int i = 0; i < 1_000_000; i++)
    {
        var obj = new object();
    }
    sw.Stop();
    Console.WriteLine(\`Without GC.Collect: \${sw.ElapsedMilliseconds}ms\`);
    
    // Reset timer
    sw.Restart();
    for (int i = 0; i < 1_000_000; i++)
    {
        var obj = new object();
        if (i % 1000 == 0)
            GC.Collect(); // Call GC.Collect every 1000 allocations
    }
    sw.Stop();
    Console.WriteLine(\`With GC.Collect: \${sw.ElapsedMilliseconds}ms\`);
    // Shows HUGE performance difference!
}

// Better approach: Let GC do its job
public void RecommendedApproach()
{
    // Trust the GC - it's optimized
    var list = new List<byte[]>();
    for (int i = 0; i < 1000; i++)
    {
        list.Add(new byte[1024 * 1024]);
    }
    // GC handles memory automatically
    // No manual GC.Collect() needed
}`}]},{id:"q9",question:"What are weak references and when would you use them?",answer:"Weak references point to objects without preventing garbage collection. The GC can collect weakly referenced objects. Use them for caches where you want objects freed if memory is needed, but can keep them if memory is available.",codeSnippets:[{language:"csharp",code:`// WeakReference - allows GC to collect referenced object
public class Cache<K, V>
{
    // Strong reference - keeps object alive
    private Dictionary<K, V> strongCache = new();
    
    // Weak reference - allows GC to collect
    private Dictionary<K, WeakReference<V>> weakCache = new();
    
    public void AddToWeakCache(K key, V value)
    {
        weakCache[key] = new WeakReference<V>(value);
    }
    
    public bool TryGetFromWeakCache(K key, out V value)
    {
        if (weakCache.TryGetValue(key, out var weakRef))
        {
            // Try to get the object
            if (weakRef.TryGetTarget(out var target))
            {
                value = target; // Object still alive
                return true;
            }
            
            // Object was garbage collected
            weakCache.Remove(key);
        }
        
        value = null;
        return false;
    }
}

// Practical example: Image cache
public class ImageCache
{
    private Dictionary<string, WeakReference<Bitmap>> cache
        = new();
    
    public Bitmap GetImage(string path)
    {
        if (cache.TryGetValue(path, out var weakRef))
        {
            if (weakRef.TryGetTarget(out var bitmap))
            {
                return bitmap; // Image still in memory
            }
        }
        
        // Image was garbage collected or not cached
        var newBitmap = LoadImage(path);
        cache[path] = new WeakReference<Bitmap>(newBitmap);
        return newBitmap;
    }
    
    private Bitmap LoadImage(string path)
    {
        return new Bitmap(path);
    }
}

// Strong vs Weak References
public class ReferenceComparison
{
    public void Demonstrate()
    {
        var obj = new byte[10 * 1024 * 1024]; // 10MB
        
        // Strong reference
        var strong = obj;
        
        // Weak reference
        var weak = new WeakReference<byte[]>(obj);
        
        // Check if weak ref is alive
        bool isAlive = weak.TryGetTarget(out var target);
        Console.WriteLine(\`Alive: \${isAlive}\`); // true
        
        // Remove strong reference
        obj = null;
        strong = null;
        
        // Now weak reference might be dead
        isAlive = weak.TryGetTarget(out target);
        Console.WriteLine(\`Alive after strong ref removed: \${isAlive}\`); // false
    }
}

// Use cases:
// 1. Object Pools - cache objects but don't prevent GC
// 2. Event Handler Caches - weak cache of subscribers
// 3. Large Object Caches - free if memory needed
// 4. View Model Caches - free when view is closed

public class EventCache
{
    private Dictionary<string, WeakReference<Action>> handlers
        = new();
    
    public void Register(string eventName, Action handler)
    {
        handlers[eventName] = new WeakReference<Action>(handler);
    }
    
    public void Invoke(string eventName)
    {
        if (handlers.TryGetValue(eventName, out var weak))
        {
            if (weak.TryGetTarget(out var handler))
            {
                handler();
            }
            else
            {
                // Handler was collected
                handlers.Remove(eventName);
            }
        }
    }
}`}]},{id:"q10",question:"What is the difference between reference types (classes) and value types (structs)? How does this relate to GC?",answer:"Reference types are allocated on the heap and managed by GC. Value types are allocated on the stack (in methods) or inline in objects and don't need GC. Stack allocation is faster, but reference types are more flexible.",codeSnippets:[{language:"csharp",code:`// Reference Type - allocated on heap, managed by GC
public class Person
{
    public string Name { get; set; }
    public int Age { get; set; }
}

// Value Type - allocated on stack or inline
public struct Point
{
    public int X { get; set; }
    public int Y { get; set; }
}

public class AllocationDemo
{
    public void Demonstrate()
    {
        // Reference type - allocated on HEAP
        var person = new Person { Name = "Alice", Age = 30 };
        // Stack: person (reference/pointer)
        // Heap: Person object, managed by GC
        
        // Value type - allocated on STACK
        var point = new Point { X = 10, Y = 20 };
        // Stack: X, Y values (embedded in stack frame)
        // When method ends, point is freed (no GC involved)
        
        // Value type inside reference type - allocated on HEAP
        var people = new List<Point>();
        people.Add(point);
        // Heap: List object, contains Point values
        // Point stored directly in List (not as separate object)
    }
}

// Performance difference
public class PerformanceComparison
{
    public class RefPoint
    {
        public int X, Y;
    }
    
    public struct ValuePoint
    {
        public int X, Y;
    }
    
    public void Benchmark()
    {
        const int count = 1_000_000;
        
        // Value type - stack allocation (fast!)
        var sw = Stopwatch.StartNew();
        for (int i = 0; i < count; i++)
        {
            var p = new ValuePoint { X = 1, Y = 2 };
        }
        sw.Stop();
        Console.WriteLine(\`ValuePoint: \${sw.ElapsedMilliseconds}ms\`); // ~1-5ms
        
        // Reference type - heap allocation with GC (slower)
        sw.Restart();
        for (int i = 0; i < count; i++)
        {
            var p = new RefPoint { X = 1, Y = 2 };
        }
        sw.Stop();
        Console.WriteLine(\`RefPoint: \${sw.ElapsedMilliseconds}ms\`); // ~50-200ms
        
        // Reference type is much slower due to:
        // 1. Heap allocation overhead
        // 2. GC overhead
        // 3. Indirection (following pointers)
    }
}

// Boxing - value type becomes reference type
public void BoxingDemo()
{
    // Value type
    int value = 42;
    
    // Boxing - creates heap object
    object boxed = value; // Value copied to heap
    
    // Unboxing - extract value
    int unboxed = (int)boxed; // Value copied back to stack
    
    // Performance cost of boxing/unboxing
    for (int i = 0; i < 1_000_000; i++)
    {
        object box = i; // Box: copy to heap
        int unbox = (int)box; // Unbox: copy to stack
    }
    // Much slower than working with pure value types
}

// Guidelines:
// Use Reference Types (classes) for:
// - Large objects
// - Long-lived objects
// - Objects with inheritance
// - When identity matters
// - Most domain objects

// Use Value Types (structs) for:
// - Small immutable values (Point, Color, Size)
// - Performance-critical code
// - Stack allocation scenario
// - Avoid boxing overhead
// - Keep structs small (<16 bytes)

public struct SmallValue
{
    public int X, Y; // 8 bytes - good
}

public struct BadValue
{
    public byte[] data; // Large reference - bad!
    public string name;
}

// Disposal with both types
public class ManagedResource : IDisposable
{
    private IntPtr handle;
    
    public void Dispose()
    {
        // Reference type - GC will call finalizer if not disposed
        // Value type can't implement finalizer
    }
}

public struct ValueWithNativeResource
{
    // CAN implement IDisposable but unusual
    private IntPtr handle;
    
    public void Dispose()
    {
        // Must be called explicitly - struct on stack won't auto-dispose!
    }
}`}]},{id:"q11",question:"What is the Stack and Heap? How do they relate to garbage collection?",answer:"Stack stores value types and references (pointers), allocated/freed automatically when scope ends. Heap stores objects (reference types), memory managed by GC. Stack is faster and doesn't need GC. Heap is flexible but requires GC.",codeSnippets:[{language:"csharp",code:`// Memory Layout
public class MemoryDemo
{
    public void Demonstrate()
    {
        // STACK allocation
        int x = 5;                        // Stack: int value 5
        string name = "Alice";            // Stack: reference/pointer
                                           // Heap: "Alice" string object
        
        var person = new Person();        // Stack: reference/pointer
                                          // Heap: Person object
        person.Age = 30;                  // Heap: Age field set to 30
        
        // STACK LAYOUT:
        // [Return Address]
        // [x = 5]
        // [name = pointer to "Alice"]
        // [person = pointer to Person object]
        
        // HEAP LAYOUT:
        // [String object: "Alice"]
        // [Person object: Age=30, ...]
        
        NestedMethod();
    }
    
    private void NestedMethod()
    {
        // New stack frame created
        int y = 10;
        var local = new byte[1024];
    } // Stack frame destroyed, y and local pointer freed
      // Byte array might be collected later by GC
}

// Stack behavior - automatic
public void StackExample()
{
    int a = 1;
    {
        int b = 2; // New scope
        int c = 3;
    } // b and c freed automatically when scope ends
    // a still alive
} // a freed when method ends

// Heap behavior - GC managed
public void HeapExample()
{
    var obj1 = new byte[1_000_000]; // Heap: 1MB allocated
    var obj2 = new byte[1_000_000]; // Heap: 1MB allocated
    
    obj1 = null; // Reference removed
    // 1MB on heap is now unreachable
    // GC will free it eventually (maybe in milliseconds or seconds)
    
    obj2 = null; // Another 1MB unreachable
} // Method ends, both freed by GC

// Stack overflow
public void StackOverflow()
{
    int[] huge = new int[1_000_000]; // 4MB stack - might overflow!
    // Large value types on stack are bad
    
    // Better approach
    var huge2 = new int[1_000_000]; // Heap - no problem
}

// Escape analysis (modern .NET)
public void ModernOptimization()
{
    // Small objects might be allocated on stack (escape analysis)
    var point = new Point { X = 1, Y = 2 }; // Might be stack!
    
    // The JIT compiler analyzes: does this escape the method?
    // If Point never escapes, allocate on stack instead of heap
    // Avoids GC overhead!
}

// Stack trace - shows stack frames
public void Demonstration()
{
    Method1();
}

private void Method1()
{
    // Stack: [Return to Demonstrate]
    // Stack: [Method1 frame]
    Method2();
}

private void Method2()
{
    // Stack: [Return to Method1]
    // Stack: [Method2 frame]
    
    var trace = Environment.StackTrace;
    // Shows:
    // - Method2 (current)
    // - Method1 (called from)
    // - Demonstrate (called from)
}

// Key differences:
// Stack:
// - Fast allocation (just increment pointer)
// - Automatic deallocation
// - Limited size
// - LIFO order
// - No GC needed

// Heap:
// - Slower allocation
// - GC overhead
// - Large capacity
// - Any order
// - GC manages lifecycle`}]},{id:"q12",question:"How can you monitor and optimize garbage collection? What tools and techniques are available?",answer:"Use GC class for statistics, profilers like Perfview and dotTrace, and Event Tracing for Windows (ETW). Monitor Gen 2 collections and pause times. Optimize by reducing allocations, using object pools, and tuning GC modes.",codeSnippets:[{language:"csharp",code:`using System;
using System.Diagnostics;

// 1. Monitor GC Statistics
public class GCMonitoring
{
    public void MonitorGC()
    {
        // Get total memory before
        long before = GC.GetTotalMemory(false);
        
        // Do work
        DoWork();
        
        // Get total memory after
        long after = GC.GetTotalMemory(false);
        Console.WriteLine(\`Memory used: \${(after - before) / 1024}KB\`);
        
        // Get collection counts
        Console.WriteLine(\`Gen 0 Collections: \${GC.CollectionCount(0)}\`);
        Console.WriteLine(\`Gen 1 Collections: \${GC.CollectionCount(1)}\`);
        Console.WriteLine(\`Gen 2 Collections: \${GC.CollectionCount(2)}\`);
    }
    
    // Monitor individual object
    public void MonitorObject()
    {
        var obj = new byte[1024];
        
        Console.WriteLine(\`Generation: \${GC.GetGeneration(obj)}\`);
        
        int gen = GC.GetGeneration(obj);
        Console.WriteLine(\`In Gen \${gen}\`);
    }
    
    private void DoWork()
    {
        var list = new List<byte[]>();
        for (int i = 0; i < 1000; i++)
        {
            list.Add(new byte[1024]);
        }
    }
}

// 2. Use GC Modes
public class GCModes
{
    public void DemoGCModes()
    {
        // Workstation mode (default) - low latency
        // Server mode - high throughput
        
        // Check GC info
        var info = GCSettings.IsServerGC;
        Console.WriteLine(\`Server GC: \${info}\`);
        
        // Configure latency
        // GCLatencyMode.Interactive (default)
        // GCLatencyMode.Batch (high throughput)
        // GCLatencyMode.SustainedLowLatency
        
        var oldMode = GCSettings.LatencyMode;
        GCSettings.LatencyMode = GCLatencyMode.SustainedLowLatency;
        
        // Critical section with minimal GC pauses
        CriticalGameLoop();
        
        GCSettings.LatencyMode = oldMode;
    }
    
    private void CriticalGameLoop()
    {
        for (int i = 0; i < 100; i++)
        {
            // Frame rendering with minimal GC interruption
        }
    }
}

// 3. Object Pool Pattern - reduce allocations
public class ObjectPool<T> where T : class, new()
{
    private Stack<T> pool = new();
    private int maxPoolSize = 100;
    
    public T Rent()
    {
        return pool.Count > 0 ? pool.Pop() : new T();
    }
    
    public void Return(T obj)
    {
        if (pool.Count < maxPoolSize)
        {
            (obj as IPoolable)?.Reset();
            pool.Push(obj);
        }
    }
}

public interface IPoolable
{
    void Reset();
}

// 4. Reduce allocations in hot paths
public class AllocationOptimization
{
    // Bad - allocation per loop iteration
    public void BadAllocations()
    {
        var results = new List<string>();
        for (int i = 0; i < 1000; i++)
        {
            var text = new string('x', 100); // Allocation each time!
            results.Add(text);
        }
    }
    
    // Better - reuse buffer
    public void BetterAllocations()
    {
        var buffer = new StringBuilder();
        var results = new List<string>();
        
        for (int i = 0; i < 1000; i++)
        {
            buffer.Clear();
            buffer.Append('x', 100); // Reuses buffer
            results.Add(buffer.ToString());
        }
    }
    
    // Use Span<T> and stackalloc for small arrays
    public void StackAllocation()
    {
        Span<int> buffer = stackalloc int[10]; // Stack allocation!
        for (int i = 0; i < buffer.Length; i++)
        {
            buffer[i] = i;
        }
        // No heap allocation, no GC
    }
}

// 5. Profiler commands
public class ProfilingHelpers
{
    public void ProfileMethod(Action method)
    {
        GC.Collect();
        GC.WaitForPendingFinalizers();
        GC.Collect();
        
        long before = GC.GetTotalMemory(false);
        int gen0Before = GC.CollectionCount(0);
        int gen2Before = GC.CollectionCount(2);
        
        var sw = Stopwatch.StartNew();
        method();
        sw.Stop();
        
        long after = GC.GetTotalMemory(false);
        int gen0After = GC.CollectionCount(0);
        int gen2After = GC.CollectionCount(2);
        
        Console.WriteLine(\`Time: \${sw.ElapsedMilliseconds}ms\`);
        Console.WriteLine(\`Memory: \${(after - before) / 1024}KB\`);
        Console.WriteLine(\`Gen 0 Collections: \${gen0After - gen0Before}\`);
        Console.WriteLine(\`Gen 2 Collections: \${gen2After - gen2Before}\`);
    }
}

// 6. Configure for low latency (gaming, real-time)
public void ConfigureLowLatency()
{
    // In .csproj or programmatically:
    // <PropertyGroup>
    //   <TieredCompilationQuickJit>true</TieredCompilationQuickJit>
    //   <TieredCompilationQuickJitForLoops>true</TieredCompilationQuickJitForLoops>
    //   <ReadyToRun>false</ReadyToRun>
    // </PropertyGroup>
    
    GCSettings.IsGCWorkingSetQuotaEnabled = true; // Respect memory limits
    GCSettings.LatencyMode = GCLatencyMode.SustainedLowLatency;
}

// Common optimization techniques:
// 1. Use stackalloc for small buffers
// 2. Implement object pooling for frequently allocated objects
// 3. Use value types for small immutable values
// 4. Avoid boxing
// 5. Reuse collections instead of creating new ones
// 6. Use ArrayPool<T> for temporary arrays
// 7. Profile to find hotspots
// 8. Configure GC mode appropriately (Workstation vs Server)`}]}]},_y={id:"csharp-collections",name:"Collections",questions:[{id:"q1",question:"What are collections in C# and what are the main types?",answer:"Collections are data structures that store and manage groups of objects. Main types: List<T> (ordered, indexable), Dictionary<K,V> (key-value pairs), HashSet<T> (unique items), Queue<T> (FIFO), Stack<T> (LIFO), LinkedList<T> (doubly-linked). Located in System.Collections.Generic namespace.",codeSnippets:[{language:"csharp",code:`using System;
using System.Collections.Generic;

// 1. List<T> - Dynamic array, ordered
var list = new List<int> { 1, 2, 3 };
list.Add(4);
list.Remove(2);
Console.WriteLine(list[0]); // Access by index: 1

// 2. Dictionary<K,V> - Key-value pairs
var dict = new Dictionary<string, int>
{
    { "Alice", 25 },
    { "Bob", 30 }
};
dict["Charlie"] = 28;
var age = dict["Alice"]; // 25

// 3. HashSet<T> - Unique items only
var set = new HashSet<int> { 1, 2, 3, 2 }; // 2 ignored
set.Add(4);
bool contains = set.Contains(2); // true

// 4. Queue<T> - FIFO (First In, First Out)
var queue = new Queue<string>();
queue.Enqueue("First");
queue.Enqueue("Second");
var first = queue.Dequeue(); // "First"

// 5. Stack<T> - LIFO (Last In, First Out)
var stack = new Stack<string>();
stack.Push("First");
stack.Push("Second");
var last = stack.Pop(); // "Second"

// 6. LinkedList<T> - Doubly-linked nodes
var linked = new LinkedList<int>();
linked.AddLast(1);
linked.AddLast(2);
var node = linked.First; // Access nodes

// 7. SortedDictionary<K,V> - Sorted key-value pairs
var sorted = new SortedDictionary<string, int>
{
    { "Charlie", 28 },
    { "Alice", 25 }, // Auto-sorted by key
    { "Bob", 30 }
};

// 8. Tuple - Fixed size, multiple types
var tuple = Tuple.Create(1, "Alice", 25);
Console.WriteLine(tuple.Item1); // 1`}]},{id:"q2",question:"What is the difference between IEnumerable, ICollection, and IList interfaces?",answer:"IEnumerable provides iteration (foreach). ICollection adds Count, Add, Remove, Contains. IList adds indexing ([]). Each builds on the previous one. IEnumerable is most basic, IList most feature-rich. Choose based on what operations you need.",codeSnippets:[{language:"csharp",code:`using System;
using System.Collections.Generic;

// IEnumerable - Only iteration
public void ProcessEnumerable(IEnumerable<int> items)
{
    foreach (var item in items) // Only operation available
    {
        Console.WriteLine(item);
    }
    // Can't: access by index, count, add, remove
}

// ICollection - Add iteration + mutation + count
public void ProcessCollection(ICollection<int> items)
{
    var count = items.Count; // Has Count
    items.Add(5); // Can add
    items.Remove(3); // Can remove
    bool has = items.Contains(2); // Can check
    
    foreach (var item in items) // Still iterable
    {
        Console.WriteLine(item);
    }
    // Can't: access by index
}

// IList - Add indexing to everything
public void ProcessList(IList<int> items)
{
    var item = items[0]; // Access by index
    items[0] = 10; // Modify by index
    
    var count = items.Count;
    items.Add(5);
    items.Remove(3);
    
    items.Insert(1, 7); // Insert at index
    items.RemoveAt(2); // Remove by index
    
    var index = items.IndexOf(5); // Find index
    
    foreach (var i in items)
    {
        Console.WriteLine(i);
    }
}

// Hierarchy:
// IEnumerable
//      (adds Count, Add, Remove, Contains)
// ICollection<T>
//      (adds indexing)
// IList<T>

// Practical example
public void DemonstrateDifferences()
{
    var list = new List<int> { 1, 2, 3 };
    
    // Can use as IEnumerable
    IEnumerable<int> enumerable = list;
    ProcessEnumerable(enumerable);
    
    // Can use as ICollection
    ICollection<int> collection = list;
    ProcessCollection(collection);
    
    // Can use as IList
    IList<int> ilist = list;
    ProcessList(ilist);
}

// Choosing which to return from methods
public IEnumerable<User> GetActiveUsers() // Most restrictive - good for LINQ
{
    return users.Where(u => u.IsActive);
}

public ICollection<User> GetAllUsers() // Can modify collection
{
    return users;
}

public IList<User> GetUserList() // Full access
{
    return users as IList<User>;
}

// Best practice: Return most restrictive interface
// that meets your needs`}]},{id:"q3",question:"What is the difference between List<T> and Array? When to use each?",answer:"Array is fixed-size, created once. List<T> is dynamic, grows as needed. Array is faster for fixed-size, uses less memory. List<T> is flexible, supports Add/Remove. Use Array when size is known and won't change, use List<T> for flexible collections.",codeSnippets:[{language:"csharp",code:`using System;
using System.Collections.Generic;
using System.Diagnostics;

// Array - Fixed size
int[] array = new int[10]; // Size 10, fixed
array[0] = 1;
array[1] = 2;
// array[10] = 3; // IndexOutOfRangeException

// List<T> - Dynamic size
var list = new List<int> { 1, 2 };
list.Add(3); // Grows automatically
list.Add(4);

// Performance comparison
public void PerformanceComparison()
{
    const int count = 1_000_000;
    
    // Array - faster for fixed size
    var sw = Stopwatch.StartNew();
    int[] array = new int[count];
    for (int i = 0; i < count; i++)
    {
        array[i] = i; // Direct access
    }
    sw.Stop();
    Console.WriteLine(\`Array: \${sw.ElapsedMilliseconds}ms\`); // ~1-5ms
    
    // List - dynamic but slightly slower
    sw.Restart();
    var list = new List<int>(count); // Pre-allocate capacity
    for (int i = 0; i < count; i++)
    {
        list.Add(i);
    }
    sw.Stop();
    Console.WriteLine(\`List: \${sw.ElapsedMilliseconds}ms\`); // ~5-15ms
    
    // List without pre-allocated capacity - even slower
    sw.Restart();
    var list2 = new List<int>();
    for (int i = 0; i < count; i++)
    {
        list2.Add(i); // Reallocates when full
    }
    sw.Stop();
    Console.WriteLine(\`List (no capacity): \${sw.ElapsedMilliseconds}ms\`); // ~20-50ms
}

// Memory comparison
public void MemoryComparison()
{
    // Array uses contiguous memory
    int[] array = new int[100]; // 400 bytes + object header
    
    // List uses internal array + size tracking
    var list = new List<int>(100);
    // Uses more memory due to wrapper overhead
    // But grows efficiently (usually doubles capacity)
}

// Key differences:
// Feature          Array                List<T>
// Size             Fixed at creation    Dynamic
// Speed            Fastest              Very fast
// Memory           Minimal              More overhead
// Resize           Not possible         Grows automatically
// API              Basic                Rich (Add, Remove, etc)
// Type safety      Generic (if T[])     Generic
// Performance      O(1) access          O(1) access

// When to use Array:
// - Size is known and fixed
// - Performance critical
// - Need minimal memory overhead
// - Working with existing code expecting arrays

public void ProcessFixedData(int[] data)
{
    // Size won't change, array is perfect
    for (int i = 0; i < data.Length; i++)
    {
        data[i] *= 2;
    }
}

// When to use List<T>:
// - Size changes dynamically
// - Need Add/Remove/Insert operations
// - Working with LINQ
// - Flexibility is important

public void ProcessDynamicData(IEnumerable<int> numbers)
{
    var list = new List<int>(numbers); // Convert to List for manipulation
    list.Add(999); // Add operations
    list.RemoveAll(n => n < 0); // Rich API
}

// Converting between them
int[] array = new int[] { 1, 2, 3 };
var list = new List<int>(array); // Array to List
array = list.ToArray(); // List to Array

// Array initialization
int[] arr1 = new int[5]; // Default values (0)
int[] arr2 = new[] { 1, 2, 3 }; // Array initializer
int[] arr3 = { 1, 2, 3 }; // Also works

// List initialization
var list1 = new List<int>(); // Empty
var list2 = new List<int>(10); // Capacity 10
var list3 = new List<int> { 1, 2, 3 }; // With values`}]},{id:"q4",question:"What is the difference between Dictionary, Hashtable, and SortedDictionary?",answer:"Dictionary<K,V> is generic, fast, unordered. Hashtable is non-generic, slower, legacy. SortedDictionary keeps keys sorted. Use Dictionary for most cases (type-safe, fast), Hashtable rarely (backward compatibility), SortedDictionary when you need sorted order.",codeSnippets:[{language:"csharp",code:`using System;
using System.Collections;
using System.Collections.Generic;

// Dictionary<K,V> - Generic, Fast (PREFERRED)
var dict = new Dictionary<string, int>
{
    { "Alice", 25 },
    { "Bob", 30 },
    { "Charlie", 28 }
};

dict["David"] = 32;
var age = dict["Alice"];
bool has = dict.ContainsKey("Bob");
dict.TryGetValue("Alice", out int aliceAge);

// Hashtable - Non-generic, legacy (AVOID)
Hashtable hashtable = new Hashtable
{
    { "Alice", 25 },
    { "Bob", 30 }
};

hashtable["David"] = 32;
var age2 = (int)hashtable["Alice"]; // Requires casting!
bool has2 = hashtable.ContainsKey("Bob");

// SortedDictionary - Ordered by key
var sorted = new SortedDictionary<string, int>
{
    { "Charlie", 28 },
    { "Alice", 25 },
    { "Bob", 30 }
};

// Iteration order: Alice, Bob, Charlie (sorted)
foreach (var kvp in sorted)
{
    Console.WriteLine($"{kvp.Key}: {kvp.Value}");
}

// Comparison
// Feature              Dictionary   Hashtable   SortedDictionary
// Type-safe            Yes          No          Yes
// Performance          Fast         Slow        Slow (maintains order)
// Order                Unordered    Unordered   Sorted by key
// Boxing               No           Yes         No
// Thread-safe          No           Yes         No
// Null keys            No           Yes         No
// Generics             Yes          No          Yes

public void DemonstrateDifferences()
{
    // Dictionary is fastest and type-safe
    var dict = new Dictionary<string, int>();
    dict["Alice"] = 25; // Type-safe
    int age = dict["Alice"]; // No casting needed
    
    // Hashtable requires casting and boxing
    var hashtable = new Hashtable();
    hashtable["Alice"] = 25; // Boxing
    int age2 = (int)hashtable["Alice"]; // Casting required!
    
    // SortedDictionary maintains order
    var sorted = new SortedDictionary<int, string>();
    sorted[3] = "Third";
    sorted[1] = "First";
    sorted[2] = "Second";
    
    // Iteration: First, Second, Third (sorted order)
    foreach (var item in sorted)
    {
        Console.WriteLine(item.Value);
    }
}

// Performance benchmark
public void PerformanceBench()
{
    const int iterations = 1_000_000;
    
    // Dictionary - fastest
    var sw = Stopwatch.StartNew();
    var dict = new Dictionary<string, int>();
    for (int i = 0; i < iterations; i++)
    {
        dict[$"Key{i}"] = i;
    }
    sw.Stop();
    Console.WriteLine($"Dictionary: {sw.ElapsedMilliseconds}ms");
    
    // Hashtable - slower
    sw.Restart();
    var hashtable = new Hashtable();
    for (int i = 0; i < iterations; i++)
    {
        hashtable[$"Key{i}"] = i;
    }
    sw.Stop();
    Console.WriteLine($"Hashtable: {sw.ElapsedMilliseconds}ms");
    
    // SortedDictionary - slowest (maintains order)
    sw.Restart();
    var sorted = new SortedDictionary<string, int>();
    for (int i = 0; i < iterations; i++)
    {
        sorted[$"Key{i}"] = i;
    }
    sw.Stop();
    Console.WriteLine($"SortedDictionary: {sw.ElapsedMilliseconds}ms");
}

// When to use each:
// Dictionary - 99% of cases (fast, type-safe)
public void ModernApproach()
{
    var dict = new Dictionary<string, User>();
    dict["alice"] = new User { Name = "Alice" };
}

// Hashtable - Legacy code compatibility only
public void LegacyApproach()
{
    var ht = new Hashtable();
    ht["alice"] = new User { Name = "Alice" };
}

// SortedDictionary - When you need sorted order
public void SortedApproach()
{
    var sorted = new SortedDictionary<string, decimal>();
    sorted["Banana"] = 0.5m;
    sorted["Apple"] = 0.8m;
    // Iteration is always in sorted order: Apple, Banana
}`}]},{id:"q5",question:"What is the difference between HashSet and SortedSet? When to use each?",answer:"HashSet is unordered, fast, no duplicates. SortedSet is ordered, slower, no duplicates. HashSet is O(1) for add/remove/lookup. SortedSet is O(log n). Use HashSet for fast membership testing, SortedSet when you need sorted order.",codeSnippets:[{language:"csharp",code:`using System;
using System.Collections.Generic;

// HashSet<T> - Fast, unordered, no duplicates
var hashSet = new HashSet<int> { 3, 1, 4, 1, 5 }; // Duplicates ignored
Console.WriteLine(hashSet.Count); // 4 (not 5)

hashSet.Add(2);
bool has = hashSet.Contains(3); // O(1) - very fast
hashSet.Remove(1);

// Iteration order is unpredictable
foreach (var item in hashSet)
{
    Console.WriteLine(item); // Order not guaranteed
}

// SortedSet<T> - Ordered, no duplicates
var sortedSet = new SortedSet<int> { 3, 1, 4, 1, 5 };
Console.WriteLine(sortedSet.Count); // 4

sortedSet.Add(2);
bool has2 = sortedSet.Contains(3); // O(log n)
sortedSet.Remove(1);

// Iteration order is always sorted
foreach (var item in sortedSet)
{
    Console.WriteLine(item); // 2, 3, 4, 5 (sorted)
}

// Comparison
// Feature              HashSet      SortedSet
// Order                Unordered    Sorted
// Add/Remove/Lookup    O(1)         O(log n)
// Space                Less         More
// Iteration speed      Fast         Fast
// Range queries        No           Yes
// Min/Max              No           Yes (free)
// Memory               Minimal      More overhead

public void DemonstrateDifferences()
{
    // HashSet - Fast for membership testing
    var users = new HashSet<string> { "Alice", "Bob", "Charlie" };
    
    if (users.Contains("Alice")) // O(1) - instant
    {
        Console.WriteLine("User exists");
    }
}

// Unique numbers example
public void FindUniqueNumbers()
{
    int[] numbers = { 1, 2, 2, 3, 3, 3, 4, 4, 4, 4 };
    
    // HashSet removes duplicates automatically
    var unique = new HashSet<int>(numbers);
    Console.WriteLine(unique.Count); // 4
}

// Set operations
public void SetOperations()
{
    var set1 = new HashSet<int> { 1, 2, 3, 4, 5 };
    var set2 = new HashSet<int> { 4, 5, 6, 7, 8 };
    
    // Union
    set1.UnionWith(set2); // { 1, 2, 3, 4, 5, 6, 7, 8 }
    
    // Intersection
    var result = new HashSet<int> { 1, 2, 3, 4, 5 };
    result.IntersectWith(set2); // { 4, 5 }
    
    // Difference
    result = new HashSet<int> { 1, 2, 3, 4, 5 };
    result.ExceptWith(set2); // { 1, 2, 3 }
    
    // Symmetric difference
    result = new HashSet<int> { 1, 2, 3, 4, 5 };
    result.SymmetricExceptWith(set2); // { 1, 2, 3, 6, 7, 8 }
}

// SortedSet - Range queries
public void RangeQueries()
{
    var scores = new SortedSet<int> { 10, 20, 30, 40, 50 };
    
    // Get range of values
    var range = scores.GetViewBetween(20, 40); // { 20, 30, 40 }
    
    // Get elements less than a value
    var lessThan30 = scores.Where(x => x < 30); // { 10, 20 }
    
    // Min and Max
    var min = scores.Min; // 10
    var max = scores.Max; // 50
}

// Performance comparison
public void PerformanceBench()
{
    const int iterations = 100_000;
    var numbers = Enumerable.Range(0, iterations).ToArray();
    
    // HashSet - much faster for lookups
    var sw = Stopwatch.StartNew();
    var hashSet = new HashSet<int>();
    foreach (var n in numbers)
    {
        hashSet.Add(n);
        hashSet.Contains(n);
    }
    sw.Stop();
    Console.WriteLine(\`HashSet: \${sw.ElapsedMilliseconds}ms\`);
    
    // SortedSet - slower but maintains order
    sw.Restart();
    var sortedSet = new SortedSet<int>();
    foreach (var n in numbers)
    {
        sortedSet.Add(n);
        sortedSet.Contains(n);
    }
    sw.Stop();
    Console.WriteLine(\`SortedSet: \${sw.ElapsedMilliseconds}ms\`);
}

// When to use each:
// HashSet - Checking membership, removing duplicates
public void FastMembership()
{
    var bannedUsers = new HashSet<string> { "spammer1", "spammer2" };
    if (!bannedUsers.Contains(currentUser))
    {
        AllowAccess();
    }
}

// SortedSet - Need order or range queries
public void NeedSorted()
{
    var highScores = new SortedSet<int>();
    highScores.Add(100);
    highScores.Add(90);
    
    var topScores = highScores.GetViewBetween(90, 100);
}`}]},{id:"q6",question:"What are Queue and Stack? Give practical examples of when to use each.",answer:"Queue<T> is FIFO (First In, First Out) - use for task queues, printer queues, BFS. Stack<T> is LIFO (Last In, First Out) - use for undo/redo, function call stacks, DFS. Queue has Enqueue/Dequeue, Stack has Push/Pop.",codeSnippets:[{language:"csharp",code:`using System;
using System.Collections.Generic;

// Queue<T> - FIFO (First In, First Out)
var queue = new Queue<string>();
queue.Enqueue("First request");
queue.Enqueue("Second request");
queue.Enqueue("Third request");

var first = queue.Dequeue(); // "First request"
var second = queue.Dequeue(); // "Second request"

// Stack<T> - LIFO (Last In, First Out)
var stack = new Stack<string>();
stack.Push("First action");
stack.Push("Second action");
stack.Push("Third action");

var last = stack.Pop(); // "Third action"
var previous = stack.Pop(); // "Second action"

// Practical: Task Queue
public class TaskQueue
{
    private Queue<Task> tasks = new();
    
    public void AddTask(Task task)
    {
        tasks.Enqueue(task); // Add to end
    }
    
    public Task ProcessNextTask()
    {
        if (tasks.Count > 0)
            return tasks.Dequeue(); // Process first task
        return null;
    }
}

// Usage
var queue = new TaskQueue();
queue.AddTask(new Task { Name = "Print document" });
queue.AddTask(new Task { Name = "Send email" });
queue.AddTask(new Task { Name = "Backup files" });

// Process in order: Print, Send, Backup
var task1 = queue.ProcessNextTask(); // Print
var task2 = queue.ProcessNextTask(); // Send
var task3 = queue.ProcessNextTask(); // Backup

// Practical: Undo/Redo with Stack
public class UndoRedo
{
    private Stack<Action> undoStack = new();
    private Stack<Action> redoStack = new();
    
    public void DoAction(Action action, Action undoAction)
    {
        action();
        undoStack.Push(undoAction);
        redoStack.Clear(); // Clear redo on new action
    }
    
    public void Undo()
    {
        if (undoStack.Count > 0)
        {
            var action = undoStack.Pop();
            action();
            // Push corresponding redo action
        }
    }
    
    public void Redo()
    {
        if (redoStack.Count > 0)
        {
            var action = redoStack.Pop();
            action();
        }
    }
}

// Usage
var editor = new UndoRedo();
editor.DoAction(
    () => Console.WriteLine("Type: Hello"),
    () => Console.WriteLine("Delete: Hello")
);

editor.DoAction(
    () => Console.WriteLine("Type: World"),
    () => Console.WriteLine("Delete: World")
);

editor.Undo(); // Delete: World
editor.Undo(); // Delete: Hello
editor.Redo(); // Type: Hello

// Practical: Breadth-First Search with Queue
public void BreadthFirstSearch(Node root)
{
    var queue = new Queue<Node>();
    var visited = new HashSet<Node>();
    
    queue.Enqueue(root);
    visited.Add(root);
    
    while (queue.Count > 0)
    {
        var node = queue.Dequeue();
        Console.WriteLine(node.Value);
        
        foreach (var neighbor in node.Neighbors)
        {
            if (!visited.Contains(neighbor))
            {
                queue.Enqueue(neighbor);
                visited.Add(neighbor);
            }
        }
    }
}

// Practical: Depth-First Search with Stack
public void DepthFirstSearch(Node root)
{
    var stack = new Stack<Node>();
    var visited = new HashSet<Node>();
    
    stack.Push(root);
    
    while (stack.Count > 0)
    {
        var node = stack.Pop();
        if (visited.Contains(node))
            continue;
        
        visited.Add(node);
        Console.WriteLine(node.Value);
        
        foreach (var neighbor in node.Neighbors)
        {
            if (!visited.Contains(neighbor))
                stack.Push(neighbor);
        }
    }
}

// Queue methods
public void QueueOperations()
{
    var queue = new Queue<int>();
    
    queue.Enqueue(1); // Add to back
    queue.Enqueue(2);
    queue.Enqueue(3);
    
    var front = queue.Peek(); // 1 (without removing)
    var first = queue.Dequeue(); // 1 (with removing)
    
    bool has = queue.Contains(2);
    var count = queue.Count;
}

// Stack methods
public void StackOperations()
{
    var stack = new Stack<int>();
    
    stack.Push(1); // Add to top
    stack.Push(2);
    stack.Push(3);
    
    var top = stack.Peek(); // 3 (without removing)
    var last = stack.Pop(); // 3 (with removing)
    
    bool has = stack.Contains(2);
    var count = stack.Count;
}

// Comparison
// Operation    Queue        Stack
// Add          Enqueue      Push
// Remove       Dequeue      Pop
// Peek         Peek         Peek
// Order        FIFO         LIFO
// Use case     Tasks        Undo/DFS

// When to use Queue:
// - Job scheduling
// - BFS algorithms
// - Printer queues
// - Message processing
// - Buffering data

// When to use Stack:
// - Undo/Redo functionality
// - DFS algorithms
// - Expression evaluation
// - Function call stack
// - Backtracking problems`}]},{id:"q7",question:"What is LinkedList<T> and when would you use it instead of List<T>?",answer:"LinkedList<T> is a doubly-linked list with nodes. Use when you need efficient insertions/deletions in the middle. List<T> is better for random access. LinkedList has O(1) insert/delete at known position, but O(n) random access. Use LinkedList rarely, List<T> is usually better.",codeSnippets:[{language:"csharp",code:`using System;
using System.Collections.Generic;

// LinkedList<T> - Doubly-linked nodes
var linked = new LinkedList<int>();

var node1 = linked.AddLast(10); // Add to end
var node2 = linked.AddLast(20);
var node3 = linked.AddLast(30);

// Efficient insertion in the middle
linked.AddAfter(node1, 15); // Insert between 10 and 20
linked.AddBefore(node3, 25); // Insert before 30

// Result: 10 -> 15 -> 20 -> 25 -> 30

// Access nodes
var first = linked.First; // LinkedListNode<int>
var last = linked.Last;

// Traverse
foreach (var item in linked)
{
    Console.WriteLine(item); // 10, 15, 20, 25, 30
}

// Remove by node reference (O(1))
linked.Remove(node2); // Very fast - O(1)

// Find a value
var foundNode = linked.Find(20); // O(n)

// Comparison with List
// Operation            LinkedList   List<T>
// Add to end          O(1)         O(1)
// Add to start        O(1)         O(n) - shifts elements
// Insert at index     O(n)         O(n) - shifts elements
// Remove by node      O(1)         O(n)
// Random access [i]   O(n)         O(1)
// Memory              More         Less
// Cache friendly      No           Yes

public class ComparisonDemo()
{
    public void InsertionPerformance()
    {
        const int count = 10_000;
        
        // List - slow at inserting in middle
        var sw = Stopwatch.StartNew();
        var list = new List<int>();
        for (int i = 0; i < count; i++)
        {
            list.Insert(0, i); // Insert at start - O(n)
        }
        sw.Stop();
        Console.WriteLine(\`List insert at start: \${sw.ElapsedMilliseconds}ms\`);
        
        // LinkedList - fast at inserting
        sw.Restart();
        var linked = new LinkedList<int>();
        LinkedListNode<int> node = null;
        for (int i = 0; i < count; i++)
        {
            node = linked.AddFirst(i); // O(1)
        }
        sw.Stop();
        Console.WriteLine(\`LinkedList insert at start: \${sw.ElapsedMilliseconds}ms\`);
    }
    
    public void RandomAccessPerformance()
    {
        const int count = 10_000;
        var list = new List<int>(Enumerable.Range(0, count));
        var linked = new LinkedList<int>(Enumerable.Range(0, count));
        
        // List - fast random access
        var sw = Stopwatch.StartNew();
        for (int i = 0; i < count; i++)
        {
            var item = list[i]; // O(1)
        }
        sw.Stop();
        Console.WriteLine(\`List random access: \${sw.ElapsedMilliseconds}ms\`);
        
        // LinkedList - slow random access
        sw.Restart();
        for (int i = 0; i < count; i++)
        {
            var node = linked.First;
            for (int j = 0; j < i; j++)
                node = node.Next; // O(n)
        }
        sw.Stop();
        Console.WriteLine(\`LinkedList random access: \${sw.ElapsedMilliseconds}ms\`);
    }
}

// Practical: Circular Buffer with LinkedList
public class CircularBuffer<T>
{
    private LinkedList<T> buffer = new();
    private int maxSize;
    
    public CircularBuffer(int size)
    {
        maxSize = size;
    }
    
    public void Add(T item)
    {
        buffer.AddLast(item);
        
        // Remove oldest if exceeds max
        if (buffer.Count > maxSize)
            buffer.RemoveFirst(); // O(1) removal
    }
    
    public IEnumerable<T> GetAll()
    {
        return buffer;
    }
}

// Usage
var buffer = new CircularBuffer<int>(3);
buffer.Add(1);
buffer.Add(2);
buffer.Add(3);
buffer.Add(4); // Removes 1
buffer.Add(5); // Removes 2
// Buffer contains: 3, 4, 5

// Practical: LRU Cache with LinkedList
public class LRUCache<K, V>
{
    private Dictionary<K, LinkedListNode<(K key, V value)>> cache;
    private LinkedList<(K key, V value)> order;
    private int capacity;
    
    public LRUCache(int capacity)
    {
        this.capacity = capacity;
        cache = new Dictionary<K, LinkedListNode<(K, V)>>(capacity);
        order = new LinkedList<(K, V)>();
    }
    
    public void Put(K key, V value)
    {
        if (cache.ContainsKey(key))
        {
            // Remove old entry
            order.Remove(cache[key]);
        }
        else if (cache.Count >= capacity)
        {
            // Evict least recently used
            var lru = order.First;
            order.RemoveFirst();
            cache.Remove(lru.Value.key);
        }
        
        // Add new entry to end (most recently used)
        var node = order.AddLast((key, value));
        cache[key] = node;
    }
    
    public bool TryGet(K key, out V value)
    {
        if (!cache.ContainsKey(key))
        {
            value = default;
            return false;
        }
        
        // Move to end (mark as recently used)
        var node = cache[key];
        order.Remove(node);
        order.AddLast(node);
        
        value = node.Value.value;
        return true;
    }
}

// When to use LinkedList:
// 1. Frequent insertions/deletions in middle
var musicians = new LinkedList<string>();
musicians.AddLast("Alice");
var bob = musicians.AddLast("Bob");
var charlie = musicians.AddLast("Charlie");
musicians.AddAfter(bob, "Beatrice"); // Efficient

// 2. Circular buffers or queues
var ring = new LinkedList<int>();

// 3. Implementing other data structures
// (usually prefer built-in collections)

// When NOT to use LinkedList:
// - Need random access - use List<T>
// - Need fast iteration - use List<T>
// - Most general-purpose use - use List<T>

// Rule of thumb: Use List<T> 95% of the time,
// LinkedList<T> only when you specifically need
// efficient middle insertions/deletions`}]},{id:"q8",question:"What is IEqualityComparer and when would you implement it?",answer:"IEqualityComparer defines how to compare objects for equality and hash them. Implement when default equality doesn't suit your needs. Use in HashSet, Dictionary, LINQ Distinct/GroupBy to customize comparison logic.",codeSnippets:[{language:"csharp",code:`using System;
using System.Collections.Generic;
using System.Linq;

// Default comparison - uses reference equality for classes
public class Person
{
    public string Name { get; set; }
    public int Age { get; set; }
}

var person1 = new Person { Name = "Alice", Age = 25 };
var person2 = new Person { Name = "Alice", Age = 25 };

Console.WriteLine(person1 == person2); // false (different references)

// Custom IEqualityComparer - compare by value
public class PersonNameComparer : IEqualityComparer<Person>
{
    public bool Equals(Person x, Person y)
    {
        if (x == null && y == null) return true;
        if (x == null || y == null) return false;
        return x.Name == y.Name; // Compare by name only
    }
    
    public int GetHashCode(Person obj)
    {
        return obj?.Name?.GetHashCode() ?? 0;
    }
}

// Custom comparer for age-based comparison
public class PersonAgeComparer : IEqualityComparer<Person>
{
    public bool Equals(Person x, Person y)
    {
        if (x == null && y == null) return true;
        if (x == null || y == null) return false;
        return x.Age == y.Age; // Compare by age
    }
    
    public int GetHashCode(Person obj)
    {
        return obj?.Age.GetHashCode() ?? 0;
    }
}

// Case-insensitive string comparer
public class CaseInsensitiveStringComparer : IEqualityComparer<string>
{
    public bool Equals(string x, string y)
    {
        return string.Equals(x, y, StringComparison.OrdinalIgnoreCase);
    }
    
    public int GetHashCode(string obj)
    {
        return obj?.ToLower().GetHashCode() ?? 0;
    }
}

public void DemonstrateCustomComparers()
{
    var people = new List<Person>
    {
        new Person { Name = "Alice", Age = 25 },
        new Person { Name = "Bob", Age = 30 },
        new Person { Name = "Alice", Age = 25 },
        new Person { Name = "Charlie", Age = 25 }
    };
    
    // Using custom comparer in HashSet
    var uniqueByName = new HashSet<Person>(people, new PersonNameComparer());
    Console.WriteLine(\`Unique by name: \${uniqueByName.Count}\`); // 3 (Alice, Bob, Charlie)
    
    var uniqueByAge = new HashSet<Person>(people, new PersonAgeComparer());
    Console.WriteLine(\`Unique by age: \${uniqueByAge.Count}\`); // 2 (age 25, age 30)
}

// Using with Dictionary
public void CustomComparerWithDictionary()
{
    var dict = new Dictionary<string, int>(new CaseInsensitiveStringComparer());
    
    dict["Alice"] = 25;
    dict["BOB"] = 30;
    dict["ALICE"] = 26; // Overwrites "Alice"
    
    Console.WriteLine(dict["alice"]); // 26 (case-insensitive)
}

// Using with LINQ Distinct
public void CustomComparerWithLinq()
{
    var people = new List<Person>
    {
        new Person { Name = "Alice", Age = 25 },
        new Person { Name = "alice", Age = 25 },
        new Person { Name = "Bob", Age = 30 }
    };
    
    // Remove duplicates using custom comparer
    var unique = people.Distinct(new PersonNameComparer()).ToList();
    Console.WriteLine($"Unique count: {unique.Count}"); // 2
}

// Using with GroupBy
public void CustomComparerWithGroupBy()
{
    var words = new[] { "Hello", "hello", "HELLO", "World", "world" };
    
    var groups = words.GroupBy(w => w, new CaseInsensitiveStringComparer());
    
    foreach (var group in groups)
    {
        Console.WriteLine($"{group.Key}: {group.Count()}");
        // hello: 3
        // world: 2
    }
}

// Important: GetHashCode and Equals must be consistent!
// If two objects are equal, they MUST have the same hash code
public class BadEqualityComparer : IEqualityComparer<int>
{
    public bool Equals(int x, int y) => x == y;
    
    public int GetHashCode(int obj)
    {
        return 42; // WRONG! Breaks HashSet/Dictionary
    }
}

// Correct implementation
public class GoodEqualityComparer : IEqualityComparer<int>
{
    public bool Equals(int x, int y)
    {
        return x == y;
    }
    
    public int GetHashCode(int obj)
    {
        return obj.GetHashCode(); // Must be consistent
    }
}

// Complex example: comparing objects by multiple fields
public class PersonFullComparer : IEqualityComparer<Person>
{
    public bool Equals(Person x, Person y)
    {
        if (x == null && y == null) return true;
        if (x == null || y == null) return false;
        return x.Name == y.Name && x.Age == y.Age;
    }
    
    public int GetHashCode(Person obj)
    {
        unchecked
        {
            int hash = 17;
            hash = hash * 31 + obj.Name?.GetHashCode() ?? 0;
            hash = hash * 31 + obj.Age.GetHashCode();
            return hash;
        }
    }
}

// Override Equals and GetHashCode on the class itself (preferred)
public class ImprovedPerson : IEquatable<ImprovedPerson>
{
    public string Name { get; set; }
    public int Age { get; set; }
    
    public bool Equals(ImprovedPerson other)
    {
        if (other == null) return false;
        return Name == other.Name && Age == other.Age;
    }
    
    public override bool Equals(object obj)
    {
        return Equals(obj as ImprovedPerson);
    }
    
    public override int GetHashCode()
    {
        unchecked
        {
            int hash = 17;
            hash = hash * 31 + Name?.GetHashCode() ?? 0;
            hash = hash * 31 + Age.GetHashCode();
            return hash;
        }
    }
}

// Usage
var person = new ImprovedPerson { Name = "Alice", Age = 25 };
var hashSet = new HashSet<ImprovedPerson> { person };
hashSet.Contains(new ImprovedPerson { Name = "Alice", Age = 25 }); // true!`}]},{id:"q9",question:"What is ConcurrentBag, ConcurrentDictionary, and other thread-safe collections?",answer:"Thread-safe collections from System.Collections.Concurrent allow safe concurrent access without external locking. Include ConcurrentBag, ConcurrentQueue, ConcurrentDictionary, ConcurrentStack. Use for multi-threaded scenarios instead of locking regular collections.",codeSnippets:[{language:"csharp",code:`using System;
using System.Collections.Concurrent;
using System.Threading;
using System.Threading.Tasks;

// ConcurrentBag<T> - Unordered, thread-safe collection
var bag = new ConcurrentBag<int>();

Task.Run(() =>
{
    for (int i = 0; i < 100; i++)
    {
        bag.Add(i); // Thread-safe add
    }
});

Task.Run(() =>
{
    for (int i = 100; i < 200; i++)
    {
        bag.Add(i); // Thread-safe add
    }
});

// ConcurrentQueue<T> - Thread-safe FIFO queue
var queue = new ConcurrentQueue<string>();

Task.Run(() =>
{
    for (int i = 0; i < 50; i++)
    {
        queue.Enqueue($"Task {i}");
    }
});

Task.Run(() =>
{
    while (queue.TryDequeue(out var item))
    {
        Console.WriteLine($"Processing: {item}");
    }
});

// ConcurrentStack<T> - Thread-safe LIFO stack
var stack = new ConcurrentStack<int>();

for (int i = 0; i < 10; i++)
{
    stack.Push(i); // Thread-safe
}

if (stack.TryPop(out var value))
{
    Console.WriteLine(value); // Thread-safe pop
}

// ConcurrentDictionary<K,V> - Thread-safe dictionary
var dict = new ConcurrentDictionary<string, int>();

Task.Run(() =>
{
    for (int i = 0; i < 100; i++)
    {
        dict[$"Key{i}"] = i; // Thread-safe
    }
});

Task.Run(() =>
{
    foreach (var kvp in dict)
    {
        Console.WriteLine(kvp); // Thread-safe iteration
    }
});

// Thread-safe operations on ConcurrentDictionary
var dict2 = new ConcurrentDictionary<string, int>();

// AddOrUpdate - atomic operation
dict2.AddOrUpdate("count", 1, (key, oldValue) => oldValue + 1);
dict2.AddOrUpdate("count", 1, (key, oldValue) => oldValue + 1);
Console.WriteLine(dict2["count"]); // 2

// TryAdd - atomic operation
bool added = dict2.TryAdd("name", 123); // true if added
bool added2 = dict2.TryAdd("name", 456); // false (already exists)

// TryGetValue - atomic operation
if (dict2.TryGetValue("name", out int value))
{
    Console.WriteLine(value);
}

// Comparison: Bad vs Good for multithreading
// BAD - Using regular collection with lock
public class BadMultithreadedCounter
{
    private Dictionary<string, int> counts = new();
    private object lockObj = new();
    
    public void Increment(string key)
    {
        lock (lockObj) // Bottleneck!
        {
            if (counts.ContainsKey(key))
                counts[key]++;
            else
                counts[key] = 1;
        }
    }
}

// GOOD - Using ConcurrentDictionary
public class GoodMultithreadedCounter
{
    private ConcurrentDictionary<string, int> counts = new();
    
    public void Increment(string key)
    {
        counts.AddOrUpdate(key, 1, (k, v) => v + 1); // No lock!
    }
}

// Thread-safe collection summary
// Collection              Type      Operations
// ConcurrentBag           Unordered Add, Take
// ConcurrentQueue         FIFO      Enqueue, TryDequeue
// ConcurrentStack         LIFO      Push, TryPop
// ConcurrentDictionary    K-V       Add, TryAdd, AddOrUpdate

// Practical: Producer-Consumer with ConcurrentQueue
public class ProducerConsumer
{
    private ConcurrentQueue<int> queue = new();
    
    public void ProduceItems()
    {
        for (int i = 0; i < 100; i++)
        {
            queue.Enqueue(i);
            Thread.Sleep(10);
        }
    }
    
    public void ConsumeItems()
    {
        while (true)
        {
            if (queue.TryDequeue(out var item))
            {
                Console.WriteLine($"Processing: {item}");
            }
            else
            {
                Thread.Sleep(100); // Wait for items
            }
        }
    }
}

// Usage
var pc = new ProducerConsumer();
var producer = Task.Run(() => pc.ProduceItems());
var consumer = Task.Run(() => pc.ConsumeItems());

// Important: Thread-safe collections don't make your code thread-safe!
// Example of race condition even with ConcurrentDictionary
var concurrentDict = new ConcurrentDictionary<string, int>();

// This is NOT atomic!
if (!concurrentDict.ContainsKey("key"))
{
    // Another thread could add "key" here!
    concurrentDict["key"] = 1;
}

// Correct approach using AddOrUpdate
concurrentDict.AddOrUpdate("key", 1, (k, v) => v + 1); // Atomic

// Performance tips:
// - ConcurrentDictionary is slower than Dictionary + lock
// - Use when you have high contention
// - Use regular collections with lock for low contention
// - Minimize time spent in critical sections`}]},{id:"q10",question:"How do you choose between different collection types? What are the selection criteria?",answer:"Choose based on: (1) Access pattern (random vs sequential), (2) Frequency of insert/delete, (3) Order preservation, (4) Duplicates allowed, (5) Key-value pairs needed, (6) Thread-safety required. Use flowchart: Need random access?  List. Need key-value?  Dictionary. Need unique?  HashSet. Need ordered?  SortedDictionary.",codeSnippets:[{language:"csharp",code:`using System;
using System.Collections.Generic;

// Selection Guide - Decision Tree

// 1. Do you need key-value pairs?
if (needKeyValue)
{
    // Yes -> Use Dictionary or SortedDictionary
    
    // Need sorted order?
    if (needSorted)
    {
        var dict = new SortedDictionary<string, int>(); // Sorted
    }
    else
    {
        var dict = new Dictionary<string, int>(); // Fast
    }
}
else
{
    // No -> Use List, HashSet, Queue, or Stack
    
    // Need random access by index?
    if (needRandomAccess)
    {
        var list = new List<int>(); // O(1) access
    }
    else
    {
        // Need unique items?
        if (needUnique)
        {
            // Need order?
            if (needOrder)
            {
                var set = new SortedSet<int>(); // Ordered, unique
            }
            else
            {
                var set = new HashSet<int>(); // Fast, unique
            }
        }
        else
        {
            // Need FIFO or LIFO?
            if (needFIFO)
            {
                var queue = new Queue<int>(); // FIFO
            }
            else if (needLIFO)
            {
                var stack = new Stack<int>(); // LIFO
            }
        }
    }
}

// Practical Scenarios

// Scenario 1: Cache user data by ID
// Need: Fast lookup by ID, key-value pairs
var userCache = new Dictionary<int, User>();
userCache[123] = new User { Name = "Alice" };
var user = userCache[123]; // Fast O(1)

// Scenario 2: Autocomplete suggestions
// Need: All matching items, starts with prefix
var autoComplete = new SortedSet<string>();
autoComplete.Add("Hello");
autoComplete.Add("Help");
var matches = autoComplete.Where(s => s.StartsWith("He"));

// Scenario 3: Process job queue
// Need: FIFO order, dequeue first item
var jobQueue = new Queue<Job>();
jobQueue.Enqueue(new Job { Name = "Task1" });
var nextJob = jobQueue.Dequeue();

// Scenario 4: Undo/Redo functionality
// Need: LIFO order for undo
var undoStack = new Stack<Action>();
undoStack.Push(() => Console.WriteLine("Undo action 1"));
var action = undoStack.Pop();

// Scenario 5: Remove duplicates
// Need: Unique items, fast membership testing
var uniqueUsers = new HashSet<User>(users, new UserIdComparer());

// Scenario 6: Sorted leaderboard
// Need: Sorted by score, range queries
var scores = new SortedSet<(string name, int score)>(
    new ScoreComparer());

// Scenario 7: Graph adjacency list
// Need: Multiple neighbors per node, order doesn't matter
var graph = new Dictionary<Node, List<Node>>();
graph[nodeA] = new List<Node> { nodeB, nodeC };

// Performance Comparison Table
Console.WriteLine("Collection Performance Comparison:");
Console.WriteLine("Operation          List    Dict    Hash    Queue   Stack");
Console.WriteLine("Add to end         O(1)    -       O(1)    O(1)    O(1)");
Console.WriteLine("Add to start       O(n)    -       -       -       -");
Console.WriteLine("Remove first       O(n)    -       -       O(1)    -");
Console.WriteLine("Remove last        O(1)    -       -       -       O(1)");
Console.WriteLine("Random access      O(1)    -       -       -       -");
Console.WriteLine("Contains           O(n)    O(1)    O(1)    O(n)    O(n)");
Console.WriteLine("Remove by value    O(n)    O(1)    O(1)    O(n)    O(n)");

// Selection Checklist
/*
List<T>:
 Need random access by index
 Maintain insertion order
 Mostly appending items
 Need Count, Insert, RemoveAt
 Large frequent insertions in middle
 Need unique items
 Need key-value association

Dictionary<K,V>:
 Need fast lookup by key
 Key-value association
 Most operations O(1)
 No required order
 Null keys
 Need sorted order
 Need unique values

HashSet<T>:
 Need unique items
 Need fast membership testing
 Don't care about order
 Set operations (Union, Intersect)
 Need sorted order
 Need random access
 Need to preserve duplicates

SortedSet<T>:
 Need unique items
 Need sorted order
 Need range queries
 Large frequent updates (slower)
 Need random access by index

Queue<T>:
 FIFO processing needed
 Task scheduling
 Fast operations
 Random access
 Need to access middle items

Stack<T>:
 LIFO processing needed
 Undo/Redo
 DFS algorithms
 Random access
 Need to access from bottom

LinkedList<T>:
 Frequent middle insertions
 Frequent removals by node
 Random access needed
 Memory overhead acceptable
 Large collections

SortedDictionary<K,V>:
 Need sorted key-value pairs
 Range queries on keys
 High performance needed
 Large frequent updates
*/

// Examples for different scenarios
public class SelectionExamples
{
    // Student grades management
    public void ManageGrades()
    {
        // Lookup grade by student ID
        var grades = new Dictionary<int, decimal>();
    }
    
    // Shopping cart items
    public void ShoppingCart()
    {
        // Add/remove items, maintain order
        var cart = new List<CartItem>();
    }
    
    // Blocked users
    public void BlockedUsers()
    {
        // Fast membership check
        var blocked = new HashSet<int>();
    }
    
    // Task processing
    public void ProcessTasks()
    {
        // Process in order received (FIFO)
        var queue = new Queue<Task>();
    }
    
    // Undo operations
    public void UndoOperations()
    {
        // Access last operation (LIFO)
        var undoStack = new Stack<Operation>();
    }
}`}]}]},Vy={id:"csharp-net-core",name:".NET Core",questions:[{id:"q1",question:"What is .NET Core and how is it different from .NET Framework?",answer:".NET Core is a cross-platform, open-source runtime for building modern applications. .NET Framework is Windows-only, older, not open-source. .NET Core runs on Windows, Linux, macOS. .NET Core is faster, lighter, modular. .NET Core 5+ is now called just '.NET'. Use .NET Core for new projects.",codeSnippets:[{language:"csharp",code:`// .NET Core Program.cs - Minimal hosting setup
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Hosting;

// Check .NET version at runtime
Console.WriteLine($".NET Version: {System.Runtime.InteropServices.RuntimeInformation.FrameworkDescription}");
// Output: .NET Version: .NET 7.0.0

// Simple .NET Core console app
var host = Host.CreateDefaultBuilder(args)
    .ConfigureServices(services =>
    {
        services.AddScoped<IGreeter, Greeter>();
    })
    .Build();

using (host)
{
    var greeter = host.Services.GetRequiredService<IGreeter>();
    greeter.Greet("World");
}

public interface IGreeter
{
    void Greet(string name);
}

public class Greeter : IGreeter
{
    public void Greet(string name)
    {
        Console.WriteLine($"Hello, {name}!");
    }
}

// Key differences comparison
Console.WriteLine("Comparison: .NET Core vs .NET Framework");
Console.WriteLine("Feature              .NET Core              .NET Framework");
Console.WriteLine("Cross-platform       Yes                    No (Windows only)");
Console.WriteLine("Open source          Yes                    No");
Console.WriteLine("Performance          Faster                 Slower");
Console.WriteLine("Size                 Lightweight            Heavy");
Console.WriteLine("NuGet                Modern                 Older");
Console.WriteLine("async/await          First class            Added later");
Console.WriteLine("Dependency inject    Built-in               Requires package");
Console.WriteLine("Latest version       .NET 8                 4.8 (legacy)");
Console.WriteLine("LTS                  .NET 8 (Nov 2024)      Not applicable");
Console.WriteLine("Active support       Yes                    Limited");

// .NET Core projects are simpler
// .NET Framework:
// <Project Sdk="Microsoft.NET.Sdk">
//   <TargetFramework>net472</TargetFramework>
// </Project>

// .NET Core (modern):
// <Project Sdk="Microsoft.NET.Sdk">
//   <TargetFramework>net8.0</TargetFramework>
// </Project>

// Package format changed
// .NET Framework: packages.config (XML)
// .NET Core: PackageReference in .csproj (cleaner)

// NuGet package restoration is automatic in .NET Core
// No need for "Update-Package" command`}]},{id:"q2",question:"What is Dependency Injection (DI) and how does it work in .NET Core?",answer:"DI is a pattern where dependencies are injected rather than created internally. .NET Core has built-in DI in IServiceCollection. Register services (singleton, scoped, transient). Inject via constructor. Singleton - one instance forever. Scoped - one per request. Transient - new instance each time.",codeSnippets:[{language:"csharp",code:`using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Hosting;

// ========== SERVICE REGISTRATION ==========
var services = new ServiceCollection();

// 1. SINGLETON - One instance for entire application
services.AddSingleton<IConfiguration>(new ConfigurationBuilder().Build());
// Expensive to create, stateless services

// 2. SCOPED - New instance per request (web apps)
services.AddScoped<IUserRepository, UserRepository>();
// Default for web apps, perfect for DbContext

// 3. TRANSIENT - New instance every time
services.AddTransient<ILogger, ConsoleLogger>();
// Lightweight, stateless objects

// ========== SERVICE INJECTION ==========
public class UserService
{
    private readonly IUserRepository repository;
    private readonly ILogger logger;
    
    // Constructor injection
    public UserService(IUserRepository repository, ILogger logger)
    {
        this.repository = repository;
        this.logger = logger;
    }
    
    public User GetUser(int id)
    {
        logger.Log($"Fetching user {id}");
        return repository.GetById(id);
    }
}

// ========== REAL EXAMPLE ==========
public interface IUserRepository
{
    User GetById(int id);
    void Save(User user);
}

public class UserRepository : IUserRepository
{
    public User GetById(int id)
    {
        return new User { Id = id, Name = "Alice" };
    }
    
    public void Save(User user)
    {
        Console.WriteLine($"Saving user: {user.Name}");
    }
}

public interface ILogger
{
    void Log(string message);
}

public class ConsoleLogger : ILogger
{
    public void Log(string message)
    {
        Console.WriteLine($"[LOG] {message}");
    }
}

public class User
{
    public int Id { get; set; }
    public string Name { get; set; }
}

// ========== SETUP PROGRAM ==========
var host = Host.CreateDefaultBuilder(args)
    .ConfigureServices(services =>
    {
        // Register dependencies
        services.AddSingleton<ILogger, ConsoleLogger>();
        services.AddScoped<IUserRepository, UserRepository>();
        services.AddScoped<UserService>();
    })
    .Build();

// Get service and use it
using (host)
{
    var userService = host.Services.GetRequiredService<UserService>();
    var user = userService.GetUser(1);
    Console.WriteLine(user.Name);
}

// ========== LIFETIME COMPARISON ==========
Console.WriteLine("Lifetime Comparison:");
Console.WriteLine("Lifetime    Instance   Use Case");
Console.WriteLine("Singleton   1 total    Config, logging factory, cache");
Console.WriteLine("Scoped      1/request  DbContext, unit of work");
Console.WriteLine("Transient   Always new Stateless utilities");

// ========== FACTORY PATTERN ==========
services.AddScoped<IUserRepository>(provider =>
{
    var logger = provider.GetRequiredService<ILogger>();
    return new UserRepository(); // Custom creation logic
});

// ========== IServiceProvider USAGE ==========
var serviceProvider = services.BuildServiceProvider();

// Resolve service
var logger = serviceProvider.GetRequiredService<ILogger>();
logger.Log("Application started");

// Try get service (doesn't throw if not found)
if (serviceProvider.GetService(typeof(IUserRepository)) is IUserRepository repo)
{
    Console.WriteLine("Repository found");
}

// ========== COMMON PITFALL: Captive dependency ==========
// BAD: Scoped dependency injected into Singleton
// services.AddSingleton<MySingleton>(); // Holds reference
// services.AddScoped<MyScoped>(); // Can't be scoped if singleton needs it

// GOOD: Inject IServiceProvider instead
public class BadSingleton
{
    private readonly IUserRepository repository; // WRONG!
    
    public BadSingleton(IUserRepository repository)
    {
        this.repository = repository; // Holds scoped object forever
    }
}

public class GoodSingleton
{
    private readonly IServiceProvider provider;
    
    public GoodSingleton(IServiceProvider provider)
    {
        this.provider = provider; // Can create new scopes
    }
    
    public User GetUser(int id)
    {
        using var scope = provider.CreateScope();
        var repo = scope.ServiceProvider.GetRequiredService<IUserRepository>();
        return repo.GetById(id);
    }
}`}]},{id:"q3",question:"What is the middleware pipeline in ASP.NET Core and how does it work?",answer:"Middleware is a component that processes HTTP requests/responses. They form a pipeline where each middleware can modify request/response or pass to next. Order matters - added in Program.cs in order. Request flows through, response comes back through (onion model). Common: logging, auth, CORS, error handling.",codeSnippets:[{language:"csharp",code:`using Microsoft.AspNetCore.Builder;
using Microsoft.AspNetCore.Http;

// ========== MIDDLEWARE PIPELINE SETUP ==========
var builder = WebApplication.CreateBuilder(args);
var app = builder.Build();

// Middleware order is important (top to bottom)
// 1. Exception handler must be FIRST
app.UseExceptionHandler("/error");

// 2. HTTPS redirect
app.UseHttpsRedirection();

// 3. Static files (before routing)
app.UseStaticFiles();

// 4. Routing
app.UseRouting();

// 5. Authentication
app.UseAuthentication();

// 6. Authorization
app.UseAuthorization();

// 7. Custom middleware
app.Use(async (context, next) =>
{
    Console.WriteLine($"Request: {context.Request.Path}");
    await next(); // Pass to next middleware
    Console.WriteLine($"Response: {context.Response.StatusCode}");
});

// 8. Endpoint mapping
app.MapGet("/", () => "Hello World");

app.Run();

// ========== CUSTOM MIDDLEWARE CLASS ==========
public class LoggingMiddleware
{
    private readonly RequestDelegate next;
    
    public LoggingMiddleware(RequestDelegate next)
    {
        this.next = next;
    }
    
    public async Task InvokeAsync(HttpContext context)
    {
        // Before request
        Console.WriteLine($"Incoming: {context.Request.Method} {context.Request.Path}");
        var startTime = DateTime.UtcNow;
        
        try
        {
            // Call next middleware
            await next(context);
        }
        finally
        {
            // After request (even if exception)
            var duration = DateTime.UtcNow - startTime;
            Console.WriteLine($"Outgoing: {context.Response.StatusCode} ({duration.TotalMilliseconds}ms)");
        }
    }
}

// Register custom middleware
app.UseMiddleware<LoggingMiddleware>();

// ========== MIDDLEWARE PIPELINE FLOW (ONION MODEL) ==========
// Request comes in
//  ExceptionHandler
//  HttpsRedirection
//  StaticFiles
//  Routing
//  Authentication
//  Authorization
//  Custom middleware
//  Endpoint handler
//  Response flows back up through same pipeline
// Response sent

// ========== INLINE MIDDLEWARE ==========
app.Use(async (context, next) =>
{
    // Modify request
    if (context.Request.Path == "/admin")
    {
        if (!context.User.Identity.IsAuthenticated)
        {
            context.Response.StatusCode = 401;
            await context.Response.WriteAsync("Unauthorized");
            return; // Don't call next - stop pipeline
        }
    }
    
    await next(); // Pass to next middleware
});

// ========== CONDITIONAL MIDDLEWARE ==========
if (app.Environment.IsDevelopment())
{
    app.UseDeveloperExceptionPage();
}
else
{
    app.UseExceptionHandler("/error");
}

// ========== SHORT-CIRCUIT MIDDLEWARE ==========
app.MapGet("/health", () => Results.Ok("Healthy"));
// Short-circuits - doesn't go through endpoint handler

// ========== MIDDLEWARE WITH OPTIONS ==========
app.UseCors(policy =>
{
    policy.AllowAnyOrigin()
          .AllowAnyMethod()
          .AllowAnyHeader();
});

// ========== TERMINAL MIDDLEWARE ==========
// Middleware that doesn't call next()
app.Run(async context =>
{
    // This terminates the pipeline
    await context.Response.WriteAsync("This is the end");
});

// Anything after app.Run() won't execute

// ========== BEST PRACTICES ==========
Console.WriteLine("Middleware Best Practices:");
Console.WriteLine("1. Exception handler FIRST");
Console.WriteLine("2. HTTPS before routing");
Console.WriteLine("3. Static files before routing");
Console.WriteLine("4. Auth/Authorization in order");
Console.WriteLine("5. Custom middleware before endpoints");
Console.WriteLine("6. Use try-finally to ensure cleanup");
Console.WriteLine("7. Call next() to pass to next middleware");
Console.WriteLine("8. Don't call next() to terminate pipeline");`}]},{id:"q4",question:"What is configuration management in .NET Core? How do you read app settings?",answer:"Configuration in .NET Core comes from multiple sources: appsettings.json, environment variables, command-line args. Use IConfiguration interface. Access nested values with ':' separator. Environment-specific files like appsettings.Development.json override defaults. Options pattern provides type-safe configuration access.",codeSnippets:[{language:"csharp",code:`using Microsoft.Extensions.Configuration;
using Microsoft.Extensions.Options;

// ========== BASIC CONFIGURATION SETUP ==========
var configuration = new ConfigurationBuilder()
    .SetBasePath(Directory.GetCurrentDirectory())
    .AddJsonFile("appsettings.json", optional: false, reloadOnChange: true)
    .AddJsonFile($"appsettings.{Environment.GetEnvironmentVariable("ASPNETCORE_ENVIRONMENT")}.json", optional: true)
    .AddEnvironmentVariables()
    .AddCommandLine(args)
    .Build();

// appsettings.json
/*
{
  "ConnectionStrings": {
    "DefaultConnection": "Server=localhost;Database=mydb;"
  },
  "Logging": {
    "LogLevel": {
      "Default": "Information",
      "Microsoft": "Warning"
    }
  },
  "AppSettings": {
    "ApiUrl": "https://api.example.com",
    "Timeout": 30,
    "EnableCache": true
  }
}
*/

// ========== READING CONFIGURATION ==========
// Access top-level keys
string? apiUrl = configuration["AppSettings:ApiUrl"];

// Access connection string
string? connString = configuration.GetConnectionString("DefaultConnection");

// Get nested value
string logLevel = configuration["Logging:LogLevel:Default"];

// Get with default value
string? cache = configuration["AppSettings:EnableCache"] ?? "false";

// ========== TYPE-SAFE CONFIGURATION (OPTIONS PATTERN) ==========
public class AppSettings
{
    public string ApiUrl { get; set; }
    public int Timeout { get; set; }
    public bool EnableCache { get; set; }
}

public class DatabaseSettings
{
    public string Host { get; set; }
    public int Port { get; set; }
    public string Database { get; set; }
}

// Register options in DI
var builder = WebApplication.CreateBuilder(args);
builder.Services.Configure<AppSettings>(configuration.GetSection("AppSettings"));
builder.Services.Configure<DatabaseSettings>(configuration.GetSection("Database"));

var app = builder.Build();

// ========== INJECTING OPTIONS ==========
public class MyService
{
    private readonly AppSettings settings;
    
    // Inject IOptions<T>
    public MyService(IOptions<AppSettings> options)
    {
        settings = options.Value; // Get typed settings
    }
    
    public void DoSomething()
    {
        Console.WriteLine($"API URL: {settings.ApiUrl}");
        Console.WriteLine($"Timeout: {settings.Timeout}");
    }
}

// Or use IOptionsMonitor for live reload
public class MyServiceWithMonitor
{
    private readonly IOptionsMonitor<AppSettings> monitor;
    
    public MyServiceWithMonitor(IOptionsMonitor<AppSettings> monitor)
    {
        this.monitor = monitor;
    }
    
    public void DoSomething()
    {
        var settings = monitor.CurrentValue; // Gets latest value
    }
}

// ========== ENVIRONMENT-SPECIFIC SETTINGS ==========
// appsettings.json (base)
// appsettings.Development.json (overrides)
// appsettings.Production.json (overrides)

// appsettings.Development.json
/*
{
  "Logging": {
    "LogLevel": {
      "Default": "Debug"
    }
  },
  "AppSettings": {
    "ApiUrl": "https://localhost:5001"
  }
}
*/

// Get current environment
var environment = builder.Environment;
Console.WriteLine($"Environment: {environment.EnvironmentName}");

if (environment.IsDevelopment())
{
    // Development-only setup
}
else if (environment.IsProduction())
{
    // Production-only setup
}

// ========== ENVIRONMENT VARIABLES ==========
// Set in system or via .env file
// var value = configuration["MyEnvVariable"];

// Override JSON with env vars
// Docker: Set environment variables
// Windows: setx MYKEY myvalue

// ========== COMMAND-LINE ARGUMENTS ==========
// dotnet run --AppSettings:ApiUrl="https://custom-api.com"
var customUrl = configuration["AppSettings:ApiUrl"];

// ========== CONFIGURATION VALIDATION ==========
public class ValidatedSettings
{
    [Range(1, 100)]
    public int Timeout { get; set; }
    
    [Required]
    public string ApiUrl { get; set; }
    
    [EmailAddress]
    public string AdminEmail { get; set; }
}

// Validate on startup
builder.Services.AddOptions<ValidatedSettings>()
    .BindConfiguration("AppSettings")
    .ValidateDataAnnotations()
    .ValidateOnStart(); // Fail fast

// ========== KEY VAULT INTEGRATION ==========
// For production secrets
var keyVaultUrl = new Uri("https://myvault.vault.azure.net/");
builder.Configuration.AddAzureKeyVault(
    keyVaultUrl,
    new DefaultAzureCredential()
);

// Secrets in Key Vault override JSON

// ========== CONFIGURATION BINDING ==========
var appSettings = configuration.GetSection("AppSettings").Get<AppSettings>();

// Now appSettings has typed values
Console.WriteLine($"URL: {appSettings.ApiUrl}");
Console.WriteLine($"Timeout: {appSettings.Timeout}");

// ========== RELOAD ON CHANGE ==========
// Set reloadOnChange: true
configuration.GetReloadToken().RegisterChangeCallback(_ =>
{
    Console.WriteLine("Configuration changed!");
}, null);`}]},{id:"q5",question:"What is Entity Framework Core (EF Core) and how does it differ from EF 6?",answer:"EF Core is a lightweight ORM for .NET Core. EF 6 is older ORM for .NET Framework. EF Core is faster, modular, supports multiple databases. EF Core has DbSet/DbContext for accessing databases. Use DbContext for queries and CRUD. EF Core supports LINQ-to-database queries.",codeSnippets:[{language:"csharp",code:`using Microsoft.EntityFrameworkCore;
using System.Collections.Generic;

// ========== DBCONTEXT ==========
public class ApplicationDbContext : DbContext
{
    public DbSet<User> Users { get; set; }
    public DbSet<Order> Orders { get; set; }
    
    protected override void OnConfiguring(DbContextOptionsBuilder options)
    {
        // Configure database
        options.UseSqlServer("Server=localhost;Database=mydb;");
    }
}

// ========== MODELS ==========
public class User
{
    public int Id { get; set; }
    public string Name { get; set; }
    public string Email { get; set; }
    
    // Navigation property
    public ICollection<Order> Orders { get; set; } = new List<Order>();
}

public class Order
{
    public int Id { get; set; }
    public int UserId { get; set; }
    public decimal Amount { get; set; }
    public DateTime CreatedDate { get; set; }
    
    // Foreign key relationship
    public User User { get; set; }
}

// ========== DEPENDENCY INJECTION SETUP ==========
var builder = WebApplication.CreateBuilder(args);

builder.Services.AddDbContext<ApplicationDbContext>(options =>
    options.UseSqlServer(
        builder.Configuration.GetConnectionString("DefaultConnection")
    )
);

var app = builder.Build();

// ========== CRUD OPERATIONS ==========
public class UserRepository
{
    private readonly ApplicationDbContext context;
    
    public UserRepository(ApplicationDbContext context)
    {
        this.context = context;
    }
    
    // CREATE
    public async Task<User> CreateUserAsync(User user)
    {
        context.Users.Add(user);
        await context.SaveChangesAsync();
        return user;
    }
    
    // READ
    public async Task<User> GetUserAsync(int id)
    {
        return await context.Users.FindAsync(id);
    }
    
    // READ ALL
    public async Task<List<User>> GetAllUsersAsync()
    {
        return await context.Users.ToListAsync();
    }
    
    // UPDATE
    public async Task<User> UpdateUserAsync(User user)
    {
        context.Users.Update(user);
        await context.SaveChangesAsync();
        return user;
    }
    
    // DELETE
    public async Task DeleteUserAsync(int id)
    {
        var user = await context.Users.FindAsync(id);
        if (user != null)
        {
            context.Users.Remove(user);
            await context.SaveChangesAsync();
        }
    }
}

// ========== LINQ QUERIES ==========
public class QueryExamples
{
    private readonly ApplicationDbContext context;
    
    public QueryExamples(ApplicationDbContext context)
    {
        this.context = context;
    }
    
    // Simple query
    public async Task<List<User>> GetActiveUsers()
    {
        return await context.Users
            .Where(u => u.Email.Contains("@example.com"))
            .ToListAsync();
    }
    
    // Join query
    public async Task<List<(User user, int orderCount)>> GetUsersWithOrderCount()
    {
        return await context.Users
            .Include(u => u.Orders)
            .Select(u => new ValueTuple<User, int>(u, u.Orders.Count))
            .ToListAsync();
    }
    
    // Aggregation
    public async Task<decimal> GetTotalOrderAmount()
    {
        return await context.Orders
            .SumAsync(o => o.Amount);
    }
    
    // Grouping
    public async Task<List<(int userId, decimal totalAmount)>> GetUserTotalOrders()
    {
        return await context.Orders
            .GroupBy(o => o.UserId)
            .Select(g => new ValueTuple<int, decimal>(g.Key, g.Sum(o => o.Amount)))
            .ToListAsync();
    }
}

// ========== MIGRATIONS ==========
// dotnet ef migrations add InitialCreate
// dotnet ef database update

// Migration file (auto-generated)
/*
public partial class InitialCreate : Migration
{
    protected override void Up(MigrationBuilder migrationBuilder)
    {
        migrationBuilder.CreateTable(
            name: "Users",
            columns: table => new
            {
                Id = table.Column<int>(nullable: false)
                    .Annotation("SqlServer:Identity", "1, 1"),
                Name = table.Column<string>(nullable: true),
                Email = table.Column<string>(nullable: true)
            }
        );
    }
}
*/

// ========== RELATIONSHIPS ==========
// One-to-Many: User has many Orders
public class UserWithOrders
{
    public int Id { get; set; }
    public string Name { get; set; }
    
    // One user, many orders
    public ICollection<Order> Orders { get; set; }
}

// Many-to-Many
public class Student
{
    public int Id { get; set; }
    public string Name { get; set; }
    
    // Many students, many courses
    public ICollection<StudentCourse> StudentCourses { get; set; }
}

public class Course
{
    public int Id { get; set; }
    public string Title { get; set; }
    
    public ICollection<StudentCourse> StudentCourses { get; set; }
}

public class StudentCourse
{
    public int StudentId { get; set; }
    public Student Student { get; set; }
    
    public int CourseId { get; set; }
    public Course Course { get; set; }
}

// ========== COMPARISON: EF 6 vs EF CORE ==========
Console.WriteLine("EF 6 vs EF Core:");
Console.WriteLine("Feature              EF 6                EF Core");
Console.WriteLine("Platform             .NET Framework      .NET Core/.NET");
Console.WriteLine("Performance          Slower              Faster");
Console.WriteLine("LINQ support         Full                Most features");
Console.WriteLine("Database support     SQL Server mainly   Multiple databases");
Console.WriteLine("Async                Limited             First-class");
Console.WriteLine("Lightweight          Heavy               Lightweight");
Console.WriteLine("Open source          No                  Yes");
Console.WriteLine("Active development   Limited             Active");

// ========== BEST PRACTICES ==========
// 1. Use async operations
await userRepository.GetAllUsersAsync();

// 2. Use Include for eager loading
context.Users.Include(u => u.Orders).ToList();

// 3. Use Select for projection (reduce data)
context.Users
    .Select(u => new { u.Id, u.Name })
    .ToList();

// 4. Avoid N+1 queries
// BAD:
foreach (var user in context.Users)
{
    var orders = context.Orders.Where(o => o.UserId == user.Id);
}

// GOOD:
var users = context.Users.Include(u => u.Orders);

// 5. Use DbContextFactory for multi-tenancy or complex scenarios
var factory = new PooledDbContextFactory<ApplicationDbContext>(options);`}]},{id:"q6",question:"What is ASP.NET Core and how is it different from ASP.NET Framework?",answer:"ASP.NET Core is modern, cross-platform web framework for .NET Core. ASP.NET Framework is older, Windows-only. ASP.NET Core is faster, unified platform (MVC, Web API, SignalR together), supports microservices. ASP.NET Core uses Kestrel web server (lightweight). Built on dependency injection and middleware.",codeSnippets:[{language:"csharp",code:`using Microsoft.AspNetCore.Builder;
using Microsoft.AspNetCore.Mvc;
using Microsoft.Extensions.DependencyInjection;

// ========== ASPNET CORE PROJECT SETUP ==========
var builder = WebApplication.CreateBuilder(args);

// Add services
builder.Services.AddControllers();
builder.Services.AddScoped<IUserService, UserService>();
builder.Services.AddCors(options =>
{
    options.AddPolicy("AllowAll", policy =>
        policy.AllowAnyOrigin().AllowAnyMethod().AllowAnyHeader()
    );
});

var app = builder.Build();

// Configure middleware pipeline
app.UseCors("AllowAll");
app.UseRouting();
app.MapControllers();

app.Run();

// ========== MINIMAL API (ASP.NET Core 6+) ==========
var builder2 = WebApplication.CreateBuilder(args);
var app2 = builder2.Build();

// Define API without controllers
app2.MapGet("/api/users/{id}", async (int id, IUserService service) =>
{
    var user = await service.GetUserAsync(id);
    return user is null ? Results.NotFound() : Results.Ok(user);
});

app2.MapPost("/api/users", async (CreateUserRequest request, IUserService service) =>
{
    var user = await service.CreateUserAsync(request.Name, request.Email);
    return Results.Created($"/api/users/{user.Id}", user);
});

app2.Run();

// ========== CONTROLLER-BASED API ==========
[ApiController]
[Route("api/[controller]")]
public class UsersController : ControllerBase
{
    private readonly IUserService userService;
    
    public UsersController(IUserService userService)
    {
        this.userService = userService;
    }
    
    [HttpGet("{id}")]
    public async Task<ActionResult<User>> GetUser(int id)
    {
        var user = await userService.GetUserAsync(id);
        if (user is null)
            return NotFound();
        
        return Ok(user);
    }
    
    [HttpGet]
    public async Task<ActionResult<List<User>>> GetAllUsers()
    {
        var users = await userService.GetAllUsersAsync();
        return Ok(users);
    }
    
    [HttpPost]
    public async Task<ActionResult<User>> CreateUser(CreateUserRequest request)
    {
        var user = await userService.CreateUserAsync(request.Name, request.Email);
        return CreatedAtAction(nameof(GetUser), new { id = user.Id }, user);
    }
    
    [HttpPut("{id}")]
    public async Task<IActionResult> UpdateUser(int id, UpdateUserRequest request)
    {
        var user = await userService.UpdateUserAsync(id, request.Name, request.Email);
        if (user is null)
            return NotFound();
        
        return NoContent();
    }
    
    [HttpDelete("{id}")]
    public async Task<IActionResult> DeleteUser(int id)
    {
        var success = await userService.DeleteUserAsync(id);
        if (!success)
            return NotFound();
        
        return NoContent();
    }
}

// ========== SERVICES ==========
public interface IUserService
{
    Task<User> GetUserAsync(int id);
    Task<List<User>> GetAllUsersAsync();
    Task<User> CreateUserAsync(string name, string email);
    Task<User> UpdateUserAsync(int id, string name, string email);
    Task<bool> DeleteUserAsync(int id);
}

public class UserService : IUserService
{
    private readonly ApplicationDbContext context;
    
    public UserService(ApplicationDbContext context)
    {
        this.context = context;
    }
    
    public async Task<User> GetUserAsync(int id)
    {
        return await context.Users.FindAsync(id);
    }
    
    public async Task<List<User>> GetAllUsersAsync()
    {
        return await context.Users.ToListAsync();
    }
    
    public async Task<User> CreateUserAsync(string name, string email)
    {
        var user = new User { Name = name, Email = email };
        context.Users.Add(user);
        await context.SaveChangesAsync();
        return user;
    }
    
    public async Task<User> UpdateUserAsync(int id, string name, string email)
    {
        var user = await context.Users.FindAsync(id);
        if (user is null)
            return null;
        
        user.Name = name;
        user.Email = email;
        await context.SaveChangesAsync();
        return user;
    }
    
    public async Task<bool> DeleteUserAsync(int id)
    {
        var user = await context.Users.FindAsync(id);
        if (user is null)
            return false;
        
        context.Users.Remove(user);
        await context.SaveChangesAsync();
        return true;
    }
}

// ========== REQUEST/RESPONSE MODELS ==========
public record User(int Id, string Name, string Email);

public record CreateUserRequest(string Name, string Email);

public record UpdateUserRequest(string Name, string Email);

// ========== COMPARISON: ASP.NET Core vs ASP.NET Framework ==========
Console.WriteLine("ASP.NET Core vs ASP.NET Framework:");
Console.WriteLine("Feature              ASP.NET Core        ASP.NET Framework");
Console.WriteLine("Cross-platform       Yes                 No (Windows only)");
Console.WriteLine("Performance          Faster              Slower");
Console.WriteLine("Web server           Kestrel             IIS");
Console.WriteLine("Framework unification Yes (MVC/API)      Separate");
Console.WriteLine("DI built-in          Yes                 No");
Console.WriteLine("Middleware pipeline  Modern              Limited");
Console.WriteLine("Microservices        Built for it        Not ideal");
Console.WriteLine("Latest version       Latest              4.8 (legacy)");
Console.WriteLine("Active development   Yes                 Limited");

// ========== KEY FEATURES ==========
// 1. Kestrel - lightweight, cross-platform web server
// 2. Dependency Injection - built-in
// 3. Middleware - powerful request pipeline
// 4. Unified platform - MVC, Web API, SignalR together
// 5. Configuration - multiple sources
// 6. Logging - built-in
// 7. Health checks - built-in
// 8. Authentication/Authorization - integrated
// 9. CORS - integrated
// 10. Async/await - first class`}]},{id:"q7",question:"What are the different hosting models in .NET Core? Console, Web, Windows Service, Docker?",answer:"Console app - simple command-line app. Web app - ASP.NET Core with Kestrel. Windows Service - runs in background on Windows. Docker - containerized app for any platform. Cloud - Azure App Service, AWS. Each model uses Host.CreateDefaultBuilder() for dependency injection and configuration.",codeSnippets:[{language:"csharp",code:`using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Hosting;

// ========== 1. CONSOLE APPLICATION ==========
// Program.cs for console app
var host = Host.CreateDefaultBuilder(args)
    .ConfigureServices(services =>
    {
        services.AddScoped<IGreeterService, GreeterService>();
    })
    .Build();

using (host)
{
    var greeter = host.Services.GetRequiredService<IGreeterService>();
    greeter.Greet("World");
}

Console.WriteLine("Console app finished");

// ========== 2. BACKGROUND SERVICE / WORKER SERVICE ==========
// Program.cs for worker service
var builder = Host.CreateDefaultBuilder(args)
    .ConfigureServices(services =>
    {
        services.AddHostedService<MyBackgroundWorker>();
    });

var host2 = builder.Build();
await host2.RunAsync(); // Runs indefinitely

public class MyBackgroundWorker : BackgroundService
{
    private readonly ILogger<MyBackgroundWorker> logger;
    
    public MyBackgroundWorker(ILogger<MyBackgroundWorker> logger)
    {
        this.logger = logger;
    }
    
    protected override async Task ExecuteAsync(CancellationToken stoppingToken)
    {
        while (!stoppingToken.IsCancellationRequested)
        {
            logger.LogInformation("Worker executing at: {time}", DateTimeOffset.Now);
            
            // Do background work
            await Task.Delay(1000, stoppingToken);
        }
    }
    
    public override async Task StartAsync(CancellationToken cancellationToken)
    {
        logger.LogInformation("Worker starting");
        await base.StartAsync(cancellationToken);
    }
    
    public override async Task StopAsync(CancellationToken cancellationToken)
    {
        logger.LogInformation("Worker stopping");
        await base.StopAsync(cancellationToken);
    }
}

// ========== 3. WEB APPLICATION (ASP.NET Core) ==========
// Program.cs for web app
var builder3 = WebApplication.CreateBuilder(args);

builder3.Services.AddControllers();

var app = builder3.Build();

app.UseRouting();
app.MapControllers();

await app.RunAsync();

// ========== 4. WINDOWS SERVICE ==========
// Program.cs for Windows Service
var builder4 = Host.CreateDefaultBuilder(args)
    .UseWindowsService()
    .ConfigureServices(services =>
    {
        services.AddHostedService<MyWindowsService>();
    });

var host4 = builder4.Build();
await host4.RunAsync();

public class MyWindowsService : BackgroundService
{
    private readonly ILogger<MyWindowsService> logger;
    
    public MyWindowsService(ILogger<MyWindowsService> logger)
    {
        this.logger = logger;
    }
    
    protected override async Task ExecuteAsync(CancellationToken stoppingToken)
    {
        while (!stoppingToken.IsCancellationRequested)
        {
            logger.LogInformation("Windows Service running");
            await Task.Delay(5000, stoppingToken);
        }
    }
}

// Install as Windows Service:
// sc create MyService binPath= "C:\\path\\to\\app.exe"
// net start MyService

// ========== 5. DOCKER CONTAINER ==========
// Dockerfile
/*
FROM mcr.microsoft.com/dotnet/sdk:8.0 AS build
WORKDIR /src
COPY ["MyApp.csproj", "."]
RUN dotnet restore "MyApp.csproj"
COPY . .
RUN dotnet build "MyApp.csproj" -c Release -o /app/build

FROM mcr.microsoft.com/dotnet/runtime:8.0
WORKDIR /app
COPY --from=build /app/build .
ENTRYPOINT ["dotnet", "MyApp.dll"]
*/

// docker build -t myapp:latest .
// docker run myapp:latest

// ========== 6. CLOUD HOSTING (AZURE) ==========
// Deploy to Azure App Service
// dotnet publish -c Release -o ./publish
// Upload publish folder to Azure

// appsettings.json - read from Azure Key Vault
var builder5 = WebApplication.CreateBuilder(args);

var keyVaultUrl = new Uri(builder5.Configuration["KeyVault:Url"]);
builder5.Configuration.AddAzureKeyVault(
    keyVaultUrl,
    new DefaultAzureCredential()
);

// ========== HOSTING COMPARISON ==========
Console.WriteLine("Hosting Models Comparison:");
Console.WriteLine("Model               Lifetime      Use Case");
Console.WriteLine("Console             Finite        One-off tasks, utilities");
Console.WriteLine("Worker Service      Infinite      Background jobs, processing");
Console.WriteLine("Web App             Infinite      REST APIs, web sites");
Console.WriteLine("Windows Service     Infinite      Long-running Windows tasks");
Console.WriteLine("Docker              Container     Microservices, cloud");
Console.WriteLine("Cloud               Managed       Scalable production apps");

// ========== TYPICAL WEB APP STRUCTURE ==========
// Program.cs (entry point)
// appsettings.json (config)
// Startup.cs (optional - alternative to Program.cs)
// Controllers/ (request handlers)
// Services/ (business logic)
// Models/ (data models)
// Data/ (DbContext)
// Middleware/ (custom)

// ========== CHECKING HOSTING ENVIRONMENT ==========
var env = builder3.Environment;

if (env.IsDevelopment())
{
    // Development setup
}
else if (env.IsStaging())
{
    // Staging setup
}
else if (env.IsProduction())
{
    // Production setup
}

var customEnv = env.IsEnvironment("CustomEnv");

// Set environment variable:
// Windows: set ASPNETCORE_ENVIRONMENT=Production
// Linux: export ASPNETCORE_ENVIRONMENT=Production
// Docker: ENV ASPNETCORE_ENVIRONMENT=Production`}]},{id:"q8",question:"What is logging in .NET Core and how do you configure it?",answer:"Logging is built into .NET Core using ILogger interface. Configure in Program.cs with AddLogging(). Multiple providers: Console, Debug, EventLog, Trace, Application Insights. Log levels: Trace, Debug, Information, Warning, Error, Critical, None. Use dependency injection to inject ILogger into classes.",codeSnippets:[{language:"csharp",code:`using Microsoft.Extensions.Logging;

// ========== LOGGING SETUP IN PROGRAM.CS ==========
var builder = WebApplication.CreateBuilder(args);

builder.Services.AddLogging(config =>
{
    config.ClearProviders(); // Remove default providers
    config.AddConsole(); // Console output
    config.AddDebug(); // Debug output
    config.AddEventLog(); // Windows Event Log
    
    // Set minimum log level
    config.SetMinimumLevel(LogLevel.Information);
});

var app = builder.Build();

// Configuration via appsettings.json (preferred)
/*
{
  "Logging": {
    "LogLevel": {
      "Default": "Information",
      "Microsoft": "Warning",
      "System": "Error"
    }
  }
}
*/

// ========== USING LOGGER ==========
public class UserService
{
    private readonly ILogger<UserService> logger;
    
    public UserService(ILogger<UserService> logger)
    {
        this.logger = logger;
    }
    
    public void CreateUser(string name)
    {
        // Log levels (severity)
        logger.LogTrace("Trace: Very detailed info");
        logger.LogDebug($"Debug: Creating user: {name}");
        logger.LogInformation($"Information: User created: {name}");
        logger.LogWarning("Warning: Potential issue");
        logger.LogError(new Exception(), "Error: Something failed");
        logger.LogCritical("Critical: System failure");
    }
}

// ========== LOG LEVELS EXPLAINED ==========
Console.WriteLine("Log Levels (Severity Order):");
Console.WriteLine("1. Trace - Very detailed diagnostic info");
Console.WriteLine("2. Debug - Debug information");
Console.WriteLine("3. Information - General informational messages");
Console.WriteLine("4. Warning - Warning messages (don't fail)");
Console.WriteLine("5. Error - Error messages (operation fails)");
Console.WriteLine("6. Critical - Critical errors (system may fail)");
Console.WriteLine("7. None - No logging");

// ========== STRUCTURED LOGGING ==========
public class OrderService
{
    private readonly ILogger<OrderService> logger;
    
    public OrderService(ILogger<OrderService> logger)
    {
        this.logger = logger;
    }
    
    public void ProcessOrder(int orderId, string customerName, decimal amount)
    {
        // Log with named parameters (structured)
        logger.LogInformation(
            "Processing order {OrderId} for customer {Customer} with amount {Amount}",
            orderId,
            customerName,
            amount
        );
        
        // Structured logging is searchable and filterable
    }
}

// ========== EXCEPTION LOGGING ==========
public class PaymentService
{
    private readonly ILogger<PaymentService> logger;
    
    public PaymentService(ILogger<PaymentService> logger)
    {
        this.logger = logger;
    }
    
    public void ProcessPayment(decimal amount)
    {
        try
        {
            // Process payment
            if (amount <= 0)
                throw new InvalidOperationException("Invalid amount");
        }
        catch (Exception ex)
        {
            // Log exception with details
            logger.LogError(ex, "Payment processing failed for amount {Amount}", amount);
            throw;
        }
    }
}

// ========== LOGGING WITH SCOPE ==========
public class RequestLoggingMiddleware
{
    private readonly RequestDelegate next;
    private readonly ILogger logger;
    
    public RequestLoggingMiddleware(RequestDelegate next, ILogger<RequestLoggingMiddleware> logger)
    {
        this.next = next;
        this.logger = logger;
    }
    
    public async Task InvokeAsync(HttpContext context)
    {
        // Create scope with request ID
        var requestId = context.TraceIdentifier;
        
        using (logger.BeginScope(new Dictionary<string, object>
        {
            { "RequestId", requestId },
            { "User", context.User?.Identity?.Name ?? "Anonymous" }
        }))
        {
            logger.LogInformation("Request started: {Method} {Path}", 
                context.Request.Method, 
                context.Request.Path);
            
            try
            {
                await next(context);
                logger.LogInformation("Request completed: {StatusCode}", 
                    context.Response.StatusCode);
            }
            catch (Exception ex)
            {
                logger.LogError(ex, "Request failed with exception");
                throw;
            }
        }
    }
}

// ========== CUSTOM LOGGER PROVIDER ==========
public class CustomLoggerProvider : ILoggerProvider
{
    public ILogger CreateLogger(string categoryName)
    {
        return new CustomLogger(categoryName);
    }
    
    public void Dispose() { }
}

public class CustomLogger : ILogger
{
    private readonly string categoryName;
    
    public CustomLogger(string categoryName)
    {
        this.categoryName = categoryName;
    }
    
    public IDisposable BeginScope<TState>(TState state) => null;
    
    public bool IsEnabled(LogLevel logLevel) => true;
    
    public void Log<TState>(
        LogLevel logLevel,
        EventId eventId,
        TState state,
        Exception exception,
        Func<TState, Exception, string> formatter)
    {
        var message = formatter(state, exception);
        File.AppendAllText("logs.txt", 
            $"[{DateTime.UtcNow:O}] [{logLevel}] {categoryName}: {message}
");
    }
}

// Register custom provider
builder.Services.AddLogging(config =>
{
    config.AddProvider(new CustomLoggerProvider());
});

// ========== THIRD-PARTY LOGGING (SERILOG) ==========
// Install: dotnet add package Serilog.AspNetCore

using Serilog;

Log.Logger = new LoggerConfiguration()
    .MinimumLevel.Debug()
    .WriteTo.Console()
    .WriteTo.File("logs/log-.txt", rollingInterval: RollingInterval.Day)
    .CreateLogger();

try
{
    Log.Information("Application starting");
    var builder2 = WebApplication.CreateBuilder(args);
    builder2.Host.UseSerilog();
    
    var app2 = builder2.Build();
    await app2.RunAsync();
}
catch (Exception ex)
{
    Log.Fatal(ex, "Application terminated unexpectedly");
}
finally
{
    await Log.CloseAndFlushAsync();
}

// ========== BEST PRACTICES ==========
Console.WriteLine("Logging Best Practices:");
Console.WriteLine("1. Use appropriate log levels");
Console.WriteLine("2. Use structured logging with parameters");
Console.WriteLine("3. Log exceptions with context");
Console.WriteLine("4. Use scopes for correlation IDs");
Console.WriteLine("5. Don't log sensitive data");
Console.WriteLine("6. Use centralized logging (Application Insights, ELK)");
Console.WriteLine("7. Set appropriate minimum log levels per environment");
Console.WriteLine("8. Use correlation IDs for request tracing");
Console.WriteLine("9. Don't log in hot paths (performance)");
Console.WriteLine("10. Use async logging for production");`}]},{id:"q9",question:"What is a hosted service in .NET Core? How do you create background tasks?",answer:"Hosted service implements IHostedService, runs when app starts. Use BackgroundService abstract class (simpler). Methods: StartAsync (when app starts), StopAsync (when app stops). Use ExecuteAsync for the work loop. Register in DI with AddHostedService<T>(). Perfect for background jobs, timers, message consumers.",codeSnippets:[{language:"csharp",code:`using Microsoft.Extensions.Hosting;
using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Logging;

// ========== SIMPLE BACKGROUND SERVICE ==========
public class TimerBackgroundService : BackgroundService
{
    private readonly ILogger<TimerBackgroundService> logger;
    private Timer timer;
    
    public TimerBackgroundService(ILogger<TimerBackgroundService> logger)
    {
        this.logger = logger;
    }
    
    protected override async Task ExecuteAsync(CancellationToken stoppingToken)
    {
        logger.LogInformation("Timer service starting");
        
        timer = new Timer(DoWork, null, TimeSpan.Zero, TimeSpan.FromSeconds(10));
        
        // Keep running until cancellation requested
        await Task.Delay(Timeout.Infinite, stoppingToken);
    }
    
    private void DoWork(object state)
    {
        logger.LogInformation("Timer work executing at: {time}", DateTimeOffset.Now);
        
        // Do background work
    }
    
    public override async Task StopAsync(CancellationToken cancellationToken)
    {
        logger.LogInformation("Timer service stopping");
        timer?.Dispose();
        await base.StopAsync(cancellationToken);
    }
}

// Register in Program.cs
var builder = Host.CreateDefaultBuilder(args)
    .ConfigureServices(services =>
    {
        services.AddHostedService<TimerBackgroundService>();
    });

var host = builder.Build();
await host.RunAsync();

// ========== QUEUE PROCESSING SERVICE ==========
public class QueueProcessingService : BackgroundService
{
    private readonly ILogger<QueueProcessingService> logger;
    private readonly IServiceProvider serviceProvider;
    private readonly Channel<QueueItem> queue;
    
    public QueueProcessingService(ILogger<QueueProcessingService> logger, IServiceProvider serviceProvider)
    {
        this.logger = logger;
        this.serviceProvider = serviceProvider;
        queue = Channel.CreateUnbounded<QueueItem>();
    }
    
    public async ValueTask EnqueueAsync(QueueItem item)
    {
        await queue.Writer.WriteAsync(item);
    }
    
    protected override async Task ExecuteAsync(CancellationToken stoppingToken)
    {
        logger.LogInformation("Queue processor starting");
        
        await foreach (var item in queue.Reader.ReadAllAsync(stoppingToken))
        {
            try
            {
                // Create scope for processing
                using var scope = serviceProvider.CreateScope();
                var processor = scope.ServiceProvider.GetRequiredService<IQueueItemProcessor>();
                
                await processor.ProcessAsync(item);
                logger.LogInformation("Processed queue item: {ItemId}", item.Id);
            }
            catch (Exception ex)
            {
                logger.LogError(ex, "Error processing queue item: {ItemId}", item.Id);
            }
        }
    }
}

public class QueueItem
{
    public string Id { get; set; }
    public string Data { get; set; }
}

public interface IQueueItemProcessor
{
    Task ProcessAsync(QueueItem item);
}

public class QueueItemProcessor : IQueueItemProcessor
{
    private readonly ILogger<QueueItemProcessor> logger;
    
    public QueueItemProcessor(ILogger<QueueItemProcessor> logger)
    {
        this.logger = logger;
    }
    
    public async Task ProcessAsync(QueueItem item)
    {
        logger.LogInformation("Processing item: {ItemId}", item.Id);
        await Task.Delay(100); // Simulate work
    }
}

// Register
builder.Services.AddSingleton<QueueProcessingService>();
builder.Services.AddHostedService(provider => provider.GetRequiredService<QueueProcessingService>());
builder.Services.AddScoped<IQueueItemProcessor, QueueItemProcessor>();

// ========== PERIODIC TASK SERVICE ==========
public class PeriodicTaskService : BackgroundService
{
    private readonly ILogger<PeriodicTaskService> logger;
    private readonly IServiceProvider serviceProvider;
    
    public PeriodicTaskService(ILogger<PeriodicTaskService> logger, IServiceProvider serviceProvider)
    {
        this.logger = logger;
        this.serviceProvider = serviceProvider;
    }
    
    protected override async Task ExecuteAsync(CancellationToken stoppingToken)
    {
        logger.LogInformation("Periodic task service starting");
        
        while (!stoppingToken.IsCancellationRequested)
        {
            try
            {
                // Calculate next execution time (e.g., next midnight)
                var now = DateTime.UtcNow;
                var nextRun = now.Date.AddDays(1); // Tomorrow midnight
                var delay = nextRun - now;
                
                await Task.Delay(delay, stoppingToken);
                
                // Execute periodic task
                using var scope = serviceProvider.CreateScope();
                var taskExecutor = scope.ServiceProvider.GetRequiredService<IPeriodicTaskExecutor>();
                
                await taskExecutor.ExecuteAsync();
                logger.LogInformation("Periodic task executed successfully");
            }
            catch (Exception ex)
            {
                logger.LogError(ex, "Error executing periodic task");
            }
        }
    }
}

public interface IPeriodicTaskExecutor
{
    Task ExecuteAsync();
}

// ========== LONG-RUNNING TASK SERVICE ==========
public class DataSyncService : BackgroundService
{
    private readonly ILogger<DataSyncService> logger;
    private readonly IDataRepository repository;
    private readonly IExternalDataService externalService;
    
    public DataSyncService(ILogger<DataSyncService> logger, IDataRepository repository, IExternalDataService externalService)
    {
        this.logger = logger;
        this.repository = repository;
        this.externalService = externalService;
    }
    
    protected override async Task ExecuteAsync(CancellationToken stoppingToken)
    {
        logger.LogInformation("Data sync service starting");
        
        while (!stoppingToken.IsCancellationRequested)
        {
            try
            {
                // Sync data
                var externalData = await externalService.FetchDataAsync();
                await repository.UpdateAsync(externalData);
                
                logger.LogInformation("Data sync completed. Records: {Count}", externalData.Count());
                
                // Wait before next sync
                await Task.Delay(TimeSpan.FromHours(1), stoppingToken);
            }
            catch (OperationCanceledException)
            {
                logger.LogInformation("Data sync cancelled");
                break;
            }
            catch (Exception ex)
            {
                logger.LogError(ex, "Error during data sync");
                // Wait before retry
                await Task.Delay(TimeSpan.FromSeconds(30), stoppingToken);
            }
        }
    }
    
    public override async Task StopAsync(CancellationToken cancellationToken)
    {
        logger.LogInformation("Data sync service stopping");
        await base.StopAsync(cancellationToken);
    }
}

public interface IDataRepository
{
    Task UpdateAsync(IEnumerable<dynamic> data);
}

public interface IExternalDataService
{
    Task<IEnumerable<dynamic>> FetchDataAsync();
}

// ========== BEST PRACTICES ==========
Console.WriteLine("Hosted Service Best Practices:");
Console.WriteLine("1. Always use CancellationToken for graceful shutdown");
Console.WriteLine("2. Create scopes for dependency injection");
Console.WriteLine("3. Log start and stop events");
Console.WriteLine("4. Handle exceptions gracefully");
Console.WriteLine("5. Implement backoff for retries");
Console.WriteLine("6. Use async/await for all I/O operations");
Console.WriteLine("7. Don't block in ExecuteAsync");
Console.WriteLine("8. Monitor service health");
Console.WriteLine("9. Use configuration for intervals/settings");
Console.WriteLine("10. Test services independently");`}]},{id:"q10",question:"What is an extension method in C#? How do you create and use them?",answer:"Extension method adds functionality to existing types without inheritance. Must be in static class, first parameter has 'this' keyword. Allows calling like instance method. Useful for adding helpers to built-in types. Cannot access private members. Used extensively in LINQ (Where, Select, etc.).",codeSnippets:[{language:"csharp",code:`using System;
using System.Collections.Generic;
using System.Linq;

// ========== BASIC EXTENSION METHOD ==========
public static class StringExtensions
{
    // Extension method adds method to string
    public static string Reverse(this string str)
    {
        char[] charArray = str.ToCharArray();
        Array.Reverse(charArray);
        return new string(charArray);
    }
    
    public static string ToTitleCase(this string str)
    {
        return System.Globalization.CultureInfo.CurrentCulture
            .TextInfo.ToTitleCase(str.ToLower());
    }
    
    public static bool IsPalindrome(this string str)
    {
        var cleaned = System.Text.RegularExpressions.Regex.Replace(str, "[^a-zA-Z0-9]", "").ToLower();
        return cleaned == cleaned.Reverse();
    }
    
    public static string RepeatString(this string str, int times)
    {
        return string.Concat(Enumerable.Repeat(str, times));
    }
}

// Usage
var text = "Hello World";
Console.WriteLine(text.Reverse()); // dlroW olleH
Console.WriteLine(text.ToTitleCase()); // Hello World
Console.WriteLine("racecar".IsPalindrome()); // true
Console.WriteLine("x".RepeatString(5)); // xxxxx

// ========== EXTENSION ON COLLECTIONS ==========
public static class ListExtensions
{
    public static List<T> AddRange<T>(this List<T> list, params T[] items)
    {
        foreach (var item in items)
        {
            list.Add(item);
        }
        return list; // Fluent
    }
    
    public static bool IsNullOrEmpty<T>(this IEnumerable<T> source)
    {
        return source == null || !source.Any();
    }
    
    public static T GetRandom<T>(this IList<T> list)
    {
        var random = new Random();
        return list[random.Next(list.Count)];
    }
    
    public static List<T> Shuffle<T>(this List<T> list)
    {
        var random = new Random();
        for (int i = list.Count - 1; i > 0; i--)
        {
            int randomIndex = random.Next(i + 1);
            // Swap
            (list[i], list[randomIndex]) = (list[randomIndex], list[i]);
        }
        return list;
    }
    
    public static void ForEach<T>(this IEnumerable<T> source, Action<T> action)
    {
        foreach (var item in source)
        {
            action(item);
        }
    }
}

// Usage
var numbers = new List<int> { 1, 2, 3 };
numbers.AddRange(4, 5, 6);
Console.WriteLine(numbers.Count); // 6

var random = numbers.GetRandom();

numbers.Shuffle();

var names = new List<string> { "Alice", "Bob", "Charlie" };
names.ForEach(n => Console.WriteLine(n)); // Print each

// ========== EXTENSION ON NUMERIC TYPES ==========
public static class NumericExtensions
{
    public static bool IsEven(this int number)
    {
        return number % 2 == 0;
    }
    
    public static bool IsOdd(this int number)
    {
        return number % 2 != 0;
    }
    
    public static int Square(this int number)
    {
        return number * number;
    }
    
    public static bool IsPrime(this int number)
    {
        if (number < 2) return false;
        for (int i = 2; i <= Math.Sqrt(number); i++)
        {
            if (number % i == 0) return false;
        }
        return true;
    }
    
    public static TimeSpan Days(this int days)
    {
        return TimeSpan.FromDays(days);
    }
}

// Usage
Console.WriteLine(5.IsEven()); // false
Console.WriteLine(5.IsOdd()); // true
Console.WriteLine(5.Square()); // 25
Console.WriteLine(17.IsPrime()); // true

var futureDate = DateTime.Now.Add(7.Days());

// ========== EXTENSION ON DATETIME ==========
public static class DateTimeExtensions
{
    public static bool IsWeekend(this DateTime date)
    {
        return date.DayOfWeek == DayOfWeek.Saturday || 
               date.DayOfWeek == DayOfWeek.Sunday;
    }
    
    public static DateTime StartOfDay(this DateTime date)
    {
        return date.Date;
    }
    
    public static DateTime EndOfDay(this DateTime date)
    {
        return date.Date.AddDays(1).AddTicks(-1);
    }
    
    public static int GetAge(this DateTime birthDate)
    {
        var today = DateTime.Today;
        var age = today.Year - birthDate.Year;
        if (birthDate.Date > today.AddYears(-age)) age--;
        return age;
    }
}

// Usage
var today = DateTime.Now;
Console.WriteLine(today.IsWeekend()); // Depends on day
Console.WriteLine(today.StartOfDay()); // Today at 00:00:00
Console.WriteLine(today.EndOfDay()); // Today at 23:59:59

var birthDate = new DateTime(1990, 5, 15);
Console.WriteLine(birthDate.GetAge()); // Age in years

// ========== CHAINABLE (FLUENT) EXTENSIONS ==========
public static class FluentExtensions
{
    public static T Also<T>(this T obj, Action<T> action)
    {
        action(obj);
        return obj;
    }
    
    public static TResult Apply<T, TResult>(this T obj, Func<T, TResult> func)
    {
        return func(obj);
    }
}

// Usage
var result = new List<int> { 1, 2, 3 }
    .Also(list => Console.WriteLine($"Count: {list.Count}"))
    .Also(list => list.Add(4))
    .Apply(list => list.Sum()); // 10

// ========== LINQ EXTENSION METHODS (BUILT-IN EXAMPLES) ==========
// These are all extension methods on IEnumerable<T>
var nums = new[] { 1, 2, 3, 4, 5 };

var evens = nums.Where(n => n.IsEven()); // Extension
var squares = nums.Select(n => n.Square()); // Extension
var sum = nums.Sum(); // Extension
var count = nums.Count(); // Extension
var first = nums.First(); // Extension
var ordered = nums.OrderBy(n => n); // Extension

// ========== LIMITATIONS ==========
// Cannot:
// - Override existing methods
// - Access private/protected members
// - Be used for operators
// - Replace instance methods
// - Work on static classes

// Can:
// - Add to sealed classes
// - Add to built-in types
// - Be used in LINQ
// - Improve fluency
// - Reduce code duplication

// ========== BEST PRACTICES ==========
Console.WriteLine("Extension Method Best Practices:");
Console.WriteLine("1. Put in static class with Related Name + Extensions");
Console.WriteLine("2. Use only for true extensions, not replacements");
Console.WriteLine("3. Keep logic simple");
Console.WriteLine("4. Avoid conflicting with existing methods");
Console.WriteLine("5. Document with XML comments");
Console.WriteLine("6. Use namespacing to avoid pollution");
Console.WriteLine("7. Don't abuse - keep code readable");
Console.WriteLine("8. Consider performance for frequently called methods");`}]}]},Qy={id:"csharp-advanced",name:"C# Advanced",icon:"",topics:[By,zy,Gy,Hy,jy,Fy,_y,Vy]},Ky={id:"azure-app-services",name:"App Services",questions:[{id:"q1",question:"What is Azure App Service and what types of applications can you host?",answer:"Azure App Service is a fully managed platform for building and hosting web apps, mobile backends, and RESTful APIs. Types: Web Apps (.NET, Node, Python, Java, PHP), Mobile Apps, API Apps, Function Apps. Provides auto-scaling, built-in CI/CD, SSL/TLS, monitoring. Pricing tiers: Free, Shared, Basic, Standard, Premium, Isolated.",codeSnippets:[{language:"csharp",code:`// Azure App Service - Deployment from Program.cs
using Microsoft.AspNetCore.Builder;
using Azure.Identity;
using Azure.Security.KeyVault.Secrets;

var builder = WebApplication.CreateBuilder(args);

// App Service environment detection
var isAppService = !string.IsNullOrEmpty(Environment.GetEnvironmentVariable("WEBSITE_INSTANCE_ID"));

if (isAppService)
{
    Console.WriteLine("Running in Azure App Service");
    
    // Use Key Vault for secrets in production
    var keyVaultUrl = new Uri(builder.Configuration["KeyVault:Url"]);
    builder.Configuration.AddAzureKeyVault(
        keyVaultUrl,
        new DefaultAzureCredential()
    );
}

builder.Services.AddControllers();
builder.Services.AddScoped<IUserService, UserService>();

var app = builder.Build();
app.UseRouting();
app.MapControllers();

await app.RunAsync();

// App Service Tiers Comparison
Console.WriteLine("App Service Pricing Tiers:");
Console.WriteLine("Tier         Auto-scale  SSL  Slots  Cost");
Console.WriteLine("Free         No          No   No     $0");
Console.WriteLine("Shared       No          No   No     ~$10");
Console.WriteLine("Basic        No          Yes  No     ~$55");
Console.WriteLine("Standard     Yes         Yes  Yes    ~$100");
Console.WriteLine("Premium      Yes         Yes  Yes    ~$300");
Console.WriteLine("Isolated     Yes         Yes  Yes    ~$600+");

// Health Check - App Service expects 200 response
app.MapGet("/health", () => Results.Ok("Healthy"));
app.MapGet("/health/live", () => Results.Ok("Live"));
app.MapGet("/health/ready", () => Results.Ok("Ready"));

// App Service runs your code with these benefits:
// - Auto-scaling based on metrics
// - Built-in authentication (Easy Auth)
// - Deployment slots (staging)
// - Traffic routing
// - Monitoring & diagnostics
// - SSL/TLS certificates
// - Custom domains
// - Backups and restore`}]},{id:"q2",question:"What are deployment slots in Azure App Service and how do you use them?",answer:"Deployment slots are separate instances of your app for staging/testing before production. Each slot has unique URL. Common setup: Production + Staging. Test in staging slot, then swap to production (zero downtime). Slots share settings and have separate DNS. Perfect for testing updates, A/B testing, canary releases.",codeSnippets:[{language:"csharp",code:`// Deployment Slots Strategy
using Microsoft.AspNetCore.Builder;

var builder = WebApplication.CreateBuilder(args);
var app = builder.Build();

// Get slot name
var slotName = Environment.GetEnvironmentVariable("WEBSITE_DEPLOYMENT_ID") ?? "Production";

// Slot-specific logging
Console.WriteLine($"Deployed to slot: {slotName}");

// Return slot info in response
app.MapGet("/api/info", () => new
{
    Slot = slotName,
    Environment = builder.Environment.EnvironmentName,
    Version = "1.0.0",
    Timestamp = DateTime.UtcNow
});

// Warm up logic for slot swap
app.MapPost("/api/warmup", async (HttpContext context) =>
{
    Console.WriteLine("Warmup request received");
    
    // Initialize resources
    await Task.Delay(1000); // Simulate init
    
    return Results.Ok("Warmed up");
});

// Slot swap workflow:
// 1. Create Staging slot (copy of Production)
// 2. Deploy new version to Staging
// 3. Test in Staging at: myapp-staging.azurewebsites.net
// 4. Run warmup on Staging slot
// 5. Swap Staging  Production (instant!)
// 6. If issues, swap back (instant rollback!)

// Slot swap is instant with zero downtime
// Before swap:
//   Production: v1.0 (myapp.azurewebsites.net)
//   Staging: v2.0 (myapp-staging.azurewebsites.net)

// After swap:
//   Production: v2.0 (myapp.azurewebsites.net)
//   Staging: v1.0 (myapp-staging.azurewebsites.net)

// Sticky slots configuration
var stickySettings = new Dictionary<string, bool>
{
    { "ASPNETCORE_ENVIRONMENT", true }, // Don't swap
    { "ConnectionStrings:Default", true }, // Don't swap
    { "API_KEY", false } // Do swap
};

Console.WriteLine("Sticky Settings (don't swap during slot swap):");
foreach (var setting in stickySettings.Where(x => x.Value))
{
    Console.WriteLine($"  - {setting.Key}");
}

// Azure CLI commands for slots:
// az webapp deployment slot create --resource-group myRG --name myApp --slot staging
// az webapp deployment slot swap --resource-group myRG --name myApp --slot staging
// az webapp deployment slot list --resource-group myRG --name myApp

// Benefits of slots:
Console.WriteLine("Deployment Slots Benefits:");
Console.WriteLine(" Zero-downtime deployments");
Console.WriteLine(" Easy rollback");
Console.WriteLine(" Test before production");
Console.WriteLine(" A/B testing");
Console.WriteLine(" Warmup before swap");
Console.WriteLine(" Canary deployments");
Console.WriteLine(" Blue-Green deployments");`}]},{id:"q3",question:"What is Azure App Service Plan and how does scaling work?",answer:"App Service Plan defines resources for one or more apps. Contains: compute size (CPU, RAM), instance count, pricing tier. Auto-scale rules: scale out (add instances) or scale up (bigger VM). Metrics: CPU %, memory, HTTP queue, disk I/O. Scale set: min/max instances, rules when to scale.",codeSnippets:[{language:"csharp",code:`// Auto-Scaling in Azure App Service

// Azure provides these scaling options:
// 1. Scale UP (Vertical) - Bigger machine
// 2. Scale OUT (Horizontal) - More instances

Console.WriteLine("Azure App Service Scaling:");
Console.WriteLine("Scale UP (Vertical):");
Console.WriteLine("  Free  Shared  Basic  Standard  Premium  Isolated");
Console.WriteLine("  Same number of instances, but bigger resources");
Console.WriteLine("");
Console.WriteLine("Scale OUT (Horizontal):");
Console.WriteLine("  Add more instances of same size");
Console.WriteLine("  Requires Standard tier or higher");

// Auto-Scale Rules Example
/*
Rule 1: Scale OUT when CPU > 70% for 5 minutes
  - Add 1 instance
  - Max instances: 10

Rule 2: Scale IN when CPU < 30% for 10 minutes
  - Remove 1 instance
  - Min instances: 1
*/

// Application code benefits from scaling:
using Microsoft.AspNetCore.Builder;

var builder = WebApplication.CreateBuilder(args);
var app = builder.Build();

// Get instance ID (each instance has unique ID)
var instanceId = Environment.MachineName;

app.MapGet("/api/instance", () => new
{
    InstanceId = instanceId,
    Cores = Environment.ProcessorCount,
    WorkingMemory = GC.GetTotalMemory(false) / 1024 / 1024 // MB
});

// Multiple instances require:
app.UseSession(); // Distributed session (use cache)

// Connect to Distributed Cache (Redis)
builder.Services.AddStackExchangeRedisCache(options =>
{
    options.Configuration = builder.Configuration.GetConnectionString("Redis");
});

// Store session in Redis (not in-memory)
app.UseSession();

// Each instance can handle requests independently
// Load balancer distributes requests across instances

app.MapPost("/api/process", async (HttpContext context) =>
{
    var sessionId = context.Session.Id;
    context.Session.SetString("ProcessedBy", Environment.MachineName);
    
    return Results.Ok(new
    {
        Message = "Processing...",
        SessionId = sessionId,
        Instance = Environment.MachineName
    });
});

// Sticky Sessions (Session Affinity)
// Default: Requests from same client go to same instance (via ARR cookie)
// This is usually NOT recommended for scalability
// Better: Use distributed cache (Redis, Cosmos DB)

Console.WriteLine("Scaling Best Practices:");
Console.WriteLine("1. Use distributed session/cache (Redis)");
Console.WriteLine("2. Make apps stateless");
Console.WriteLine("3. Store state in database or cache");
Console.WriteLine("4. Monitor scale metrics");
Console.WriteLine("5. Test with multiple instances");
Console.WriteLine("6. Set up auto-scale rules");
Console.WriteLine("7. Configure health checks");
Console.WriteLine("8. Implement graceful shutdown");

// Health checks for auto-scaling
app.MapGet("/health", () =>
{
    var healthy = new
    {
        Status = "Healthy",
        Uptime = Environment.TickCount64,
        Connections = GC.GetTotalMemory(false)
    };
    
    return Results.Ok(healthy);
});

// Common scaling patterns
Console.WriteLine("Scaling Patterns:");
Console.WriteLine("1. Predictable: Scale on schedule");
Console.WriteLine("2. Metric-based: Scale on CPU/Memory");
Console.WriteLine("3. Queue-based: Scale on queue length");
Console.WriteLine("4. Custom: Scale on application metrics");`}]},{id:"q4",question:"How do you configure continuous deployment/continuous integration (CI/CD) with Azure App Service?",answer:"Azure App Service integrates with GitHub, Azure Repos, Bitbucket, OneDrive. Supported build providers: Azure Pipelines, GitHub Actions. On code push: build  test  deploy automatically. For advanced: use Azure Pipelines with custom steps. Can deploy Docker containers automatically on build.",codeSnippets:[{language:"csharp",code:`// Azure App Service - CI/CD Configuration

// 1. GitHub Actions Workflow
/*
.github/workflows/azure-deploy.yml

name: Build and Deploy

on:
  push:
    branches:
      - main

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup .NET
        uses: actions/setup-dotnet@v3
        with:
          dotnet-version: '8.0'
      
      - name: Build
        run: dotnet build --configuration Release
      
      - name: Test
        run: dotnet test
      
      - name: Publish
        run: dotnet publish -c Release -o ./publish
      
      - name: Deploy to Azure App Service
        uses: azure/webapps-deploy@v2
        with:
          app-name: myapp
          publish-profile: \${{ secrets.AZURE_PUBLISH_PROFILE }}
          package: ./publish
*/

// 2. Azure Pipelines (azure-pipelines.yml)
/*
trigger:
  - main

pool:
  vmImage: 'ubuntu-latest'

steps:
  - task: UseDotNet@2
    inputs:
      version: '8.0'
  
  - task: DotNetCoreCLI@2
    inputs:
      command: 'build'
      arguments: '--configuration Release'
  
  - task: DotNetCoreCLI@2
    inputs:
      command: 'test'
  
  - task: DotNetCoreCLI@2
    inputs:
      command: 'publish'
      publishWebProjects: true
      arguments: '--configuration Release --output $(Build.ArtifactStagingDirectory)'
  
  - task: PublishBuildArtifacts@1
    inputs:
      PathtoPublish: '$(Build.ArtifactStagingDirectory)'
  
  - task: AzureWebApp@1
    inputs:
      azureSubscription: 'Azure Service Connection'
      appType: 'webAppLinux'
      appName: 'myapp'
      package: '$(Build.ArtifactStagingDirectory)'
*/

// 3. Local deployment using Azure CLI
Console.WriteLine("Azure CLI Deployment Commands:");
Console.WriteLine("# Build the application");
Console.WriteLine("dotnet build --configuration Release");
Console.WriteLine("");
Console.WriteLine("# Publish to folder");
Console.WriteLine("dotnet publish -c Release -o ./publish");
Console.WriteLine("");
Console.WriteLine("# Deploy to App Service");
Console.WriteLine("az webapp deployment source config-zip \\");
Console.WriteLine("  --resource-group myResourceGroup \\");
Console.WriteLine("  --name myapp \\");
Console.WriteLine("  --src publish.zip");
Console.WriteLine("");
Console.WriteLine("# Or deploy from folder directly");
Console.WriteLine("az webapp up --name myapp --resource-group myRG");

// 4. Continuous deployment settings
using Microsoft.AspNetCore.Builder;

var builder = WebApplication.CreateBuilder(args);
var app = builder.Build();

// Deployment info endpoint
app.MapGet("/api/deployment-info", () =>
{
    var info = new
    {
        DeploymentTime = System.IO.File.GetLastWriteTimeUtc(typeof(Program).Assembly.Location),
        Version = typeof(Program).Assembly.GetName().Version.ToString(),
        EnvironmentName = builder.Environment.EnvironmentName,
        ContentRootPath = builder.Environment.ContentRootPath
    };
    
    return Results.Ok(info);
});

// Health check for CI/CD
app.MapGet("/health/startup", () => Results.Ok("Ready"));

Console.WriteLine("CI/CD Pipeline Stages:");
Console.WriteLine("1. Trigger: Code push to main branch");
Console.WriteLine("2. Build: Compile code");
Console.WriteLine("3. Test: Run unit tests");
Console.WriteLine("4. Package: Create deployment package");
Console.WriteLine("5. Deploy: Deploy to App Service");
Console.WriteLine("6. Verify: Health checks pass");

// Pre-deployment checks
Console.WriteLine("Pre-Deployment Checks:");
Console.WriteLine(" All tests pass");
Console.WriteLine(" Code quality gates pass");
Console.WriteLine(" Build succeeds");
Console.WriteLine(" Deployment slot created");
Console.WriteLine(" Health checks configured");

// Post-deployment verification
Console.WriteLine("Post-Deployment Verification:");
Console.WriteLine(" Application starts");
Console.WriteLine(" Database migrations succeed");
Console.WriteLine(" Health endpoint responds");
Console.WriteLine(" Slot swap successful");
Console.WriteLine(" Monitoring shows no errors");`}]}]},$y={id:"azure-containers",name:"Container Deployment",questions:[{id:"q1",question:"What is Docker and how do you containerize a .NET application?",answer:"Docker packages application with dependencies in isolated container. Dockerfile defines build steps. Container runs same everywhere (development, testing, production). Base images: mcr.microsoft.com/dotnet/sdk (build), mcr.microsoft.com/dotnet/runtime (run). Multi-stage builds: build in SDK, run in runtime for smaller image.",codeSnippets:[{language:"csharp",code:`// Dockerfile for .NET Application

/*
# Multi-stage build
FROM mcr.microsoft.com/dotnet/sdk:8.0 AS build
WORKDIR /src

# Copy project file
COPY ["MyApp.csproj", "."]

# Restore dependencies
RUN dotnet restore "MyApp.csproj"

# Copy source code
COPY . .

# Build application
RUN dotnet build "MyApp.csproj" -c Release -o /app/build

# Publish
FROM mcr.microsoft.com/dotnet/sdk:8.0 AS publish
WORKDIR /src
COPY --from=build /src .
RUN dotnet publish "MyApp.csproj" -c Release -o /app/publish

# Runtime stage
FROM mcr.microsoft.com/dotnet/aspnet:8.0
WORKDIR /app
COPY --from=publish /app/publish .

EXPOSE 80
ENTRYPOINT ["dotnet", "MyApp.dll"]
*/

// Dockerfile is text file with build instructions
Console.WriteLine("Dockerfile Instructions:");
Console.WriteLine("FROM - Base image");
Console.WriteLine("WORKDIR - Working directory");
Console.WriteLine("COPY - Copy files to container");
Console.WriteLine("RUN - Execute command during build");
Console.WriteLine("ENV - Environment variable");
Console.WriteLine("EXPOSE - Port to expose");
Console.WriteLine("ENTRYPOINT - Command to run");
Console.WriteLine("CMD - Default parameters");

// Build and run Docker container
Console.WriteLine("Docker Commands:");
Console.WriteLine("# Build image");
Console.WriteLine("docker build -t myapp:latest .");
Console.WriteLine("");
Console.WriteLine("# Run container");
Console.WriteLine("docker run -p 80:80 myapp:latest");
Console.WriteLine("");
Console.WriteLine("# View running containers");
Console.WriteLine("docker ps");
Console.WriteLine("");
Console.WriteLine("# Stop container");
Console.WriteLine("docker stop <container-id>");`}]},{id:"q2",question:"What is Azure Container Registry (ACR) and Azure Container Instances (ACI)?",answer:"Azure Container Registry stores Docker images privately. Push/pull images to ACR. Azure Container Instances runs containers serverless (no VM management). Pay per second. Good for dev/test, batch jobs, event-driven tasks. For production: use AKS (Kubernetes) for orchestration.",codeSnippets:[{language:"csharp",code:`// Azure Container Registry (ACR) & Container Instances (ACI)

Console.WriteLine("ACR - Azure Container Registry");
Console.WriteLine(" Private Docker image storage");
Console.WriteLine(" Geo-replication");
Console.WriteLine(" Webhook triggers");
Console.WriteLine(" Built-in authentication");

// ACR CLI commands
Console.WriteLine("ACR Commands:");
Console.WriteLine("# Login to ACR");
Console.WriteLine("az acr login --name myregistry");
Console.WriteLine("");
Console.WriteLine("# Tag image");
Console.WriteLine("docker tag myapp:latest myregistry.azurecr.io/myapp:latest");
Console.WriteLine("");
Console.WriteLine("# Push to ACR");
Console.WriteLine("docker push myregistry.azurecr.io/myapp:latest");
Console.WriteLine("");
Console.WriteLine("# List images in ACR");
Console.WriteLine("az acr repository list --name myregistry");

Console.WriteLine("");
Console.WriteLine("ACI - Azure Container Instances");
Console.WriteLine(" Serverless container execution");
Console.WriteLine(" Pay per second");
Console.WriteLine(" Fast startup");
Console.WriteLine(" No container orchestration needed");

// Deploy to ACI
Console.WriteLine("Deploy to ACI:");
Console.WriteLine("az container create \\");
Console.WriteLine("  --resource-group myRG \\");
Console.WriteLine("  --name mycontainer \\");
Console.WriteLine("  --image myregistry.azurecr.io/myapp:latest \\");
Console.WriteLine("  --cpu 1 --memory 1 \\");
Console.WriteLine("  --port 80 \\");
Console.WriteLine("  --environment-variables ENV=Production API_KEY=secret");

// Environment variables for container
var containerEnvVars = new Dictionary<string, string>
{
    { "ASPNETCORE_ENVIRONMENT", "Production" },
    { "ConnectionStrings:Default", "Server=...;Database=..." },
    { "Logging:LogLevel:Default", "Information" }
};

Console.WriteLine("ACI Pricing:");
Console.WriteLine("- 1 CPU core: ~$0.0000145/second (~$40/month)");
Console.WriteLine("- 4 CPU cores: ~$0.000116/second (~$320/month)");
Console.WriteLine("- Pay only when running");`}]},{id:"q3",question:"What is Azure Kubernetes Service (AKS) and when should you use it?",answer:"Azure Kubernetes Service is managed Kubernetes cluster for container orchestration. Automatically scales pods, manages updates, health checks. Use when: many containers, complex deployments, auto-scaling needed, multi-environment. Higher complexity than ACI. Includes monitoring, RBAC, networking policies.",codeSnippets:[{language:"csharp",code:`// Azure Kubernetes Service (AKS)

Console.WriteLine("AKS - Azure Kubernetes Service");
Console.WriteLine(" Managed Kubernetes");
Console.WriteLine(" Auto-scaling");
Console.WriteLine(" Health management");
Console.WriteLine(" Rolling updates");
Console.WriteLine(" RBAC");
Console.WriteLine(" Monitoring integration");

// AKS Kubernetes manifest (deployment.yaml)
/*
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: myapp
        image: myregistry.azurecr.io/myapp:latest
        ports:
        - containerPort: 80
        env:
        - name: ASPNETCORE_ENVIRONMENT
          value: "Production"
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 80
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health/ready
            port: 80
          initialDelaySeconds: 10
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: myapp-service
spec:
  type: LoadBalancer
  ports:
  - port: 80
    targetPort: 80
  selector:
    app: myapp
*/

// Create AKS cluster
Console.WriteLine("AKS Cluster Creation:");
Console.WriteLine("az aks create \\");
Console.WriteLine("  --resource-group myRG \\");
Console.WriteLine("  --name myCluster \\");
Console.WriteLine("  --node-count 3 \\");
Console.WriteLine("  --vm-set-type VirtualMachineScaleSets \\");
Console.WriteLine("  --enable-managed-identity");

// Deploy to AKS
Console.WriteLine("Deploy to AKS:");
Console.WriteLine("# Get cluster credentials");
Console.WriteLine("az aks get-credentials --resource-group myRG --name myCluster");
Console.WriteLine("");
Console.WriteLine("# Deploy manifest");
Console.WriteLine("kubectl apply -f deployment.yaml");
Console.WriteLine("");
Console.WriteLine("# Check deployment");
Console.WriteLine("kubectl get deployments");
Console.WriteLine("kubectl get pods");
Console.WriteLine("kubectl get svc");

// Auto-scaling in Kubernetes
/*
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: myapp-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: myapp-deployment
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
*/

Console.WriteLine("Kubernetes Concepts:");
Console.WriteLine("Pod - Smallest unit, wraps container");
Console.WriteLine("Deployment - Manages pods");
Console.WriteLine("Service - Exposes pods");
Console.WriteLine("Namespace - Logical partition");
Console.WriteLine("PersistentVolume - Storage");
Console.WriteLine("ConfigMap - Configuration");
Console.WriteLine("Secret - Sensitive data");

Console.WriteLine("When to use AKS:");
Console.WriteLine(" Large-scale container deployments");
Console.WriteLine(" Need complex orchestration");
Console.WriteLine(" Microservices architecture");
Console.WriteLine(" Multi-cloud or hybrid");
Console.WriteLine(" Need RBAC and security policies");`}]},{id:"q4",question:"What is Azure App Service for Containers and how do you deploy a Docker image?",answer:"App Service for Containers runs Docker containers on App Service (with same scaling/deployment benefits). Simpler than AKS. Deploy from: Docker Hub, ACR, or private registry. Single container or docker-compose. Faster startup than traditional App Service.",codeSnippets:[{language:"csharp",code:`// Azure App Service for Containers

Console.WriteLine("App Service for Containers");
Console.WriteLine(" Single container or docker-compose");
Console.WriteLine(" App Service scaling");
Console.WriteLine(" Deployment slots");
Console.WriteLine(" Auto-scaling");
Console.WriteLine(" Easier than AKS for simple deployments");

// Deploy from ACR
Console.WriteLine("Deploy from Azure Container Registry:");
Console.WriteLine("az webapp create \\");
Console.WriteLine("  --resource-group myRG \\");
Console.WriteLine("  --plan myPlan \\");
Console.WriteLine("  --name mycontainerapp \\");
Console.WriteLine("  --deployment-container-image-name myregistry.azurecr.io/myapp:latest");

// Docker Compose for multiple containers
/*
version: '3.8'
services:
  web:
    image: myregistry.azurecr.io/myapp:latest
    ports:
      - "80:80"
    environment:
      - ASPNETCORE_ENVIRONMENT=Production
      - ConnectionStrings:Default=Server=db;Database=mydb;
    depends_on:
      - db
  
  db:
    image: mcr.microsoft.com/mssql/server:2022-latest
    environment:
      - ACCEPT_EULA=Y
      - SA_PASSWORD=StrongPassword123!
    ports:
      - "1433:1433"
*/

// Deploy docker-compose
Console.WriteLine("Deploy docker-compose.yml:");
Console.WriteLine("az webapp create \\");
Console.WriteLine("  --resource-group myRG \\");
Console.WriteLine("  --plan myPlan \\");
Console.WriteLine("  --name myapp \\");
Console.WriteLine("  --multicontainer-config-type compose \\");
Console.WriteLine("  --multicontainer-config-file docker-compose.yml");

// Update container image
Console.WriteLine("Update container image:");
Console.WriteLine("az webapp config container set \\");
Console.WriteLine("  --resource-group myRG \\");
Console.WriteLine("  --name myapp \\");
Console.WriteLine("  --docker-custom-image-name myregistry.azurecr.io/myapp:v2 \\");
Console.WriteLine("  --docker-registry-server-url https://myregistry.azurecr.io \\");
Console.WriteLine("  --docker-registry-server-user <username> \\");
Console.WriteLine("  --docker-registry-server-password <password>");

// Webhook for auto-update on ACR push
Console.WriteLine("Webhook triggers automatic deployment on image push");`}]}]},Yy={id:"azure-service-bus",name:"Service Bus & Functions",questions:[{id:"q1",question:"What is Azure Service Bus and what are its main components?",answer:"Azure Service Bus is enterprise messaging service (asynchronous communication). Components: Queues (one-to-one), Topics (one-to-many with subscriptions), Relay (hybrid connections). Features: message sessions, dead-letter queues, duplicate detection, message TTL. Use for decoupling applications, ordering guarantees, delayed processing.",codeSnippets:[{language:"csharp",code:`using Azure.Messaging.ServiceBus;

// Azure Service Bus - Queues and Topics

// Queue: One sender, one receiver (FIFO)
var queueClient = new ServiceBusClient("connection-string").CreateSender("myqueue");

// Send message to queue
var message = new ServiceBusMessage("Hello, Service Bus!")
{
    MessageId = Guid.NewGuid().ToString(),
    CorrelationId = "order-123",
    Subject = "OrderProcessing",
    TimeToLive = TimeSpan.FromHours(1)
};

await queueClient.SendMessageAsync(message);

// Receive from queue
var receiver = new ServiceBusClient("connection-string").CreateReceiver("myqueue");
var receivedMessage = await receiver.ReceiveMessageAsync();

if (receivedMessage != null)
{
    Console.WriteLine(receivedMessage.Body.ToString());
    await receiver.CompleteMessageAsync(receivedMessage); // Acknowledge
}

// Topic: One sender, multiple receivers (Publish-Subscribe)
var topicClient = new ServiceBusClient("connection-string").CreateSender("orders");

var topicMessage = new ServiceBusMessage("Order #123")
{
    Subject = "NewOrder",
    ContentType = "application/json"
};

await topicClient.SendMessageAsync(topicMessage);

// Subscribe to topic
var subscriptionClient = new ServiceBusClient("connection-string")
    .CreateReceiver("orders", "email-subscription");

var subscriptionMessage = await subscriptionClient.ReceiveMessageAsync();
if (subscriptionMessage != null)
{
    Console.WriteLine($"Email subscriber received: {subscriptionMessage.Body}");
    await subscriptionClient.CompleteMessageAsync(subscriptionMessage);
}

// Dead-Letter Queue: Messages that can't be processed
var deadLetterReceiver = new ServiceBusClient("connection-string")
    .CreateReceiver("myqueue", new ServiceBusReceiverOptions 
    { 
        SubQueue = SubQueue.DeadLetter 
    });

var dlMessage = await deadLetterReceiver.ReceiveMessageAsync();

Console.WriteLine("Service Bus Components:");
Console.WriteLine("Queue:");
Console.WriteLine("  - FIFO order");
Console.WriteLine("  - One receiver (at a time)");
Console.WriteLine("  - At-least-once delivery");
Console.WriteLine("");
Console.WriteLine("Topic with Subscriptions:");
Console.WriteLine("  - Publish-Subscribe pattern");
Console.WriteLine("  - Multiple subscribers");
Console.WriteLine("  - Filter rules");
Console.WriteLine("");
Console.WriteLine("Dead-Letter Queue:");
Console.WriteLine("  - Messages that failed processing");
Console.WriteLine("  - Retry logic can be applied");`}]},{id:"q2",question:"What is Azure Functions and how do you create serverless functions?",answer:"Azure Functions runs code without managing infrastructure. Pay only for execution time. Triggered by: HTTP, Timer, Queue, Blob, Event Hub, Service Bus, etc. Languages: C#, Python, Node.js, Java. Hosting: Consumption plan (pay-per-use), App Service plan, Elastic Premium. Bindings simplify code (Input/Output).",codeSnippets:[{language:"csharp",code:`using Microsoft.Azure.Functions.Worker;
using Microsoft.Extensions.Logging;

// HTTP Trigger Function
[Function("HttpTriggerFunction")]
public static HttpResponseData HttpTrigger(
    [HttpTrigger(AuthorizationLevel.Function, "get", "post", Route = "hello")] 
    HttpRequestData req,
    FunctionContext context)
{
    var logger = context.GetLogger("HttpTriggerFunction");
    logger.LogInformation("C# HTTP trigger function processed a request.");
    
    var response = req.CreateResponse(System.Net.HttpStatusCode.OK);
    response.Headers.Add("Content-Type", "text/plain; charset=utf-8");
    response.WriteString("Hello from Azure Functions!");
    
    return response;
}

// Queue Trigger Function
[Function("QueueTriggerFunction")]
public static void QueueTrigger(
    [QueueTrigger("myqueue")] string myQueueItem,
    FunctionContext context)
{
    var logger = context.GetLogger("QueueTriggerFunction");
    logger.LogInformation($"Queue message received: {myQueueItem}");
    
    // Process queue message
}

// Timer Trigger Function
[Function("TimerTriggerFunction")]
public static void TimerTrigger(
    [TimerTrigger("0 */5 * * * *")] TimerInfo myTimer, // Every 5 minutes
    FunctionContext context)
{
    var logger = context.GetLogger("TimerTriggerFunction");
    logger.LogInformation($"Timer triggered at: {DateTime.Now}");
}

// Service Bus Trigger
[Function("ServiceBusTriggerFunction")]
public static void ServiceBusTrigger(
    [ServiceBusTrigger("myqueue", Connection = "ServiceBusConnection")] 
    string sbMessage,
    FunctionContext context)
{
    var logger = context.GetLogger("ServiceBusTriggerFunction");
    logger.LogInformation($"Service Bus message: {sbMessage}");
}

// Blob Trigger
[Function("BlobTriggerFunction")]
public static void BlobTrigger(
    [BlobTrigger("mycontainer/{name}")] Stream myBlob,
    string name,
    FunctionContext context)
{
    var logger = context.GetLogger("BlobTriggerFunction");
    logger.LogInformation($"Blob processed: {name}, Size: {myBlob.Length}");
}

// Output Binding: Write to Blob
[Function("WriteToBlob")]
public static void WriteToBlob(
    [HttpTrigger(AuthorizationLevel.Function, "post")] HttpRequestData req,
    [BlobOutput("mycontainer/{id}.txt")] IAsyncCollector<string> outputBlob,
    FunctionContext context)
{
    outputBlob.AddAsync("File content here");
}

// Output Binding: Write to Queue
[Function("WriteToQueue")]
public static async Task WriteToQueue(
    [HttpTrigger(AuthorizationLevel.Function, "post")] HttpRequestData req,
    [QueueOutput("myqueue")] IAsyncCollector<string> outputQueue)
{
    await outputQueue.AddAsync("Message to queue");
}

// function.json configuration (for isolated worker)
/*
{
  "version": "2.0",
  "logging": {
    "applicationInsights": {
      "samplingSettings": {
        "isEnabled": true,
        "maxTelemetryItemsPerSecond": 20
      }
    }
  },
  "functionTimeout": "00:05:00"
}
*/

Console.WriteLine("Azure Functions Triggers:");
Console.WriteLine("HTTP - REST API");
Console.WriteLine("Timer - Scheduled");
Console.WriteLine("Queue - Azure Storage Queue");
Console.WriteLine("Service Bus - Azure Service Bus");
Console.WriteLine("Blob - Azure Blob Storage");
Console.WriteLine("Event Hub - Event streaming");
Console.WriteLine("Cosmos DB - Database change");
Console.WriteLine("Event Grid - Event routing");

Console.WriteLine("Function Bindings:");
Console.WriteLine("Input Binding - Read data");
Console.WriteLine("Output Binding - Write data");
Console.WriteLine("Trigger - Start execution");

Console.WriteLine("Hosting Plans:");
Console.WriteLine("Consumption - Pay per execution");
Console.WriteLine("App Service - Share App Service Plan");
Console.WriteLine("Elastic Premium - Dedicated resources, auto-scale");
Console.WriteLine("Dedicated - Custom orchestration");`}]},{id:"q3",question:"How do you integrate Service Bus with Azure Functions?",answer:"Use ServiceBusTrigger to automatically process messages. Set Connection string in local.settings.json (local) or Application Settings (cloud). Each message triggers function execution. Can batch messages. Supports dead-letter handling. Perfect for event-driven architecture and asynchronous processing.",codeSnippets:[{language:"csharp",code:`using Microsoft.Azure.Functions.Worker;
using Microsoft.Extensions.Logging;
using Azure.Messaging.ServiceBus;

// Service Bus + Functions Integration

// Single message processing
[Function("ProcessServiceBusMessage")]
public static async Task ProcessMessage(
    [ServiceBusTrigger("orders", "email-subscription", Connection = "ServiceBusConnection")]
    ServiceBusReceivedMessage message,
    ServiceBusClient client,
    ILogger log)
{
    log.LogInformation($"Processing message: {message.MessageId}");
    log.LogInformation($"Body: {message.Body}");
    
    try
    {
        // Process order
        var orderData = message.Body.ToString();
        
        // Business logic
        await SendConfirmationEmail(orderData);
        
        log.LogInformation("Message processed successfully");
        
        // Message is auto-completed
    }
    catch (Exception ex)
    {
        log.LogError($"Error processing message: {ex.Message}");
        
        // Throw to move to dead-letter queue
        throw;
    }
}

// Batch processing (multiple messages at once)
[Function("ProcessBatch")]
public static async Task ProcessBatch(
    [ServiceBusTrigger("orders", Connection = "ServiceBusConnection", IsSingleDispatch = false)]
    ServiceBusReceivedMessage[] messages,
    ILogger log)
{
    log.LogInformation($"Processing batch of {messages.Length} messages");
    
    foreach (var message in messages)
    {
        try
        {
            log.LogInformation($"Message: {message.Body}");
            // Process each message
        }
        catch (Exception ex)
        {
            log.LogError($"Error: {ex.Message}");
        }
    }
}

// With custom properties
[Function("ProcessWithProperties")]
public static void ProcessWithProperties(
    [ServiceBusTrigger("orders", Connection = "ServiceBusConnection")]
    ServiceBusReceivedMessage message,
    ILogger log)
{
    log.LogInformation($"Message ID: {message.MessageId}");
    log.LogInformation($"Correlation ID: {message.CorrelationId}");
    log.LogInformation($"Subject: {message.Subject}");
    
    // Access user properties
    if (message.ApplicationProperties.TryGetValue("OrderId", out var orderId))
    {
        log.LogInformation($"Order ID: {orderId}");
    }
}

// local.settings.json (local development)
/*
{
  "IsEncrypted": false,
  "Values": {
    "AzureWebJobsStorage": "DefaultEndpointsProtocol=https;AccountName=...",
    "FUNCTIONS_WORKER_RUNTIME": "dotnet-isolated",
    "ServiceBusConnection": "Endpoint=sb://mynamespace.servicebus.windows.net/;..."
  }
}
*/

// Sending messages to Service Bus from Function
[Function("CreateOrder")]
public static async Task CreateOrder(
    [HttpTrigger(AuthorizationLevel.Function, "post")] HttpRequestData req,
    [ServiceBusOutput("orders", Connection = "ServiceBusConnection")] 
    IAsyncCollector<ServiceBusMessage> output)
{
    var message = new ServiceBusMessage("New Order Data")
    {
        MessageId = Guid.NewGuid().ToString(),
        Subject = "NewOrder",
        CorrelationId = "order-123"
    };
    
    message.ApplicationProperties.Add("OrderId", "ORD-001");
    
    await output.AddAsync(message);
}

async Task SendConfirmationEmail(string orderData)
{
    // Send email
    await Task.Delay(100); // Simulate
}

Console.WriteLine("Service Bus + Functions Patterns:");
Console.WriteLine("1. Event-driven processing");
Console.WriteLine("2. Decoupled microservices");
Console.WriteLine("3. Async message handling");
Console.WriteLine("4. Auto-scaling per message");
Console.WriteLine("5. Guaranteed delivery");
Console.WriteLine("6. Dead-letter handling");`}]}]},Jy={id:"azure-cloud-deployment",name:"Cloud Deployment",questions:[{id:"q1",question:"What is Infrastructure as Code (IaC) and how do you use it in Azure?",answer:"IaC defines infrastructure in code files (Bicep, ARM templates, Terraform). Version control friendly. Repeatable deployments. Azure-specific: Bicep (recommended, simpler syntax), ARM templates (JSON). Terraform (multi-cloud). Define resources in code, deploy via CLI or pipelines.",codeSnippets:[{language:"csharp",code:`// Bicep - Infrastructure as Code for Azure

/*
// main.bicep
param location string = resourceGroup().location
param appName string = 'myapp'
param environment string = 'dev'

var resourceGroupName = '\${appName}-\${environment}-rg'
var appServicePlanName = '\${appName}-\${environment}-plan'
var appServiceName = '\${appName}-\${environment}-app'

resource appServicePlan 'Microsoft.Web/serverfarms@2021-02-01' = {
  name: appServicePlanName
  location: location
  sku: {
    name: 'S1'
    capacity: 1
  }
  kind: 'linux'
}

resource appService 'Microsoft.Web/sites@2021-02-01' = {
  name: appServiceName
  location: location
  properties: {
    serverFarmId: appServicePlan.id
    httpsOnly: true
  }
  identity: {
    type: 'SystemAssigned'
  }
}

resource appServiceConfig 'Microsoft.Web/sites/config@2021-02-01' = {
  parent: appService
  name: 'web'
  properties: {
    alwaysOn: true
    netFrameworkVersion: 'v6.0'
    linuxFxVersion: 'DOTNETCORE|6.0'
  }
}

output appServiceId string = appService.id
output appServiceUrl string = 'https://\${appService.properties.defaultHostName}'
*/

// Parameters file (parameters.json)
/*
{
  "$schema": "https://schema.management.azure.com/schemas/2019-04-01/deploymentParameters.json#",
  "contentVersion": "1.0.0.0",
  "parameters": {
    "appName": {
      "value": "myapp"
    },
    "environment": {
      "value": "production"
    },
    "location": {
      "value": "eastus"
    }
  }
}
*/

// Deployment commands
Console.WriteLine("Azure CLI Deployment Commands:");
Console.WriteLine("# Validate Bicep");
Console.WriteLine("az deployment group validate \\");
Console.WriteLine("  --resource-group myRG \\");
Console.WriteLine("  --template-file main.bicep \\");
Console.WriteLine("  --parameters parameters.json");
Console.WriteLine("");
Console.WriteLine("# Deploy Bicep");
Console.WriteLine("az deployment group create \\");
Console.WriteLine("  --resource-group myRG \\");
Console.WriteLine("  --template-file main.bicep \\");
Console.WriteLine("  --parameters parameters.json");
Console.WriteLine("");
Console.WriteLine("# Deploy to subscription level");
Console.WriteLine("az deployment sub create \\");
Console.WriteLine("  --location eastus \\");
Console.WriteLine("  --template-file main.bicep");

// Terraform for Azure (multi-cloud)
/*
# main.tf
terraform {
  required_providers {
    azurerm = {
      source  = "hashicorp/azurerm"
      version = "~> 3.0"
    }
  }
}

provider "azurerm" {
  features {}
}

resource "azurerm_resource_group" "rg" {
  name     = "myapp-rg"
  location = "East US"
}

resource "azurerm_app_service_plan" "plan" {
  name                = "myapp-plan"
  location            = azurerm_resource_group.rg.location
  resource_group_name = azurerm_resource_group.rg.name
  kind                = "Linux"
  reserved            = true

  sku {
    tier = "Standard"
    size = "S1"
  }
}

resource "azurerm_app_service" "app" {
  name                = "myapp"
  location            = azurerm_resource_group.rg.location
  resource_group_name = azurerm_resource_group.rg.name
  app_service_plan_id = azurerm_app_service_plan.plan.id

  site_config {
    linux_fx_version = "DOTNETCORE|6.0"
  }
}
*/

Console.WriteLine("IaC Benefits:");
Console.WriteLine(" Version controlled");
Console.WriteLine(" Reproducible deployments");
Console.WriteLine(" Environment parity");
Console.WriteLine(" Easy rollback");
Console.WriteLine(" Team collaboration");
Console.WriteLine(" Cost estimation");
Console.WriteLine(" Disaster recovery");`}]},{id:"q2",question:"What is Azure DevOps and how do you set up CI/CD pipelines?",answer:"Azure DevOps provides tools for planning, developing, deploying, operating. Components: Boards (work tracking), Repos (Git), Pipelines (CI/CD), Test Plans, Artifacts. Pipelines: build (compile, test)  release (deploy to environments). YAML-based pipelines stored in repo.",codeSnippets:[{language:"csharp",code:`// Azure Pipelines - CI/CD Configuration

/*
# azure-pipelines.yml
trigger:
  - main
  - develop

pool:
  vmImage: 'ubuntu-latest'

variables:
  buildConfiguration: 'Release'
  dotnetVersion: '8.0'

stages:
- stage: Build
  jobs:
  - job: BuildJob
    steps:
    - task: UseDotNet@2
      inputs:
        packageType: 'sdk'
        version: $(dotnetVersion)
      displayName: 'Install .NET SDK'
    
    - task: DotNetCoreCLI@2
      inputs:
        command: 'restore'
        projects: '**/*.csproj'
      displayName: 'Restore NuGet packages'
    
    - task: DotNetCoreCLI@2
      inputs:
        command: 'build'
        arguments: '--configuration $(buildConfiguration) --no-restore'
      displayName: 'Build application'
    
    - task: DotNetCoreCLI@2
      inputs:
        command: 'test'
        arguments: '--configuration $(buildConfiguration) --no-build'
      displayName: 'Run unit tests'
    
    - task: SonarCloudPrepare@1
      inputs:
        SonarCloud: 'SonarCloud'
        organization: 'myorg'
        scannerMode: 'msbuild'
        projectKey: 'myproject'
      displayName: 'Prepare SonarCloud analysis'
    
    - task: SonarCloudAnalyze@1
      displayName: 'Run SonarCloud analysis'
    
    - task: DotNetCoreCLI@2
      inputs:
        command: 'publish'
        arguments: '--configuration $(buildConfiguration) --output $(Build.ArtifactStagingDirectory)'
      displayName: 'Publish application'
    
    - task: PublishBuildArtifacts@1
      inputs:
        PathtoPublish: '$(Build.ArtifactStagingDirectory)'
        ArtifactName: 'drop'
      displayName: 'Publish artifacts'

- stage: DeployDev
  dependsOn: Build
  condition: succeeded()
  jobs:
  - deployment: DeployToDev
    environment: 'dev'
    strategy:
      runOnce:
        deploy:
          steps:
          - task: AzureWebApp@1
            inputs:
              azureSubscription: 'Azure-Dev'
              appType: 'webAppLinux'
              appName: 'myapp-dev'
              package: '$(Pipeline.Workspace)/drop'
            displayName: 'Deploy to Dev App Service'

- stage: DeployProd
  dependsOn: Build
  condition: and(succeeded(), eq(variables['Build.SourceBranch'], 'refs/heads/main'))
  jobs:
  - deployment: DeployToProd
    environment: 'production'
    strategy:
      runOnce:
        deploy:
          steps:
          - task: AzureWebApp@1
            inputs:
              azureSubscription: 'Azure-Prod'
              appType: 'webAppLinux'
              appName: 'myapp-prod'
              package: '$(Pipeline.Workspace)/drop'
            displayName: 'Deploy to Prod App Service'
*/

// Azure DevOps Components
Console.WriteLine("Azure DevOps:");
Console.WriteLine("Boards - Work item tracking (Agile, Scrum)");
Console.WriteLine("Repos - Git repository (or TFVC)");
Console.WriteLine("Pipelines - CI/CD automation");
Console.WriteLine("Test Plans - Manual test execution");
Console.WriteLine("Artifacts - NuGet, Maven, npm packages");

Console.WriteLine("Pipeline Stages:");
Console.WriteLine("1. Trigger - On code push, PR, schedule");
Console.WriteLine("2. Build - Compile, test, analyze");
Console.WriteLine("3. Deploy Dev - Deploy to development");
Console.WriteLine("4. Deploy Staging - Deploy to staging");
Console.WriteLine("5. Approval - Manual approval");
Console.WriteLine("6. Deploy Prod - Deploy to production");

Console.WriteLine("Self-Hosted Agents:");
Console.WriteLine("- Run on your own machine");
Console.WriteLine("- Full control");
Console.WriteLine("- Access to on-premises resources");
Console.WriteLine("- Azure Pipelines Microsoft-hosted agents also available");`}]},{id:"q3",question:"What is Azure Resource Manager (ARM) and resource groups?",answer:"ARM is Azure's deployment and management service. Resource groups are containers for related resources (logical grouping). Manage permissions, billing, and lifecycle together. Can't be nested. One resource can only belong to one resource group. Delete resource group deletes all resources.",codeSnippets:[{language:"csharp",code:`// Azure Resource Manager & Resource Groups

// Create resource group
Console.WriteLine("Resource Group Commands:");
Console.WriteLine("# Create resource group");
Console.WriteLine("az group create \\");
Console.WriteLine("  --name myResourceGroup \\");
Console.WriteLine("  --location eastus");
Console.WriteLine("");
Console.WriteLine("# List resource groups");
Console.WriteLine("az group list");
Console.WriteLine("");
Console.WriteLine("# Delete resource group (deletes all resources)");
Console.WriteLine("az group delete \\");
Console.WriteLine("  --name myResourceGroup \\");
Console.WriteLine("  --yes");

// Resource organization
var resourceGroupStructure = new
{
    ResourceGroup = "myapp-prod-rg",
    Resources = new[]
    {
        "App Service",
        "SQL Database",
        "Storage Account",
        "Key Vault",
        "Application Insights",
        "Virtual Network"
    }
};

Console.WriteLine("Typical Resource Group Structure:");
Console.WriteLine(resourceGroupStructure.ResourceGroup);
foreach (var resource in resourceGroupStructure.Resources)
{
    Console.WriteLine($"   {resource}");
}

// Tagging resources
Console.WriteLine("Resource Tags (metadata):");
Console.WriteLine("# Set tags");
Console.WriteLine("az resource tag \\");
Console.WriteLine("  --resource-group myRG \\");
Console.WriteLine("  --name myapp \\");
Console.WriteLine("  --resource-type Microsoft.Web/sites \\");
Console.WriteLine("  --tags environment=production cost-center=engineering team=backend");
Console.WriteLine("");
Console.WriteLine("# Query by tags");
Console.WriteLine("az resource list --tags environment=production");

// Management operations
Console.WriteLine("ARM Operations:");
Console.WriteLine("PUT - Create or update resource");
Console.WriteLine("GET - Get resource details");
Console.WriteLine("DELETE - Delete resource");
Console.WriteLine("PATCH - Update resource");

// Role-Based Access Control (RBAC)
Console.WriteLine("RBAC Examples:");
Console.WriteLine("# Assign Contributor role");
Console.WriteLine("az role assignment create \\");
Console.WriteLine("  --assignee user@example.com \\");
Console.WriteLine("  --role Contributor \\");
Console.WriteLine("  --scope /subscriptions/<subscription-id>/resourceGroups/myRG");
Console.WriteLine("");
Console.WriteLine("# Assign Reader role");
Console.WriteLine("az role assignment create \\");
Console.WriteLine("  --assignee team@example.com \\");
Console.WriteLine("  --role Reader \\");
Console.WriteLine("  --scope /subscriptions/<subscription-id>");

Console.WriteLine("Built-in Roles:");
Console.WriteLine("Owner - Full access including RBAC");
Console.WriteLine("Contributor - Full access, no RBAC");
Console.WriteLine("Reader - Read-only access");
Console.WriteLine("User Access Administrator - Manage RBAC");`}]}]},Xy={id:"azure-networking",name:"Networking",questions:[{id:"q1",question:"What is Azure Virtual Network (VNet) and how do you use it?",answer:"VNet is isolated network environment in Azure. Contains subnets (subdivisions). Enables: communication between Azure resources, access to on-premises networks via VPN/ExpressRoute, filtering with Network Security Groups (NSG). Supports custom IP address space. Required for VMs, databases, etc.",codeSnippets:[{language:"csharp",code:`// Azure Virtual Network (VNet)

Console.WriteLine("VNet Components:");
Console.WriteLine("Virtual Network (VNet) - IP address space (e.g., 10.0.0.0/16)");
Console.WriteLine("   Subnet 1 - 10.0.1.0/24");
Console.WriteLine("   Subnet 2 - 10.0.2.0/24");
Console.WriteLine("   Subnet 3 - 10.0.3.0/24");

// VNet Creation
Console.WriteLine("Create VNet:");
Console.WriteLine("az network vnet create \\");
Console.WriteLine("  --name myVNet \\");
Console.WriteLine("  --resource-group myRG \\");
Console.WriteLine("  --address-prefix 10.0.0.0/16");

// Create Subnets
Console.WriteLine("Create Subnet:");
Console.WriteLine("az network vnet subnet create \\");
Console.WriteLine("  --vnet-name myVNet \\");
Console.WriteLine("  --resource-group myRG \\");
Console.WriteLine("  --name frontend \\");
Console.WriteLine("  --address-prefix 10.0.1.0/24");

// Network Security Group (NSG)
Console.WriteLine("NSG - Firewall rules");
Console.WriteLine("Allow HTTP (port 80)");
Console.WriteLine("Allow HTTPS (port 443)");
Console.WriteLine("Allow RDP (port 3389) from admin IP");
Console.WriteLine("Deny all else");

// NSG Creation
Console.WriteLine("Create NSG:");
Console.WriteLine("az network nsg create \\");
Console.WriteLine("  --name myNSG \\");
Console.WriteLine("  --resource-group myRG");

Console.WriteLine("Add inbound rule:");
Console.WriteLine("az network nsg rule create \\");
Console.WriteLine("  --resource-group myRG \\");
Console.WriteLine("  --nsg-name myNSG \\");
Console.WriteLine("  --name AllowHTTPS \\");
Console.WriteLine("  --priority 100 \\");
Console.WriteLine("  --direction Inbound \\");
Console.WriteLine("  --access Allow \\");
Console.WriteLine("  --protocol Tcp \\");
Console.WriteLine("  --destination-port-ranges 443");

// VNet Peering (connect VNets)
Console.WriteLine("VNet Peering - Connect two VNets");
Console.WriteLine("az network vnet peering create \\");
Console.WriteLine("  --vnet-name myVNet1 \\");
Console.WriteLine("  --resource-group myRG \\");
Console.WriteLine("  --name myVNet1-to-myVNet2 \\");
Console.WriteLine("  --remote-vnet /subscriptions/.../myVNet2 \\");
Console.WriteLine("  --allow-vnet-access");

// Service Endpoints (access Azure services securely)
Console.WriteLine("Service Endpoints:");
Console.WriteLine("- Azure Storage");
Console.WriteLine("- SQL Database");
Console.WriteLine("- Key Vault");
Console.WriteLine("- Cosmos DB");
Console.WriteLine("- Event Hub");`}]},{id:"q2",question:"What is Azure Load Balancer and Application Gateway?",answer:"Load Balancer: Layer 4 (Transport), distributes traffic across VMs, high performance, lower cost. Application Gateway: Layer 7 (Application), URL-based routing, SSL termination, WAF (Web Application Firewall), better for HTTP/HTTPS. Choose based on: simple round-robin (LB) vs complex routing (AppGW).",codeSnippets:[{language:"csharp",code:`// Azure Load Balancer vs Application Gateway

Console.WriteLine("Load Balancer (Layer 4):");
Console.WriteLine(" Transport layer (TCP/UDP)");
Console.WriteLine(" High performance");
Console.WriteLine(" Low latency");
Console.WriteLine(" Simple round-robin or session affinity");
Console.WriteLine(" Lower cost");
Console.WriteLine(" No URL-based routing");

Console.WriteLine("");
Console.WriteLine("Application Gateway (Layer 7):");
Console.WriteLine(" Application layer (HTTP/HTTPS)");
Console.WriteLine(" URL-based routing");
Console.WriteLine(" Hostname-based routing");
Console.WriteLine(" SSL termination");
Console.WriteLine(" WAF (Web Application Firewall)");
Console.WriteLine(" Cookie-based session affinity");
Console.WriteLine(" Slightly higher latency");
Console.WriteLine(" Higher cost");

// Load Balancer Configuration
Console.WriteLine("Load Balancer Setup:");
Console.WriteLine("az network lb create \\");
Console.WriteLine("  --name myLB \\");
Console.WriteLine("  --resource-group myRG \\");
Console.WriteLine("  --sku Standard \\");
Console.WriteLine("  --public-ip-address myPublicIP");

Console.WriteLine("Add backend pool:");
Console.WriteLine("az network lb address-pool create \\");
Console.WriteLine("  --lb-name myLB \\");
Console.WriteLine("  --resource-group myRG \\");
Console.WriteLine("  --name myBackendPool");

Console.WriteLine("Add health probe:");
Console.WriteLine("az network lb probe create \\");
Console.WriteLine("  --lb-name myLB \\");
Console.WriteLine("  --resource-group myRG \\");
Console.WriteLine("  --name myHealthProbe \\");
Console.WriteLine("  --protocol http \\");
Console.WriteLine("  --path /health \\");
Console.WriteLine("  --port 80");

Console.WriteLine("Add load rule:");
Console.WriteLine("az network lb rule create \\");
Console.WriteLine("  --lb-name myLB \\");
Console.WriteLine("  --resource-group myRG \\");
Console.WriteLine("  --name myLBRule \\");
Console.WriteLine("  --protocol tcp \\");
Console.WriteLine("  --frontend-port 80 \\");
Console.WriteLine("  --backend-port 80 \\");
Console.WriteLine("  --backend-pool-name myBackendPool \\");
Console.WriteLine("  --probe-name myHealthProbe");

// Application Gateway Configuration
Console.WriteLine("Application Gateway Setup:");
Console.WriteLine("az network application-gateway create \\");
Console.WriteLine("  --name myAppGW \\");
Console.WriteLine("  --location eastus \\");
Console.WriteLine("  --resource-group myRG \\");
Console.WriteLine("  --vnet-name myVNet \\");
Console.WriteLine("  --subnet mySubnet \\");
Console.WriteLine("  --capacity 2 \\");
Console.WriteLine("  --sku Standard_v2");

Console.WriteLine("URL-based routing:");
Console.WriteLine("Frontend: myappgw.com");
Console.WriteLine("   /api/*  Backend API Pool");
Console.WriteLine("   /images/*  Static Storage Account");
Console.WriteLine("   /*  Web App Pool");

Console.WriteLine("WAF (Web Application Firewall):");
Console.WriteLine(" DDoS protection");
Console.WriteLine(" SQL injection prevention");
Console.WriteLine(" XSS protection");
Console.WriteLine(" Cookie protection");
Console.WriteLine(" Attack signature detection");`}]},{id:"q3",question:"What is ExpressRoute and VPN Gateway for hybrid connectivity?",answer:"VPN Gateway: IPSec VPN over internet, lower cost, variable bandwidth. ExpressRoute: dedicated private connection, consistent performance, higher cost, supports large data transfers. Choose: VPN for cost-sensitive, ExpressRoute for performance-critical, consistent bandwidth.",codeSnippets:[{language:"csharp",code:`// Azure VPN Gateway vs ExpressRoute

Console.WriteLine("VPN Gateway:");
Console.WriteLine(" IPSec VPN tunnels");
Console.WriteLine(" Over public internet");
Console.WriteLine(" Lower cost");
Console.WriteLine(" Variable bandwidth");
Console.WriteLine(" Encrypted traffic");
Console.WriteLine(" Latency variance");

Console.WriteLine("");
Console.WriteLine("ExpressRoute:");
Console.WriteLine(" Dedicated private connection");
Console.WriteLine(" Consistent, low latency");
Console.WriteLine(" High bandwidth (10 Gbps+)");
Console.WriteLine(" Direct connection to Microsoft backbone");
Console.WriteLine(" Higher cost");
Console.WriteLine(" Longer setup time");

// VPN Gateway Setup
Console.WriteLine("VPN Gateway Configuration:");
Console.WriteLine("az network vnet-gateway create \\");
Console.WriteLine("  --name myVPNGateway \\");
Console.WriteLine("  --location eastus \\");
Console.WriteLine("  --resource-group myRG \\");
Console.WriteLine("  --vnet myVNet \\");
Console.WriteLine("  --gateway-type Vpn \\");
Console.WriteLine("  --vpn-type RouteBased \\");
Console.WriteLine("  --sku VpnGw1");

Console.WriteLine("Create local gateway (on-premises):");
Console.WriteLine("az network local-gateway create \\");
Console.WriteLine("  --name myOnPremisesGateway \\");
Console.WriteLine("  --location eastus \\");
Console.WriteLine("  --resource-group myRG \\");
Console.WriteLine("  --gateway-ip-address 203.0.113.12 \\");
Console.WriteLine("  --address-prefix 192.168.0.0/16");

Console.WriteLine("Create connection:");
Console.WriteLine("az network vpn-connection create \\");
Console.WriteLine("  --name myConnection \\");
Console.WriteLine("  --resource-group myRG \\");
Console.WriteLine("  --vnet-gateway1 myVPNGateway \\");
Console.WriteLine("  --local-gateway2 myOnPremisesGateway \\");
Console.WriteLine("  --shared-key MySharedSecret");

// ExpressRoute
Console.WriteLine("ExpressRoute Connectivity Models:");
Console.WriteLine("1. Colocation facility");
Console.WriteLine("2. Point-to-point Ethernet");
Console.WriteLine("3. Any-to-any (IPVPN)");

Console.WriteLine("Peering Types:");
Console.WriteLine("- Private Peering (to Azure VNets)");
Console.WriteLine("- Public Peering (Azure services)");
Console.WriteLine("- Microsoft Peering (Office 365, Dynamics 365)");

Console.WriteLine("Setup (requires provider):");
Console.WriteLine("1. Contact ExpressRoute provider");
Console.WriteLine("2. Provision circuit");
Console.WriteLine("3. Create connection");
Console.WriteLine("4. Configure BGP peering");`}]}]},Zy={id:"azure-api-security",name:"API Security & API Management",questions:[{id:"q1",question:"What is Azure API Management (APIM) and its key features?",answer:"APIM is gateway for APIs: publish, manage, secure, monitor. Key features: API versioning, rate limiting, authentication (OAuth, API Key), request/response transformation, analytics, developer portal, policy engine. Sits between clients and backend services.",codeSnippets:[{language:"csharp",code:`// Azure API Management (APIM)

Console.WriteLine("APIM Components:");
Console.WriteLine(" Gateway");
Console.WriteLine("   Request/response policies");
Console.WriteLine("   Authentication & authorization");
Console.WriteLine("   Rate limiting & throttling");
Console.WriteLine("   Request/response transformation");
Console.WriteLine(" Admin Portal (management)");
Console.WriteLine(" Developer Portal (API discovery)");
Console.WriteLine(" Service (metadata & configuration)");

// Create APIM Instance
Console.WriteLine("Create APIM:");
Console.WriteLine("az apim create \\");
Console.WriteLine("  --name myAPIM \\");
Console.WriteLine("  --resource-group myRG \\");
Console.WriteLine("  --publisher-name 'My Company' \\");
Console.WriteLine("  --publisher-email admin@company.com \\");
Console.WriteLine("  --sku-name Developer");

// Add API
Console.WriteLine("Add API:");
Console.WriteLine("az apim api create \\");
Console.WriteLine("  --service-name myAPIM \\");
Console.WriteLine("  --resource-group myRG \\");
Console.WriteLine("  --api-id myapi \\");
Console.WriteLine("  --display-name 'My API' \\");
Console.WriteLine("  --path /api \\");
Console.WriteLine("  --service-url https://api.backend.com");

// Add Operation
Console.WriteLine("Add Operation (GET /products):");
Console.WriteLine("az apim api operation create \\");
Console.WriteLine("  --service-name myAPIM \\");
Console.WriteLine("  --resource-group myRG \\");
Console.WriteLine("  --api-id myapi \\");
Console.WriteLine("  --operation-id getProducts \\");
Console.WriteLine("  --display-name 'Get Products' \\");
Console.WriteLine("  --method GET \\");
Console.WriteLine("  --url-template /products");

// API Versions & Revisions
Console.WriteLine("Versioning Schemes:");
Console.WriteLine("1. Query parameter: /api?api-version=1.0");
Console.WriteLine("2. Header: API-Version: 1.0");
Console.WriteLine("3. URL path: /api/v1/products");
Console.WriteLine("4. Custom header: Custom-Version: 1.0");

// Products (access control)
Console.WriteLine("Products (group APIs):");
Console.WriteLine("- Starter");
Console.WriteLine("- Basic");
Console.WriteLine("- Premium");

Console.WriteLine("Configure Product:");
Console.WriteLine("az apim product create \\");
Console.WriteLine("  --service-name myAPIM \\");
Console.WriteLine("  --resource-group myRG \\");
Console.WriteLine("  --product-name Starter \\");
Console.WriteLine("  --display-name 'Starter' \\");
Console.WriteLine("  --published true");

// Add API to Product
Console.WriteLine("Add API to Product:");
Console.WriteLine("az apim product api add \\");
Console.WriteLine("  --service-name myAPIM \\");
Console.WriteLine("  --resource-group myRG \\");
Console.WriteLine("  --product-name Starter \\");
Console.WriteLine("  --api-id myapi");

// Subscriptions (API keys)
Console.WriteLine("Create Subscription (API key):");
Console.WriteLine("az apim subscription create \\");
Console.WriteLine("  --service-name myAPIM \\");
Console.WriteLine("  --resource-group myRG \\");
Console.WriteLine("  --subscription-name myapp-sub \\");
Console.WriteLine("  --product-id Starter");

// Policies
Console.WriteLine("APIM Policies (XML-based):");
Console.WriteLine("- Inbound: Authentication, rate limit, validate");
Console.WriteLine("- Outbound: Cache, transform response");
Console.WriteLine("- Backend: Forward request, set backend");
Console.WriteLine("- On-error: Error handling");`}]},{id:"q2",question:"How do you secure APIs with APIM? Authentication & authorization?",answer:"APIM supports: API Key (subscription key), OAuth 2.0 (delegated auth), JWT tokens, Basic auth. Implement via inbound policies. Use AAD (Azure AD) for enterprise. Rate limiting via policies. SSL/TLS encryption. API consumers authenticated via subscriptions.",codeSnippets:[{language:"csharp",code:`// Azure APIM Security - Authentication & Authorization

Console.WriteLine("Authentication Methods:");

Console.WriteLine("1. API Key (Subscription Key)");
Console.WriteLine("   - Client sends key in header: Ocp-Apim-Subscription-Key");
Console.WriteLine("   - Easy, not for sensitive data");

Console.WriteLine("2. OAuth 2.0");
Console.WriteLine("   - Token-based authentication");
Console.WriteLine("   - Delegated authorization");
Console.WriteLine("   - User grants permission to app");

Console.WriteLine("3. Azure AD (Entra ID)");
Console.WriteLine("   - Enterprise SSO");
Console.WriteLine("   - SAML, OpenID Connect");

Console.WriteLine("4. JWT Tokens");
Console.WriteLine("   - Self-contained claims");
Console.WriteLine("   - Signature verification");

Console.WriteLine("5. Basic Authentication");
Console.WriteLine("   - Username:password in Authorization header");
Console.WriteLine("   - Always use HTTPS");

// APIM Policy - Validate JWT
Console.WriteLine("Validate JWT Token Policy:");
Console.WriteLine(@"
<policies>
  <inbound>
    <validate-jwt header-name=""Authorization"" 
                   failed-validation-httpcode=""401"" 
                   failed-validation-error-message=""Unauthorized"">
      <openid-config url=""https://login.microsoftonline.com/{tenant-id}/.well-known/openid-configuration"" />
      <audiences>
        <audience>https://api.example.com</audience>
      </audiences>
      <claim name=""iss"" match=""any"">
        <value>https://sts.windows.net/{tenant-id}/</value>
      </claim>
    </validate-jwt>
  </inbound>
</policies>");

// APIM Policy - Rate Limiting
Console.WriteLine("Rate Limiting Policy:");
Console.WriteLine(@"
<policies>
  <inbound>
    <rate-limit-by-key calls=""100"" 
                        renewal-period=""60"" 
                        counter-key=""@(context.Request.Headers.GetValueOrDefault("Authorization", "").AsJwt()?.Subject)"" />
  </inbound>
</policies>");

// APIM Policy - API Key Validation
Console.WriteLine("Validate Subscription Key:");
Console.WriteLine(@"
<policies>
  <inbound>
    <check-header name=""Ocp-Apim-Subscription-Key"" failed-check-httpcode=""401"" failed-check-error-message=""Missing or invalid subscription key"" />
  </inbound>
</policies>");

// APIM Policy - Transform Response
Console.WriteLine("Transform Response (add headers):");
Console.WriteLine(@"
<policies>
  <outbound>
    <set-header name=""X-API-Version"" exists-action=""override"">
      <value>1.0</value>
    </set-header>
    <set-header name=""X-Powered-By"" exists-action=""override"">
      <value>Azure API Management</value>
    </set-header>
  </outbound>
</policies>");

// Mock Response
Console.WriteLine("Mock Response (for testing):");
Console.WriteLine(@"
<policies>
  <inbound>
    <mock-response status-code=""200"" content-type=""application/json"">
      <payload>{ ""message"": ""mocked response"" }</payload>
    </mock-response>
  </inbound>
</policies>");

// Redirect Secure
Console.WriteLine("Redirect to HTTPS:");
Console.WriteLine(@"
<policies>
  <inbound>
    <redirect-content-urls />
  </inbound>
</policies>");`}]},{id:"q3",question:"What is Azure Application Gateway WAF and how to use it?",answer:"WAF (Web Application Firewall) on Application Gateway: protects against web vulnerabilities (SQL injection, XSS, DDoS). Rules: OWASP Core Rule Set. Modes: Detection (log), Prevention (block). Custom rules possible. Prevents malicious requests reaching backend.",codeSnippets:[{language:"csharp",code:`// Azure Application Gateway WAF (Web Application Firewall)

Console.WriteLine("WAF Protection:");
Console.WriteLine(" SQL Injection");
Console.WriteLine(" Cross-Site Scripting (XSS)");
Console.WriteLine(" Cross-Site Request Forgery (CSRF)");
Console.WriteLine(" Local File Inclusion (LFI)");
Console.WriteLine(" Remote File Inclusion (RFI)");
Console.WriteLine(" PHP Injection");
Console.WriteLine(" Session Fixation");

// Create App Gateway with WAF
Console.WriteLine("Create App Gateway with WAF:");
Console.WriteLine("az network application-gateway create \\");
Console.WriteLine("  --name myAppGW \\");
Console.WriteLine("  --location eastus \\");
Console.WriteLine("  --resource-group myRG \\");
Console.WriteLine("  --vnet-name myVNet \\");
Console.WriteLine("  --subnet mySubnet \\");
Console.WriteLine("  --capacity 2 \\");
Console.WriteLine("  --sku WAF_v2 \\");
Console.WriteLine("  --http-settings-cookie-based-affinity Disabled \\");
Console.WriteLine("  --frontend-port 443 \\");
Console.WriteLine("  --http-settings-port 443 \\");
Console.WriteLine("  --http-settings-protocol Https");

// Create WAF Policy
Console.WriteLine("Create WAF Policy:");
Console.WriteLine("az network application-gateway waf-policy create \\");
Console.WriteLine("  --name myWAFPolicy \\");
Console.WriteLine("  --resource-group myRG \\");
Console.WriteLine("  --type OWASP \\");
Console.WriteLine("  --version 3.0");

// WAF Modes
Console.WriteLine("WAF Modes:");
Console.WriteLine("1. Detection - Log threats, don't block");
Console.WriteLine("2. Prevention - Log threats, block requests");

Console.WriteLine("Set WAF Mode:");
Console.WriteLine("az network application-gateway waf-policy policy-settings update \\");
Console.WriteLine("  --name myWAFPolicy \\");
Console.WriteLine("  --resource-group myRG \\");
Console.WriteLine("  --mode Prevention");

// Rule Sets
Console.WriteLine("OWASP Core Rule Set (CRS):");
Console.WriteLine("- CRS 3.1 (latest)");
Console.WriteLine("- CRS 3.0");
Console.WriteLine("- CRS 2.2.9");

// Custom Rules
Console.WriteLine("Custom WAF Rule (block pattern):");
Console.WriteLine("az network application-gateway waf-policy custom-rule create \\");
Console.WriteLine("  --name BlockSuspiciousUserAgent \\");
Console.WriteLine("  --policy-name myWAFPolicy \\");
Console.WriteLine("  --resource-group myRG \\");
Console.WriteLine("  --priority 1 \\");
Console.WriteLine("  --rule-type MatchRule \\");
Console.WriteLine("  --action Block");

// Rate Limiting Rule
Console.WriteLine("Rate Limiting Custom Rule:");
Console.WriteLine("az network application-gateway waf-policy custom-rule create \\");
Console.WriteLine("  --name RateLimitPerIP \\");
Console.WriteLine("  --policy-name myWAFPolicy \\");
Console.WriteLine("  --resource-group myRG \\");
Console.WriteLine("  --priority 2 \\");
Console.WriteLine("  --rule-type RateLimitRule \\");
Console.WriteLine("  --action Block \\");
Console.WriteLine("  --rate-limit-duration 1m \\");
Console.WriteLine("  --rate-limit-threshold 100");

// Geo-blocking Rule
Console.WriteLine("Geo-blocking Rule:");
Console.WriteLine("az network application-gateway waf-policy custom-rule create \\");
Console.WriteLine("  --name AllowUSOnly \\");
Console.WriteLine("  --policy-name myWAFPolicy \\");
Console.WriteLine("  --resource-group myRG \\");
Console.WriteLine("  --priority 3 \\");
Console.WriteLine("  --rule-type MatchRule \\");
Console.WriteLine("  --action Allow");

// Exclusions
Console.WriteLine("WAF Exclusions (bypass rules):");
Console.WriteLine("- Exclude certain users");
Console.WriteLine("- Exclude parameters");
Console.WriteLine("- Exclude patterns");

Console.WriteLine("Add Exclusion:");
Console.WriteLine("az network application-gateway waf-policy managed-rule exclusion create \\");
Console.WriteLine("  --policy-name myWAFPolicy \\");
Console.WriteLine("  --resource-group myRG \\");
Console.WriteLine("  --exclusion-rule-set OWASP \\");
Console.WriteLine("  --exclusion-rule-group SQLi \\");
Console.WriteLine("  --selector-match-operator Contains \\");
Console.WriteLine("  --selector admin");

// Monitoring WAF
Console.WriteLine("Monitor WAF:");
Console.WriteLine("- Application Gateway Logs");
Console.WriteLine("- Application Gateway Metrics");
Console.WriteLine("- Log Analytics Workspace");`}]}]},eh={id:"azure-storage-services",name:"Storage Services",questions:[{id:"q1",question:"What are the main Azure Storage services and their use cases?",answer:"Azure Storage consists of four main services: 1) Blob Storage - for unstructured data (files, images, videos, backups). 2) File Shares - for managed SMB/NFS file shares accessible from multiple VMs. 3) Queue Storage - for asynchronous message queuing between services. 4) Table Storage - for NoSQL structured data (now mostly replaced by Cosmos DB). All support redundancy options: LRS (3 copies locally), GRS (3 locally + 3 in region pair), RA-GRS (GRS + read access). Pricing tiers: Hot (frequent access), Cool (infrequent), Archive (rare access).",codeSnippets:[{language:"csharp",code:`// Azure Storage Services Overview
using Azure.Storage.Blobs;
using Azure.Storage.Files.Shares;
using Azure.Storage.Queues;
using Azure.Data.Tables;
using Azure.Identity;

var storageAccountName = "mystorageaccount";
var storageUri = new Uri($"https://{storageAccountName}.blob.core.windows.net");

// 1. Blob Storage - Unstructured data (images, documents, videos)
var blobClient = new BlobContainerClient(
    new Uri($"https://{storageAccountName}.blob.core.windows.net/mycontainer"),
    new DefaultAzureCredential()
);

await blobClient.UploadBlobAsync("file.txt", BinaryData.FromString("content"));
BlobDownloadInfo download = await blobClient.GetBlobClient("file.txt").DownloadAsync();

// 2. File Shares - SMB/NFS file shares for VMs
var fileShareUri = new Uri($"https://{storageAccountName}.file.core.windows.net/myshare");
var shareClient = new ShareClient(fileShareUri, new DefaultAzureCredential());

ShareDirectoryClient dirClient = shareClient.GetRootDirectoryClient();
await dirClient.UploadFileAsync("document.txt", BinaryData.FromString("data"));

// 3. Queue Storage - Asynchronous messaging
var queueUri = new Uri($"https://{storageAccountName}.queue.core.windows.net/myqueue");
var queueClient = new QueueClient(queueUri, new DefaultAzureCredential());

await queueClient.SendMessageAsync("order-12345");
QueueMessage[] messages = await queueClient.ReceiveMessagesAsync(1);

// 4. Table Storage - NoSQL structured data
var tableUri = new Uri($"https://{storageAccountName}.table.core.windows.net");
var tableClient = new TableClient(tableUri, "Products", new DefaultAzureCredential());

// Storage Tiers
Console.WriteLine("Azure Storage Tiers:");
Console.WriteLine("Hot    - Frequent access, highest cost, instant retrieval");
Console.WriteLine("Cool   - Infrequent access (30+ days), lower cost");
Console.WriteLine("Archive - Rare access (90+ days), lowest cost, rehydration needed");

// Redundancy Options
Console.WriteLine("\\nRedundancy Options:");
Console.WriteLine("LRS  - Locally Redundant (3 copies in same datacenter)");
Console.WriteLine("GRS  - Geo-Redundant (3 local + 3 in secondary region)");
Console.WriteLine("RA-GRS - Read-Access Geo-Redundant (can read from secondary)");
Console.WriteLine("GZRS - Geo-Zone-Redundant (zone redundancy + geo)");`}]},{id:"q2",question:"How do you implement Blob Storage with access tiers and lifecycle management?",answer:"Blob Storage supports access tiers (Hot, Cool, Archive) for cost optimization. Hot tier is for frequent access. Cool tier for infrequent access (30+ days minimum), cheaper but retrieval slightly slower. Archive tier for rare access (90+ days), cheapest but requires rehydration. Lifecycle policies automatically move blobs between tiers based on age. Can specify rules like: move to Cool after 30 days, to Archive after 90 days. Supports blob versioning and soft delete for protection.",codeSnippets:[{language:"csharp",code:`// Azure Blob Storage - Access Tiers & Lifecycle
using Azure.Storage.Blobs;
using Azure.Storage.Blobs.Models;
using Azure.Identity;

var blobContainerUri = new Uri("https://mystorageaccount.blob.core.windows.net/mycontainer");
var containerClient = new BlobContainerClient(blobContainerUri, new DefaultAzureCredential());

// 1. Upload to different tiers
var blobClient = containerClient.GetBlobClient("report.pdf");

// Upload to Hot tier (default)
using (var stream = new MemoryStream(File.ReadAllBytes("large-file.pdf")))
{
    await blobClient.UploadAsync(stream, overwrite: true);
}

// Move to Cool tier
await blobClient.SetAccessTierAsync(AccessTier.Cool);

// Move to Archive tier (requires rehydration to access)
await blobClient.SetAccessTierAsync(AccessTier.Archive);

// 2. Rehydrate from Archive
await blobClient.SetAccessTierAsync(AccessTier.Hot, RehydratePriority.High);
// High priority: 1 hour, Standard priority: 15 hours

// 3. Download and check tier
BlobDownloadInfo download = await blobClient.DownloadAsync();
Console.WriteLine($"Blob tier: {download.Details.AccessTier}");

// 4. List blobs with properties
await foreach (BlobItem blobItem in containerClient.GetBlobsAsync(
    BlobTraits.None,
    BlobStates.None))
{
    Console.WriteLine($"Name: {blobItem.Name}");
    Console.WriteLine($"Size: {blobItem.Properties.ContentLength} bytes");
    Console.WriteLine($"Tier: {blobItem.Properties.AccessTier}");
    Console.WriteLine($"Created: {blobItem.Properties.CreatedOn}");
}

// 5. Lifecycle Management Policy (JSON config for Azure Portal or CLI)
var lifecyclePolicy = @"
{
  'rules': [
    {
      'name': 'AutoTiering',
      'enabled': true,
      'type': 'Lifecycle',
      'definition': {
        'actions': {
          'baseBlob': {
            'tierToCool': {
              'daysAfterModificationGreaterThan': 30
            },
            'tierToArchive': {
              'daysAfterModificationGreaterThan': 90
            },
            'delete': {
              'daysAfterModificationGreaterThan': 365
            }
          }
        },
        'filters': {
          'blobTypes': ['blockBlob']
        }
      }
    }
  ]
}";

// CLI to set lifecycle policy:
// az storage account management-policy create --account-name mystorageaccount 
// --resource-group myRG --policy @policy.json

// 6. Soft Delete & Versioning
var containerProperties = new BlobContainerProperties();
// Enable soft delete (items recoverable for 7 days after deletion)
// Enable versioning (keeps previous versions)

// Cost Optimization Example
Console.WriteLine("Storage Cost Optimization Strategy:");
Console.WriteLine("- New data (0-30 days)  Hot tier");
Console.WriteLine("- Aged data (30-90 days)  Cool tier");
Console.WriteLine("- Old backups (90+ days)  Archive tier");
Console.WriteLine("- Never accessed (365+ days)  Delete");
Console.WriteLine("\\nThis can reduce storage costs by 50-80%");`}]},{id:"q3",question:"What is the difference between Blob Storage, File Shares, and Queue Storage?",answer:"Blob Storage: Unstructured data storage (images, videos, documents, backups), REST API access, optimal for massive scale data. File Shares: Managed SMB/NFS shares for network access, mount like network drives, supports Windows/Linux, good for legacy apps sharing files. Queue Storage: Asynchronous message queuing for decoupling services, FIFO, messages expire after 7 days (default), small payload size (64KB). Choose Blob for files, File Shares for shared network access, Queue for async communication.",codeSnippets:[{language:"csharp",code:`// Comparison: Blob vs File Shares vs Queue Storage
using Azure.Storage.Blobs;
using Azure.Storage.Files.Shares;
using Azure.Storage.Queues;
using Azure.Storage.Queues.Models;
using Azure.Identity;

var accountName = "mystorageaccount";

// ============= BLOB STORAGE =============
// Use Case: Large files, images, backups, unstructured data
// Access: REST API, HTTP/HTTPS, SDKs
// Scale: Petabytes, millions of files

var blobUri = new Uri($"https://{accountName}.blob.core.windows.net/files");
var blobContainer = new BlobContainerClient(blobUri, new DefaultAzureCredential());

// Upload large file
var blockBlobClient = blobContainer.GetBlockBlobClient("large-video.mp4");
await blockBlobClient.UploadAsync("video.mp4", overwrite: true);

// Upload with metadata
var blobHttpHeaders = new BlobHttpHeaders { ContentType = "image/jpeg" };
var metadata = new Dictionary<string, string> { { "department", "marketing" } };
await blockBlobClient.SetHttpHeadersAsync(blobHttpHeaders);
await blockBlobClient.SetMetadataAsync(metadata);

Console.WriteLine(" Blob Storage: Best for unstructured large data");

// ============= FILE SHARES =============
// Use Case: Shared file access, legacy apps, SMB protocol
// Access: SMB 3.0 (Windows/Linux/macOS), NFS 4.1
// Scale: Up to 100TB per share

var fileShareUri = new Uri($"https://{accountName}.file.core.windows.net");
var fileShareClient = new ShareClient(fileShareUri, new DefaultAzureCredential());

var shareRootDir = fileShareClient.GetRootDirectoryClient();
var subdirectory = shareRootDir.GetSubdirectoryClient("documents");
await subdirectory.CreateIfNotExistsAsync();

// Upload file to share
using (var stream = File.OpenRead("report.docx"))
{
    await subdirectory.GetFileClient("report.docx").UploadAsync(stream, overwrite: true);
}

// Can be mounted like network drive:
// Windows: net use Z: \\\\mystorageaccount.file.core.windows.net\\fileshare password /user:azure\\mystorageaccount
// Linux: mount -t cifs //mystorageaccount.file.core.windows.net/fileshare /mnt/share -o username=mystorageaccount

Console.WriteLine(" File Shares: Best for shared network file access");

// ============= QUEUE STORAGE =============
// Use Case: Asynchronous job queuing, decoupling services
// Access: REST API, message-based
// Message Size: Up to 64KB, TTL 7 days default

var queueUri = new Uri($"https://{accountName}.queue.core.windows.net");
var queueClient = new QueueClient(queueUri, new DefaultAzureCredential());

// Producer: Enqueue message
await queueClient.SendMessageAsync("process-order-12345");
await queueClient.SendMessageAsync("send-email-user-456");

// Consumer: Dequeue and process
QueueMessage[] messages = await queueClient.ReceiveMessagesAsync(
    maxMessages: 10,
    visibilityTimeout: TimeSpan.FromMinutes(5)
);

foreach (QueueMessage message in messages)
{
    Console.WriteLine($"Processing: {message.Body}");
    
    // Process the message
    await ProcessOrderAsync(message.Body.ToString());
    
    // Delete from queue when done
    await queueClient.DeleteMessageAsync(message.MessageId, message.PopReceipt);
}

// If processing fails, message becomes visible again after visibilityTimeout
// Max retries: message TTL (default 7 days)

Console.WriteLine(" Queue Storage: Best for asynchronous task queuing");

// ============= COMPARISON TABLE =============
var comparison = new[]
{
    new { Service = "Blob", Use = "Large files/images/backups", Protocol = "REST/HTTP", Scale = "Petabytes", Cost = "$" },
    new { Service = "File Shares", Use = "Shared network access", Protocol = "SMB/NFS", Scale = "100TB/share", Cost = "$" },
    new { Service = "Queue", Use = "Async messaging", Protocol = "REST/HTTP", Scale = "Millions msg", Cost = "$" }
};

Console.WriteLine("\\nComparison:");
Console.WriteLine("Service      | Use Case               | Protocol    | Scale         | Cost");
Console.WriteLine("-------------|------------------------|-------------|---------------|------");
foreach (var row in comparison)
{
    Console.WriteLine($"{row.Service,-12} | {row.Use,-22} | {row.Protocol,-11} | {row.Scale,-13} | {row.Cost}");
}

async Task ProcessOrderAsync(string orderId)
{
    await Task.Delay(1000);
    Console.WriteLine($"Order {orderId} processed successfully");
}`}]},{id:"q4",question:"How do you secure Azure Storage with SAS tokens and managed identities?",answer:"Azure Storage can be secured using: 1) Storage Account Keys (not recommended for production, full access). 2) Shared Access Signatures (SAS) - time-limited tokens with specific permissions, can be Account-level or Service-level. 3) Managed Identities - best practice, Azure AD integration, no credentials to manage, automatic rotation. 4) Azure RBAC - role-based access control with fine-grained permissions. SAS tokens include expiration, IP restrictions, protocol constraints. Managed identities with Azure.Identity DefaultAzureCredential is production-recommended.",codeSnippets:[{language:"csharp",code:`// Azure Storage Security - SAS Tokens & Managed Identities
using Azure.Storage.Blobs;
using Azure.Storage.Blobs.Sas;
using Azure.Storage.Sas;
using Azure.Identity;
using Azure;

var accountName = "mystorageaccount";
var accountKey = "your-account-key";
var containerName = "mycontainer";

// ============= APPROACH 1: Managed Identity (RECOMMENDED) =============
// Best practice: No credentials needed, automatic rotation
// Requirements: Enable Managed Identity on your Azure resource (VM, App Service, Function, etc.)

var blobUri = new Uri($"https://{accountName}.blob.core.windows.net/{containerName}");
var blobContainerClient = new BlobContainerClient(
    blobUri,
    new DefaultAzureCredential() // Uses Managed Identity automatically
);

// Access blob without any credentials!
var blobClient = blobContainerClient.GetBlobClient("data.json");
BlobDownloadInfo download = await blobClient.DownloadAsync();
Console.WriteLine(" Accessed blob using Managed Identity");

// ============= APPROACH 2: Account-Level SAS Token =============
// Temporary token with expiration, specific permissions, IP/protocol restrictions

var sharedKeyCredential = new StorageSharedKeyCredential(accountName, accountKey);

// Create Account SAS (high privilege, access to all services)
AccountSasBuilder sasBuilder = new AccountSasBuilder()
{
    Services = AccountSasServices.Blobs | AccountSasServices.Queues,
    ResourceTypes = AccountSasResourceTypes.All,
    ExpiresOn = DateTimeOffset.UtcNow.AddHours(1),
    Protocol = SasProtocol.Https,
    IPRange = new SasIPRange(System.Net.IPAddress.Parse("203.0.113.0"), System.Net.IPAddress.Parse("203.0.113.100"))
};

sasBuilder.SetPermissions(AccountSasPermissions.All);

string accountSasToken = sasBuilder.ToSasQueryParameters(sharedKeyCredential).ToString();
Console.WriteLine($"Account SAS Token: {accountSasToken}");

// ============= APPROACH 3: Service-Level SAS Token =============
// Specific to a container or blob, more secure than account SAS

BlobSasBuilder blobSasBuilder = new BlobSasBuilder()
{
    BlobContainerName = containerName,
    BlobName = "data.json",
    ExpiresOn = DateTimeOffset.UtcNow.AddMinutes(30), // Expires in 30 minutes
    Protocol = SasProtocol.Https
};

// Read-only permissions
blobSasBuilder.SetPermissions(BlobSasPermissions.Read);

string blobSasToken = blobSasBuilder.ToSasQueryParameters(sharedKeyCredential).ToString();
string sasUri = new UriBuilder(blobUri)
{
    Query = blobSasToken
}.Uri.ToString();

Console.WriteLine($"Blob SAS URI: {sasUri}");

// Grant write permission for 1 hour
var writeSasBuilder = new BlobSasBuilder()
{
    BlobContainerName = containerName,
    ExpiresOn = DateTimeOffset.UtcNow.AddHours(1)
};
writeSasBuilder.SetPermissions(BlobSasPermissions.Write | BlobSasPermissions.Create | BlobSasPermissions.Delete);

// ============= APPROACH 4: Azure RBAC (Recommended for production) =============
// Assign roles to Managed Identity or users
// Roles: Storage Blob Data Owner, Storage Blob Data Contributor, Storage Blob Data Reader

// Example: Assign 'Storage Blob Data Reader' role to app's Managed Identity
// az role assignment create \\
//   --role "Storage Blob Data Reader" \\
//   --assignee-object-id <managed-identity-object-id> \\
//   --scope /subscriptions/<sub>/resourceGroups/<rg>/providers/Microsoft.Storage/storageAccounts/<account>

// ============= SECURITY BEST PRACTICES =============
Console.WriteLine("\\nSecurity Best Practices:");
Console.WriteLine("1.  Use Managed Identity for Azure services (no credentials)");
Console.WriteLine("2.  Use SAS tokens for temporary/external access (time-limited)");
Console.WriteLine("3.  Apply IP restrictions to SAS tokens");
Console.WriteLine("4.  Use HTTPS only (SasProtocol.Https)");
Console.WriteLine("5.  Never expose account keys in code");
Console.WriteLine("6.  Rotate keys regularly (if using)");
Console.WriteLine("7.  Use RBAC for permanent role-based access");
Console.WriteLine("8.  Enable firewall rules (allow specific VNets/IPs)");
Console.WriteLine("9.  Monitor access logs and alerts");
Console.WriteLine("10.  Use private endpoints (deny public access)");

// ============= PRIVATE ENDPOINT EXAMPLE =============
// Block public internet, only allow from private VNet
Console.WriteLine("\\nPrivate Endpoint Setup:");
Console.WriteLine("az network private-endpoint create \\\\");
Console.WriteLine("  --name myPrivateEndpoint \\\\");
Console.WriteLine("  --resource-group myRG \\\\");
Console.WriteLine("  --vnet-name myVNet \\\\");
Console.WriteLine("  --subnet mySubnet \\\\");
Console.WriteLine("  --private-connection-resource-id /subscriptions/.../storageAccounts/mystorageaccount \\\\");
Console.WriteLine("  --group-ids blob");`}]},{id:"q5",question:"How do you implement Queue Storage for producer-consumer patterns?",answer:"Queue Storage enables decoupling of services using producer-consumer pattern. Producer sends messages, consumer processes them. Messages have TTL (7 days default), visibility timeout (how long message hidden after receive), and dead-letter handling. Implement polling or use Azure Functions with Queue trigger for automatic scaling. Use message batching for efficiency. Implement idempotent processing for reliability (same message processed multiple times shouldn't cause issues).",codeSnippets:[{language:"csharp",code:`// Azure Queue Storage - Producer-Consumer Pattern
using Azure.Storage.Queues;
using Azure.Storage.Queues.Models;
using Azure.Identity;
using System.Text.Json;

var queueUri = new Uri("https://mystorageaccount.queue.core.windows.net/orders");
var queueClient = new QueueClient(queueUri, new DefaultAzureCredential());

// ============= PRODUCER: Send Orders =============
async Task ProduceOrdersAsync()
{
    var orders = new[]
    {
        new Order { OrderId = "ORD-001", CustomerId = "CUST-100", Total = 99.99m },
        new Order { OrderId = "ORD-002", CustomerId = "CUST-101", Total = 149.99m },
        new Order { OrderId = "ORD-003", CustomerId = "CUST-102", Total = 79.99m }
    };

    foreach (var order in orders)
    {
        // Serialize order to JSON
        string messageText = JsonSerializer.Serialize(order);
        
        // Send to queue
        await queueClient.SendMessageAsync(messageText);
        Console.WriteLine($" Enqueued order: {order.OrderId}");
    }
}

// ============= CONSUMER: Process Orders (Polling) =============
async Task ConsumeOrdersAsync(CancellationToken cancellationToken)
{
    Console.WriteLine("Consumer started, waiting for messages...");
    
    while (!cancellationToken.IsCancellationRequested)
    {
        try
        {
            // Receive up to 10 messages
            QueueMessage[] messages = await queueClient.ReceiveMessagesAsync(
                maxMessages: 10,
                visibilityTimeout: TimeSpan.FromMinutes(5) // Hidden for 5 min while processing
            );

            if (messages.Length == 0)
            {
                Console.WriteLine("No messages, waiting...");
                await Task.Delay(TimeSpan.FromSeconds(10));
                continue;
            }

            foreach (QueueMessage message in messages)
            {
                try
                {
                    // Deserialize message
                    var order = JsonSerializer.Deserialize<Order>(message.Body.ToString());
                    Console.WriteLine($"Processing order: {order?.OrderId}");

                    // Process order (simulate work)
                    await ProcessOrderAsync(order);

                    // Delete message on successful processing
                    await queueClient.DeleteMessageAsync(message.MessageId, message.PopReceipt);
                    Console.WriteLine($" Order processed and removed from queue");
                }
                catch (Exception ex)
                {
                    Console.WriteLine($"Error processing message: {ex.Message}");
                    // Message visibility resets, will be retried
                    // After max retries (TTL expires), goes to dead-letter queue
                }
            }
        }
        catch (Exception ex)
        {
            Console.WriteLine($"Consumer error: {ex.Message}");
            await Task.Delay(TimeSpan.FromSeconds(5));
        }
    }
}

// ============= DEAD-LETTER QUEUE =============
async Task HandleDeadLettersAsync()
{
    var dlqClient = new QueueClient(
        new Uri("https://mystorageaccount.queue.core.windows.net/orders-deadletter"),
        new DefaultAzureCredential()
    );

    var messages = await dlqClient.ReceiveMessagesAsync(maxMessages: 1);
    if (messages.Length > 0)
    {
        Console.WriteLine($"Dead-letter message: {messages[0].Body}");
        // Manual review or retry logic
    }
}

// ============= IDEMPOTENT PROCESSING =============
async Task ProcessOrderIdempotentAsync(Order order)
{
    // Check if already processed (idempotency key)
    string idempotencyKey = $"order-{order.OrderId}";
    
    if (await IsAlreadyProcessedAsync(idempotencyKey))
    {
        Console.WriteLine($"Order {order.OrderId} already processed, skipping");
        return;
    }

    // Process order
    await ProcessOrderAsync(order);

    // Mark as processed
    await MarkAsProcessedAsync(idempotencyKey);
}

// ============= BATCH PROCESSING =============
async Task ProcessBatchAsync()
{
    int batchSize = 10;
    var messages = await queueClient.ReceiveMessagesAsync(maxMessages: batchSize);

    if (messages.Length > 0)
    {
        var orders = messages
            .Select(m => JsonSerializer.Deserialize<Order>(m.Body.ToString()))
            .ToList();

        // Batch database insert (more efficient)
        await BatchInsertOrdersAsync(orders);

        // Delete all messages at once
        foreach (var message in messages)
        {
            await queueClient.DeleteMessageAsync(message.MessageId, message.PopReceipt);
        }
    }
}

// ============= PRIORITY QUEUES =============
async Task PriorityQueuePatternAsync()
{
    var highPriorityQueue = new QueueClient(
        new Uri("https://mystorageaccount.queue.core.windows.net/orders-high-priority"),
        new DefaultAzureCredential()
    );

    var normalQueue = new QueueClient(
        new Uri("https://mystorageaccount.queue.core.windows.net/orders-normal"),
        new DefaultAzureCredential()
    );

    // Consumer processes high-priority first
    var highPriorityMessages = await highPriorityQueue.ReceiveMessagesAsync(maxMessages: 5);
    if (highPriorityMessages.Length > 0)
    {
        Console.WriteLine("Processing high-priority orders first!");
    }

    var normalMessages = await normalQueue.ReceiveMessagesAsync(maxMessages: 5);
    Console.WriteLine("Then processing normal orders");
}

// ============= HELPER METHODS =============
async Task ProcessOrderAsync(Order order)
{
    await Task.Delay(1000); // Simulate processing
    Console.WriteLine($"Order {order.OrderId} processed successfully");
}

async Task<bool> IsAlreadyProcessedAsync(string idempotencyKey)
{
    await Task.Delay(100);
    return false; // Check in database
}

async Task MarkAsProcessedAsync(string idempotencyKey)
{
    await Task.Delay(100);
    Console.WriteLine($"Marked {idempotencyKey} as processed");
}

async Task BatchInsertOrdersAsync(List<Order> orders)
{
    await Task.Delay(500);
    Console.WriteLine($"Batch inserted {orders.Count} orders");
}

// ============= QUEUE CONFIGURATION =============
Console.WriteLine("Queue Storage Configuration:");
Console.WriteLine("- Max message size: 64 KB");
Console.WriteLine("- Default TTL: 7 days");
Console.WriteLine("- Visibility timeout: Configurable per receive (max 12 hours)");
Console.WriteLine("- Max queue size: 500 TB");
Console.WriteLine("- Throughput: Millions of messages per day");

// Main execution
var cts = new CancellationTokenSource();

// Start producer
await ProduceOrdersAsync();

// Start consumer
_ = ConsumeOrdersAsync(cts.Token);

// Run for 30 seconds
await Task.Delay(TimeSpan.FromSeconds(30));
cts.Cancel();

class Order
{
    public string OrderId { get; set; }
    public string CustomerId { get; set; }
    public decimal Total { get; set; }
}`}]}]},th={id:"azure-durable-functions",name:"Durable Functions",questions:[{id:"q1",question:"What are Azure Durable Functions and what problems do they solve?",answer:"Azure Durable Functions extend Azure Functions with stateful workflow capabilities. They solve problems: 1) Function orchestration - coordinating multiple functions with dependencies. 2) Long-running processes - workflows lasting hours/days without timeout. 3) Distributed transactions - managing state across function calls. 4) Retry logic - built-in with exponential backoff. 5) Checkpointing - automatic resumption from failure point. 6) Fan-out/fan-in - parallel task execution and aggregation. Key patterns: Orchestrator functions coordinate work, Activity functions do the work, Entity functions maintain state. Uses event sourcing internally, enabling replaying from checkpoints.",codeSnippets:[{language:"csharp",code:`// Azure Durable Functions - Core Concepts
using Microsoft.Azure.WebJobs;
using Microsoft.Azure.WebJobs.Extensions.DurableTask;
using System;
using System.Collections.Generic;
using System.Threading.Tasks;

// ============= ORCHESTRATOR FUNCTION =============
// Coordinates workflow, schedules tasks, manages state
// Note: Must be deterministic (same input = same execution path)

[FunctionName("OrderProcessingOrchestrator")]
public static async Task RunOrchestrator(
    [OrchestrationTrigger] IDurableOrchestrationContext context)
{
    var order = context.GetInput<Order>();
    var results = new List<string>();

    try
    {
        // Step 1: Validate order (calls activity function)
        var isValid = await context.CallActivityAsync<bool>(
            "ValidateOrderActivity",
            order
        );

        if (!isValid)
        {
            throw new InvalidOperationException("Order validation failed");
        }

        // Step 2: Process payment
        var paymentResult = await context.CallActivityAsync<string>(
            "ProcessPaymentActivity",
            order.Total
        );
        results.Add(paymentResult);

        // Step 3: Send confirmation email
        await context.CallActivityAsync(
            "SendConfirmationEmailActivity",
            order.CustomerEmail
        );

        // Step 4: Update inventory
        await context.CallActivityAsync(
            "UpdateInventoryActivity",
            order.Items
        );

        await context.CallActivityAsync(
            "LogSuccessActivity",
            $"Order {order.OrderId} completed successfully"
        );
    }
    catch (Exception ex)
    {
        await context.CallActivityAsync(
            "LogErrorActivity",
            ex.Message
        );
        throw;
    }
}

// ============= ACTIVITY FUNCTIONS =============
// Do the actual work (HTTP calls, database operations, etc.)
// Can be retried, can fail, no side-effect restrictions

[FunctionName("ValidateOrderActivity")]
public static async Task<bool> ValidateOrder(
    [ActivityTrigger] Order order)
{
    Console.WriteLine($"Validating order {order.OrderId}");
    await Task.Delay(500);
    return order.Total > 0 && !string.IsNullOrEmpty(order.CustomerEmail);
}

[FunctionName("ProcessPaymentActivity")]
public static async Task<string> ProcessPayment(
    [ActivityTrigger] decimal paymentAmount)
{
    Console.WriteLine($"Processing payment of \${paymentAmount}");
    await Task.Delay(1000); // Simulate payment gateway
    return $"Payment processed: \${paymentAmount}";
}

[FunctionName("SendConfirmationEmailActivity")]
public static async Task SendConfirmationEmail(
    [ActivityTrigger] string email)
{
    Console.WriteLine($"Sending confirmation to {email}");
    await Task.Delay(300);
}

[FunctionName("UpdateInventoryActivity")]
public static async Task UpdateInventory(
    [ActivityTrigger] List<OrderItem> items)
{
    Console.WriteLine($"Updating inventory for {items.Count} items");
    await Task.Delay(400);
}

[FunctionName("LogSuccessActivity")]
public static void LogSuccess([ActivityTrigger] string message)
{
    Console.WriteLine($" {message}");
}

[FunctionName("LogErrorActivity")]
public static void LogError([ActivityTrigger] string error)
{
    Console.WriteLine($" Error: {error}");
}

// ============= CLIENT FUNCTION =============
// Starts the orchestrator

[FunctionName("StartOrderProcessing")]
public static async Task<string> StartOrchestrator(
    [HttpTrigger(AuthorizationLevel.Anonymous, "post", Route = "orders")] Order order,
    [DurableClient] IDurableOrchestrationClient client)
{
    string instanceId = await client.StartNewAsync(
        "OrderProcessingOrchestrator",
        order
    );

    Console.WriteLine($"Started orchestration with ID: {instanceId}");
    return instanceId;
}

// ============= CHECK STATUS =============
[FunctionName("GetOrchestrationStatus")]
public static async Task<IActionResult> GetStatus(
    [HttpTrigger(AuthorizationLevel.Anonymous, "get", Route = "orders/{instanceId}")] string instanceId,
    [DurableClient] IDurableOrchestrationClient client)
{
    var status = await client.GetStatusAsync(instanceId);
    
    return new OkObjectResult(new
    {
        InstanceId = instanceId,
        Status = status.RuntimeStatus,
        Input = status.Input,
        Output = status.Output,
        CreatedTime = status.CreatedTime,
        LastUpdatedTime = status.LastUpdatedTime
    });
}

// ============= KEY BENEFITS =============
Console.WriteLine("Durable Functions Benefits:");
Console.WriteLine(" Automatic checkpointing - resume from failure point");
Console.WriteLine(" Long-running workflows - hours/days, no timeout");
Console.WriteLine(" Built-in retry logic - exponential backoff");
Console.WriteLine(" Fan-out/fan-in patterns - parallel execution");
Console.WriteLine(" State management - automatic");
Console.WriteLine(" Event sourcing - full execution history");

class Order
{
    public string OrderId { get; set; }
    public decimal Total { get; set; }
    public string CustomerEmail { get; set; }
    public List<OrderItem> Items { get; set; }
}

class OrderItem
{
    public string ProductId { get; set; }
    public int Quantity { get; set; }
}`}]},{id:"q2",question:"What are the different Durable Functions patterns (Fan-out/Fan-in, Chaining, etc.)?",answer:"Main patterns: 1) Function Chaining - sequential execution where output of one is input to next. 2) Fan-out/Fan-in - call multiple activities in parallel, then aggregate results. 3) Async HTTP APIs - long-running workflows with polling mechanism. 4) Monitor - recurring operations checking conditions. 5) Human interaction - workflows waiting for human approval. 6) Sub-orchestrations - orchestrators calling other orchestrators. 7) Entity functions - durable state management for counters, voting, etc. Each pattern solves specific workflow challenges.",codeSnippets:[{language:"csharp",code:`// Durable Functions - Common Patterns
using Microsoft.Azure.WebJobs;
using Microsoft.Azure.WebJobs.Extensions.DurableTask;
using System;
using System.Collections.Generic;
using System.Linq;
using System.Threading.Tasks;

// ============= PATTERN 1: FUNCTION CHAINING =============
// Sequential execution: A  B  C
// Output of A becomes input to B, etc.

[FunctionName("ChainingOrchestrator")]
public static async Task<string> Chaining(
    [OrchestrationTrigger] IDurableOrchestrationContext context,
    string input)
{
    try
    {
        // Step 1: Get user
        var user = await context.CallActivityAsync<User>(
            "GetUserActivity",
            input
        );
        Console.WriteLine($"Step 1: Got user {user.Name}");

        // Step 2: Get user orders (uses user from step 1)
        var orders = await context.CallActivityAsync<List<Order>>(
            "GetUserOrdersActivity",
            user.UserId
        );
        Console.WriteLine($"Step 2: Got {orders.Count} orders");

        // Step 3: Calculate total spent (uses orders from step 2)
        var totalSpentAmount = await context.CallActivityAsync<decimal>(
            "CalculateTotalSpentActivity",
            orders
        );
        Console.WriteLine($"Step 3: Total spent: \${totalSpentAmount}");

        // Step 4: Award loyalty points (uses totalSpent from step 3)
        var loyaltyPoints = await context.CallActivityAsync<int>(
            "AwardLoyaltyPointsActivity",
            new { UserId = user.UserId, TotalSpent = totalSpentAmount }
        );

        return $"Chaining complete. User earned {loyaltyPoints} points";
    }
    catch (Exception ex)
    {
        return $"Chaining failed: {ex.Message}";
    }
}

// ============= PATTERN 2: FAN-OUT/FAN-IN =============
// Call multiple tasks in PARALLEL, then aggregate results
// Parallel execution = faster than sequential

[FunctionName("FanOutFanInOrchestrator")]
public static async Task<ParallelResults> FanOutFanIn(
    [OrchestrationTrigger] IDurableOrchestrationContext context,
    string orderId)
{
    try
    {
        // Start multiple tasks in PARALLEL
        var tasks = new List<Task>();

        // Task 1: Validate order
        tasks.Add(context.CallActivityAsync("ValidateOrderActivity", orderId));

        // Task 2: Check inventory (runs in parallel!)
        tasks.Add(context.CallActivityAsync("CheckInventoryActivity", orderId));

        // Task 3: Verify payment method (runs in parallel!)
        tasks.Add(context.CallActivityAsync("VerifyPaymentActivity", orderId));

        // Task 4: Check fraud (runs in parallel!)
        tasks.Add(context.CallActivityAsync("CheckFraudActivity", orderId));

        // Wait for ALL tasks to complete
        await Task.WhenAll(tasks);

        // FAN-IN: Aggregate results
        var results = await context.CallActivityAsync<ParallelResults>(
            "AggregateResultsActivity",
            orderId
        );

        return results;
    }
    catch (Exception ex)
    {
        throw;
    }
}

// ============= PATTERN 3: ASYNC HTTP APIS =============
// Long-running workflow with status checking

[FunctionName("ReportOrchestrator")]
public static async Task<string> GenerateReportOrchestrator(
    [OrchestrationTrigger] IDurableOrchestrationContext context,
    ReportRequest request)
{
    // This orchestrator runs for hours
    var location = await context.CallActivityAsync<string>(
        "GenerateLargeReportActivity",
        request
    );

    return location;
}

[FunctionName("GenerateLargeReportActivity")]
public static async Task<string> GenerateLargeReport(
    [ActivityTrigger] ReportRequest request)
{
    // Simulate long-running report generation (1 hour+)
    await Task.Delay(TimeSpan.FromHours(1));
    return $"https://storage.blob.core.windows.net/reports/{request.ReportName}.pdf";
}

[FunctionName("StartReportGeneration")]
public static async Task<DurableOrchestrationStatus> StartReport(
    [HttpTrigger(AuthorizationLevel.Anonymous, "post", Route = "reports")] ReportRequest request,
    [DurableClient] IDurableOrchestrationClient client)
{
    string instanceId = await client.StartNewAsync(
        "ReportOrchestrator",
        request
    );

    // Return status URL for polling
    return new DurableOrchestrationStatus
    {
        InstanceId = instanceId,
        StatusQueryGetUri = $"/api/reports/{instanceId}"
    };
}

// ============= PATTERN 4: MONITOR =============
// Continuously check a condition, retry on failure

[FunctionName("MonitorOrchestrator")]
public static async Task Monitor(
    [OrchestrationTrigger] IDurableOrchestrationContext context,
    string deploymentId)
{
    var retryPolicy = new RetryOptions(
        firstRetryInterval: TimeSpan.FromSeconds(5),
        maxNumberOfAttempts: 30 // Try for 2.5 minutes
    )
    {
        BackoffCoefficient = 1.5
    };

    while (true)
    {
        try
        {
            // Check deployment status every 5 seconds
            var status = await context.CallActivityWithRetryAsync<string>(
                "CheckDeploymentStatusActivity",
                retryPolicy,
                deploymentId
            );

            if (status == "Completed")
            {
                Console.WriteLine("Deployment completed!");
                break;
            }

            // Wait before next check
            var nextCheckTime = context.CurrentUtcDateTime.AddSeconds(5);
            await context.CreateTimer(nextCheckTime, CancellationToken.None);
        }
        catch (Exception ex)
        {
            Console.WriteLine($"Deployment failed: {ex.Message}");
            throw;
        }
    }
}

// ============= PATTERN 5: HUMAN INTERACTION =============
// Workflow waiting for human approval

[FunctionName("ApprovalOrchestrator")]
public static async Task<string> HumanApproval(
    [OrchestrationTrigger] IDurableOrchestrationContext context,
    PurchaseOrder po)
{
    // Request human approval
    await context.CallActivityAsync("RequestApprovalActivity", po);

    // Wait for approval (timeout after 48 hours)
    var approvalTimeout = context.CreateTimer(
        context.CurrentUtcDateTime.AddHours(48),
        CancellationToken.None
    );

    var approvalTask = context.WaitForExternalEvent<bool>("ApprovalSubmitted");

    var winner = await Task.WhenAny(approvalTask, approvalTimeout);

    if (winner == approvalTask)
    {
        // Approval received before timeout
        bool isApproved = approvalTask.Result;

        if (isApproved)
        {
            await context.CallActivityAsync("ProcessPurchaseActivity", po);
            return "Purchase approved and processed";
        }
        else
        {
            await context.CallActivityAsync("RejectPurchaseActivity", po);
            return "Purchase rejected";
        }
    }
    else
    {
        // Timeout
        return "Approval request timed out";
    }
}

[FunctionName("SubmitApproval")]
public static async Task SubmitApproval(
    [HttpTrigger(AuthorizationLevel.Anonymous, "post", Route = "approve/{instanceId}")] string instanceId,
    bool approved,
    [DurableClient] IDurableOrchestrationClient client)
{
    // Send approval decision to waiting orchestrator
    await client.RaiseEventAsync(instanceId, "ApprovalSubmitted", approved);
}

// ============= PATTERN 6: SUB-ORCHESTRATIONS =============
// Orchestrator calling another orchestrator

[FunctionName("ParentOrchestrator")]
public static async Task<string> ParentOrchestrator(
    [OrchestrationTrigger] IDurableOrchestrationContext context,
    int orderId)
{
    // Call sub-orchestrator
    var paymentResult = await context.CallSubOrchestratorAsync<string>(
        "PaymentSubOrchestrator",
        orderId
    );

    var shipmentResult = await context.CallSubOrchestratorAsync<string>(
        "ShipmentSubOrchestrator",
        orderId
    );

    return $"Parent: {paymentResult}, {shipmentResult}";
}

[FunctionName("PaymentSubOrchestrator")]
public static async Task<string> PaymentSubOrchestrator(
    [OrchestrationTrigger] IDurableOrchestrationContext context,
    int orderId)
{
    var result = await context.CallActivityAsync<string>(
        "ProcessPaymentActivity",
        orderId
    );
    return result;
}

// ============= PATTERN 7: ENTITY FUNCTIONS =============
// Durable state management (counters, flags, etc.)

[FunctionName("CounterEntity")]
public static void Counter(
    [EntityFunctionInput] IDurableEntityContext context)
{
    var currentValue = context.State<int>();

    switch (context.OperationName.ToLowerInvariant())
    {
        case "add":
            currentValue += (int)context.GetInput<int>();
            break;
        case "get":
            context.SetResult(currentValue);
            break;
        case "set":
            currentValue = (int)context.GetInput<int>();
            break;
    }

    context.State = currentValue;
}

// Use entity in orchestrator
[FunctionName("CounterOrchestrator")]
public static async Task UseCounter(
    [OrchestrationTrigger] IDurableOrchestrationContext context)
{
    var entityId = new EntityId("CounterEntity", "myCounter");

    // Call entity operations
    await context.CallEntityAsync(entityId, "add", 5);
    await context.CallEntityAsync(entityId, "add", 3);
    var value = await context.CallEntityAsync<int>(entityId, "get");

    Console.WriteLine($"Counter value: {value}"); // 8
}

// ============= PATTERN SUMMARY =============
Console.WriteLine("Durable Functions Patterns:");
Console.WriteLine("1. Chaining        - Sequential ABC");
Console.WriteLine("2. Fan-out/Fan-in  - Parallel tasks then aggregate");
Console.WriteLine("3. Async HTTP APIs - Long-running with status polling");
Console.WriteLine("4. Monitor         - Repeated checks with backoff");
Console.WriteLine("5. Human Approval  - Wait for external approval event");
Console.WriteLine("6. Sub-orchestrations - Nested orchestrator calls");
Console.WriteLine("7. Entity Functions - Durable state management");

class User { public string UserId { get; set; } public string Name { get; set; } }
class Order { public string OrderId { get; set; } }
class ReportRequest { public string ReportName { get; set; } }
class PurchaseOrder { public string PONumber { get; set; } public decimal Amount { get; set; } }
class ParallelResults { public bool ValidationPassed { get; set; } }
class DurableOrchestrationStatus { public string InstanceId { get; set; } public string StatusQueryGetUri { get; set; } }`}]},{id:"q3",question:"How do you handle retries and error handling in Durable Functions?",answer:"Durable Functions provide RetryOptions for automatic retry with exponential backoff. Configure firstRetryInterval, maxNumberOfAttempts, and backoffCoefficient. Activity functions can fail and retry automatically. Use try-catch in orchestrators to handle exceptions. Failed activity calls throw exceptions. Orchestrators are replayed from checkpoints on failure, so they must be deterministic (no DateTime.Now, no random). Automatic state management means retries don't duplicate side effects. Dead-letter pattern: move failed messages to separate queue after exhausting retries.",codeSnippets:[{language:"csharp",code:`// Durable Functions - Retry & Error Handling
using Microsoft.Azure.WebJobs;
using Microsoft.Azure.WebJobs.Extensions.DurableTask;
using System;
using System.Collections.Generic;
using System.Threading.Tasks;

// ============= RETRY OPTIONS =============
// Automatic retry with exponential backoff

[FunctionName("RetryOrchestrator")]
public static async Task RetryExample(
    [OrchestrationTrigger] IDurableOrchestrationContext context)
{
    // Configure retry policy
    var retryOptions = new RetryOptions(
        firstRetryInterval: TimeSpan.FromSeconds(1),
        maxNumberOfAttempts: 3
    )
    {
        BackoffCoefficient = 2.0, // Exponential backoff: 1s, 2s, 4s
        Handle = ex => ex is TimeoutException or HttpRequestException // Retry only these
    };

    try
    {
        // Call with retry
        var result = await context.CallActivityWithRetryAsync<string>(
            "UnreliableApiCallActivity",
            retryOptions,
            "data"
        );

        Console.WriteLine($"Success: {result}");
    }
    catch (FunctionFailedException ex)
    {
        // After 3 retries, still failed
        Console.WriteLine($"Failed after retries: {ex.InnerException?.Message}");
    }
}

// ============= CUSTOM RETRY LOGIC =============

[FunctionName("CustomRetryOrchestrator")]
public static async Task CustomRetry(
    [OrchestrationTrigger] IDurableOrchestrationContext context,
    string orderId)
{
    int maxAttempts = 5;
    int attempt = 0;
    Exception lastException = null;

    while (attempt < maxAttempts)
    {
        try
        {
            attempt++;
            Console.WriteLine($"Attempt {attempt} of {maxAttempts}");

            var result = await context.CallActivityAsync<string>(
                "ProcessOrderActivity",
                orderId
            );

            Console.WriteLine($"Success on attempt {attempt}");
            return;
        }
        catch (Exception ex)
        {
            lastException = ex;
            Console.WriteLine($"Attempt {attempt} failed: {ex.Message}");

            if (attempt < maxAttempts)
            {
                // Exponential backoff: 2^attempt seconds
                var backoffSeconds = Math.Pow(2, attempt);
                var nextRetryTime = context.CurrentUtcDateTime.AddSeconds(backoffSeconds);

                // Wait before retry
                await context.CreateTimer(nextRetryTime, CancellationToken.None);
            }
        }
    }

    // All retries exhausted
    throw new InvalidOperationException(
        $"Failed after {maxAttempts} attempts",
        lastException
    );
}

// ============= DEAD-LETTER PATTERN =============
// Move permanently failed messages to separate queue

[FunctionName("DeadLetterOrchestrator")]
public static async Task DeadLetterPattern(
    [OrchestrationTrigger] IDurableOrchestrationContext context,
    OrderMessage message)
{
    var retryOptions = new RetryOptions(
        TimeSpan.FromSeconds(1),
        maxNumberOfAttempts: 3
    );

    try
    {
        await context.CallActivityWithRetryAsync(
            "ProcessOrderActivity",
            retryOptions,
            message
        );
    }
    catch (FunctionFailedException ex)
    {
        // Send to dead-letter queue for manual review
        await context.CallActivityAsync(
            "SendToDeadLetterActivity",
            new { Message = message, Error = ex.InnerException?.Message }
        );
    }
}

[FunctionName("SendToDeadLetterActivity")]
public static async Task SendToDeadLetter(
    [ActivityTrigger] IDictionary<string, object> failedData,
    [Queue("order-deadletter")] IAsyncCollector<string> deadLetterQueue)
{
    await deadLetterQueue.AddAsync(System.Text.Json.JsonSerializer.Serialize(failedData));
    Console.WriteLine("Message sent to dead-letter queue for review");
}

// ============= HANDLE SPECIFIC EXCEPTIONS =============

[FunctionName("SelectiveRetryOrchestrator")]
public static async Task SelectiveRetry(
    [OrchestrationTrigger] IDurableOrchestrationContext context,
    string paymentId)
{
    var retryOptions = new RetryOptions(
        TimeSpan.FromSeconds(1),
        maxNumberOfAttempts: 3
    )
    {
        // Only retry transient errors (network, timeout)
        // Don't retry validation errors
        Handle = ex =>
        {
            var innerEx = ex.InnerException;
            if (innerEx is TimeoutException) return true;
            if (innerEx is HttpRequestException) return true;
            if (innerEx is InvalidOperationException) return false; // Validation error, don't retry

            return false;
        }
    };

    try
    {
        await context.CallActivityWithRetryAsync(
            "ProcessPaymentActivity",
            retryOptions,
            paymentId
        );
    }
    catch (FunctionFailedException ex)
    {
        var innerException = ex.InnerException;

        if (innerException is InvalidOperationException)
        {
            // Validation failed, don't retry
            Console.WriteLine($"Validation error (permanent): {innerException.Message}");
            throw;
        }

        if (innerException is TimeoutException)
        {
            // Timeout, already retried
            Console.WriteLine($"Timeout after retries: {innerException.Message}");
            throw;
        }
    }
}

// ============= ORCHESTRATOR MUST BE DETERMINISTIC =============
// These will cause issues with replaying!

[FunctionName("NonDeterministicOrchestrator")]
public static async Task BadPractices(
    [OrchestrationTrigger] IDurableOrchestrationContext context)
{
    //  BAD: Using DateTime.Now - not deterministic
    // var now = DateTime.Now;

    //  GOOD: Use context.CurrentUtcDateTime
    var now = context.CurrentUtcDateTime;

    //  BAD: Using Random
    // var random = new Random().Next(10);

    //  GOOD: Pass randomness from activity
    // var random = await context.CallActivityAsync<int>("GetRandomActivity", null);

    //  BAD: Using GUID directly
    // var id = Guid.NewGuid();

    //  GOOD: Get GUID from activity
    // var id = await context.CallActivityAsync<Guid>("GenerateGuidActivity", null);

    //  BAD: Direct I/O operations
    // File.WriteAllText("log.txt", "message");

    //  GOOD: Use activity function
    // await context.CallActivityAsync("LogActivity", "message");
}

// ============= TIMEOUT HANDLING =============

[FunctionName("TimeoutOrchestrator")]
public static async Task<string> HandleTimeout(
    [OrchestrationTrigger] IDurableOrchestrationContext context,
    string reportId)
{
    try
    {
        // Set timeout of 30 minutes
        var timeoutAttempt = context.CreateTimer(
            context.CurrentUtcDateTime.AddMinutes(30),
            CancellationToken.None
        );

        var reportTask = context.CallActivityAsync<string>(
            "GenerateReportActivity",
            reportId
        );

        // Race: either report completes or timeout fires
        var winner = await Task.WhenAny(reportTask, timeoutAttempt);

        if (winner == reportTask)
        {
            return reportTask.Result;
        }
        else
        {
            return "Report generation timed out after 30 minutes";
        }
    }
    catch (FunctionFailedException ex)
    {
        Console.WriteLine($"Error: {ex.InnerException?.Message}");
        throw;
    }
}

// ============= BEST PRACTICES =============
Console.WriteLine("Retry & Error Handling Best Practices:");
Console.WriteLine(" Use RetryOptions for automatic exponential backoff");
Console.WriteLine(" Configure maxNumberOfAttempts appropriate to SLA");
Console.WriteLine(" Use Handle predicate to filter retryable exceptions");
Console.WriteLine(" Use dead-letter pattern for permanently failed messages");
Console.WriteLine(" Keep orchestrators deterministic (no DateTime.Now, Random, I/O)");
Console.WriteLine(" Use activity functions for side effects");
Console.WriteLine(" Handle FunctionFailedException to access inner exception");
Console.WriteLine(" Set appropriate timeouts with CreateTimer");
Console.WriteLine(" Log failures for monitoring and alerting");
Console.WriteLine(" Test retry scenarios in development");

class OrderMessage { public string OrderId { get; set; } }`}]},{id:"q4",question:"What is event sourcing in Durable Functions and how is it used internally?",answer:"Event sourcing is the internal mechanism Durable Functions uses for reliability. Instead of storing function state directly, it stores all events (actions) that happened: 'orchestrator called activity X', 'activity X returned result Y', etc. On failure, the orchestrator replays all events to restore to the exact point of failure, then continues. This enables zero data loss, automatic checkpointing, and instant recovery. History is stored in storage account (table storage or SQL database). Replay is deterministic if orchestrator is pure (same inputs always produce same execution path). This is why orchestrators must be deterministic.",codeSnippets:[{language:"csharp",code:`// Azure Durable Functions - Event Sourcing Internals
using Microsoft.Azure.WebJobs;
using Microsoft.Azure.WebJobs.Extensions.DurableTask;
using System;
using System.Collections.Generic;
using System.Threading.Tasks;

// ============= HOW EVENT SOURCING WORKS =============

[FunctionName("EventSourcingExampleOrchestrator")]
public static async Task EventSourcingExample(
    [OrchestrationTrigger] IDurableOrchestrationContext context,
    OrderData order)
{
    // Every action generates an event that is stored

    // Event 1: Orchestrator started
    Console.WriteLine("[Event 1] Orchestrator started");

    // Event 2: Call ValidateOrder activity
    var isValid = await context.CallActivityAsync<bool>(
        "ValidateOrderActivity",
        order
    );
    // Event stored: { Type: "TaskScheduled", Activity: "ValidateOrder", ... }
    // Event stored: { Type: "TaskCompleted", Activity: "ValidateOrder", Result: true }
    Console.WriteLine("[Event 2] Validate order returned: " + isValid);

    // Event 3: Call ProcessPayment activity
    var paymentId = await context.CallActivityAsync<string>(
        "ProcessPaymentActivity",
        order.Amount
    );
    // Event stored: { Type: "TaskScheduled", Activity: "ProcessPayment", ... }
    // Event stored: { Type: "TaskCompleted", Activity: "ProcessPayment", Result: "PAY-123" }
    Console.WriteLine("[Event 3] Payment processed: " + paymentId);

    // Event 4: Call UpdateInventory activity
    await context.CallActivityAsync(
        "UpdateInventoryActivity",
        order.Items
    );
    // Event stored: { Type: "TaskScheduled", Activity: "UpdateInventory", ... }
    // Event stored: { Type: "TaskCompleted", Activity: "UpdateInventory" }
    Console.WriteLine("[Event 4] Inventory updated");

    // Event 5: Orchestrator completed
    Console.WriteLine("[Event 5] Orchestrator completed successfully");

    /* HISTORY STORAGE in Azure Table Storage:
     * 
     * InstanceId: ORDER-001
     * 
     * Event History:
     * {
     *   "InstanceId": "ORDER-001",
     *   "ExecutionId": "1",
     *   "Sequence": 0,
     *   "EventType": "OrchestratorStarted",
     *   "Timestamp": "2024-01-15T10:00:00Z"
     * },
     * {
     *   "InstanceId": "ORDER-001",
     *   "Sequence": 1,
     *   "EventType": "TaskScheduled",
     *   "Name": "ValidateOrderActivity",
     *   "Input": "{ OrderId: 'ORD-001' }"
     * },
     * {
     *   "InstanceId": "ORDER-001",
     *   "Sequence": 2,
     *   "EventType": "TaskCompleted",
     *   "Result": "true"
     * },
     * ...
     */
}

// ============= REPLAY MECHANISM ON FAILURE =============

[FunctionName("ReplayOnFailureOrchestrator")]
public static async Task ReplayMechanism(
    [OrchestrationTrigger] IDurableOrchestrationContext context,
    string itemId)
{
    try
    {
        // Step 1: Get inventory
        var inventory = await context.CallActivityAsync<int>(
            "GetInventoryActivity",
            itemId
        );

        // If this crashes here , the whole orchestration restarts

        // Step 2: Check stock
        if (inventory < 10)
        {
            throw new InvalidOperationException("Low stock!");
        }

        // Step 3: Reorder
        var orderId = await context.CallActivityAsync<string>(
            "PlaceReorderActivity",
            itemId
        );

        // REPLAY FLOW ON FAILURE:
        // 1. Orchestrator restarts from beginning
        // 2. Events replayed: GetInventory activity ran, returned same result (cached)
        // 3. Stock check runs again (using cached result, not calling activity again)
        // 4. Reaches the point where it crashed
        // 5. Continues from there (PlaceReorder now executes)
    }
    catch (Exception ex)
    {
        Console.WriteLine($"Error: {ex.Message}");
    }
}

// ============= WHY DETERMINISTIC? =============

[FunctionName("DeterministicRequirementOrchestrator")]
public static async Task DeterministicRequirement(
    [OrchestrationTrigger] IDurableOrchestrationContext context,
    string processId)
{
    // SCENARIO: First execution completes up to step 2, then fails

    //  WRONG: Using DateTime.Now
    // First execution:
    //   Step 1: now = 2024-01-15 10:00:00
    //   Step 2: CRASH
    // Replay:
    //   Step 1: now = 2024-01-15 10:00:05 (different time!)
    //   This causes different behavior, breaking replay guarantee

    //  CORRECT: Use context.CurrentUtcDateTime
    var now = context.CurrentUtcDateTime;
    // First execution:
    //   Step 1: now = 2024-01-15 10:00:00
    //   Step 2: CRASH
    // Replay:
    //   Step 1: now = 2024-01-15 10:00:00 (same time!)
    //   Replay produces identical behavior

    //  WRONG: Using Random
    // var randomValue = new Random().Next(100);
    // First execution: randomValue = 42
    // Replay: randomValue = 73 (different!)

    //  CORRECT: Get random from activity
    // var randomValue = await context.CallActivityAsync<int>("GetRandomActivity", null);
    // Deterministic because activity result is replayed

    //  WRONG: Direct I/O
    // var data = File.ReadAllText("data.json");
    // File may have changed!

    //  CORRECT: Use activity
    // var data = await context.CallActivityAsync<string>("ReadFileActivity", "data.json");
}

// ============= CHECKING EXECUTION HISTORY =============

[FunctionName("CheckExecutionHistory")]
public static async Task CheckHistory(
    [HttpTrigger(AuthorizationLevel.Anonymous, "get", Route = "history/{instanceId}")] string instanceId,
    [DurableClient] IDurableOrchestrationClient client)
{
    var status = await client.GetStatusAsync(instanceId);

    Console.WriteLine($"Instance ID: {instanceId}");
    Console.WriteLine($"Status: {status.RuntimeStatus}");
    Console.WriteLine($"Created: {status.CreatedTime}");
    Console.WriteLine($"Completed: {status.CompletedTime}");
    Console.WriteLine($"\\nExecution History:");

    var history = status.History;
    for (int i = 0; i < history.Count; i++)
    {
        var item = history[i];
        Console.WriteLine($"  Event {i}: {item}");
    }

    // Example output:
    // Event 0: { "EventType": "OrchestratorStarted" }
    // Event 1: { "EventType": "TaskScheduled", "Name": "ValidateOrder" }
    // Event 2: { "EventType": "TaskCompleted", "Result": "true" }
    // Event 3: { "EventType": "TaskScheduled", "Name": "ProcessPayment" }
    // Event 4: { "EventType": "TaskCompleted", "Result": "payment-123" }
}

// ============= EVENT SOURCING BENEFITS =============
Console.WriteLine("Event Sourcing Benefits in Durable Functions:");
Console.WriteLine(" Automatic checkpointing - save to storage after each step");
Console.WriteLine(" Deterministic replay - exact restoration to failure point");
Console.WriteLine(" Zero data loss - all work is recorded");
Console.WriteLine(" Instant recovery - continue from last checkpoint");
Console.WriteLine(" Full history - complete audit trail of execution");
Console.WriteLine(" Failure handling - transparent automatic recovery");

// ============= CONFIGURING STORAGE =============
Console.WriteLine("\\nEvent Storage Backends:");
Console.WriteLine("- Table Storage (default, cost-effective)");
Console.WriteLine("- SQL Database (better for analysis)");
Console.WriteLine("- Netherite (faster, event log only)");

class OrderData { public string OrderId { get; set; } public decimal Amount { get; set; } public List<string> Items { get; set; } }`}]},{id:"q5",question:"How do you monitor, debug, and troubleshoot Durable Functions?",answer:"Monitor using Application Insights with custom metrics and traces. Track orchestrator status: Pending, Running, Completed, Failed, Terminated. Use IDurableOrchestrationClient.GetStatusAsync() to check instance status and execution history. Debug: enable verbose logging, inspect history in storage table, replay execution in local emulator. Common issues: orchestrator not deterministic (changes cause mismatches), activity timeouts (configure with RetryOptions), storage account connectivity. Use Durable Functions monitoring extension in Azure Portal to visualize workflow execution. Set up alerts for failures.",codeSnippets:[{language:"csharp",code:`// Durable Functions - Monitoring, Debugging, Troubleshooting
using Microsoft.Azure.WebJobs;
using Microsoft.Azure.WebJobs.Extensions.DurableTask;
using Microsoft.Extensions.Logging;
using System;
using System.Collections.Generic;
using System.Threading.Tasks;

// ============= MONITORING WITH APPLICATION INSIGHTS =============

[FunctionName("MonitoredOrchestrator")]
public static async Task MonitoredWorkflow(
    [OrchestrationTrigger] IDurableOrchestrationContext context,
    ILogger log,
    string orderId)
{
    try
    {
        // Log orchestrator events
        context.SetCustomStatus("Starting order processing");

        var isValid = await context.CallActivityAsync<bool>(
            "ValidateOrderActivity",
            orderId
        );

        if (!isValid)
        {
            context.SetCustomStatus("Validation failed");
            throw new InvalidOperationException("Invalid order");
        }

        context.SetCustomStatus("Processing payment");
        var paymentId = await context.CallActivityAsync<string>(
            "ProcessPaymentActivity",
            orderId
        );

        context.SetCustomStatus("Updating inventory");
        await context.CallActivityAsync("UpdateInventoryActivity", orderId);

        context.SetCustomStatus("Order completed");
    }
    catch (Exception ex)
    {
        context.SetCustomStatus($"Failed: {ex.Message}");
        throw;
    }
}

// ============= DETAILED LOGGING IN ACTIVITIES =============

[FunctionName("LoggedActivity")]
public static async Task<string> ActivityWithLogging(
    [ActivityTrigger] string orderId,
    ILogger log)
{
    log.LogInformation($"Processing order: {orderId}");

    try
    {
        // Simulate work
        await Task.Delay(1000);

        log.LogInformation($"Order {orderId} processed successfully");
        return $"Completed-{orderId}";
    }
    catch (Exception ex)
    {
        log.LogError($"Error processing order {orderId}: {ex.Message}");
        throw;
    }
}

// ============= CHECK INSTANCE STATUS =============

[FunctionName("CheckInstanceStatus")]
public static async Task<object> CheckStatus(
    [HttpTrigger(AuthorizationLevel.Anonymous, "get", Route = "orchestration/{instanceId}/status")] string instanceId,
    [DurableClient] IDurableOrchestrationClient client,
    ILogger log)
{
    var status = await client.GetStatusAsync(instanceId);

    if (status == null)
    {
        return new { Error = "Instance not found" };
    }

    log.LogInformation($"Instance {instanceId} status: {status.RuntimeStatus}");

    return new
    {
        InstanceId = instanceId,
        Status = status.RuntimeStatus.ToString(), // Pending, Running, Completed, Failed, etc.
        Input = status.Input,
        Output = status.Output,
        CreatedTime = status.CreatedTime,
        LastUpdatedTime = status.LastUpdatedTime,
        CompletedTime = status.CompletedTime,
        IsRuntimeStatus = status.IsRuntimeStatus,
        
        // History of all events
        History = status.History,
        
        // Custom status set by orchestrator
        CustomStatus = status.CustomStatus
    };
}

// ============= EXECUTION HISTORY ANALYSIS =============

[FunctionName("AnalyzeExecutionHistory")]
public static async Task AnalyzeHistory(
    [HttpTrigger(AuthorizationLevel.Anonymous, "get", Route = "orchestration/{instanceId}/history")] string instanceId,
    [DurableClient] IDurableOrchestrationClient client,
    ILogger log)
{
    var status = await client.GetStatusAsync(instanceId);

    if (status?.History == null)
        return;

    var taskDurations = new Dictionary<string, TimeSpan>();
    DateTime? previousTimestamp = null;

    foreach (var historyItem in status.History)
    {
        // Each history item contains execution details
        var json = historyItem.ToString();
        
        // Parse to find task completions
        if (json.Contains("TaskCompleted"))
        {
            log.LogInformation($"Task completed: {json}");
        }

        if (json.Contains("TaskFailed"))
        {
            log.LogError($"Task failed: {json}");
        }

        if (json.Contains("OrchestratorStarted"))
        {
            log.LogInformation("Orchestrator started");
        }
    }

    log.LogInformation($"Total events in history: {status.History.Count}");
}

// ============= TERMINATE STUCK ORCHESTRATION =============

[FunctionName("TerminateOrchestration")]
public static async Task Terminate(
    [HttpTrigger(AuthorizationLevel.Anonymous, "post", Route = "orchestration/{instanceId}/terminate")] string instanceId,
    [DurableClient] IDurableOrchestrationClient client,
    ILogger log)
{
    await client.TerminateAsync(instanceId, "Manually terminated");
    log.LogWarning($"Orchestration {instanceId} terminated");
}

// ============= PURGE INSTANCE HISTORY =============

[FunctionName("PurgeHistory")]
public static async Task PurgeOldInstances(
    [HttpTrigger(AuthorizationLevel.Anonymous, "post", Route = "purge")] object input,
    [DurableClient] IDurableOrchestrationClient client,
    ILogger log)
{
    // Clean up instances older than 30 days
    var cutoffTime = DateTime.UtcNow.AddDays(-30);

    await client.PurgeInstanceHistoryAsync(
        createdTimeFrom: DateTime.MinValue,
        createdTimeTo: cutoffTime,
        runtimeStatus: new[] { OrchestrationRuntimeStatus.Completed }
    );

    log.LogInformation("Purged completed instances older than 30 days");
}

// ============= COMMON ISSUES & SOLUTIONS =============

[FunctionName("TroubleshootingGuide")]
public static void TroubleshootingGuide()
{
    Console.WriteLine("Durable Functions Troubleshooting:");
    Console.WriteLine("");

    Console.WriteLine("Issue 1: Orchestration stuck in 'Running' state");
    Console.WriteLine("  Cause: Activity function crashed, orchestrator waiting");
    Console.WriteLine("  Solution: Check activity function logs in Application Insights");
    Console.WriteLine("  Action: Fix activity bug and redeploy");
    Console.WriteLine("");

    Console.WriteLine("Issue 2: 'Orchestration violated deterministic constraint'");
    Console.WriteLine("  Cause: Orchestrator code changed or non-deterministic operation used");
    Console.WriteLine("  Solution: Don't modify orchestrator logic mid-flight, use DateTime.UtcNow");
    Console.WriteLine("  Action: Deploy orchestrator change only after current instances complete");
    Console.WriteLine("");

    Console.WriteLine("Issue 3: Activity function timeouts");
    Console.WriteLine("  Cause: Activity takes longer than expected");
    Console.WriteLine("  Solution: Configure RetryOptions with longer timeout");
    Console.WriteLine("  Action: await context.CallActivityWithRetryAsync() with RetryOptions");
    Console.WriteLine("");

    Console.WriteLine("Issue 4: Storage account connection errors");
    Console.WriteLine("  Cause: Connection string misconfigured");
    Console.WriteLine("  Solution: Check AzureWebJobsStorage setting in local.settings.json");
    Console.WriteLine("  Action: Verify storage account access keys in Azure Portal");
    Console.WriteLine("");

    Console.WriteLine("Issue 5: Instance history not updating");
    Console.WriteLine("  Cause: Storage account permissions issue");
    Console.WriteLine("  Solution: Ensure managed identity has Storage Contributor role");
    Console.WriteLine("  Action: Check RBAC assignments in Azure Portal");
    Console.WriteLine("");

    Console.WriteLine("Issue 6: Duplicate execution of activity");
    Console.WriteLine("  Cause: Activity called twice due to wrong code");
    Console.WriteLine("  Solution: Implement idempotent activities");
    Console.WriteLine("  Action: Use idempotency keys to prevent duplicate processing");
}

// ============= CUSTOM METRICS =============

[FunctionName("MetricsOrchestrator")]
public static async Task MetricsExample(
    [OrchestrationTrigger] IDurableOrchestrationContext context)
{
    var startTime = context.CurrentUtcDateTime;

    try
    {
        await context.CallActivityAsync("LongRunningActivity", null);

        var duration = context.CurrentUtcDateTime - startTime;
        context.SetCustomStatus($"Completed in {duration.TotalSeconds}s");
    }
    catch (Exception ex)
    {
        context.SetCustomStatus($"Failed after {(context.CurrentUtcDateTime - startTime).TotalSeconds}s");
    }
}

// ============= STRUCTURED LOGGING =============

[FunctionName("StructuredLoggingActivity")]
public static async Task StructuredLogging(
    [ActivityTrigger] IDictionary<string, object> data,
    ILogger log)
{
    // Structured logging for better querying in Application Insights
    using (log.BeginScope(new Dictionary<string, object>
    {
        { "OrderId", data["OrderId"] },
        { "CustomerId", data["CustomerId"] },
        { "Amount", data["Amount"] }
    }))
    {
        log.LogInformation("Processing order with structured logging");
        // Logs will include OrderId, CustomerId, Amount for correlation
    }
}

// ============= MONITORING BEST PRACTICES =============
Console.WriteLine("\\nMonitoring Best Practices:");
Console.WriteLine(" Use SetCustomStatus() for workflow visibility");
Console.WriteLine(" Track orchestration instances with tags");
Console.WriteLine(" Set up alerts for failed orchestrations");
Console.WriteLine(" Monitor storage account metrics (latency, failures)");
Console.WriteLine(" Use Application Insights for distributed tracing");
Console.WriteLine(" Implement activity function timeouts");
Console.WriteLine(" Regular purge of old instance history");
Console.WriteLine(" Test disaster scenarios (storage failure, activity timeout)");
Console.WriteLine(" Document retry policies and timeouts");
Console.WriteLine(" Use correlation IDs for end-to-end tracing");`}]}]},nh={id:"azure-event-grid",name:"Event Grid",questions:[{id:"q1",question:"What is Azure Event Grid and what are its core components?",answer:"Azure Event Grid is a fully managed event routing service that connects event publishers to event subscribers using pub-sub pattern. Core components: 1) Event Sources - produce events (Storage, Service Bus, custom topics). 2) Event Handlers - receive and process events (Functions, Logic Apps, Webhooks, Event Hubs). 3) Topics - endpoints where events are published. 4) Event Subscriptions - route events from topics to handlers. 5) Event Filters - filter events by type, subject, or data. Supports thousands of events per second with at-least-once delivery guarantee. Integrates with 200+ Azure services and custom webhooks.",codeSnippets:[{language:"csharp",code:`// Azure Event Grid - Core Concepts
using Azure;
using Azure.Messaging.EventGrid;
using Microsoft.Azure.WebJobs;
using System;
using System.Collections.Generic;
using System.Threading.Tasks;

// ============= EVENT SOURCES =============
// Built-in sources: Storage, Service Bus, App Configuration, IoT Hub, etc.

public static class EventSources
{
    public const string StorageSource = "Microsoft.Storage.StorageAccounts";
    public const string ServiceBusSource = "Microsoft.ServiceBus.Namespaces";
    public const string AppConfigSource = "Microsoft.AppConfiguration.ConfigurationStores";
    public const string IoTHubSource = "Microsoft.Devices.IoTHubs";
}

// ============= CUSTOM TOPIC =============
// Create custom topic for application events

[FunctionName("PublishEventToCustomTopic")]
public static async Task PublishEvent(
    [HttpTrigger(AuthorizationLevel.Anonymous, "post", Route = "events")] EventData eventData,
    [EventGrid(TopicEndpointUri = "EventGridTopicUri", TopicKeySetting = "EventGridTopicKey")] IAsyncCollector<EventGridEvent> eventCollector)
{
    // Create event
    var eventGridEvent = new EventGridEvent(
        subject: $"/orders/{eventData.OrderId}",
        eventType: "Orders.OrderCreated",
        dataVersion: "1.0",
        data: eventData
    );

    // Publish event
    await eventCollector.AddAsync(eventGridEvent);

    Console.WriteLine($"Event published for order {eventData.OrderId}");
}

// ============= EVENT HANDLER (WEBHOOK) =============
// Handle events from Event Grid

[FunctionName("EventGridWebhook")]
public static async Task HandleEventGridEvents(
    [HttpTrigger(AuthorizationLevel.Function, "post", Route = "eventgrid")] EventGridEvent[] events)
{
    foreach (var @event in events)
    {
        // Handle validation event (sent first time webhook is registered)
        if (@event.EventType == "Microsoft.EventGrid.SubscriptionValidationEvent")
        {
            var validationEvent = @event.Data as dynamic;
            var validationCode = validationEvent?.validationCode;
            Console.WriteLine($"Validation code: {validationCode}");
            continue;
        }

        Console.WriteLine($"Event Type: {@event.EventType}");
        Console.WriteLine($"Subject: {@event.Subject}");
        Console.WriteLine($"Data: {@event.Data}");
    }

    await Task.CompletedTask;
}

// ============= EVENT HANDLER (AZURE FUNCTION) =============
// Process events using Event Grid trigger

[FunctionName("OrderCreatedEventHandler")]
public static async Task ProcessOrderEvent(
    [EventGridTrigger] EventGridEvent eventGridEvent,
    ILogger log)
{
    log.LogInformation($"Processing event: {eventGridEvent.EventType}");
    log.LogInformation($"Subject: {eventGridEvent.Subject}");

    // Parse event data
    var orderData = eventGridEvent.Data as dynamic;
    var orderId = orderData.OrderId;

    log.LogInformation($"Order created: {orderId}");

    // Process order (call function, write to database, etc.)
    await ProcessOrderAsync(orderId);
}

// ============= EVENT SUBSCRIPTION =============
// Route events from topic to handler

public class EventSubscriptionConfig
{
    // Topics: Custom topic or event source (Storage, Service Bus, etc.)
    public string TopicName { get; set; }

    // Event types to subscribe to
    public List<string> EventTypes { get; set; } = new()
    {
        "Orders.OrderCreated",
        "Orders.OrderUpdated",
        "Orders.OrderCancelled"
    };

    // Filter by subject prefix/suffix
    public string SubjectFilter { get; set; } = "/orders/";

    // Endpoint where events are sent
    public string EndpointUri { get; set; }

    // Retry policy
    public RetryPolicy RetryPolicy { get; set; } = new()
    {
        MaxDeliveryAttempts = 30,
        EventTimeToLiveInMinutes = 1440 // 24 hours
    };

    // Dead-letter endpoint for failed events
    public string DeadLetterEndpoint { get; set; }
}

public class RetryPolicy
{
    public int MaxDeliveryAttempts { get; set; }
    public int EventTimeToLiveInMinutes { get; set; }
}

// ============= EVENT TYPES =============
// Common Event Grid event types

public static class CommonEventTypes
{
    // Storage events
    public const string BlobCreated = "Microsoft.Storage.BlobCreated";
    public const string BlobDeleted = "Microsoft.Storage.BlobDeleted";

    // Service Bus events
    public const string ServiceBusQueueMessage = "Microsoft.ServiceBus.QueueMessageDelivered";

    // App Configuration events
    public const string AppConfigKeyValueModified = "Microsoft.AppConfiguration.KeyValueModified";

    // IoT Hub events
    public const string IoTDeviceTelemetry = "Microsoft.Devices.DeviceTelemetry";

    // Custom events
    public const string OrderCreated = "Orders.OrderCreated";
    public const string PaymentProcessed = "Payment.PaymentProcessed";
}

// ============= EVENT DATA =============
class EventData
{
    public string OrderId { get; set; }
    public decimal Amount { get; set; }
    public string CustomerEmail { get; set; }
    public DateTime CreatedAt { get; set; }
}

async Task ProcessOrderAsync(string orderId)
{
    await Task.Delay(100);
    Console.WriteLine($"Order {orderId} processed");
}

// ============= EVENT GRID ARCHITECTURE =============
Console.WriteLine("Event Grid Architecture:");
Console.WriteLine("Event Sources  Event Grid Topic  Event Subscriptions  Event Handlers");
Console.WriteLine("");
Console.WriteLine("Publishers publish events to topics");
Console.WriteLine("Subscribers subscribe to topics");
Console.WriteLine("Event Grid routes events based on subscriptions and filters");
Console.WriteLine("");
Console.WriteLine("Delivery: At-least-once (events may be delivered multiple times)");
Console.WriteLine("Ordering: Best-effort (not guaranteed within same subscription)");
Console.WriteLine("Throughput: Thousands of events per second");`}]},{id:"q2",question:"How do you configure event subscriptions and filters in Event Grid?",answer:"Event subscriptions connect event sources to handlers. Configure: 1) Event types - subscribe to specific event types (Azure-provided or custom). 2) Subject filtering - include/exclude by subject prefix/suffix (e.g., /orders/premium). 3) Advanced filters - filter by data properties (e.g., amount > 100). 4) Endpoints - send to Webhook, Function, Logic App, Event Hub, Service Bus Queue, Storage Queue. 5) Delivery properties - add custom headers or properties to events. 6) Retry policy - set max attempts and TTL. 7) Dead-letter - handle failed deliveries. Multiple subscriptions per topic enable different handlers to process same events.",codeSnippets:[{language:"csharp",code:`// Event Grid - Subscriptions & Filters
using Azure.Messaging.EventGrid;
using System;
using System.Collections.Generic;

// ============= EVENT SUBSCRIPTION WITH FILTERS =============

public class EventSubscriptionWithFilters
{
    // Filter 1: By Event Type
    public List<string> FilterByEventType()
    {
        return new List<string>
        {
            "Orders.OrderCreated",
            "Orders.OrderCancelled"
        };
        // Only these event types are delivered
    }

    // Filter 2: By Subject (Simple)
    public class SubjectFilter
    {
        public string Prefix { get; set; } = "/orders/premium/";  // Include prefix
        public string Suffix { get; set; } = ".json";             // Include suffix
    }

    // Filter 3: Advanced Filters (on data properties)
    public class AdvancedFilters
    {
        // Number comparisons
        public bool FilterByAmount(decimal eventAmount)
        {
            return eventAmount > 100;  // Only amounts > 100
        }

        // String contains
        public bool FilterByCustomer(string customerEmail)
        {
            return customerEmail.Contains("@premium.com");
        }

        // String in list
        public bool FilterByStatus(string orderStatus)
        {
            var validStatuses = new[] { "Pending", "Processing", "Shipped" };
            return Array.Exists(validStatuses, s => s == orderStatus);
        }

        // Boolean matches
        public bool FilterByExpressShipping(bool isExpress)
        {
            return isExpress == true;  // Only express orders
        }
    }
}

// ============= CREATE SUBSCRIPTION PROGRAMMATICALLY =============

public async Task CreateEventSubscription(string topicName, string resourceGroup)
{
    // Subscription 1: Premium orders to premium handler
    var premiumSubscription = new
    {
        Name = "PremiumOrderSubscription",
        EventTypes = new[] { "Orders.OrderCreated" },
        SubjectFilter = new
        {
            Prefix = "/orders/premium/",
            CaseSensitive = false
        },
        Labels = new[] { "premium-orders" },
        EndpointType = "WebHook",
        Endpoint = "https://myfunction.azurewebsites.net/api/premium-orders",
        RetryPolicy = new
        {
            MaxDeliveryAttempts = 30,
            EventTimeToLiveInMinutes = 1440
        },
        DeadLetterDestination = new
        {
            EndpointType = "StorageQueue",
            ResourceId = "/subscriptions/.../queues/order-deadletter"
        }
    };

    // Subscription 2: Large orders to Logic App
    var largeOrderSubscription = new
    {
        Name = "LargeOrderSubscription",
        EventTypes = new[] { "Orders.OrderCreated" },
        AdvancedFilters = new
        {
            Filters = new[]
            {
                new
                {
                    OperatorType = "NumberGreaterThan",
                    Key = "data.amount",
                    Value = 1000
                }
            }
        },
        EndpointType = "LogicApp",
        Endpoint = "https://prod-logicapp.azurelogicapps.net/...",
        RetryPolicy = new
        {
            MaxDeliveryAttempts = 60,
            EventTimeToLiveInMinutes = 2880
        }
    };

    // Subscription 3: All events to Event Hub
    var eventHubSubscription = new
    {
        Name = "AllEventsToEventHub",
        EventTypes = new[] { "*" },  // All event types
        EndpointType = "EventHub",
        Endpoint = "/subscriptions/.../eventhubs/order-stream/",
        DeliveryWithResourceIdentity = new
        {
            Identity = new { Type = "SystemAssigned" },
            Destination = new
            {
                EndpointType = "EventHub",
                ResourceId = "/subscriptions/.../eventhubs/order-stream/"
            }
        }
    };

    Console.WriteLine("Subscriptions configured");
}

// ============= DELIVERY PROPERTIES =============

public class DeliveryProperties
{
    public static Dictionary<string, string> AddCustomHeaders()
    {
        return new Dictionary<string, string>
        {
            { "X-Custom-Header", "OrderProcessing" },
            { "X-Order-Priority", "High" },
            { "Authorization", "Bearer token" }
        };
    }
}

// ============= FILTER OPERATORS =============

public class FilterOperators
{
    // Number operators
    public const string NumberGreaterThan = "NumberGreaterThan";
    public const string NumberGreaterThanOrEquals = "NumberGreaterThanOrEquals";
    public const string NumberLessThan = "NumberLessThan";
    public const string NumberLessThanOrEquals = "NumberLessThanOrEquals";
    public const string NumberIn = "NumberIn";
    public const string NumberNotIn = "NumberNotIn";

    // String operators
    public const string StringContains = "StringContains";
    public const string StringNotContains = "StringNotContains";
    public const string StringBeginsWith = "StringBeginsWith";
    public const string StringNotBeginsWith = "StringNotBeginsWith";
    public const string StringEndsWith = "StringEndsWith";
    public const string StringNotEndsWith = "StringNotEndsWith";
    public const string StringIn = "StringIn";
    public const string StringNotIn = "StringNotIn";

    // Boolean operators
    public const string BoolEquals = "BoolEquals";

    // Example: Filter orders with amount > 500 AND status = "Pending"
    public static void ExampleComplexFilter()
    {
        var filters = new[]
        {
            new
            {
                OperatorType = "NumberGreaterThan",
                Key = "data.amount",
                Value = 500
            },
            new
            {
                OperatorType = "StringEquals",
                Key = "data.status",
                Value = "Pending"
            }
        };
        // Both conditions must be true (AND logic)
    }
}

// ============= ENDPOINT TYPES =============

public class EndpointTypes
{
    // 1. Webhook - Custom HTTP endpoint
    public string WebhookEndpoint => "https://myapp.com/webhook";

    // 2. Azure Function - Managed by Azure Functions runtime
    public string FunctionEndpoint => "https://myfunc.azurewebsites.net/api/handler";

    // 3. Event Hub - Stream events to Event Hub
    public string EventHubEndpoint => "/subscriptions/.../eventhubs/myeventhub";

    // 4. Service Bus Queue - Route to queue
    public string ServiceBusQueueEndpoint => "/subscriptions/.../queues/myqueue";

    // 5. Service Bus Topic - Route to topic
    public string ServiceBusTopicEndpoint => "/subscriptions/.../topics/mytopic";

    // 6. Storage Queue - Route to storage queue
    public string StorageQueueEndpoint => "https://mystg.queue.core.windows.net/myqueue";

    // 7. Logic App - Managed connector
    public string LogicAppEndpoint => "https://prod-logicapp.azurelogicapps.net/triggers/manual";

    // 8. Hybrid Connection - Relay to on-premises
    public string HybridConnectionEndpoint => "/subscriptions/.../hybridConnections/myconnection";
}

// ============= SUBSCRIPTION BEST PRACTICES =============

Console.WriteLine("Event Subscription Best Practices:");
Console.WriteLine(" Use specific event types, not '*' unless needed");
Console.WriteLine(" Filter by subject prefix to reduce unwanted events");
Console.WriteLine(" Use advanced filters for fine-grained control");
Console.WriteLine(" Configure dead-letter endpoint for failed events");
Console.WriteLine(" Set appropriate retry policy (max 30 attempts default)");
Console.WriteLine(" Use managed identity instead of connection strings");
Console.WriteLine(" Test subscriptions with test events before production");
Console.WriteLine(" Monitor subscription health and event delivery");
Console.WriteLine(" Use Event Grid explorer to validate filters");`}]},{id:"q3",question:"How do you handle event delivery failures and implement dead-letter processing?",answer:"Event Grid uses retry policy for failed deliveries. Configure: 1) Max delivery attempts (1-30, default 30). 2) Event TTL (1440 minutes default, max 1440). After max retries or TTL expiration, events go to dead-letter endpoint if configured. Dead-letter handlers receive failed events for analysis/reprocessing. Failures occur due to: non-2xx HTTP responses, timeouts, malformed requests. Use exponential backoff between retries (internal). Implement dead-letter as Storage Queue or custom blob for audit trail. Monitor dead-letter queue for patterns and fix root causes.",codeSnippets:[{language:"csharp",code:`// Event Grid - Failure Handling & Dead-Letter
using Azure.Messaging.EventGrid;
using Azure.Storage.Queues;
using Microsoft.Azure.Cosmos.Table;
using Microsoft.Azure.WebJobs;
using System;
using System.Collections.Generic;
using System.Threading.Tasks;

// ============= RETRY POLICY CONFIGURATION =============

public class RetryConfiguration
{
    // Conservative: Few retries, quick failure
    public static Dictionary<string, object> ConservativeRetry()
    {
        return new Dictionary<string, object>
        {
            { "MaxDeliveryAttempts", 3 },
            { "EventTimeToLiveInMinutes", 60 }  // 1 hour
        };
    }

    // Aggressive: Many retries, long TTL
    public static Dictionary<string, object> AggressiveRetry()
    {
        return new Dictionary<string, object>
        {
            { "MaxDeliveryAttempts", 30 },
            { "EventTimeToLiveInMinutes", 1440 }  // 24 hours
        };
    }

    // Custom: Tailored to workload
    public static Dictionary<string, object> CustomRetry(int maxAttempts, int ttlMinutes)
    {
        return new Dictionary<string, object>
        {
            { "MaxDeliveryAttempts", Math.Clamp(maxAttempts, 1, 30) },
            { "EventTimeToLiveInMinutes", Math.Clamp(ttlMinutes, 1, 1440) }
        };
    }
}

// ============= HANDLER WITH PROPER ERROR HANDLING =============

[FunctionName("EventHandler")]
public static async Task HandleEventWithErrorHandling(
    [EventGridTrigger] EventGridEvent[] events,
    ILogger log)
{
    foreach (var @event in events)
    {
        try
        {
            log.LogInformation($"Processing event: {@event.EventType}");

            // Simulate processing
            var order = @event.Data as dynamic;
            var orderId = order?.orderId;

            // Business logic might fail (non-2xx response)
            if (orderId == null)
            {
                throw new ArgumentException("Order ID is required");
            }

            await ProcessOrderAsync(orderId);
            log.LogInformation($"Event processed successfully for {orderId}");
        }
        catch (Exception ex)
        {
            // Log error - Event Grid will retry
            log.LogError($"Error processing event: {ex.Message}");
            
            // Important: Throw to signal failure (HTTP non-2xx)
            // Event Grid will retry based on retry policy
            throw;
        }
    }
}

// ============= DEAD-LETTER HANDLER =============

[FunctionName("DeadLetterProcessor")]
public static async Task ProcessDeadLetterEvents(
    [QueueTrigger("event-deadletter")] CloudQueueMessage deadLetterMessage,
    [Queue("event-deadletter-archive")] IAsyncCollector<string> archiveQueue,
    [Table("DeadLetterEvents")] CloudTable deadLetterTable,
    ILogger log)
{
    try
    {
        log.LogError($"Processing dead-letter event: {deadLetterMessage.AsString}");

        // Parse event
        var eventData = deadLetterMessage.AsString;

        // 1. Archive for audit trail
        await archiveQueue.AddAsync(eventData);

        // 2. Log to table for analysis
        var deadLetterEntity = new DeadLetterEntity
        {
            PartitionKey = DateTime.UtcNow.ToString("yyyy-MM-dd"),
            RowKey = Guid.NewGuid().ToString(),
            EventData = eventData,
            ReceivedAt = DateTime.UtcNow,
            Reason = "Max retries exceeded or TTL expired"
        };

        await deadLetterTable.ExecuteAsync(TableOperation.Insert(deadLetterEntity));

        // 3. Alert on critical errors
        await AlertOnCriticalErrorAsync(eventData, log);

        // 4. Reprocess if applicable
        bool shouldRetry = ShouldRetryEvent(eventData);
        if (shouldRetry)
        {
            await ResubmitEventAsync(eventData, log);
        }
    }
    catch (Exception ex)
    {
        log.LogError($"Error processing dead-letter: {ex.Message}");
        throw;
    }
}

// ============= DEAD-LETTER ENTITY FOR TABLE STORAGE =============

public class DeadLetterEntity : TableEntity
{
    public string EventData { get; set; }
    public DateTime ReceivedAt { get; set; }
    public string Reason { get; set; }
    public int RetryCount { get; set; }
    public string ErrorMessage { get; set; }
}

// ============= FAILURE ANALYSIS =============

[FunctionName("AnalyzeDeadLetterPatterns")]
public static async Task AnalyzeFailurePatterns(
    [TimerTrigger("0 0 * * * *")] TimerInfo myTimer,
    [Table("DeadLetterEvents")] CloudTable deadLetterTable,
    ILogger log)
{
    // Query dead-letter events from last hour
    var filter = TableQuery.GenerateFilterCondition(
        "ReceivedAt",
        QueryComparisons.GreaterThan,
        DateTime.UtcNow.AddHours(-1).ToString("O")
    );

    var query = new TableQuery<DeadLetterEntity>().Where(filter);
    var results = await deadLetterTable.ExecuteQuerySegmentedAsync(query, null);

    log.LogInformation($"Dead-letter events in last hour: {results.Results.Count}");

    // Analyze patterns
    var errorCounts = new Dictionary<string, int>();
    foreach (var entity in results.Results)
    {
        if (errorCounts.ContainsKey(entity.Reason))
        {
            errorCounts[entity.Reason]++;
        }
        else
        {
            errorCounts[entity.Reason] = 1;
        }
    }

    // Log summary
    foreach (var error in errorCounts)
    {
        log.LogWarning($"Error: {error.Key} - Count: {error.Value}");
    }

    // Alert if threshold exceeded
    if (results.Results.Count > 100)
    {
        log.LogError("Dead-letter queue exceeding threshold!");
        await SendAlertAsync(log);
    }
}

// ============= EVENT RETRY DECISION LOGIC =============

private static bool ShouldRetryEvent(string eventData)
{
    // Determine if event should be retried based on error type
    // Transient errors: timeout, rate limit, service unavailable
    // Permanent errors: validation failure, authentication error

    // Example: Check if error is transient
    if (eventData.Contains("timeout") || eventData.Contains("ServiceUnavailable"))
    {
        return true;  // Retry transient errors
    }

    if (eventData.Contains("ValidationError") || eventData.Contains("Unauthorized"))
    {
        return false;  // Don't retry permanent errors
    }

    return false;
}

// ============= RESUBMIT EVENT TO EVENT GRID =============

private static async Task ResubmitEventAsync(string eventData, ILogger log)
{
    try
    {
        // Parse original event
        var originalEvent = System.Text.Json.JsonDocument.Parse(eventData);

        // Create new event for reprocessing
        var resubmitEvent = new EventGridEvent(
            subject: "/resubmitted/",
            eventType: "Event.Resubmitted",
            dataVersion: "1.0",
            data: originalEvent.RootElement
        );

        log.LogInformation("Event resubmitted to Event Grid");
        await Task.CompletedTask;
    }
    catch (Exception ex)
    {
        log.LogError($"Failed to resubmit event: {ex.Message}");
    }
}

// ============= ALERTING =============

private static async Task AlertOnCriticalErrorAsync(string eventData, ILogger log)
{
    // Send alert via email, SMS, or Teams
    log.LogError($"CRITICAL: Dead-letter event: {eventData}");
    await Task.CompletedTask;
}

private static async Task SendAlertAsync(ILogger log)
{
    // Trigger alert (email, Teams, SMS)
    log.LogError("ALERT: Dead-letter queue threshold exceeded");
    await Task.CompletedTask;
}

// ============= HTTP STATUS CODES =============

Console.WriteLine("HTTP Status Code Handling:");
Console.WriteLine(" 2xx (Success) - Event delivered, no retry");
Console.WriteLine(" 3xx (Redirect) - Treated as failure, will retry");
Console.WriteLine(" 4xx (Client Error) - Treated as failure, will retry");
Console.WriteLine("  - 400, 401, 403: Permanent failures, consider dead-letter");
Console.WriteLine(" 5xx (Server Error) - Transient failure, will retry");
Console.WriteLine(" Timeout - Transient failure, will retry");
Console.WriteLine(" No Response - Treated as failure, will retry");

async Task ProcessOrderAsync(string orderId)
{
    await Task.Delay(100);
}`}]},{id:"q4",question:"What are Event Grid event schemas and how do you parse events?",answer:"Event Grid uses CloudEvents or Event Grid schema. CloudEvents: standardized, W3C format with subject, type, source, id, time. Event Grid schema: Azure-specific with eventType, subject, data, eventTime, id. Both support custom data payload. Events are delivered as JSON array (even single events). Parse using: EventGridEvent[] (built-in), JsonDocument for raw JSON, or custom deserializers. Event properties: subject (resource identifier), eventType (what happened), eventTime (UTC), data (payload), id (unique), dataVersion. Handle both system events (Storage, Service Bus) and custom application events.",codeSnippets:[{language:"csharp",code:`// Event Grid - Event Schemas & Parsing
using Azure.Messaging.EventGrid;
using System;
using System.Collections.Generic;
using System.Text.Json;

// ============= EVENT GRID SCHEMA =============

public class EventGridSchema
{
    public static void ExampleEventGridEvent()
    {
        var json = @"
{
  ""id"": ""2d1781af-3a4c-4d7c-b93d-aacd7590859c"",
  ""eventType"": ""Microsoft.Storage.BlobCreated"",
  ""subject"": ""/blobServices/default/containers/test-container/blobs/test.txt"",
  ""eventTime"": ""2024-01-15T12:34:56.000Z"",
  ""data"": {
    ""api"": ""PutBlob"",
    ""clientRequestId"": ""xyz123"",
    ""requestId"": ""abc456"",
    ""eTag"": ""0x123456"",
    ""contentType"": ""text/plain"",
    ""contentLength"": 1024,
    ""blobType"": ""BlockBlob"",
    ""url"": ""https://mystg.blob.core.windows.net/test-container/test.txt""
  },
  ""dataVersion"": ""1.0"",
  ""metadataVersion"": ""1""
}";

        Console.WriteLine("Event Grid Schema Properties:");
        Console.WriteLine("- id: Unique event identifier");
        Console.WriteLine("- eventType: What happened (e.g., BlobCreated)");
        Console.WriteLine("- subject: Resource that generated event");
        Console.WriteLine("- eventTime: When event occurred (UTC)");
        Console.WriteLine("- data: Event-specific data payload");
        Console.WriteLine("- dataVersion: Schema version for data");
        Console.WriteLine("- metadataVersion: Event Grid schema version");
    }
}

// ============= CLOUD EVENTS SCHEMA =============

public class CloudEventsSchema
{
    public static void ExampleCloudEvent()
    {
        var json = @"
{
  ""specversion"": ""1.0"",
  ""type"": ""com.example.orders.created"",
  ""source"": ""https://myapp.com/orders"",
  ""subject"": ""order/12345"",
  ""id"": ""A234-1234-1234"",
  ""time"": ""2024-01-15T12:34:56Z"",
  ""datacontenttype"": ""application/json"",
  ""data"": {
    ""orderId"": ""12345"",
    ""amount"": 99.99,
    ""customer"": ""john@example.com""
  }
}";

        Console.WriteLine("CloudEvents Schema Properties:");
        Console.WriteLine("- specversion: CloudEvents specification version (1.0)");
        Console.WriteLine("- type: Event type (reverse-domain notation)");
        Console.WriteLine("- source: Event source");
        Console.WriteLine("- subject: Resource context");
        Console.WriteLine("- id: Unique identifier");
        Console.WriteLine("- time: Timestamp");
        Console.WriteLine("- datacontenttype: Payload content type");
        Console.WriteLine("- data: Event payload");
    }
}

// ============= PARSING EVENT GRID EVENTS =============

public class EventParsing
{
    // Method 1: Using EventGridEvent (built-in binding)
    public static void ParseUsingEventGridEvent(EventGridEvent[] events)
    {
        foreach (var @event in events)
        {
            Console.WriteLine($"ID: {@event.Id}");
            Console.WriteLine($"Type: {@event.EventType}");
            Console.WriteLine($"Subject: {@event.Subject}");
            Console.WriteLine($"Time: {@event.EventTime}");
            Console.WriteLine($"Data: {@event.Data}");
            Console.WriteLine($"Data Version: {@event.DataVersion}");
        }
    }

    // Method 2: Custom deserialization
    public static void ParseCustom(string jsonPayload)
    {
        using var document = JsonDocument.Parse(jsonPayload);
        var root = document.RootElement;

        if (root.ValueKind == JsonValueKind.Array)
        {
            foreach (var item in root.EnumerateArray())
            {
                var id = item.GetProperty("id").GetString();
                var eventType = item.GetProperty("eventType").GetString();
                var subject = item.GetProperty("subject").GetString();
                var data = item.GetProperty("data");

                Console.WriteLine($"Event: {eventType} for {subject}");
            }
        }
    }

    // Method 3: POCO deserialization
    public static void ParseToPoco(string jsonPayload)
    {
        var options = new JsonSerializerOptions { PropertyNameCaseInsensitive = true };
        var events = JsonSerializer.Deserialize<EventGridEventDto[]>(jsonPayload, options);

        foreach (var @event in events)
        {
            Console.WriteLine($"Event: {@event.EventType}");
            var orderData = JsonSerializer.Deserialize<OrderData>(@event.Data.ToString(), options);
            Console.WriteLine($"Order: {orderData?.OrderId}");
        }
    }
}

public class EventGridEventDto
{
    public string Id { get; set; }
    public string EventType { get; set; }
    public string Subject { get; set; }
    public DateTime EventTime { get; set; }
    public JsonElement Data { get; set; }
    public string DataVersion { get; set; }
}

public class OrderData
{
    public string OrderId { get; set; }
    public decimal Amount { get; set; }
}

// ============= SYSTEM EVENTS PARSING =============

public class SystemEventsParser
{
    // Storage Blob event
    public static void ParseStorageBlobEvent(EventGridEvent @event)
    {
        if (@event.EventType == "Microsoft.Storage.BlobCreated")
        {
            var blobData = @event.Data as dynamic;
            var url = blobData?.url;
            var contentLength = blobData?.contentLength;

            Console.WriteLine($"Blob created: {url}, Size: {contentLength}");
        }
    }

    // Service Bus message event
    public static void ParseServiceBusEvent(EventGridEvent @event)
    {
        if (@event.EventType.Contains("ServiceBus"))
        {
            var messageData = @event.Data as dynamic;
            var messageId = messageData?.messageId;

            Console.WriteLine($"Service Bus message: {messageId}");
        }
    }

    // IoT Hub event
    public static void ParseIoTEvent(EventGridEvent @event)
    {
        if (@event.EventType.Contains("Devices"))
        {
            var deviceData = @event.Data as dynamic;
            var deviceId = deviceData?.deviceId;

            Console.WriteLine($"IoT Device: {deviceId}");
        }
    }
}

// ============= CUSTOM APPLICATION EVENTS =============

public class CustomEventParser
{
    public class CustomOrderEvent
    {
        public string OrderId { get; set; }
        public decimal Amount { get; set; }
        public string Status { get; set; }
        public DateTime CreatedAt { get; set; }
    }

    public static void ParseCustomOrderEvent(EventGridEvent @event)
    {
        if (@event.EventType == "Orders.OrderCreated")
        {
            var options = new JsonSerializerOptions { PropertyNameCaseInsensitive = true };
            var orderEvent = JsonSerializer.Deserialize<CustomOrderEvent>(
                @event.Data.ToString(),
                options
            );

            Console.WriteLine($"Order {orderEvent.OrderId}: {orderEvent.Amount}");
        }
    }
}

// ============= EVENT VALIDATION =============

public class EventValidation
{
    public static bool ValidateEvent(EventGridEvent @event)
    {
        // Check required fields
        if (string.IsNullOrEmpty(@event.Id))
            return false;

        if (string.IsNullOrEmpty(@event.EventType))
            return false;

        if (@event.EventTime == default)
            return false;

        if (@event.Data == null)
            return false;

        return true;
    }

    public static void ValidateEventData(EventGridEvent @event)
    {
        // Event-specific validation
        if (@event.EventType == "Orders.OrderCreated")
        {
            var orderData = @event.Data as dynamic;

            if (orderData?.orderId == null)
                throw new ArgumentException("Order ID required");

            if ((decimal)orderData?.amount <= 0)
                throw new ArgumentException("Amount must be positive");
        }
    }
}

// ============= PARSING BEST PRACTICES =============

Console.WriteLine("Event Parsing Best Practices:");
Console.WriteLine(" Always validate event structure before parsing");
Console.WriteLine(" Use try-catch for JSON parsing");
Console.WriteLine(" Handle both event types in subscription");
Console.WriteLine(" Use PropertyNameCaseInsensitive for JSON deserialization");
Console.WriteLine(" Validate required fields exist");
Console.WriteLine(" Log unparseable events for debugging");
Console.WriteLine(" Version your event schema (dataVersion)");
Console.WriteLine(" Test with actual events from Event Grid");`}]},{id:"q5",question:"How do you monitor and troubleshoot Event Grid issues?",answer:"Monitor Event Grid using: 1) Azure Portal - view metrics (published events, delivery attempts, unmatched events). 2) Diagnostic Logs - activity logs, failed deliveries. 3) Application Insights - track handler performance. 4) Event Grid Viewer - test event delivery. 5) Metrics to track: delivery success rate, latency, unmatched events, dead-letter count. Common issues: handlers returning non-2xx, validation webhook failing, subject filters too strict, mismatched event types. Debug by: testing webhook with Event Grid Viewer, checking handler logs, verifying filters, inspecting dead-letter queue. Set up alerts for high failure rates or dead-letter queue growth.",codeSnippets:[{language:"csharp",code:`// Event Grid - Monitoring & Troubleshooting
using Azure.Monitor.Query;
using Microsoft.ApplicationInsights;
using Microsoft.ApplicationInsights.DataContracts;
using Microsoft.Azure.WebJobs;
using Microsoft.Extensions.Logging;
using System;
using System.Collections.Generic;
using System.Threading.Tasks;

// ============= MONITORING WITH APPLICATION INSIGHTS =============

[FunctionName("MonitoredEventHandler")]
public static async Task HandleEventWithMonitoring(
    [EventGridTrigger] EventGridEvent[] events,
    TelemetryClient telemetryClient,
    ILogger log)
{
    foreach (var @event in events)
    {
        using (var operation = telemetryClient.StartOperation<RequestTelemetry>(
            $"EventProcessing-{@event.EventType}"))
        {
            try
            {
                var startTime = DateTime.UtcNow;

                log.LogInformation($"Processing event: {@event.EventType}");

                // Custom dimension tracking
                telemetryClient.TrackEvent(
                    "EventReceived",
                    new Dictionary<string, string>
                    {
                        { "EventType", @event.EventType },
                        { "Subject", @event.Subject },
                        { "EventId", @event.Id }
                    }
                );

                // Process event
                await ProcessEventAsync(@event);

                var duration = DateTime.UtcNow - startTime;
                telemetryClient.TrackEvent(
                    "EventProcessed",
                    new Dictionary<string, string>
                    {
                        { "EventType", @event.EventType },
                        { "Status", "Success" }
                    },
                    new Dictionary<string, double>
                    {
                        { "ProcessingTimeMs", duration.TotalMilliseconds }
                    }
                );
            }
            catch (Exception ex)
            {
                // Track exception
                telemetryClient.TrackException(ex);
                telemetryClient.TrackEvent(
                    "EventProcessingFailed",
                    new Dictionary<string, string>
                    {
                        { "EventType", @event.EventType },
                        { "ErrorMessage", ex.Message }
                    }
                );

                operation.Telemetry.Success = false;
                throw;
            }
        }
    }
}

// ============= CUSTOM METRICS TRACKING =============

public class EventGridMetrics
{
    public static void TrackMetrics(TelemetryClient telemetryClient)
    {
        // Track custom metrics
        telemetryClient.GetMetric("EventsProcessed").TrackValue(1);
        telemetryClient.GetMetric("EventProcessingDurationMs").TrackValue(150);
        telemetryClient.GetMetric("DeadLetterQueueSize").TrackValue(5);
        telemetryClient.GetMetric("FailureRate").TrackValue(0.02); // 2%
    }
}

// ============= DIAGNOSTIC LOGGING =============

[FunctionName("DiagnosticEventHandler")]
public static async Task HandleEventWithDiagnostics(
    [EventGridTrigger] EventGridEvent[] events,
    ILogger log)
{
    log.LogInformation($"Received {events.Length} events");

    foreach (var @event in events)
    {
        try
        {
            // Log event details
            log.LogInformation(
                "Event: {@EventDetails}",
                new
                {
                    Id = @event.Id,
                    Type = @event.EventType,
                    Subject = @event.Subject,
                    Time = @event.EventTime,
                    DataVersion = @event.DataVersion
                }
            );

            // Validate event
            if (string.IsNullOrEmpty(@event.Id))
            {
                log.LogWarning("Event missing ID: {Subject}", @event.Subject);
                continue;
            }

            // Process
            await ProcessEventAsync(@event);

            log.LogInformation("Event processed successfully: {EventId}", @event.Id);
        }
        catch (Exception ex)
        {
            log.LogError(
                ex,
                "Error processing event {EventId}: {ErrorMessage}",
                @event.Id,
                ex.Message
            );

            // Log event data for debugging
            log.LogError(
                "Event data: {@EventData}",
                @event.Data
            );

            throw;
        }
    }
}

// ============= WEBHOOK VALIDATION =============

[FunctionName("ValidateEventGridWebhook")]
public static async Task ValidateWebhook(
    [HttpTrigger(AuthorizationLevel.Anonymous, "post", Route = "webhook")] EventGridEvent[] events,
    ILogger log)
{
    foreach (var @event in events)
    {
        // Handle subscription validation
        if (@event.EventType == "Microsoft.EventGrid.SubscriptionValidationEvent")
        {
            log.LogInformation("Validating Event Grid subscription");

            var validationEvent = @event.Data as dynamic;
            var validationCode = validationEvent?.validationCode;

            log.LogInformation("Validation code: {ValidationCode}", validationCode);

            // Must return validation code within 5 minutes
            // Return 200 OK with validation response
        }
    }
    await Task.CompletedTask;
}

// ============= MONITORING CHECKLIST =============

[FunctionName("MonitoringDashboard")]
public static void MonitoringChecklist()
{
    Console.WriteLine("Event Grid Monitoring Checklist:");
    Console.WriteLine("");

    Console.WriteLine("Metrics to Monitor:");
    Console.WriteLine(" Published Events - Count of events published");
    Console.WriteLine(" Delivery Attempts - Total delivery attempts");
    Console.WriteLine(" Delivered Events - Successfully delivered");
    Console.WriteLine(" Failed Events - Failed deliveries");
    Console.WriteLine(" Unmatched Events - Events not matching any subscription");
    Console.WriteLine(" Dead-letter Events - Events moved to dead-letter");
    Console.WriteLine("");

    Console.WriteLine("Alerts to Set Up:");
    Console.WriteLine(" High failure rate (>10% failed events)");
    Console.WriteLine(" Dead-letter queue growing (>100 messages/hour)");
    Console.WriteLine(" Unmatched events spike (>1000 events/hour)");
    Console.WriteLine(" Handler timeouts (>5% timeout rate)");
    Console.WriteLine(" Handler returning 4xx errors");
    Console.WriteLine("");

    Console.WriteLine("Troubleshooting Steps:");
    Console.WriteLine("1. Check Azure Portal metrics");
    Console.WriteLine("2. Review function logs in Application Insights");
    Console.WriteLine("3. Inspect dead-letter queue");
    Console.WriteLine("4. Test webhook with Event Grid Viewer");
    Console.WriteLine("5. Validate subscription filters");
    Console.WriteLine("6. Check handler response codes (must return 2xx)");
    Console.WriteLine("7. Verify network connectivity");
    Console.WriteLine("8. Review retry policy settings");
}

// ============= HEALTH CHECK ENDPOINT =============

[FunctionName("EventGridHealthCheck")]
public static async Task<object> HealthCheck(
    [HttpTrigger(AuthorizationLevel.Anonymous, "get", Route = "health")] object req,
    ILogger log)
{
    try
    {
        // Check handler readiness
        var isHealthy = await CheckHandlerHealthAsync();

        if (isHealthy)
        {
            log.LogInformation("Health check passed");
            return new { Status = "Healthy", Timestamp = DateTime.UtcNow };
        }
        else
        {
            log.LogError("Health check failed");
            return new { Status = "Unhealthy", Timestamp = DateTime.UtcNow };
        }
    }
    catch (Exception ex)
    {
        log.LogError($"Health check error: {ex.Message}");
        return new { Status = "Error", Error = ex.Message };
    }
}

// ============= PERFORMANCE MONITORING =============

public class PerformanceMonitoring
{
    public static Dictionary<string, double> TrackPerformanceMetrics()
    {
        return new Dictionary<string, double>
        {
            { "AverageProcessingTimeMs", 150 },
            { "MaxProcessingTimeMs", 5000 },
            { "P95ProcessingTimeMs", 800 },
            { "P99ProcessingTimeMs", 2000 },
            { "ThroughputEventsPerSecond", 100 },
            { "SuccessRatePercentage", 98.5 },
            { "FailureRatePercentage", 1.5 }
        };
    }
}

// ============= COMMON ISSUES & SOLUTIONS =============

Console.WriteLine("");
Console.WriteLine("Common Event Grid Issues:");
Console.WriteLine("");
Console.WriteLine("Issue 1: Webhook not receiving events");
Console.WriteLine("  Check: Is handler returning 200-299 status?");
Console.WriteLine("  Check: Can Event Grid reach the webhook URL?");
Console.WriteLine("  Check: Are subscription filters too restrictive?");
Console.WriteLine("");

Console.WriteLine("Issue 2: High dead-letter count");
Console.WriteLine("  Check: Handler error logs");
Console.WriteLine("  Check: Handler response status codes");
Console.WriteLine("  Check: Network connectivity");
Console.WriteLine("");

Console.WriteLine("Issue 3: Unmatched events spike");
Console.WriteLine("  Check: Event type filters");
Console.WriteLine("  Check: Subject filters");
Console.WriteLine("  Check: Are subscriptions correctly configured?");
Console.WriteLine("");

Console.WriteLine("Issue 4: Webhook validation failing");
Console.WriteLine("  Check: Handler must respond to validation event");
Console.WriteLine("  Check: Return validation code in response");
Console.WriteLine("  Check: Must respond within 5 minutes");

async Task ProcessEventAsync(EventGridEvent @event)
{
    await Task.Delay(100);
}

async Task<bool> CheckHandlerHealthAsync()
{
    await Task.Delay(100);
    return true;
}`}]}]},ih={id:"azure-event-hub",name:"Event Hub",questions:[{id:"q1",question:"What is Azure Event Hub and what are its core concepts?",answer:"Azure Event Hub is a fully managed, real-time big data streaming platform that ingests and processes millions of events per second. Core concepts: 1) Event Hubs - namespace containers for topics. 2) Topics - like queues but optimized for streaming. 3) Partitions - ordered log of events enabling parallel consumption. 4) Consumer Groups - independent readers of event stream. 5) Event Processors - handle event consumption and checkpointing. 6) Throughput Units/Capacity Units - control ingress/egress rates. Key differences from Service Bus: Event Hub is event streaming (append-only log), Service Bus is messaging (queue/topic). Event Hub supports 1MB+ event sizes, millions events/sec, multiple independent consumers reading same stream. Use cases: IoT telemetry, log analytics, event sourcing.",codeSnippets:[{language:"csharp",code:`// Azure Event Hub - Core Concepts
using Azure.Messaging.EventHubs;
using Azure.Messaging.EventHubs.Producer;
using Azure.Messaging.EventHubs.Consumer;
using System;
using System.Threading.Tasks;
using System.Collections.Generic;

// ============= CORE COMPONENTS =============

// 1. Event Hub Namespace
public class EventHubNamespace
{
    public string NamespaceName { get; set; } = "myeventhubns";
    public string ConnectionString { get; set; } = "Endpoint=sb://...";
    public string[] EventHubNames { get; set; } = { "order-events", "user-events" };
}

// 2. Event Hub (Topic)
public class EventHubInfo
{
    public string Name { get; set; } = "order-events";
    public int PartitionCount { get; set; } = 4;
    public int RetentionDays { get; set; } = 7;
    public long MaxMessageSizeBytes { get; set; } = 1048576; // 1MB
    public DateTime CreatedAt { get; set; }
}

// 3. Partitions & Consumer Groups
public class EventHubStructure
{
    public string EventHubName { get; set; } = "order-events";
    
    // Partitions: ordered log of events
    public int[] Partitions { get; set; } = { 0, 1, 2, 3 };
    
    // Consumer Groups: independent readers
    public Dictionary<string, ConsumerGroupInfo> ConsumerGroups { get; set; } = new()
    {
        { "order-processing", new ConsumerGroupInfo { Name = "order-processing" } },
        { "analytics", new ConsumerGroupInfo { Name = "analytics" } },
        { "backup", new ConsumerGroupInfo { Name = "backup" } }
    };
}

public class ConsumerGroupInfo
{
    public string Name { get; set; }
    public DateTime CreatedAt { get; set; }
    public Dictionary<int, PartitionProperties> PartitionStatus { get; set; } = new();
}

// 4. Event (Message)
public class EventHubEvent
{
    public string OrderId { get; set; }
    public decimal Amount { get; set; }
    public string CustomerId { get; set; }
    public DateTime CreatedAt { get; set; }
    public string Status { get; set; }
}

// ============= THROUGHPUT & SCALING =============

public class ThroughputConfiguration
{
    // Standard tier: Throughput Units (TU)
    public int ThroughputUnits { get; set; } = 10;  // 1 TU = 1 MB/s ingress, 2 MB/s egress
    public int MaxConnections { get; set; } = 5000; // Per TU

    // Premium tier: Event Hub Capacity Units (ECU)
    public int CapacityUnits { get; set; } = 1;     // 1 ECU = 10 MB/s ingress, 20 MB/s egress
    public int MaxBandwidthMbps { get; set; } = 10; // Per ECU
}

// ============= PUBLISHING EVENTS =============

public class EventPublisher
{
    private EventHubProducerClient _producer;

    public EventPublisher(string connectionString, string eventHubName)
    {
        _producer = new EventHubProducerClient(connectionString, eventHubName);
    }

    // Publish single event
    public async Task PublishEventAsync(EventHubEvent evt)
    {
        var eventData = new EventData(System.Text.Encoding.UTF8.GetBytes(
            System.Text.Json.JsonSerializer.Serialize(evt)
        ));

        // Optional: Set partition key (ensures events with same key go to same partition)
        await _producer.SendAsync(new[] { eventData }, 
            new SendEventOptions { PartitionKey = evt.CustomerId });
    }

    // Publish batch events
    public async Task PublishBatchAsync(IEnumerable<EventHubEvent> events)
    {
        var batch = await _producer.CreateBatchAsync();

        foreach (var evt in events)
        {
            var eventData = new EventData(System.Text.Encoding.UTF8.GetBytes(
                System.Text.Json.JsonSerializer.Serialize(evt)
            ));

            // Add to batch; if batch full, send and start new batch
            if (!batch.TryAdd(eventData))
            {
                await _producer.SendAsync(batch);
                batch = await _producer.CreateBatchAsync();
                batch.TryAdd(eventData);
            }
        }

        // Send remaining events
        if (batch.Count > 0)
        {
            await _producer.SendAsync(batch);
        }
    }

    public async ValueTask DisposeAsync()
    {
        await _producer.CloseAsync();
    }
}

// ============= CONSUMING EVENTS =============

public class EventConsumer
{
    private EventHubConsumerClient _consumer;

    public EventConsumer(string connectionString, string eventHubName, string consumerGroup)
    {
        _consumer = new EventHubConsumerClient(consumerGroup, connectionString, eventHubName);
    }

    // Read from specific partition
    public async Task ConsumeFromPartitionAsync(int partitionId)
    {
        var startingPosition = EventPosition.Latest;
        
        await foreach (PartitionEvent partitionEvent in 
            _consumer.ReadEventsFromPartitionAsync(partitionId, startingPosition))
        {
            var eventBody = System.Text.Encoding.UTF8.GetString(partitionEvent.Data.Body);
            Console.WriteLine($"Partition {partitionId}: {eventBody}");
        }
    }

    // Read from all partitions (for specific consumer group)
    public async Task ConsumeFromAllPartitionsAsync()
    {
        var startingPosition = EventPosition.Earliest;

        await foreach (PartitionEvent partitionEvent in 
            _consumer.ReadEventsAsync(startingPosition))
        {
            var eventBody = System.Text.Encoding.UTF8.GetString(partitionEvent.Data.Body);
            var partitionId = partitionEvent.Partition.PartitionId;
            var offset = partitionEvent.Data.Offset;
            var sequenceNumber = partitionEvent.Data.SequenceNumber;

            Console.WriteLine($"Partition {partitionId}, Offset: {offset}, Seq: {sequenceNumber}");
        }
    }

    public async ValueTask DisposeAsync()
    {
        await _consumer.CloseAsync();
    }
}

// ============= KEY DIFFERENCES FROM SERVICE BUS =============

public class EventHubVsServiceBus
{
    public static void ComparisonTable()
    {
        Console.WriteLine("Event Hub vs Service Bus:");
        Console.WriteLine("");
        Console.WriteLine("Feature                  | Event Hub              | Service Bus");
        Console.WriteLine("Purpose                  | Event streaming        | Queuing/Messaging");
        Console.WriteLine("Data model               | Append-only log        | Queue/Topic");
        Console.WriteLine("Retention                | Hours/Days             | Until consumed");
        Console.WriteLine("Consumer model           | Multiple independent   | Single consumer");
        Console.WriteLine("Throughput               | Very high (millions)   | High");
        Console.WriteLine("Message size             | Up to 1MB              | 256KB default");
        Console.WriteLine("Ordering                 | Per partition          | Per session");
        Console.WriteLine("Use case                 | Real-time streaming    | Decoupled messaging");
    }
}

// ============= EVENT HUB ARCHITECTURE =============

Console.WriteLine("Event Hub Architecture:");
Console.WriteLine("");
Console.WriteLine("Publishers  Event Hub (Topic)  Partitions  Consumer Groups  Consumers");
Console.WriteLine("");
Console.WriteLine("Publishers:");
Console.WriteLine("- Send events to Event Hub");
Console.WriteLine("- Can specify partition key for ordering");
Console.WriteLine("");
Console.WriteLine("Partitions:");
Console.WriteLine("- Ordered log of events within partition");
Console.WriteLine("- 4-32 partitions typical");
Console.WriteLine("- Each partition can have concurrent consumers");
Console.WriteLine("");
Console.WriteLine("Consumer Groups:");
Console.WriteLine("- Independent stream readers");
Console.WriteLine("- Multiple apps can process same stream");
Console.WriteLine("- Each group tracks own offset per partition");
Console.WriteLine("");
Console.WriteLine("Consumers:");
Console.WriteLine("- Read from partition using consumer group");
Console.WriteLine("- Can use EventProcessorClient for automatic checkpointing");`}]},{id:"q2",question:"How do partitions and consumer groups work in Event Hub?",answer:"Partitions are ordered logs within an Event Hub - events are appended sequentially to one partition based on partition key or round-robin. Key benefits: 1) Ordered processing - events in same partition maintain order. 2) Parallel consumption - different consumers read different partitions. 3) Throughput - adding partitions increases overall event rate. Typical partition count: 4-32, can scale dynamically. Consumer Groups enable independent readers of same event stream - each group maintains own offset per partition. Multiple applications can process same events simultaneously. Default consumer group: $Default. Use consumer groups for different processing scenarios (real-time analytics, batch processing, backup). Each partition can have at most one active consumer per consumer group.",codeSnippets:[{language:"csharp",code:`// Event Hub - Partitions & Consumer Groups
using Azure.Messaging.EventHubs;
using Azure.Messaging.EventHubs.Consumer;
using Azure.Messaging.EventHubs.Processor;
using Azure.Storage.Blobs;
using System;
using System.Threading.Tasks;
using System.Collections.Generic;

// ============= PARTITION KEY =============

public class PartitionKeyStrategy
{
    // Strategy 1: Ensure ordering by customer
    public static string GetPartitionKeyByCustomer(string customerId)
    {
        return customerId;  // Same customer  same partition  ordered
    }

    // Strategy 2: Distribute events round-robin
    public static string NoPartitionKey()
    {
        return null;  // Event Hub chooses partition
    }

    // Strategy 3: Partition by tenant
    public static string GetPartitionKeyByTenant(string tenantId)
    {
        return tenantId;
    }
}

// ============= CONSUMER GROUP MANAGEMENT =============

public class ConsumerGroupManagement
{
    // Create/list consumer groups
    public async Task ManageConsumerGroupsAsync(string connectionString, string eventHubName)
    {
        var client = new EventHubAdministrationClient(connectionString);

        // List all consumer groups
        await foreach (var groupName in client.ListConsumerGroupsAsync(eventHubName))
        {
            Console.WriteLine($"Consumer Group: {groupName}");
        }

        // Get consumer group properties
        try
        {
            var properties = await client.GetConsumerGroupAsync(eventHubName, "order-processing");
            Console.WriteLine($"Consumer Group: {properties.Value.Name}");
            Console.WriteLine($"Created At: {properties.Value.CreatedOn}");
        }
        catch (Exception ex)
        {
            Console.WriteLine($"Error: {ex.Message}");
        }
    }
}

// ============= PARTITION PROPERTIES =============

public class PartitionInformation
{
    public async Task GetPartitionInfoAsync(string connectionString, string eventHubName)
    {
        var client = new EventHubConsumerClient(
            EventHubConsumerClient.DefaultConsumerGroupName,
            connectionString,
            eventHubName
        );

        try
        {
            var properties = await client.GetEventHubPropertiesAsync();

            Console.WriteLine($"Event Hub: {properties.Name}");
            Console.WriteLine($"Created: {properties.CreatedOn}");
            Console.WriteLine($"Partitions: {properties.PartitionIds.Length}");

            foreach (var partitionId in properties.PartitionIds)
            {
                var partitionProperties = await client.GetPartitionPropertiesAsync(partitionId);

                Console.WriteLine($"  Partition {partitionId}:");
                Console.WriteLine($"    First Offset: {partitionProperties.FirstSequenceNumber}");
                Console.WriteLine($"    Last Offset: {partitionProperties.LastSequenceNumber}");
                Console.WriteLine($"    Last Enqueued Time: {partitionProperties.LastEnqueuedTimeUtc}");
            }
        }
        finally
        {
            await client.CloseAsync();
        }
    }
}

// ============= CONSUMER GROUP OFFSET TRACKING =============

public class OffsetTracking
{
    // Manual offset tracking
    public async Task ReadWithManualCheckpointAsync(
        string connectionString,
        string eventHubName,
        string consumerGroup)
    {
        var client = new EventHubConsumerClient(consumerGroup, connectionString, eventHubName);

        try
        {
            var startingPosition = EventPosition.Earliest;

            await foreach (PartitionEvent partitionEvent in 
                client.ReadEventsAsync(startingPosition))
            {
                // Process event
                ProcessEvent(partitionEvent);

                // Manually track offset
                string offset = partitionEvent.Data.Offset;
                long sequenceNumber = partitionEvent.Data.SequenceNumber;

                Console.WriteLine($"Processed - Offset: {offset}, Seq: {sequenceNumber}");
                // Save offset to persistent storage (database, blob, etc.)
            }
        }
        finally
        {
            await client.CloseAsync();
        }
    }

    // Automatic checkpointing with EventProcessorClient
    public async Task ReadWithEventProcessorAsync(
        string connectionString,
        string eventHubName,
        string consumerGroup,
        string blobConnectionString,
        string blobContainerName)
    {
        var storageClient = new BlobContainerClient(
            new Uri($"https://..." + blobContainerName),
            new Azure.Storage.StorageSharedKeyCredential("", "")
        );

        var processor = new EventProcessorClient(
            storageClient,
            consumerGroup,
            connectionString,
            eventHubName
        );

        processor.ProcessEventAsync += ProcessEventHandlerAsync;
        processor.ProcessErrorAsync += ProcessErrorHandlerAsync;

        await processor.StartProcessingAsync();
        // Continue processing until stopped
        await processor.StopProcessingAsync();
    }

    private async Task ProcessEventHandlerAsync(ProcessEventArgs args)
    {
        try
        {
            ProcessEvent(args.Data);
            // Checkpoint automatically saved
            await args.UpdateCheckpointAsync();
        }
        catch (Exception ex)
        {
            Console.WriteLine($"Error processing event: {ex.Message}");
        }
    }

    private async Task ProcessErrorHandlerAsync(ProcessErrorEventArgs args)
    {
        Console.WriteLine($"Error in partition {args.PartitionId}: {args.Exception.Message}");
        await Task.CompletedTask;
    }

    private void ProcessEvent(EventData eventData)
    {
        var eventBody = System.Text.Encoding.UTF8.GetString(eventData.Body);
        Console.WriteLine($"Event: {eventBody}");
    }
}

// ============= PARTITION STRATEGY =============

public class PartitionStrategy
{
    public static void WhenToUsePartitionKey()
    {
        Console.WriteLine("Use Partition Key when:");
        Console.WriteLine(" Order matters (events from same customer should be ordered)");
        Console.WriteLine(" Downstream processing depends on order");
        Console.WriteLine(" Stateful processing (grouping related events)");
        Console.WriteLine("");

        Console.WriteLine("Don't use Partition Key when:");
        Console.WriteLine(" Order doesn't matter (random events)");
        Console.WriteLine(" Need maximum throughput (distributed across all partitions)");
        Console.WriteLine(" Want load balancing across partitions");
    }

    public static void ScalingConsumers()
    {
        Console.WriteLine("");
        Console.WriteLine("Consumer Scaling:");
        Console.WriteLine("- If partitions > consumers: Some consumers read multiple partitions");
        Console.WriteLine("- If partitions = consumers: Each consumer reads 1 partition");
        Console.WriteLine("- If partitions < consumers: Some consumers idle");
        Console.WriteLine("- Optimal: Consumers <= Partitions");
        Console.WriteLine("- Recommendation: 1 consumer per partition for best throughput");
    }
}

// ============= CONSUMER GROUP USE CASES =============

public class ConsumerGroupUseCases
{
    public static void Examples()
    {
        Console.WriteLine("");
        Console.WriteLine("Consumer Group Use Cases:");
        Console.WriteLine("");

        Console.WriteLine("1. Real-time Dashboard:");
        Console.WriteLine("   Consumer Group: 'dashboard'");
        Console.WriteLine("   Purpose: Display live event metrics");
        Console.WriteLine("   Offset: Latest (skip past events)");
        Console.WriteLine("");

        Console.WriteLine("2. Analytics Batch Processing:");
        Console.WriteLine("   Consumer Group: 'analytics'");
        Console.WriteLine("   Purpose: Process all events for analysis");
        Console.WriteLine("   Offset: Earliest (process from beginning)");
        Console.WriteLine("");

        Console.WriteLine("3. Backup/Archive:");
        Console.WriteLine("   Consumer Group: 'backup'");
        Console.WriteLine("   Purpose: Store all events to long-term storage");
        Console.WriteLine("   Offset: Earliest with checkpointing");
        Console.WriteLine("");

        Console.WriteLine("4. Multiple Applications:");
        Console.WriteLine("   Each app has own consumer group");
        Console.WriteLine("   Each reads entire event stream independently");
        Console.WriteLine("   No interference between applications");
    }
}`}]},{id:"q3",question:"How do you publish events efficiently and handle batching in Event Hub?",answer:"Event publishing optimizes throughput through batching. Key strategies: 1) Create batch with CreateBatchAsync() - groups events before sending. 2) Check batch capacity with TryAdd() - prevents exceeding size limits. 3) Send full batch immediately - reduces network round-trips. 4) Use partition keys for ordering - same key = same partition. 5) Handle backpressure - retry on transient failures. Performance optimization: batch size ~1MB, 1000 events typical batch, tune based on event size. Failed events can be retried with exponential backoff. For throughput units, calculate: events/sec * avg_event_size / 1MB = TU needed. Max batch size 1MB, individual event max 1MB.",codeSnippets:[{language:"csharp",code:`// Event Hub - Publishing & Batching
using Azure.Messaging.EventHubs;
using Azure.Messaging.EventHubs.Producer;
using System;
using System.Collections.Generic;
using System.Diagnostics;
using System.Linq;
using System.Text.Json;
using System.Threading.Tasks;

// ============= BATCH PUBLISHING =============

public class BatchPublisher
{
    private EventHubProducerClient _producer;

    public BatchPublisher(string connectionString, string eventHubName)
    {
        _producer = new EventHubProducerClient(connectionString, eventHubName);
    }

    // Basic batch publishing
    public async Task PublishBatchAsync(List<EventData> events)
    {
        var batch = await _producer.CreateBatchAsync();

        foreach (var @event in events)
        {
            if (!batch.TryAdd(@event))
            {
                // Batch is full, send it
                await _producer.SendAsync(batch);

                // Create new batch
                batch = await _producer.CreateBatchAsync();

                // Add event to new batch (must succeed)
                if (!batch.TryAdd(@event))
                {
                    throw new InvalidOperationException("Event too large for batch");
                }
            }
        }

        // Send remaining events
        if (batch.Count > 0)
        {
            await _producer.SendAsync(batch);
        }
    }

    // Publishing with partition key
    public async Task PublishWithPartitionKeyAsync(
        List<EventData> events,
        string partitionKey)
    {
        var sendOptions = new SendEventOptions { PartitionKey = partitionKey };
        var batch = await _producer.CreateBatchAsync(sendOptions);

        foreach (var @event in events)
        {
            if (!batch.TryAdd(@event))
            {
                await _producer.SendAsync(batch);
                batch = await _producer.CreateBatchAsync(sendOptions);
                batch.TryAdd(@event);
            }
        }

        if (batch.Count > 0)
        {
            await _producer.SendAsync(batch);
        }
    }

    // Publishing to specific partition
    public async Task PublishToSpecificPartitionAsync(
        List<EventData> events,
        int partitionId)
    {
        var sendOptions = new SendEventOptions { PartitionId = partitionId.ToString() };
        var batch = await _producer.CreateBatchAsync(sendOptions);

        foreach (var @event in events)
        {
            if (!batch.TryAdd(@event))
            {
                await _producer.SendAsync(batch);
                batch = await _producer.CreateBatchAsync(sendOptions);
                batch.TryAdd(@event);
            }
        }

        if (batch.Count > 0)
        {
            await _producer.SendAsync(batch);
        }
    }

    public async ValueTask DisposeAsync()
    {
        await _producer.CloseAsync();
    }
}

// ============= BATCH SIZE OPTIMIZATION =============

public class BatchOptimization
{
    // Get batch properties
    public async Task AnalyzeBatchAsync(string connectionString, string eventHubName)
    {
        var producer = new EventHubProducerClient(connectionString, eventHubName);

        try
        {
            var batchOptions = new CreateBatchOptions();
            var batch = await producer.CreateBatchAsync(batchOptions);

            Console.WriteLine($"Max Batch Size: {batch.MaximumSizeInBytes} bytes");
            Console.WriteLine($"Available Size: {batch.SizeInBytes} bytes");

            // Create sample events and check size
            var sampleEvent = new EventData(System.Text.Encoding.UTF8.GetBytes(
                JsonSerializer.Serialize(new { orderId = "12345", amount = 99.99 })
            ));

            if (batch.TryAdd(sampleEvent))
            {
                Console.WriteLine($"Sample Event Size: {sampleEvent.Body.Length} bytes");
                Console.WriteLine($"Batch Used: {batch.SizeInBytes} bytes");
            }
        }
        finally
        {
            await producer.CloseAsync();
        }
    }
}

// ============= THROUGHPUT CALCULATION =============

public class ThroughputCalculation
{
    public static void CalculateThroughputUnits()
    {
        Console.WriteLine("Throughput Unit (TU) Sizing:");
        Console.WriteLine("");

        // Example: 100,000 events/sec, average 1KB per event
        int eventsPerSecond = 100000;
        int avgEventSizeBytes = 1024;  // 1KB

        double ingressMBps = (eventsPerSecond * avgEventSizeBytes) / (1024.0 * 1024.0);
        int tuNeeded = (int)Math.Ceiling(ingressMBps);

        Console.WriteLine($"Events/sec: {eventsPerSecond}");
        Console.WriteLine($"Avg Event Size: {avgEventSizeBytes} bytes");
        Console.WriteLine($"Required Ingress: {ingressMBps:F2} MB/s");
        Console.WriteLine($"Throughput Units Needed: {tuNeeded} TU");
        Console.WriteLine("");

        Console.WriteLine("1 TU = 1 MB/s ingress, 2 MB/s egress");
        Console.WriteLine("Scale up: Add more TU");
        Console.WriteLine("Monitor: Use Azure Monitor for actual usage");
    }
}

// ============= ERROR HANDLING & RETRY =============

public class ErrorHandlingPublisher
{
    private EventHubProducerClient _producer;

    public ErrorHandlingPublisher(string connectionString, string eventHubName)
    {
        _producer = new EventHubProducerClient(connectionString, eventHubName);
    }

    // Publish with retry logic
    public async Task PublishWithRetryAsync(
        List<EventData> events,
        int maxRetries = 3)
    {
        int retryCount = 0;
        var exponentialBackoff = new System.Diagnostics.Stopwatch();

        while (retryCount < maxRetries)
        {
            try
            {
                await PublishBatchAsync(events);
                return;  // Success
            }
            catch (Azure.Messaging.EventHubs.EventHubsException ex) when (ex.IsTransient)
            {
                retryCount++;
                int delayMs = (int)Math.Pow(2, retryCount) * 1000;  // Exponential backoff

                Console.WriteLine($"Transient error, retrying in {delayMs}ms");
                await Task.Delay(delayMs);
            }
            catch (Exception ex)
            {
                Console.WriteLine($"Fatal error: {ex.Message}");
                throw;
            }
        }

        throw new InvalidOperationException($"Failed after {maxRetries} retries");
    }

    private async Task PublishBatchAsync(List<EventData> events)
    {
        var batch = await _producer.CreateBatchAsync();

        foreach (var @event in events)
        {
            if (!batch.TryAdd(@event))
            {
                await _producer.SendAsync(batch);
                batch = await _producer.CreateBatchAsync();
                batch.TryAdd(@event);
            }
        }

        if (batch.Count > 0)
        {
            await _producer.SendAsync(batch);
        }
    }

    public async ValueTask DisposeAsync()
    {
        await _producer.CloseAsync();
    }
}

// ============= PERFORMANCE MONITORING =============

public class PerformanceMonitoring
{
    public async Task MeasurePublishThroughputAsync(
        string connectionString,
        string eventHubName,
        int totalEvents)
    {
        var producer = new EventHubProducerClient(connectionString, eventHubName);
        var stopwatch = Stopwatch.StartNew();

        try
        {
            var batch = await producer.CreateBatchAsync();
            int eventCount = 0;

            for (int i = 0; i < totalEvents; i++)
            {
                var eventData = new EventData(System.Text.Encoding.UTF8.GetBytes(
                    $"Event {i}: {DateTime.UtcNow}"
                ));

                if (!batch.TryAdd(eventData))
                {
                    await producer.SendAsync(batch);
                    batch = await producer.CreateBatchAsync();
                    batch.TryAdd(eventData);
                }

                eventCount++;
            }

            if (batch.Count > 0)
            {
                await producer.SendAsync(batch);
            }

            stopwatch.Stop();

            double eventsPerSecond = totalEvents / stopwatch.Elapsed.TotalSeconds;
            Console.WriteLine($"Published {totalEvents} events");
            Console.WriteLine($"Duration: {stopwatch.ElapsedMilliseconds}ms");
            Console.WriteLine($"Throughput: {eventsPerSecond:F0} events/sec");
        }
        finally
        {
            await producer.CloseAsync();
        }
    }
}

// ============= BEST PRACTICES =============

Console.WriteLine("Event Hub Publishing Best Practices:");
Console.WriteLine("");
Console.WriteLine(" Always use batching for efficiency");
Console.WriteLine(" Batch size: Aim for 1MB (max limit)");
Console.WriteLine(" Use partition key for ordering requirements");
Console.WriteLine(" Implement exponential backoff for retries");
Console.WriteLine(" Handle EventHubsException.IsTransient for transient errors");
Console.WriteLine(" Monitor throughput unit utilization");
Console.WriteLine(" Use EventHubProducerClient connection pooling");
Console.WriteLine(" Dispose producer when done to free resources");
Console.WriteLine(" Size TU based on peak event rate");`}]},{id:"q4",question:"How do you consume events efficiently using EventProcessorClient?",answer:"EventProcessorClient automates consumption with: 1) Automatic checkpoint management - saves offset to blob storage. 2) Load balancing - distributes partitions across consumer instances. 3) Partition ownership - ensures each partition has max one owner. 4) Automatic recovery - handles consumer failures gracefully. 5) Event processing - delegates to ProcessEventAsync handler. Checkpointing strategy: automatic (after each event) or manual (batch of events). Use blob storage for checkpoint persistence - enables resuming from last checkpoint. Multiple EventProcessorClient instances with same consumer group scale horizontally. Benefits: no manual offset tracking, automatic partition rebalancing, high availability. Setup: configure storage client, define event/error handlers, start processing.",codeSnippets:[{language:"csharp",code:`// Event Hub - EventProcessorClient for Consumption
using Azure.Messaging.EventHubs;
using Azure.Messaging.EventHubs.Consumer;
using Azure.Messaging.EventHubs.Processor;
using Azure.Storage.Blobs;
using Microsoft.Azure.WebJobs;
using System;
using System.Collections.Generic;
using System.Threading.Tasks;

// ============= EVENT PROCESSOR CLIENT SETUP =============

public class EventHubConsumerSetup
{
    public static async Task SetupEventProcessorAsync(
        string eventHubConnectionString,
        string eventHubName,
        string consumerGroup,
        string storageConnectionString,
        string containerName)
    {
        // Initialize storage client for checkpointing
        var storageClient = new BlobContainerClient(
            new Uri($"https://mystg.blob.core.windows.net/{containerName}"),
            new Azure.Storage.StorageSharedKeyCredential("accountname", "accountkey")
        );

        // Create processor
        var processor = new EventProcessorClient(
            storageClient,
            consumerGroup,
            eventHubConnectionString,
            eventHubName
        );

        // Register handlers
        processor.ProcessEventAsync += ProcessEventHandlerAsync;
        processor.ProcessErrorAsync += ProcessErrorHandlerAsync;

        // Start processing
        await processor.StartProcessingAsync();

        // Keep processing until stopped
        Console.WriteLine("Event processor started. Press Ctrl+C to stop.");
        await Task.Delay(Timeout.Infinite);

        // Stop processing
        await processor.StopProcessingAsync();
    }

    private static async Task ProcessEventHandlerAsync(ProcessEventArgs args)
    {
        try
        {
            // Get event data
            var eventBody = System.Text.Encoding.UTF8.GetString(args.Data.Body);
            Console.WriteLine($"Event: {eventBody}");

            // Process event (custom logic)
            await ProcessOrderAsync(eventBody);

            // Checkpoint after successful processing
            // Saves offset to blob storage
            await args.UpdateCheckpointAsync();

            Console.WriteLine($"Checkpointed partition {args.Partition.PartitionId}, offset {args.Data.Offset}");
        }
        catch (Exception ex)
        {
            Console.WriteLine($"Error processing event: {ex.Message}");
            // Don't checkpoint on error - will retry next time
        }
    }

    private static async Task ProcessErrorHandlerAsync(ProcessErrorEventArgs args)
    {
        Console.WriteLine($"Error in partition {args.PartitionId}: {args.Exception.Message}");
        Console.WriteLine($"Operation: {args.Operation}");

        // Handle specific error types
        if (args.Exception is Azure.Messaging.EventHubs.EventHubsException ehEx)
        {
            if (ehEx.IsTransient)
            {
                Console.WriteLine("Transient error - processor will retry");
            }
            else
            {
                Console.WriteLine("Permanent error - manual intervention needed");
            }
        }

        await Task.CompletedTask;
    }

    private static async Task ProcessOrderAsync(string orderJson)
    {
        // Simulate processing
        await Task.Delay(100);
    }
}

// ============= CHECKPOINT MANAGEMENT =============

public class CheckpointManagement
{
    // Automatic checkpointing (every event)
    private static async Task AutomaticCheckpointAsync(ProcessEventArgs args)
    {
        await args.UpdateCheckpointAsync();
        Console.WriteLine($"Checkpoint updated: {args.Data.Offset}");
    }

    // Manual checkpointing (batch of events)
    public async Task ManualCheckpointingAsync(
        string eventHubConnectionString,
        string eventHubName,
        string consumerGroup,
        string storageConnectionString)
    {
        var storageClient = new BlobContainerClient(
            new Uri("https://mystg.blob.core.windows.net/checkpoints"),
            new Azure.Storage.StorageSharedKeyCredential("accountname", "key")
        );

        var processor = new EventProcessorClient(
            storageClient,
            consumerGroup,
            eventHubConnectionString,
            eventHubName
        );

        int eventCount = 0;
        const int checkpointInterval = 100;

        processor.ProcessEventAsync += async (args) =>
        {
            // Process event
            await ProcessOrderAsync(System.Text.Encoding.UTF8.GetString(args.Data.Body));

            eventCount++;

            // Checkpoint every 100 events
            if (eventCount % checkpointInterval == 0)
            {
                await args.UpdateCheckpointAsync();
                Console.WriteLine($"Batch checkpoint: {eventCount} events processed");
            }
        };

        processor.ProcessErrorAsync += (args) =>
        {
            Console.WriteLine($"Error: {args.Exception.Message}");
            return Task.CompletedTask;
        };

        await processor.StartProcessingAsync();
    }

    // Resume from checkpoint
    public async Task ResumeFromCheckpointAsync(
        string eventHubConnectionString,
        string eventHubName,
        string consumerGroup,
        string storageConnectionString)
    {
        var storageClient = new BlobContainerClient(
            new Uri("https://mystg.blob.core.windows.net/checkpoints"),
            new Azure.Storage.StorageSharedKeyCredential("accountname", "key")
        );

        var processor = new EventProcessorClient(
            storageClient,
            consumerGroup,
            eventHubConnectionString,
            eventHubName
        );

        Console.WriteLine("Processor will resume from last checkpoint...");

        processor.ProcessEventAsync += (args) => ProcessEventHandlerAsync(args);
        processor.ProcessErrorAsync += (args) => ProcessErrorHandlerAsync(args);

        await processor.StartProcessingAsync();
    }
}

// ============= PARTITION OWNERSHIP & LOAD BALANCING =============

public class PartitionOwnershipTracking
{
    public async Task TrackPartitionOwnershipAsync(
        EventProcessorClient processor)
    {
        processor.PartitionInitializingAsync += async (args) =>
        {
            Console.WriteLine($"Initializing partition {args.Partition.PartitionId}");
            // Custom initialization logic
            await Task.CompletedTask;
        };

        processor.PartitionClosingAsync += async (args) =>
        {
            Console.WriteLine($"Closing partition {args.Partition.PartitionId}");
            Console.WriteLine($"Reason: {args.Reason}");
            // Custom cleanup logic
            await Task.CompletedTask;
        };
    }

    public static void LoadBalancingBehavior()
    {
        Console.WriteLine("");
        Console.WriteLine("EventProcessorClient Load Balancing:");
        Console.WriteLine("");

        Console.WriteLine("Scenario 1: 4 Partitions, 1 Processor");
        Console.WriteLine("  Processor owns all 4 partitions");
        Console.WriteLine("");

        Console.WriteLine("Scenario 2: 4 Partitions, 2 Processors");
        Console.WriteLine("  Each processor owns 2 partitions");
        Console.WriteLine("  Automatic rebalancing");
        Console.WriteLine("");

        Console.WriteLine("Scenario 3: 4 Partitions, 5 Processors");
        Console.WriteLine("  4 processors own 1 partition each");
        Console.WriteLine("  1 processor idle (no partitions assigned)");
        Console.WriteLine("");

        Console.WriteLine("When processor added/removed:");
        Console.WriteLine("  - Automatic rebalancing triggers");
        Console.WriteLine("  - Partitions reassigned to remaining processors");
        Console.WriteLine("  - Minimal impact on processing");
    }
}

// ============= CONSUMER GROUP MANAGEMENT =============

public class ConsumerGroupScaling
{
    public static void HorizontalScaling()
    {
        Console.WriteLine("");
        Console.WriteLine("Horizontal Scaling with EventProcessorClient:");
        Console.WriteLine("");

        Console.WriteLine("1. Multiple instances of same consumer group:");
        Console.WriteLine("   - All connect to same Event Hub and consumer group");
        Console.WriteLine("   - All share same storage account for checkpoints");
        Console.WriteLine("   - Automatic partition distribution");
        Console.WriteLine("");

        Console.WriteLine("2. Scaling logic:");
        Console.WriteLine("   - Add processor: Rebalance distributes partitions");
        Console.WriteLine("   - Remove processor: Other processors take partitions");
        Console.WriteLine("   - No message loss (checkpoints saved)");
        Console.WriteLine("");

        Console.WriteLine("3. Best practices:");
        Console.WriteLine("   - Use separate consumer groups for different apps");
        Console.WriteLine("   - Size instances: 1 instance per partition optimal");
        Console.WriteLine("   - Monitor: Track partition ownership and lag");
        Console.WriteLine("   - Handle rebalancing gracefully");
    }
}

// ============= ERROR HANDLING STRATEGIES =============

public class ErrorHandlingStrategies
{
    public static async Task ConfigureErrorHandlingAsync(EventProcessorClient processor)
    {
        processor.ProcessErrorAsync += async (args) =>
        {
            // Log error details
            Console.WriteLine($"Partition: {args.PartitionId}");
            Console.WriteLine($"Operation: {args.Operation}");
            Console.WriteLine($"Exception: {args.Exception.Message}");

            // Handle specific errors
            if (args.Exception is Azure.Messaging.EventHubs.EventHubsException ehEx)
            {
                if (ehEx.IsTransient)
                {
                    // Transient error - processor will retry automatically
                    Console.WriteLine("Transient error - automatic retry");
                }
                else if (args.Exception.InnerException is TimeoutException)
                {
                    // Timeout - likely network issue
                    Console.WriteLine("Timeout - check connectivity");
                }
                else
                {
                    // Other error
                    Console.WriteLine("Fatal error - may need intervention");
                }
            }

            await Task.CompletedTask;
        };
    }
}

// ============= BEST PRACTICES =============

Console.WriteLine("EventProcessorClient Best Practices:");
Console.WriteLine("");
Console.WriteLine(" Use blob storage for checkpoint persistence");
Console.WriteLine(" Implement ProcessEventAsync handler for processing");
Console.WriteLine(" Implement ProcessErrorAsync handler for error handling");
Console.WriteLine(" Use UpdateCheckpointAsync() to save progress");
Console.WriteLine(" Handle transient errors gracefully");
Console.WriteLine(" Scale: Add multiple processor instances");
Console.WriteLine(" Monitor: Track partition ownership and processing lag");
Console.WriteLine(" Batch checkpointing for better performance");`}]},{id:"q5",question:"How do you monitor Event Hub performance and troubleshoot issues?",answer:"Monitor Event Hub using: 1) Azure Portal metrics - throughput, latency, consumer lag. 2) Diagnostic logs - operational logs, errors. 3) Application Insights - custom telemetry. 4) Azure Monitor alerts - high latency, throughput limits, errors. Key metrics: incoming messages, outgoing messages, active connections, server errors, incoming bytes. Consumer lag: difference between last enqueued offset and consumer offset. High lag indicates slow consumption. Troubleshooting: check TU/ECU limits (consider scaling), verify consumer is running, inspect error logs, validate network connectivity, review dead-letter behavior. Common issues: throttling (add TU), high latency (reduce batch size, check network), partition imbalance (verify consumer group), events lost (check retention policy).",codeSnippets:[{language:"csharp",code:`// Event Hub - Monitoring & Troubleshooting
using Azure.Monitor.Query;
using Microsoft.ApplicationInsights;
using Microsoft.ApplicationInsights.DataContracts;
using System;
using System.Collections.Generic;
using System.Threading.Tasks;

// ============= MONITORING METRICS =============

public class EventHubMonitoring
{
    public static void KeyMetricsToMonitor()
    {
        Console.WriteLine("Event Hub Key Metrics:");
        Console.WriteLine("");

        Console.WriteLine("Publisher Metrics:");
        Console.WriteLine("- Incoming Messages: Total events published");
        Console.WriteLine("- Incoming Bytes: Total data volume");
        Console.WriteLine("- Successful Requests: % of successful publishes");
        Console.WriteLine("- Server Errors: % of server-side failures");
        Console.WriteLine("");

        Console.WriteLine("Consumer Metrics:");
        Console.WriteLine("- Outgoing Messages: Total events consumed");
        Console.WriteLine("- Outgoing Bytes: Total data downloaded");
        Console.WriteLine("- Active Connections: Connected consumers");
        Console.WriteLine("");

        Console.WriteLine("Performance Metrics:");
        Console.WriteLine("- Consumer Lag: Offset difference between latest and consumed");
        Console.WriteLine("- Latency: Time from publish to consumption");
        Console.WriteLine("- Throughput Utilization: % of TU/ECU used");
    }
}

// ============= APPLICATION INSIGHTS INTEGRATION =============

public class ApplicationInsightsMonitoring
{
    private TelemetryClient _telemetryClient;

    public ApplicationInsightsMonitoring(string instrumentationKey)
    {
        var config = new Microsoft.ApplicationInsights.Config.TelemetryConfiguration(instrumentationKey);
        _telemetryClient = new TelemetryClient(config);
    }

    // Track publishing metrics
    public async Task TrackPublishingAsync(
        string eventHubName,
        int eventCount,
        long sizeBytes)
    {
        var startTime = DateTime.UtcNow;

        try
        {
            // Simulate publishing
            await Task.Delay(100);

            var duration = DateTime.UtcNow - startTime;

            _telemetryClient.TrackEvent(
                "EventHub_Publish",
                new Dictionary<string, string>
                {
                    { "EventHub", eventHubName },
                    { "Status", "Success" }
                },
                new Dictionary<string, double>
                {
                    { "EventCount", eventCount },
                    { "SizeBytes", sizeBytes },
                    { "DurationMs", duration.TotalMilliseconds }
                }
            );
        }
        catch (Exception ex)
        {
            _telemetryClient.TrackException(ex);
        }
    }

    // Track consumption metrics
    public async Task TrackConsumptionAsync(
        string eventHubName,
        string consumerGroup,
        int processedEvents,
        long processingTimeMs)
    {
        _telemetryClient.TrackEvent(
            "EventHub_Consume",
            new Dictionary<string, string>
            {
                { "EventHub", eventHubName },
                { "ConsumerGroup", consumerGroup }
            },
            new Dictionary<string, double>
            {
                { "ProcessedEvents", processedEvents },
                { "ProcessingTimeMs", processingTimeMs },
                { "AvgTimePerEventMs", processingTimeMs / (double)processedEvents }
            }
        );
    }

    // Track consumer lag
    public void TrackConsumerLag(
        string eventHubName,
        string consumerGroup,
        int partitionId,
        long lagMessages)
    {
        var severity = lagMessages > 10000 ? SeverityLevel.Warning : SeverityLevel.Information;

        _telemetryClient.TrackEvent(
            "EventHub_ConsumerLag",
            new Dictionary<string, string>
            {
                { "EventHub", eventHubName },
                { "ConsumerGroup", consumerGroup },
                { "Partition", partitionId.ToString() },
                { "Severity", severity.ToString() }
            },
            new Dictionary<string, double>
            {
                { "LagMessages", lagMessages }
            }
        );
    }
}

// ============= CONSUMER LAG TRACKING =============

public class ConsumerLagAnalysis
{
    public async Task AnalyzeLagAsync(
        string connectionString,
        string eventHubName,
        string consumerGroup)
    {
        var client = new EventHubConsumerClient(consumerGroup, connectionString, eventHubName);

        try
        {
            var properties = await client.GetEventHubPropertiesAsync();

            Console.WriteLine($"Event Hub: {eventHubName}");
            Console.WriteLine($"Consumer Group: {consumerGroup}");
            Console.WriteLine("");

            foreach (var partitionId in properties.PartitionIds)
            {
                var partitionProperties = await client.GetPartitionPropertiesAsync(partitionId);
                long lastEnqueuedSequence = partitionProperties.LastSequenceNumber;

                // Get consumer group info
                var adminClient = new EventHubAdministrationClient(connectionString);
                var consumerGroupProperties = await adminClient.GetConsumerGroupAsync(
                    eventHubName,
                    consumerGroup
                );

                // Estimate lag
                long lag = lastEnqueuedSequence - (partitionProperties.LastSequenceNumber - 1000);

                Console.WriteLine($"Partition {partitionId}:");
                Console.WriteLine($"  First Sequence: {partitionProperties.FirstSequenceNumber}");
                Console.WriteLine($"  Last Sequence: {lastEnqueuedSequence}");
                Console.WriteLine($"  Estimated Lag: {Math.Max(0, lag)} messages");
                Console.WriteLine("");
            }
        }
        finally
        {
            await client.CloseAsync();
        }
    }
}

// ============= THROTTLING & THROUGHPUT MANAGEMENT =============

public class ThrottlingHandling
{
    public static void ThroughputUnitScaling()
    {
        Console.WriteLine("");
        Console.WriteLine("Throughput Unit (TU) Scaling:");
        Console.WriteLine("");

        Console.WriteLine("When to add TU:");
        Console.WriteLine("- Throttling errors (429)");
        Console.WriteLine("- High latency (>1 second)");
        Console.WriteLine("- TU utilization >80%");
        Console.WriteLine("");

        Console.WriteLine("Scaling formula:");
        Console.WriteLine("TU Needed = (Events/sec * Avg Size) / 1MB");
        Console.WriteLine("");

        Console.WriteLine("Example:");
        Console.WriteLine("- 50,000 events/sec");
        Console.WriteLine("- 2KB average size");
        Console.WriteLine("- (50,000 * 2048) / (1024 * 1024) = 97.7 MB/s");
        Console.WriteLine("- Need ~98 TU (1 TU = 1 MB/s ingress)");
        Console.WriteLine("");

        Console.WriteLine("Premium tier (ECU):");
        Console.WriteLine("- 1 ECU = 10 MB/s ingress, 20 MB/s egress");
        Console.WriteLine("- Better for consistent high throughput");
    }
}

// ============= HEALTH CHECK =============

public class EventHubHealthCheck
{
    public async Task<HealthStatus> CheckEventHubHealthAsync(
        string connectionString,
        string eventHubName,
        string consumerGroup)
    {
        var status = new HealthStatus();

        try
        {
            // Check producer
            using (var producer = new Azure.Messaging.EventHubs.Producer.EventHubProducerClient(
                connectionString,
                eventHubName))
            {
                var properties = await producer.GetEventHubPropertiesAsync();
                status.ProducerHealthy = true;
                status.PartitionCount = properties.PartitionIds.Length;
            }

            // Check consumer
            using (var consumer = new Azure.Messaging.EventHubs.Consumer.EventHubConsumerClient(
                consumerGroup,
                connectionString,
                eventHubName))
            {
                var properties = await consumer.GetEventHubPropertiesAsync();
                status.ConsumerHealthy = true;
            }

            status.OverallHealthy = status.ProducerHealthy && status.ConsumerHealthy;
        }
        catch (Exception ex)
        {
            status.OverallHealthy = false;
            status.LastError = ex.Message;
        }

        return status;
    }

    public class HealthStatus
    {
        public bool ProducerHealthy { get; set; }
        public bool ConsumerHealthy { get; set; }
        public bool OverallHealthy { get; set; }
        public int PartitionCount { get; set; }
        public string LastError { get; set; }

        public override string ToString()
        {
            return $"Overall: {(OverallHealthy ? "Healthy" : "Unhealthy")}, " +
                   $"Producer: {(ProducerHealthy ? "OK" : "Failed")}, " +
                   $"Consumer: {(ConsumerHealthy ? "OK" : "Failed")}, " +
                   $"Partitions: {PartitionCount}";
        }
    }
}

// ============= COMMON ISSUES & SOLUTIONS =============

public class TroubleshootingGuide
{
    public static void CommonIssuesAndSolutions()
    {
        Console.WriteLine("");
        Console.WriteLine("Event Hub Troubleshooting Guide:");
        Console.WriteLine("");

        Console.WriteLine("Issue 1: Throttling errors (429)");
        Console.WriteLine("  Cause: Exceeding TU/ECU limits");
        Console.WriteLine("  Solution:");
        Console.WriteLine("    - Increase Throughput Units");
        Console.WriteLine("    - Reduce publishing rate");
        Console.WriteLine("    - Batch events efficiently");
        Console.WriteLine("");

        Console.WriteLine("Issue 2: High consumer lag");
        Console.WriteLine("  Cause: Consumer can't keep up");
        Console.WriteLine("  Solution:");
        Console.WriteLine("    - Add more consumer instances");
        Console.WriteLine("    - Increase partition count");
        Console.WriteLine("    - Optimize event processing");
        Console.WriteLine("");

        Console.WriteLine("Issue 3: Events lost");
        Console.WriteLine("  Cause: Consumer not checkpointing");
        Console.WriteLine("  Solution:");
        Console.WriteLine("    - Verify UpdateCheckpointAsync() called");
        Console.WriteLine("    - Check blob storage for checkpoints");
        Console.WriteLine("    - Monitor retention policy");
        Console.WriteLine("");

        Console.WriteLine("Issue 4: High latency");
        Console.WriteLine("  Cause: Network or processing delays");
        Console.WriteLine("  Solution:");
        Console.WriteLine("    - Check network connectivity");
        Console.WriteLine("    - Reduce batch size");
        Console.WriteLine("    - Monitor CPU/memory on consumers");
        Console.WriteLine("");

        Console.WriteLine("Issue 5: Connection failures");
        Console.WriteLine("  Cause: Network, authentication, or firewall");
        Console.WriteLine("  Solution:");
        Console.WriteLine("    - Verify connection string");
        Console.WriteLine("    - Check firewall rules");
        Console.WriteLine("    - Verify managed identity permissions");
    }
}

// ============= MONITORING BEST PRACTICES =============

Console.WriteLine("Event Hub Monitoring Best Practices:");
Console.WriteLine("");
Console.WriteLine(" Monitor TU/ECU utilization continuously");
Console.WriteLine(" Set alerts for lag exceeding threshold");
Console.WriteLine(" Track error rates and error types");
Console.WriteLine(" Monitor consumer group lag");
Console.WriteLine(" Set up Application Insights custom metrics");
Console.WriteLine(" Use Azure Monitor dashboards");
Console.WriteLine(" Review diagnostic logs regularly");
Console.WriteLine(" Implement health check endpoints");
Console.WriteLine(" Track end-to-end latency");
Console.WriteLine(" Monitor partition distribution");`}]}]},rh={id:"azure-key-vault",name:"Azure Key Vault",questions:[{id:"q1",question:"What is Azure Key Vault and what are its main features?",answer:`Azure Key Vault is a cloud service that safeguards cryptographic keys and secrets used by cloud applications and services. It provides centralized secret management, key management, and certificate management.

Main features include:
 Secrets management: Store sensitive data like connection strings, API keys, passwords
 Key management: Create and control encryption keys used in applications
 Certificate management: Provision, manage, and deploy SSL/TLS certificates
 Hardware security module (HSM): Premium tier offers FIPS 140-2 Level 3 validated HSMs
 Audit logging: Track all access and modifications
 Automatic key rotation policies: Enforce regular key updates
 Soft delete and purge protection: Prevent accidental deletion
 Network isolation: Private endpoints and firewall rules

Key Vault is accessible via REST API, SDKs, and Azure Portal, making it easy to integrate with applications.`,codeSnippets:[{language:"csharp",code:`// Storing and Retrieving Secrets
using Azure.Identity;
using Azure.Security.KeyVault.Secrets;

var keyVaultUrl = new Uri("https://<vault-name>.vault.azure.net/");
var client = new SecretClient(keyVaultUrl, new DefaultAzureCredential());

await client.SetSecretAsync("db-password", "MySecurePassword123!");
KeyVaultSecret secret = await client.GetSecretAsync("db-password");
string password = secret.Value;
Console.WriteLine($"Retrieved password: {password}");`},{language:"csharp",code:`// Working with Keys and Encryption
using Azure.Security.KeyVault.Keys;
using Azure.Security.KeyVault.Keys.Cryptography;

var keyClient = new KeyClient(keyVaultUrl, new DefaultAzureCredential());
KeyProperties key = await keyClient.CreateKeyAsync("my-encryption-key", KeyType.Rsa);

var cryptoClient = new CryptographyClient(key.Id, new DefaultAzureCredential());
byte[] plaintext = System.Text.Encoding.UTF8.GetBytes("Sensitive data");
EncryptResult encryptResult = await cryptoClient.EncryptAsync(EncryptionAlgorithm.RsaOaep, plaintext);

DecryptResult decryptResult = await cryptoClient.DecryptAsync(EncryptionAlgorithm.RsaOaep, encryptResult.Ciphertext);
string decrypted = System.Text.Encoding.UTF8.GetString(decryptResult.Plaintext);
Console.WriteLine($"Decrypted: {decrypted}");`}]},{id:"q2",question:"Explain the differences between secrets, keys, and certificates in Key Vault",answer:`Azure Key Vault manages three distinct types of cryptographic and sensitive data:

1. Secrets: Arbitrary sensitive data stored as key-value pairs
    Examples: connection strings, API keys, passwords, tokens
    Format: stored as raw strings
    Use case: for sensitive configuration data that applications need
    Limited to 25 KB per secret

2. Keys: Cryptographic keys used for encryption/decryption operations
    Types: RSA, EC (Elliptic Curve), Oct (symmetric), OKP
    Operations: sign, verify, encrypt, decrypt, wrap, unwrap
    Format: stored in JWK (JSON Web Key) format
    Use case: data encryption, digital signatures, key wrapping
    Supports key versions for rotation

3. Certificates: X.509 certificates with associated private and public keys
    Contains certificate details, public key, and optionally private key
    Can be imported or auto-renewed through certificate provider partnerships
    Format: stored as PEM or PKCS12
    Use case: SSL/TLS certificates for HTTPS, client authentication
    Supports certificate lifecycle management and auto-renewal

Each type has separate storage, access control, and operations within Key Vault.`,codeSnippets:[{language:"csharp",code:`// Accessing Secrets, Keys, and Certificates
using Azure.Security.KeyVault.Secrets;
using Azure.Security.KeyVault.Keys;
using Azure.Security.KeyVault.Certificates;

var secretClient = new SecretClient(keyVaultUrl, new DefaultAzureCredential());
var keyClient = new KeyClient(keyVaultUrl, new DefaultAzureCredential());
var certificateClient = new CertificateClient(keyVaultUrl, new DefaultAzureCredential());

KeyVaultSecret secret = await secretClient.GetSecretAsync("my-secret");
KeyVaultKey key = await keyClient.GetKeyAsync("my-key");
KeyVaultCertificate cert = await certificateClient.GetCertificateAsync("my-cert");

Console.WriteLine($"Secret Value: {secret.Value}");
Console.WriteLine($"Key Type: {key.KeyType}");
Console.WriteLine($"Certificate Thumb: {cert.Properties.X509Thumbprint}");`},{language:"csharp",code:`// Certificate Management
var certificatePem = "-----BEGIN CERTIFICATE-----\\\\n...\\\\n-----END CERTIFICATE-----";
var certificateProperties = new ImportCertificateOptions("imported-cert", certificatePem);
KeyVaultCertificate importedCert = await certificateClient.ImportCertificateAsync(certificateProperties);

await foreach (CertificateProperties certProp in certificateClient.GetPropertiesOfCertificateVersionsAsync("my-cert"))
{
    Console.WriteLine($"Version: {certProp.Version}, Created: {certProp.CreatedOn}");
}

CertificatePolicy policy = await certificateClient.GetCertificatePolicyAsync("my-cert");
Console.WriteLine($"Renewal days before expiry: {policy.RenewBeforeExpiry}");`}]},{id:"q3",question:"How do you authenticate and authorize access to Azure Key Vault?",answer:`Azure Key Vault provides multiple authentication and authorization mechanisms:

1. Authentication Methods:
    Managed Identity: Recommended for Azure resources (VMs, App Services, AKS)
    Service Principal: For applications outside Azure
    User Principal: For interactive access (CLI, Portal)
    Certificate-based: Mutual TLS authentication

2. Authorization Methods (Access Control):
    Azure RBAC (Role-Based Access Control): Uses Azure role assignments
     - Managed at resource/subscription level
     - Supports custom roles
     - Good for enterprise governance
    Vault Access Policies (Legacy): Key Vault-specific policies
     - Granular object-level permissions (secrets, keys, certificates)
     - Specified directly in Key Vault
     - Being deprecated in favor of RBAC
    Hybrid model: Both RBAC and Access Policies can work together

3. Permissions Hierarchy:
    Secret permissions: Get, List, Set, Delete, Backup, Restore, Recover, Purge
    Key permissions: Decrypt, Encrypt, UnwrapKey, WrapKey, Verify, Sign, Get, List, Update, Create, Import, Delete, Backup, Restore, Recover, Purge
    Certificate permissions: Get, List, Delete, Create, Import, Update, Backup, Restore, Recover, Purge, ManageContacts, ManageIssuers, GetIssuers, ListIssuers, SetIssuers

4. Network Security:
    Firewall rules: Restrict access to specific IPs/networks
    Private endpoints: Access Key Vault through private IP
    Service endpoints: Restrict traffic to Azure resources`,codeSnippets:[{language:"csharp",code:`// Authenticating with Managed Identity
using Azure.Identity;
using Azure.Security.KeyVault.Secrets;

var keyVaultUrl = new Uri("https://<vault-name>.vault.azure.net/");
var credential = new DefaultAzureCredential();
var secretClient = new SecretClient(keyVaultUrl, credential);

try
{
    KeyVaultSecret secret = await secretClient.GetSecretAsync("db-connection");
    Console.WriteLine($"Successfully retrieved secret: {secret.Name}");
}
catch (Azure.RequestFailedException ex)
{
    Console.WriteLine($"Authorization error: {ex.Status} - {ex.Message}");
}`},{language:"csharp",code:`// Using Service Principal Authentication
using Azure.Identity;

var tenantId = "<tenant-id>";
var clientId = "<client-id>";
var clientSecret = "<client-secret>";

var credential = new ClientSecretCredential(tenantId, clientId, clientSecret);
var secretClient = new SecretClient(keyVaultUrl, credential);

var certificatePath = "/path/to/certificate.pfx";
var clientCertCredential = new ClientCertificateCredential(tenantId, clientId, certificatePath);
var secretClientCert = new SecretClient(keyVaultUrl, clientCertCredential);`},{language:"csharp",code:`// Assigning RBAC Roles
using Azure.ResourceManager;
using Azure.ResourceManager.Authorization;
using Azure.ResourceManager.Authorization.Models;

var subscription = await client.GetDefaultSubscriptionAsync();
var keyVaultResourceId = "/subscriptions/{sub-id}/resourceGroups/{rg}/providers/Microsoft.KeyVault/vaults/{vault-name}";
var resource = await client.GetGenericResources().GetAsync(keyVaultResourceId);

var principalId = "<object-id-of-user-or-app>";
var roleDefinitionId = "/subscriptions/{sub-id}/providers/Microsoft.Authorization/roleDefinitions/00482a5a-887f-4fb3-b363-3b7fe8e74483";
var roleAssignmentCreateParams = new RoleAssignmentCreateParameters(roleDefinitionId, principalId);

var roleAssignment = await resource.GetRoleAssignments().CreateAsync(
    WaitUntil.Completed,
    System.Guid.NewGuid().ToString(),
    roleAssignmentCreateParams
);`}]},{id:"q4",question:"What are key rotation policies and how do they work?",answer:`Key rotation policies in Azure Key Vault automate the process of creating new versions of keys and marking old ones as expired. This ensures cryptographic agility and reduces exposure to compromised keys.

Key Rotation Policy Features:
 Automatic Version Creation: Creates new key versions on schedule
 Expiration Management: Automatically marks keys as expired after defined period
 Notification Triggers: Sends alerts before expiration
 Flexible Scheduling: Set rotation intervals (daily, weekly, monthly, or exact days)
 Version History: Maintains all key versions for backward compatibility

Policy Configuration:
 Expiration Time: Duration after which key versions are marked expired
 Time Before Expiration: Duration before a key version expires
 Rotation Interval: How frequently new versions are created

Rotation Lifecycle:
1. New key version is automatically created at scheduled interval
2. Applications gradually migrate to new version (old remains accessible)
3. After expiration period, key is marked as expired
4. Old versions can still decrypt data encrypted with them
5. Access controls ensure only authorized operations on expired keys

Best Practices:
 Rotate keys based on compliance requirements (often annually)
 For encryption keys: shorter rotation intervals (quarterly or monthly)
 For signing keys: longer intervals (yearly)
 Enable automatic rotation to reduce manual overhead
 Monitor rotation events in audit logs
 Plan application updates to handle key version transitions
 Maintain backward compatibility during rotation`,codeSnippets:[{language:"csharp",code:`// Creating and Managing Key Rotation Policies
using Azure.Security.KeyVault.Keys;

var keyClient = new KeyClient(keyVaultUrl, new DefaultAzureCredential());

var keyRotationPolicy = new KeyRotationPolicy()
{
    RotationIntervalTime = TimeSpan.FromDays(90),
    ExpiryTime = TimeSpan.FromDays(30)
};

KeyRotationPolicy result = await keyClient.UpdateKeyRotationPolicyAsync("my-encryption-key", keyRotationPolicy);
Console.WriteLine($"Rotation interval: {result.RotationIntervalTime}");
Console.WriteLine($"Expiry time: {result.ExpiryTime}");

KeyRotationPolicy retrievedPolicy = await keyClient.GetKeyRotationPolicyAsync("my-encryption-key");
Console.WriteLine($"Policy created on: {retrievedPolicy.CreatedOn}");`},{language:"csharp",code:`// Handling Key Versions During Rotation
await foreach (KeyProperties keyVersion in keyClient.GetPropertiesOfKeyVersionsAsync("my-encryption-key"))
{
    Console.WriteLine($"Version ID: {keyVersion.Id}");
    Console.WriteLine($"Created: {keyVersion.CreatedOn}");
    Console.WriteLine($"Expires: {keyVersion.ExpiresOn}");
    Console.WriteLine($"Enabled: {keyVersion.Enabled}");
}

KeyVaultKey latestKey = await keyClient.GetKeyAsync("my-encryption-key");
Console.WriteLine($"Latest Version: {latestKey.Properties.Version}");

var keyVersion = "abc123def456";
KeyVaultKey specificKey = await keyClient.GetKeyAsync("my-encryption-key", keyVersion);
var cryptoClient = new CryptographyClient(specificKey.Id, new DefaultAzureCredential());
DecryptResult decrypted = await cryptoClient.DecryptAsync(EncryptionAlgorithm.RsaOaep, ciphertextBytes);`}]},{id:"q5",question:"How do you implement certificate auto-renewal in Key Vault?",answer:`Azure Key Vault supports automatic certificate renewal through partnerships with certificate providers (like DigiCert). This eliminates manual renewal and prevents certificate expiration incidents.

Certificate Auto-Renewal Components:
 Certificate Policy: Defines renewal rules and provider details
 Certificate Provider: Third-party issuer (DigiCert, GlobalSign, etc.)
 Issuer Contact: Details for certificate renewal notifications
 Renewal Threshold: Days before expiration to trigger renewal
 Subject DN: Distinguished Name for certificate request

Auto-Renewal Process:
1. Certificate policy is configured with auto-renewal settings
2. On specified interval before expiration, Key Vault contacts the provider
3. Provider issues new certificate
4. New version is created in Key Vault
5. Applications can access new certificate with same name
6. Old version remains accessible for existing connections

Supported Certificate Providers:
 DigiCert: Primary provider with direct integration
 GlobalSign: Supported through partnerships
 Custom providers: Can import certificates manually

Renewal Status:
 Pending: Renewal request submitted to provider
 Inprogress: Provider processing certificate
 Completed: New certificate received and stored
 Renewal failed: Notification sent for manual intervention

Best Practices:
 Set renewal threshold 30-90 days before expiration
 Configure issuer contacts for renewal notifications
 Monitor certificate expiration dates
 Test certificate deployment before production use
 Automate certificate deployment to applications
 Maintain audit logs for compliance
 Plan for renewal failures with fallback certificates`,codeSnippets:[{language:"csharp",code:`// Configuring Certificate Auto-Renewal Policy
using Azure.Security.KeyVault.Certificates;

var certificateClient = new CertificateClient(keyVaultUrl, new DefaultAzureCredential());

var policy = new CertificatePolicy
{
    IssuerName = "Self",
    Subject = "CN=myapp.example.com",
    ValidityInMonths = 12,
    RenewBeforeExpiry = 30,
    KeyType = CertificateKeyType.Rsa,
    KeySize = 2048,
    ContentType = CertificateContentType.Pkcs12,
    LifetimeActions = new List<LifetimeAction>
    {
        new LifetimeAction(CertificatePolicyAction.AutoRenew, CertificatePolicyTrigger.LifetimePercentage(80))
    }
};

var operation = await certificateClient.StartCreateCertificateAsync("my-auto-renew-cert", policy);
var createdCertificate = await operation.WaitForCompletionAsync();
Console.WriteLine($"Certificate created: {createdCertificate.Value.Name}");
Console.WriteLine($"Auto-renewal enabled: {createdCertificate.Value.Policy.LifetimeActions.Count > 0}");`},{language:"csharp",code:`// Monitoring Certificate Renewal Status
CertificatePolicy certPolicy = await certificateClient.GetCertificatePolicyAsync("my-auto-renew-cert");
Console.WriteLine($"Certificate Subject: {certPolicy.Subject}");
Console.WriteLine($"Validity: {certPolicy.ValidityInMonths} months");
Console.WriteLine($"Renew before expiry: {certPolicy.RenewBeforeExpiry} days");

foreach (LifetimeAction action in certPolicy.LifetimeActions)
{
    Console.WriteLine($"Action: {action.Action}");
    Console.WriteLine($"Trigger: {action.Trigger}");
}

KeyVaultCertificate certificate = await certificateClient.GetCertificateAsync("my-auto-renew-cert");
Console.WriteLine($"Certificate Name: {certificate.Name}");
Console.WriteLine($"Issued On: {certificate.Properties.CreatedOn}");
Console.WriteLine($"Expires On: {certificate.Properties.ExpiresOn}");`},{language:"csharp",code:`// Setting up DigiCert Provider for Auto-Renewal
var issuerProperties = new CertificateIssuerProperties
{
    Name = "DigiCert",
    Provider = "DigiCert",
    AccountId = "your-digicert-account-id",
    Password = "your-digicert-api-key"
};

var adminContact = new CertificateContact
{
    Email = "admin@example.com",
    Name = "Admin Name",
    Phone = "+1-555-0123"
};

await certificateClient.SetIssuerAsync(issuerProperties);
await certificateClient.SetCertificateContactsAsync(new[] { adminContact });

var digicertPolicy = new CertificatePolicy
{
    IssuerName = "DigiCert",
    Subject = "CN=myapp.example.com",
    DnsNames = new[] { "myapp.example.com", "www.myapp.example.com" },
    ValidityInMonths = 12,
    RenewBeforeExpiry = 45
};

var operation = await certificateClient.StartCreateCertificateAsync("my-digicert-cert", digicertPolicy);
var certificate = await operation.WaitForCompletionAsync();
Console.WriteLine($"DigiCert auto-renewal certificate created: {certificate.Value.Name}");`}]}]},oh={id:"azure-logging-monitoring",name:"Logging & Monitoring",questions:[{id:"q1",question:"What is Azure Monitor and what are its main components?",answer:"Azure Monitor is comprehensive monitoring service for collecting, analyzing, and acting on telemetry. Components: Metrics (numeric data), Logs (structured data in Log Analytics), Alerts (notifications), Application Insights (APM), Workbooks (visualization). Collects from Azure resources, applications, VMs, containers. Enables proactive monitoring and troubleshooting.",codeSnippets:[{language:"csharp",code:`// Azure Monitor Overview

Console.WriteLine("Azure Monitor - Main Components:");
Console.WriteLine("");
Console.WriteLine(" Azure Monitor                                       ");
Console.WriteLine("");
Console.WriteLine(" Metrics        - Numeric time-series data           ");
Console.WriteLine(" Logs           - Structured data in Log Analytics   ");
Console.WriteLine(" Alerts         - Notifications & automated actions  ");
Console.WriteLine(" App Insights   - Application performance monitoring ");
Console.WriteLine(" Workbooks      - Interactive data visualizations    ");
Console.WriteLine(" Dashboards     - Custom monitoring views            ");
Console.WriteLine("");

// Data Sources for Azure Monitor
Console.WriteLine("Data Sources:");
Console.WriteLine(" Application code (via SDK)");
Console.WriteLine(" Operating system (guest OS)");
Console.WriteLine(" Azure resources (platform metrics)");
Console.WriteLine(" Azure subscriptions (activity logs)");
Console.WriteLine(" Azure tenant (AAD audit logs)");
Console.WriteLine(" Custom sources (REST API)");

// Azure Monitor Pricing
Console.WriteLine("Pricing Model:");
Console.WriteLine(" Metrics: Free for platform metrics");
Console.WriteLine(" Logs: Pay per GB ingested + retention");
Console.WriteLine(" Alerts: Pay per alert rule");
Console.WriteLine(" App Insights: Pay per GB ingested");`}]},{id:"q2",question:"What is Application Insights and how do you integrate it with a .NET application?",answer:"Application Insights is APM (Application Performance Monitoring) service. Tracks requests, dependencies, exceptions, performance, custom events. Auto-collects telemetry with SDK. Provides live metrics, failure analysis, performance counters, user analytics. Integrates via NuGet package and connection string configuration.",codeSnippets:[{language:"csharp",code:`// Application Insights Integration in .NET
using Microsoft.ApplicationInsights;
using Microsoft.ApplicationInsights.Extensibility;
using Microsoft.Extensions.DependencyInjection;

var builder = WebApplication.CreateBuilder(args);

// Add Application Insights telemetry
builder.Services.AddApplicationInsightsTelemetry(options =>
{
    options.ConnectionString = builder.Configuration["ApplicationInsights:ConnectionString"];
    options.EnableAdaptiveSampling = true;
    options.EnableQuickPulseMetricStream = true; // Live Metrics
});

var app = builder.Build();

// Manual telemetry tracking
public class OrderService
{
    private readonly TelemetryClient _telemetryClient;
    
    public OrderService(TelemetryClient telemetryClient)
    {
        _telemetryClient = telemetryClient;
    }
    
    public async Task ProcessOrder(Order order)
    {
        // Track custom event
        _telemetryClient.TrackEvent("OrderProcessed", new Dictionary<string, string>
        {
            { "OrderId", order.Id.ToString() },
            { "CustomerId", order.CustomerId }
        });
        
        // Track custom metric
        _telemetryClient.TrackMetric("OrderValue", order.TotalAmount);
        
        try
        {
            await ProcessPayment(order);
        }
        catch (Exception ex)
        {
            // Track exception
            _telemetryClient.TrackException(ex, new Dictionary<string, string>
            {
                { "OrderId", order.Id.ToString() }
            });
            throw;
        }
    }
    
    public async Task<Product> GetProduct(int id)
    {
        // Track dependency (external call)
        using var operation = _telemetryClient.StartOperation<DependencyTelemetry>("GetProduct");
        operation.Telemetry.Type = "HTTP";
        operation.Telemetry.Target = "product-api";
        
        var result = await _httpClient.GetAsync($"/api/products/{id}");
        operation.Telemetry.Success = result.IsSuccessStatusCode;
        
        return await result.Content.ReadFromJsonAsync<Product>();
    }
}

// appsettings.json
/*
{
  "ApplicationInsights": {
    "ConnectionString": "InstrumentationKey=xxx;IngestionEndpoint=https://xxx.applicationinsights.azure.com/"
  }
}
*/`}]},{id:"q3",question:"What is Azure Log Analytics and how do you query logs using KQL?",answer:"Log Analytics is centralized log storage and query service. Uses Kusto Query Language (KQL) for powerful queries. Workspace stores logs from multiple sources. Common tables: AppRequests, AppExceptions, AppDependencies, AzureActivity, Heartbeat. Query results used for alerts, dashboards, exports.",codeSnippets:[{language:"csharp",code:`// Azure Log Analytics & KQL Queries

Console.WriteLine("Log Analytics Workspace:");
Console.WriteLine(" Centralized log storage");
Console.WriteLine(" Multi-source log aggregation");
Console.WriteLine(" KQL query language");
Console.WriteLine(" Retention: 30 days free, up to 730 days paid");

// Common KQL Queries
Console.WriteLine("KQL Query Examples:");

// Query 1: Find all exceptions in last 24 hours
Console.WriteLine(@"
// Exceptions in last 24 hours
AppExceptions
| where TimeGenerated > ago(24h)
| summarize count() by ExceptionType, ProblemId
| order by count_ desc
");

// Query 2: Request performance analysis
Console.WriteLine(@"
// Slow requests (>1 second)
AppRequests
| where TimeGenerated > ago(1h)
| where DurationMs > 1000
| project TimeGenerated, Name, DurationMs, ResultCode
| order by DurationMs desc
| take 100
");

// Query 3: Failed requests by endpoint
Console.WriteLine(@"
// Failed requests by endpoint
AppRequests
| where TimeGenerated > ago(24h)
| where Success == false
| summarize FailedCount=count() by Name, ResultCode
| order by FailedCount desc
");

// Query 4: Dependency failures
Console.WriteLine(@"
// External dependency failures
AppDependencies
| where TimeGenerated > ago(1h)
| where Success == false
| summarize count() by Target, Type, ResultCode
| order by count_ desc
");

// Query 5: User activity timeline
Console.WriteLine(@"
// User session timeline
AppPageViews
| where TimeGenerated > ago(7d)
| summarize PageViews=count() by bin(TimeGenerated, 1h)
| render timechart
");

// Query 6: Resource utilization
Console.WriteLine(@"
// Performance counters
Perf
| where TimeGenerated > ago(1h)
| where ObjectName == 'Processor' and CounterName == '% Processor Time'
| summarize AvgCPU=avg(CounterValue) by bin(TimeGenerated, 5m), Computer
| render timechart
");`}]},{id:"q4",question:"How do you configure alerts in Azure Monitor?",answer:"Azure Monitor Alerts notify when conditions are met. Types: Metric alerts (threshold-based), Log alerts (KQL query), Activity log alerts (Azure events). Action groups define responses: email, SMS, webhook, Azure Function, Logic App, ITSM. Severity levels 0-4 (Critical to Verbose). Smart groups reduce alert noise.",codeSnippets:[{language:"csharp",code:`// Azure Monitor Alerts Configuration

Console.WriteLine("Alert Types:");
Console.WriteLine("");
Console.WriteLine(" Type             Use Case                           ");
Console.WriteLine("");
Console.WriteLine(" Metric Alert     CPU > 80%, Response time > 2s      ");
Console.WriteLine(" Log Alert        Error count > 100 in 5 min         ");
Console.WriteLine(" Activity Alert   VM deleted, Role assigned          ");
Console.WriteLine(" Smart Detection  Anomaly detection (App Insights)   ");
Console.WriteLine("");

// Alert Severity Levels
Console.WriteLine("Severity Levels:");
Console.WriteLine("Sev 0 - Critical");
Console.WriteLine("Sev 1 - Error");
Console.WriteLine("Sev 2 - Warning");
Console.WriteLine("Sev 3 - Informational");
Console.WriteLine("Sev 4 - Verbose");

// Action Group Configuration
Console.WriteLine("Action Group Actions:");
Console.WriteLine(" Email/SMS/Push/Voice");
Console.WriteLine(" Azure Function");
Console.WriteLine(" Logic App");
Console.WriteLine(" Webhook");
Console.WriteLine(" ITSM (ServiceNow, etc.)");
Console.WriteLine(" Automation Runbook");

// Creating Alert via Azure CLI
Console.WriteLine(@"
# Create metric alert (CPU > 80%)
az monitor metrics alert create   --name 'High CPU Alert'   --resource-group myRG   --scopes '/subscriptions/{sub}/resourceGroups/myRG/providers/Microsoft.Compute/virtualMachines/myVM'   --condition 'avg Percentage CPU > 80'   --window-size 5m   --evaluation-frequency 1m   --action /subscriptions/{sub}/resourceGroups/myRG/providers/microsoft.insights/actionGroups/myActionGroup   --severity 2
");

// Creating Log Alert
Console.WriteLine(@"
# Create log alert (Error count)
az monitor scheduled-query create   --name 'High Error Rate'   --resource-group myRG   --scopes '/subscriptions/{sub}/resourceGroups/myRG/providers/microsoft.insights/components/myAppInsights'   --condition 'count > 100'   --condition-query 'AppExceptions | where TimeGenerated > ago(5m)'   --action /subscriptions/{sub}/resourceGroups/myRG/providers/microsoft.insights/actionGroups/myActionGroup   --severity 1
");`}]},{id:"q5",question:"What is structured logging and how do you implement it with Serilog in Azure?",answer:"Structured logging captures log data as key-value pairs, not just strings. Enables filtering, searching, aggregation. Serilog is popular .NET logging library. Sinks send logs to destinations: Console, File, Application Insights, Seq, Elasticsearch. Message templates preserve structure. Enrichers add context (machine name, thread ID).",codeSnippets:[{language:"csharp",code:`// Structured Logging with Serilog in Azure
using Serilog;
using Serilog.Events;

var builder = WebApplication.CreateBuilder(args);

// Configure Serilog
Log.Logger = new LoggerConfiguration()
    .MinimumLevel.Debug()
    .MinimumLevel.Override("Microsoft", LogEventLevel.Information)
    .MinimumLevel.Override("System", LogEventLevel.Warning)
    .Enrich.FromLogContext()
    .Enrich.WithMachineName()
    .Enrich.WithThreadId()
    .Enrich.WithProperty("Application", "MyApp")
    .WriteTo.Console(outputTemplate: 
        "[{Timestamp:HH:mm:ss} {Level:u3}] {Message:lj} {Properties:j}{NewLine}{Exception}")
    .WriteTo.ApplicationInsights(
        builder.Configuration["ApplicationInsights:ConnectionString"],
        TelemetryConverter.Traces)
    .WriteTo.File(
        path: "logs/app-.log",
        rollingInterval: RollingInterval.Day,
        retainedFileCountLimit: 7)
    .CreateLogger();

builder.Host.UseSerilog();

var app = builder.Build();

// Structured logging examples
public class OrderController : ControllerBase
{
    private readonly ILogger<OrderController> _logger;
    
    public OrderController(ILogger<OrderController> logger)
    {
        _logger = logger;
    }
    
    [HttpPost]
    public async Task<IActionResult> CreateOrder(OrderRequest request)
    {
        // Structured log with properties (NOT string interpolation!)
        _logger.LogInformation(
            "Processing order {OrderId} for customer {CustomerId} with {ItemCount} items",
            request.OrderId,
            request.CustomerId,
            request.Items.Count);
        
        try
        {
            var result = await ProcessOrderAsync(request);
            
            _logger.LogInformation(
                "Order {OrderId} completed successfully. Total: {OrderTotal:C}",
                request.OrderId,
                result.Total);
                
            return Ok(result);
        }
        catch (PaymentException ex)
        {
            _logger.LogError(ex,
                "Payment failed for order {OrderId}. Provider: {PaymentProvider}, Error: {ErrorCode}",
                request.OrderId,
                ex.Provider,
                ex.ErrorCode);
                
            return BadRequest("Payment failed");
        }
    }
}

// Using LogContext for correlation
using (LogContext.PushProperty("CorrelationId", correlationId))
using (LogContext.PushProperty("UserId", userId))
{
    _logger.LogInformation("Starting request processing");
    // All logs within this scope will have CorrelationId and UserId
}

// Query structured logs in Log Analytics
/*
traces
| where customDimensions.OrderId == "12345"
| project timestamp, message, customDimensions.CustomerId, customDimensions.ItemCount
*/`}]},{id:"q6",question:"How do you implement distributed tracing in microservices with Azure?",answer:"Distributed tracing tracks requests across microservices. Uses correlation IDs to link spans. Application Insights auto-correlates with W3C Trace Context. Operation ID shared across services. Dependency tracking shows call chain. Application Map visualizes service topology. End-to-end transaction search for debugging.",codeSnippets:[{language:"csharp",code:`// Distributed Tracing in Microservices
using System.Diagnostics;
using Microsoft.ApplicationInsights;
using Microsoft.ApplicationInsights.DataContracts;

// Enable W3C Trace Context (default in .NET Core 3.0+)
Activity.DefaultIdFormat = ActivityIdFormat.W3C;
Activity.ForceDefaultIdFormat = true;

// Service A - Order Service
public class OrderService
{
    private readonly HttpClient _httpClient;
    private readonly TelemetryClient _telemetry;
    
    public async Task<Order> CreateOrder(OrderRequest request)
    {
        // Activity automatically propagated via HttpClient
        var activity = Activity.Current;
        
        _telemetry.TrackTrace($"Creating order", SeverityLevel.Information,
            new Dictionary<string, string>
            {
                { "TraceId", activity?.TraceId.ToString() },
                { "SpanId", activity?.SpanId.ToString() }
            });
        
        // Call Inventory Service (trace context auto-propagated)
        var inventory = await _httpClient.GetAsync(
            $"http://inventory-service/api/check/{request.ProductId}");
        
        // Call Payment Service
        var payment = await _httpClient.PostAsJsonAsync(
            "http://payment-service/api/process", 
            new { OrderId = request.Id, Amount = request.Total });
        
        return new Order { Id = request.Id, Status = "Created" };
    }
}

// Service B - Inventory Service (receives trace context automatically)
public class InventoryController : ControllerBase
{
    private readonly ILogger<InventoryController> _logger;
    
    [HttpGet("check/{productId}")]
    public IActionResult CheckInventory(int productId)
    {
        var traceId = Activity.Current?.TraceId.ToString();
        var parentSpanId = Activity.Current?.ParentSpanId.ToString();
        
        _logger.LogInformation(
            "Checking inventory for product {ProductId}. TraceId: {TraceId}, ParentSpan: {ParentSpan}",
            productId, traceId, parentSpanId);
        
        // Same TraceId as Order Service - linked in Application Insights!
        return Ok(new { ProductId = productId, Available = true });
    }
}

// Custom Activity for fine-grained tracing
public async Task ProcessPaymentAsync(PaymentRequest request)
{
    using var activity = new Activity("ProcessPayment").Start();
    activity.SetTag("payment.provider", "Stripe");
    activity.SetTag("payment.amount", request.Amount);
    
    try
    {
        var result = await _stripeClient.ChargeAsync(request);
        activity.SetTag("payment.status", "success");
    }
    catch (Exception ex)
    {
        activity.SetTag("payment.status", "failed");
        activity.SetTag("error.message", ex.Message);
        throw;
    }
}

// View in Application Insights:
// 1. Application Map - See service dependencies
// 2. End-to-end transaction - Trace full request flow
// 3. Failures - See where errors occur in chain`}]},{id:"q7",question:"What are Azure Monitor Workbooks and how do you create custom dashboards?",answer:"Workbooks are interactive reports combining metrics, logs, and text. Templates for common scenarios. Components: text, queries, metrics, parameters, links, groups. Parameters enable filtering. Can embed KQL queries, visualizations (charts, grids, tiles). Share via Azure Portal or export. Dashboards pin specific visualizations for quick view.",codeSnippets:[{language:"csharp",code:`// Azure Monitor Workbooks & Dashboards

Console.WriteLine("Workbook Components:");
Console.WriteLine("");
Console.WriteLine(" Component     Description                         ");
Console.WriteLine("");
Console.WriteLine(" Text          Markdown documentation              ");
Console.WriteLine(" Query         KQL query with visualization        ");
Console.WriteLine(" Metrics       Azure resource metrics chart        ");
Console.WriteLine(" Parameters    Dropdown filters, time range        ");
Console.WriteLine(" Links         Navigation to other workbooks       ");
Console.WriteLine(" Groups        Collapsible sections                ");
Console.WriteLine("");

// Example Workbook: Application Health
Console.WriteLine(@"
## Application Health Workbook

### Parameters
- Time Range: {TimeRange}
- Application: {AppName}

### Request Success Rate
AppRequests
| where TimeGenerated {TimeRange}
| where AppName == '{AppName}'
| summarize 
    TotalRequests = count(),
    FailedRequests = countif(Success == false)
| extend SuccessRate = round(100.0 * (TotalRequests - FailedRequests) / TotalRequests, 2)

### Response Time Percentiles
AppRequests
| where TimeGenerated {TimeRange}
| summarize 
    p50 = percentile(DurationMs, 50),
    p90 = percentile(DurationMs, 90),
    p99 = percentile(DurationMs, 99)
    by bin(TimeGenerated, 5m)
| render timechart

### Top Errors
AppExceptions
| where TimeGenerated {TimeRange}
| summarize Count = count() by ExceptionType, ProblemId
| top 10 by Count
| render barchart

### Dependency Health
AppDependencies
| where TimeGenerated {TimeRange}
| summarize 
    Calls = count(),
    Failures = countif(Success == false),
    AvgDuration = avg(DurationMs)
    by Target, Type
| extend FailureRate = round(100.0 * Failures / Calls, 2)
| order by Failures desc
");

// Azure Dashboard - Pin from any visualization
Console.WriteLine("Dashboard Tips:");
Console.WriteLine(" Pin metrics charts directly from resource blades");
Console.WriteLine(" Pin query results from Log Analytics");
Console.WriteLine(" Add Application Insights components");
Console.WriteLine(" Share dashboards with team members");
Console.WriteLine(" Export as ARM template for IaC");`}]},{id:"q8",question:"How do you monitor Azure Functions and implement health checks?",answer:"Azure Functions integrates with Application Insights automatically. Track invocations, duration, failures. Custom telemetry for business metrics. Durable Functions have built-in orchestration tracking. Health checks via HTTP trigger endpoint. Monitor consumption, execution units, scaling. Alerts for function failures, high duration.",codeSnippets:[{language:"csharp",code:`// Azure Functions Monitoring
using Microsoft.ApplicationInsights;
using Microsoft.Azure.Functions.Worker;
using Microsoft.Extensions.Logging;

public class OrderFunctions
{
    private readonly TelemetryClient _telemetry;
    private readonly ILogger<OrderFunctions> _logger;
    
    public OrderFunctions(TelemetryClient telemetry, ILogger<OrderFunctions> logger)
    {
        _telemetry = telemetry;
        _logger = logger;
    }
    
    [Function("ProcessOrder")]
    public async Task ProcessOrder(
        [ServiceBusTrigger("orders", Connection = "ServiceBusConnection")] Order order)
    {
        using var operation = _telemetry.StartOperation<RequestTelemetry>("ProcessOrder");
        operation.Telemetry.Properties["OrderId"] = order.Id;
        
        var stopwatch = Stopwatch.StartNew();
        
        try
        {
            _logger.LogInformation("Processing order {OrderId}", order.Id);
            
            await ValidateOrder(order);
            await ProcessPayment(order);
            await UpdateInventory(order);
            
            stopwatch.Stop();
            
            // Track custom metrics
            _telemetry.TrackMetric("OrderProcessingTime", stopwatch.ElapsedMilliseconds);
            _telemetry.TrackMetric("OrderValue", order.Total);
            
            _telemetry.TrackEvent("OrderCompleted", new Dictionary<string, string>
            {
                { "OrderId", order.Id },
                { "ProcessingTimeMs", stopwatch.ElapsedMilliseconds.ToString() }
            });
            
            operation.Telemetry.Success = true;
        }
        catch (Exception ex)
        {
            operation.Telemetry.Success = false;
            _telemetry.TrackException(ex);
            throw;
        }
    }
    
    // Health Check Endpoint
    [Function("HealthCheck")]
    public async Task<HttpResponseData> HealthCheck(
        [HttpTrigger(AuthorizationLevel.Anonymous, "get", Route = "health")] 
        HttpRequestData req)
    {
        var response = req.CreateResponse();
        
        var health = new
        {
            Status = "Healthy",
            Timestamp = DateTime.UtcNow,
            Checks = new[]
            {
                new { Name = "Database", Status = await CheckDatabase() },
                new { Name = "ServiceBus", Status = await CheckServiceBus() },
                new { Name = "Storage", Status = await CheckStorage() }
            }
        };
        
        var allHealthy = health.Checks.All(c => c.Status == "Healthy");
        response.StatusCode = allHealthy ? HttpStatusCode.OK : HttpStatusCode.ServiceUnavailable;
        
        await response.WriteAsJsonAsync(health);
        return response;
    }
}

// KQL Queries for Function Monitoring
Console.WriteLine(@"
// Function invocation failures
requests
| where cloud_RoleName contains 'func'
| where success == false
| summarize FailureCount = count() by name, resultCode
| order by FailureCount desc

// Function duration percentiles
requests
| where cloud_RoleName contains 'func'
| summarize 
    p50 = percentile(duration, 50),
    p95 = percentile(duration, 95),
    p99 = percentile(duration, 99)
    by name
| order by p99 desc

// Function scaling (concurrent executions)
requests
| where cloud_RoleName contains 'func'
| summarize ConcurrentExecutions = dcount(operation_Id) by bin(timestamp, 1m)
| render timechart
");`}]}]},ah={id:"azure-kubernetes-services",name:"Kubernetes Services (AKS)",questions:[{id:"q1",question:"What is Azure Kubernetes Service (AKS) and what are its key features?",answer:"AKS is managed Kubernetes service. Azure manages control plane (API server, scheduler, etcd). You manage worker nodes. Features: auto-scaling, auto-upgrades, Azure AD integration, Azure Monitor integration, Virtual Network integration, Azure Policy. Pricing: pay only for worker nodes (VMs), control plane is free.",codeSnippets:[{language:"csharp",code:`// Azure Kubernetes Service (AKS) Overview

Console.WriteLine("AKS Architecture:");
Console.WriteLine("");
Console.WriteLine(" Control Plane (Managed by Azure - FREE)                 ");
Console.WriteLine("  API Server     Scheduler     etcd                   ");
Console.WriteLine("  Controller Manager                                    ");
Console.WriteLine("");
Console.WriteLine(" Worker Nodes (Managed by You - Pay for VMs)             ");
Console.WriteLine("  kubelet     kube-proxy     Container runtime        ");
Console.WriteLine("  Your application pods                                 ");
Console.WriteLine("");

Console.WriteLine("Key Features:");
Console.WriteLine(" Managed control plane (free, 99.95% SLA)");
Console.WriteLine(" Cluster auto-scaler (scale nodes based on demand)");
Console.WriteLine(" Horizontal Pod Autoscaler (scale pods)");
Console.WriteLine(" Azure AD integration (RBAC)");
Console.WriteLine(" Azure CNI networking (VNet integration)");
Console.WriteLine(" Azure Monitor for containers");
Console.WriteLine(" Azure Policy for Kubernetes");
Console.WriteLine(" Automatic node OS updates");

// Create AKS Cluster
Console.WriteLine(@"
# Create AKS cluster
az aks create   --resource-group myRG   --name myAKSCluster   --node-count 3   --node-vm-size Standard_D4s_v3   --enable-managed-identity   --enable-addons monitoring   --generate-ssh-keys

# Get credentials
az aks get-credentials --resource-group myRG --name myAKSCluster

# Verify connection
kubectl get nodes
");`}]},{id:"q2",question:"How do you deploy a .NET application to AKS?",answer:"Steps: 1) Containerize app with Dockerfile, 2) Push to Azure Container Registry, 3) Create Kubernetes manifests (Deployment, Service), 4) Apply with kubectl. Deployment manages replica pods. Service exposes pods (ClusterIP internal, LoadBalancer external). ConfigMaps for config, Secrets for sensitive data.",codeSnippets:[{language:"csharp",code:`// Deploy .NET App to AKS

// Step 1: Dockerfile (multi-stage build)
Console.WriteLine(@"
# Dockerfile
FROM mcr.microsoft.com/dotnet/sdk:8.0 AS build
WORKDIR /src
COPY [""MyApp.csproj"", "".""]
RUN dotnet restore
COPY . .
RUN dotnet publish -c Release -o /app/publish

FROM mcr.microsoft.com/dotnet/aspnet:8.0
WORKDIR /app
COPY --from=build /app/publish .
EXPOSE 80
ENTRYPOINT [""dotnet"", ""MyApp.dll""]
");

// Step 2: Build and push to ACR
Console.WriteLine(@"
# Build and push to ACR
az acr build --registry myacr --image myapp:v1 .

# Or using Docker
docker build -t myacr.azurecr.io/myapp:v1 .
az acr login --name myacr
docker push myacr.azurecr.io/myapp:v1
");

// Step 3: Kubernetes Deployment manifest
Console.WriteLine(@"
# deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
  labels:
    app: myapp
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: myapp
        image: myacr.azurecr.io/myapp:v1
        ports:
        - containerPort: 80
        resources:
          requests:
            memory: '128Mi'
            cpu: '100m'
          limits:
            memory: '256Mi'
            cpu: '500m'
        env:
        - name: ASPNETCORE_ENVIRONMENT
          value: 'Production'
        - name: ConnectionStrings__Database
          valueFrom:
            secretKeyRef:
              name: myapp-secrets
              key: db-connection
        livenessProbe:
          httpGet:
            path: /health/live
            port: 80
          initialDelaySeconds: 10
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /health/ready
            port: 80
          initialDelaySeconds: 5
          periodSeconds: 5
---
# service.yaml
apiVersion: v1
kind: Service
metadata:
  name: myapp-service
spec:
  type: LoadBalancer
  ports:
  - port: 80
    targetPort: 80
  selector:
    app: myapp
");

// Step 4: Deploy to AKS
Console.WriteLine(@"
# Create secret
kubectl create secret generic myapp-secrets   --from-literal=db-connection='Server=...'

# Deploy
kubectl apply -f deployment.yaml
kubectl apply -f service.yaml

# Check status
kubectl get pods
kubectl get services
");`}]},{id:"q3",question:"What is Helm and how do you use it to manage Kubernetes deployments?",answer:"Helm is Kubernetes package manager. Charts are packages of pre-configured resources. Values files customize deployments. Releases are deployed instances. Benefits: templating, versioning, rollbacks, dependency management. Helm repos host charts. Common charts: nginx-ingress, cert-manager, prometheus.",codeSnippets:[{language:"csharp",code:`// Helm - Kubernetes Package Manager

Console.WriteLine("Helm Concepts:");
Console.WriteLine(" Chart: Package of Kubernetes resources");
Console.WriteLine(" Values: Configuration for customization");
Console.WriteLine(" Release: Deployed instance of a chart");
Console.WriteLine(" Repository: Collection of charts");

// Helm Chart Structure
Console.WriteLine(@"
myapp-chart/
 Chart.yaml          # Chart metadata
 values.yaml         # Default configuration
 templates/          # Kubernetes manifests
    deployment.yaml
    service.yaml
    ingress.yaml
    configmap.yaml
    secret.yaml
    _helpers.tpl    # Template helpers
 charts/             # Dependencies
");

// Chart.yaml
Console.WriteLine(@"
# Chart.yaml
apiVersion: v2
name: myapp
description: My .NET Application
version: 1.0.0
appVersion: '1.0.0'
dependencies:
  - name: redis
    version: 17.x.x
    repository: https://charts.bitnami.com/bitnami
");

// values.yaml
Console.WriteLine(@"
# values.yaml
replicaCount: 3

image:
  repository: myacr.azurecr.io/myapp
  tag: latest
  pullPolicy: Always

service:
  type: ClusterIP
  port: 80

ingress:
  enabled: true
  className: nginx
  hosts:
    - host: myapp.example.com
      paths:
        - path: /
          pathType: Prefix

resources:
  limits:
    cpu: 500m
    memory: 256Mi
  requests:
    cpu: 100m
    memory: 128Mi

autoscaling:
  enabled: true
  minReplicas: 2
  maxReplicas: 10
  targetCPUUtilization: 80

env:
  ASPNETCORE_ENVIRONMENT: Production
");

// Templated deployment.yaml
Console.WriteLine(@"
# templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ include ""myapp.fullname"" . }}
spec:
  replicas: {{ .Values.replicaCount }}
  selector:
    matchLabels:
      app: {{ include ""myapp.name"" . }}
  template:
    spec:
      containers:
      - name: {{ .Chart.Name }}
        image: ""{{ .Values.image.repository }}:{{ .Values.image.tag }}""
        resources:
          {{- toYaml .Values.resources | nindent 12 }}
");

// Helm Commands
Console.WriteLine(@"
# Add repository
helm repo add bitnami https://charts.bitnami.com/bitnami
helm repo update

# Install chart
helm install myapp ./myapp-chart -f values-prod.yaml

# Upgrade release
helm upgrade myapp ./myapp-chart -f values-prod.yaml

# Rollback
helm rollback myapp 1

# List releases
helm list

# Uninstall
helm uninstall myapp
");`}]},{id:"q4",question:"How do you implement auto-scaling in AKS?",answer:"Two types: Horizontal Pod Autoscaler (HPA) scales pods based on CPU/memory/custom metrics. Cluster Autoscaler scales nodes when pods can't be scheduled. KEDA (Kubernetes Event-Driven Autoscaling) scales based on external metrics (queue length, HTTP requests). Configure HPA with kubectl or YAML manifest.",codeSnippets:[{language:"csharp",code:`// AKS Auto-scaling

Console.WriteLine("Auto-scaling Types:");
Console.WriteLine("");
Console.WriteLine(" Type                What it scales  Based on          ");
Console.WriteLine("");
Console.WriteLine(" HPA                 Pods            CPU/Memory/Custom ");
Console.WriteLine(" Cluster Autoscaler  Nodes           Pending pods      ");
Console.WriteLine(" KEDA                Pods            External events   ");
Console.WriteLine("");

// Horizontal Pod Autoscaler (HPA)
Console.WriteLine(@"
# hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: myapp-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: myapp
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
      - type: Percent
        value: 100
        periodSeconds: 15
");

// Enable Cluster Autoscaler
Console.WriteLine(@"
# Enable cluster autoscaler on node pool
az aks nodepool update   --resource-group myRG   --cluster-name myAKS   --name nodepool1   --enable-cluster-autoscaler   --min-count 2   --max-count 10
");

// KEDA - Event-driven scaling
Console.WriteLine(@"
# Install KEDA
helm repo add kedacore https://kedacore.github.io/charts
helm install keda kedacore/keda --namespace keda --create-namespace

# ScaledObject for Azure Service Bus
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: myapp-scaler
spec:
  scaleTargetRef:
    name: myapp
  minReplicaCount: 1
  maxReplicaCount: 20
  triggers:
  - type: azure-servicebus
    metadata:
      queueName: orders
      messageCount: '5'
      connectionFromEnv: SERVICEBUS_CONNECTION
  - type: prometheus
    metadata:
      serverAddress: http://prometheus:9090
      metricName: http_requests_total
      threshold: '100'
      query: sum(rate(http_requests_total[2m]))
");

// Check HPA status
Console.WriteLine(@"
kubectl get hpa
kubectl describe hpa myapp-hpa
kubectl top pods
");`}]},{id:"q5",question:"How do you configure Ingress in AKS for routing external traffic?",answer:"Ingress manages external HTTP/HTTPS access to services. Ingress Controller (nginx, Azure Application Gateway) processes rules. Features: path-based routing, host-based routing, TLS termination, URL rewriting. Azure offers Application Gateway Ingress Controller (AGIC) for native integration.",codeSnippets:[{language:"csharp",code:`// AKS Ingress Configuration

Console.WriteLine("Ingress Controllers for AKS:");
Console.WriteLine(" NGINX Ingress Controller (most popular)");
Console.WriteLine(" Azure Application Gateway Ingress Controller (AGIC)");
Console.WriteLine(" Traefik");
Console.WriteLine(" HAProxy");

// Install NGINX Ingress Controller
Console.WriteLine(@"
# Install nginx ingress controller
helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
helm install ingress-nginx ingress-nginx/ingress-nginx   --namespace ingress-nginx   --create-namespace   --set controller.service.annotations.""service.beta.kubernetes.io/azure-load-balancer-health-probe-request-path""=/healthz
");

// Basic Ingress with path-based routing
Console.WriteLine(@"
# ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: myapp-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /$2
    nginx.ingress.kubernetes.io/ssl-redirect: 'true'
spec:
  ingressClassName: nginx
  tls:
  - hosts:
    - myapp.example.com
    secretName: myapp-tls
  rules:
  - host: myapp.example.com
    http:
      paths:
      - path: /api(/|$)(.*)
        pathType: Prefix
        backend:
          service:
            name: api-service
            port:
              number: 80
      - path: /(.*)
        pathType: Prefix
        backend:
          service:
            name: frontend-service
            port:
              number: 80
");

// Host-based routing (multiple apps)
Console.WriteLine(@"
# Multi-host ingress
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: multi-app-ingress
spec:
  ingressClassName: nginx
  rules:
  - host: app1.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: app1-service
            port:
              number: 80
  - host: app2.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: app2-service
            port:
              number: 80
");

// TLS with cert-manager (automatic certificates)
Console.WriteLine(@"
# Install cert-manager
helm repo add jetstack https://charts.jetstack.io
helm install cert-manager jetstack/cert-manager   --namespace cert-manager   --create-namespace   --set installCRDs=true

# ClusterIssuer for Let's Encrypt
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: letsencrypt-prod
spec:
  acme:
    server: https://acme-v02.api.letsencrypt.org/directory
    email: admin@example.com
    privateKeySecretRef:
      name: letsencrypt-prod
    solvers:
    - http01:
        ingress:
          class: nginx

# Ingress with automatic TLS
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: myapp-ingress
  annotations:
    cert-manager.io/cluster-issuer: letsencrypt-prod
spec:
  ingressClassName: nginx
  tls:
  - hosts:
    - myapp.example.com
    secretName: myapp-tls-auto  # cert-manager creates this
  rules:
  - host: myapp.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: myapp-service
            port:
              number: 80
");`}]},{id:"q6",question:"How do you manage secrets and configuration in AKS?",answer:"ConfigMaps for non-sensitive config (env vars, config files). Secrets for sensitive data (base64 encoded, not encrypted by default). Best practice: use Azure Key Vault with CSI driver for secrets. Secrets Store CSI Driver mounts Key Vault secrets as volumes or env vars. External Secrets Operator syncs from Key Vault.",codeSnippets:[{language:"csharp",code:`// Secrets & Configuration in AKS

Console.WriteLine("Configuration Options:");
Console.WriteLine(" ConfigMaps - Non-sensitive configuration");
Console.WriteLine(" Secrets - Sensitive data (base64, not encrypted)");
Console.WriteLine(" Azure Key Vault + CSI Driver - Best for production");
Console.WriteLine(" External Secrets Operator - Sync from Key Vault");

// ConfigMap
Console.WriteLine(@"
# configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: myapp-config
data:
  ASPNETCORE_ENVIRONMENT: 'Production'
  LOG_LEVEL: 'Information'
  API_URL: 'https://api.example.com'
  appsettings.json: |
    {
      ""Logging"": {
        ""LogLevel"": {
          ""Default"": ""Information""
        }
      },
      ""AllowedHosts"": ""*""
    }
");

// Kubernetes Secret
Console.WriteLine(@"
# Create secret imperatively
kubectl create secret generic myapp-secrets   --from-literal=DB_PASSWORD='MyP@ssw0rd'   --from-literal=API_KEY='abc123'

# secret.yaml (values must be base64 encoded)
apiVersion: v1
kind: Secret
metadata:
  name: myapp-secrets
type: Opaque
data:
  DB_PASSWORD: TXlQQHNzdzByZA==  # base64 encoded
  API_KEY: YWJjMTIz
");

// Using ConfigMap and Secret in Deployment
Console.WriteLine(@"
spec:
  containers:
  - name: myapp
    image: myapp:latest
    envFrom:
    - configMapRef:
        name: myapp-config
    - secretRef:
        name: myapp-secrets
    volumeMounts:
    - name: config-volume
      mountPath: /app/config
  volumes:
  - name: config-volume
    configMap:
      name: myapp-config
      items:
      - key: appsettings.json
        path: appsettings.json
");

// Azure Key Vault CSI Driver (Recommended for Production)
Console.WriteLine(@"
# Enable Key Vault CSI Driver addon
az aks enable-addons   --addons azure-keyvault-secrets-provider   --name myAKS   --resource-group myRG

# SecretProviderClass
apiVersion: secrets-store.csi.x-k8s.io/v1
kind: SecretProviderClass
metadata:
  name: azure-keyvault-secrets
spec:
  provider: azure
  parameters:
    usePodIdentity: 'false'
    useVMManagedIdentity: 'true'
    userAssignedIdentityID: '<managed-identity-client-id>'
    keyvaultName: 'mykeyvault'
    objects: |
      array:
        - |
          objectName: db-connection-string
          objectType: secret
        - |
          objectName: api-key
          objectType: secret
    tenantId: '<tenant-id>'
  secretObjects:
  - secretName: myapp-kv-secrets
    type: Opaque
    data:
    - objectName: db-connection-string
      key: DB_CONNECTION
    - objectName: api-key
      key: API_KEY

# Use in Deployment
spec:
  containers:
  - name: myapp
    envFrom:
    - secretRef:
        name: myapp-kv-secrets
    volumeMounts:
    - name: secrets-store
      mountPath: '/mnt/secrets'
      readOnly: true
  volumes:
  - name: secrets-store
    csi:
      driver: secrets-store.csi.k8s.io
      readOnly: true
      volumeAttributes:
        secretProviderClass: azure-keyvault-secrets
");`}]},{id:"q7",question:"How do you implement CI/CD for AKS deployments?",answer:"Options: Azure DevOps Pipelines, GitHub Actions, GitLab CI, Flux (GitOps). Pipeline stages: Build image  Push to ACR  Deploy to AKS. Blue-green or canary deployments with multiple replicas. ArgoCD or Flux for GitOps (pull-based). Use Helm for templated deployments.",codeSnippets:[{language:"csharp",code:`// CI/CD for AKS

Console.WriteLine("CI/CD Options:");
Console.WriteLine(" Azure DevOps Pipelines");
Console.WriteLine(" GitHub Actions");
Console.WriteLine(" GitLab CI/CD");
Console.WriteLine(" Flux/ArgoCD (GitOps)");

// GitHub Actions Workflow
Console.WriteLine(@"
# .github/workflows/deploy.yml
name: Build and Deploy to AKS

on:
  push:
    branches: [main]

env:
  AZURE_CONTAINER_REGISTRY: myacr.azurecr.io
  RESOURCE_GROUP: myRG
  CLUSTER_NAME: myAKS
  IMAGE_NAME: myapp

jobs:
  build-and-push:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Azure Login
      uses: azure/login@v1
      with:
        creds: \${{ secrets.AZURE_CREDENTIALS }}
    
    - name: Build and push to ACR
      run: |
        az acr login --name myacr
        docker build -t \${{ env.AZURE_CONTAINER_REGISTRY }}/\${{ env.IMAGE_NAME }}:\${{ github.sha }} .
        docker push \${{ env.AZURE_CONTAINER_REGISTRY }}/\${{ env.IMAGE_NAME }}:\${{ github.sha }}

  deploy:
    needs: build-and-push
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Azure Login
      uses: azure/login@v1
      with:
        creds: \${{ secrets.AZURE_CREDENTIALS }}
    
    - name: Get AKS credentials
      run: |
        az aks get-credentials --resource-group \${{ env.RESOURCE_GROUP }} --name \${{ env.CLUSTER_NAME }}
    
    - name: Deploy with Helm
      run: |
        helm upgrade --install myapp ./charts/myapp           --set image.tag=\${{ github.sha }}           --set image.repository=\${{ env.AZURE_CONTAINER_REGISTRY }}/\${{ env.IMAGE_NAME }}           --wait --timeout 5m
");

// Azure DevOps Pipeline
Console.WriteLine(@"
# azure-pipelines.yml
trigger:
  - main

pool:
  vmImage: ubuntu-latest

variables:
  azureSubscription: 'MyAzureSubscription'
  containerRegistry: 'myacr.azurecr.io'
  imageRepository: 'myapp'
  tag: '$(Build.BuildId)'

stages:
- stage: Build
  jobs:
  - job: BuildAndPush
    steps:
    - task: Docker@2
      inputs:
        containerRegistry: 'ACR-Connection'
        repository: '$(imageRepository)'
        command: buildAndPush
        Dockerfile: '**/Dockerfile'
        tags: |
          $(tag)
          latest

- stage: Deploy
  jobs:
  - deployment: DeployToAKS
    environment: 'production'
    strategy:
      runOnce:
        deploy:
          steps:
          - task: KubernetesManifest@0
            inputs:
              action: deploy
              kubernetesServiceConnection: 'AKS-Connection'
              namespace: default
              manifests: |
                $(Pipeline.Workspace)/manifests/*.yml
              containers: |
                $(containerRegistry)/$(imageRepository):$(tag)
");

// GitOps with Flux
Console.WriteLine(@"
# Install Flux
az k8s-extension create   --name flux   --extension-type microsoft.flux   --cluster-type managedClusters   --cluster-name myAKS   --resource-group myRG

# GitRepository source
apiVersion: source.toolkit.fluxcd.io/v1
kind: GitRepository
metadata:
  name: myapp-repo
  namespace: flux-system
spec:
  interval: 1m
  url: https://github.com/myorg/myapp-k8s
  ref:
    branch: main

# Kustomization (auto-deploy on git push)
apiVersion: kustomize.toolkit.fluxcd.io/v1
kind: Kustomization
metadata:
  name: myapp
  namespace: flux-system
spec:
  interval: 5m
  path: ./deploy/production
  prune: true
  sourceRef:
    kind: GitRepository
    name: myapp-repo
  healthChecks:
  - kind: Deployment
    name: myapp
    namespace: default
");`}]},{id:"q8",question:"How do you monitor and troubleshoot AKS clusters?",answer:"Azure Monitor for Containers provides insights. Container Insights shows CPU, memory, network. Log Analytics stores container logs. kubectl logs for pod logs. kubectl describe for events. kubectl exec for interactive debugging. Prometheus/Grafana for custom metrics. Azure Advisor for recommendations.",codeSnippets:[{language:"csharp",code:`// AKS Monitoring & Troubleshooting

Console.WriteLine("Monitoring Tools:");
Console.WriteLine(" Azure Monitor for Containers");
Console.WriteLine(" Container Insights");
Console.WriteLine(" Log Analytics");
Console.WriteLine(" Prometheus + Grafana");
Console.WriteLine(" kubectl commands");

// Enable Azure Monitor for Containers
Console.WriteLine(@"
# Enable monitoring addon
az aks enable-addons   --addons monitoring   --name myAKS   --resource-group myRG   --workspace-resource-id '/subscriptions/{sub}/resourceGroups/{rg}/providers/Microsoft.OperationalInsights/workspaces/{workspace}'
");

// KQL Queries for Container Insights
Console.WriteLine(@"
// Pod CPU usage
Perf
| where ObjectName == 'K8SContainer'
| where CounterName == 'cpuUsageNanoCores'
| summarize AvgCPU = avg(CounterValue) by bin(TimeGenerated, 5m), InstanceName
| render timechart

// Pod memory usage
Perf
| where ObjectName == 'K8SContainer'
| where CounterName == 'memoryWorkingSetBytes'
| summarize AvgMemory = avg(CounterValue / 1024 / 1024) by bin(TimeGenerated, 5m), InstanceName
| render timechart

// Container logs
ContainerLog
| where LogEntry contains 'error'
| project TimeGenerated, LogEntry, ContainerID
| order by TimeGenerated desc
| take 100

// Pod restart count
KubePodInventory
| where ClusterName == 'myAKS'
| summarize RestartCount = sum(PodRestartCount) by Name, Namespace
| where RestartCount > 0
| order by RestartCount desc

// Node conditions
KubeNodeInventory
| where ClusterName == 'myAKS'
| project Computer, Status, Labels
");

// kubectl troubleshooting commands
Console.WriteLine(@"
# View pod logs
kubectl logs <pod-name>
kubectl logs <pod-name> --previous  # Previous container logs
kubectl logs <pod-name> -f  # Follow logs

# Describe pod (events, status)
kubectl describe pod <pod-name>

# View all pods with status
kubectl get pods -o wide

# Check resource usage
kubectl top pods
kubectl top nodes

# Interactive shell in pod
kubectl exec -it <pod-name> -- /bin/sh

# Port forward for local debugging
kubectl port-forward <pod-name> 8080:80

# View events
kubectl get events --sort-by='.lastTimestamp'

# Check deployment rollout status
kubectl rollout status deployment/myapp
kubectl rollout history deployment/myapp
kubectl rollout undo deployment/myapp
");

// Common Issues & Solutions
Console.WriteLine("Common Issues:");
Console.WriteLine("");
Console.WriteLine(" Issue               Check                              ");
Console.WriteLine("");
Console.WriteLine(" ImagePullBackOff    ACR credentials, image exists      ");
Console.WriteLine(" CrashLoopBackOff    App logs, health probes            ");
Console.WriteLine(" Pending pods        Node resources, node selector      ");
Console.WriteLine(" OOMKilled           Increase memory limits             ");
Console.WriteLine(" Service no IP       Check service type, annotations    ");
Console.WriteLine("");`}]}]},sh={id:"azure",name:"Microsoft Azure",icon:"",topics:[Ky,$y,Yy,Jy,Xy,Zy,eh,th,nh,ih,rh,oh,ah]},lh={id:"azure-devops-overview",name:"Overview & Boards",questions:[{id:"q1",question:"What is Azure DevOps and what are its main components?",answer:"Azure DevOps is Microsoft's comprehensive DevOps platform providing development tools for planning, developing, testing, and delivering software. Main components: Azure Boards (work tracking), Azure Repos (source control), Azure Pipelines (CI/CD), Azure Test Plans (testing), Azure Artifacts (package management). Available as cloud service or on-premises (Azure DevOps Server).",codeSnippets:[{language:"csharp",code:`// Azure DevOps Services Overview

Console.WriteLine("Azure DevOps - Main Components:");
Console.WriteLine("");
Console.WriteLine(" Component         Purpose                              ");
Console.WriteLine("");
Console.WriteLine(" Azure Boards      Agile planning & work tracking       ");
Console.WriteLine(" Azure Repos       Git repositories & version control   ");
Console.WriteLine(" Azure Pipelines   CI/CD automation                     ");
Console.WriteLine(" Azure Test Plans  Manual & automated testing           ");
Console.WriteLine(" Azure Artifacts   Package management (NuGet, npm)      ");
Console.WriteLine("");

Console.WriteLine("Deployment Options:");
Console.WriteLine(" Azure DevOps Services (Cloud) - dev.azure.com");
Console.WriteLine(" Azure DevOps Server (On-premises)");

Console.WriteLine("Key Features:");
Console.WriteLine(" Integration with Visual Studio, VS Code, GitHub");
Console.WriteLine(" REST APIs for automation");
Console.WriteLine(" Extensions marketplace");
Console.WriteLine(" Role-based access control");
Console.WriteLine(" Audit logging and compliance");

// Organization Structure
Console.WriteLine("Hierarchy:");
Console.WriteLine("Organization");
Console.WriteLine("   Project");
Console.WriteLine("         Repos");
Console.WriteLine("         Boards");
Console.WriteLine("         Pipelines");
Console.WriteLine("         Test Plans");
Console.WriteLine("         Artifacts");`}]},{id:"q2",question:"What is Azure Boards and how do you use it for Agile project management?",answer:"Azure Boards provides Agile planning tools: Work Items (tasks, bugs, user stories, features, epics), Boards (Kanban), Backlogs, Sprints, Queries, Dashboards. Supports Scrum, Kanban, CMMI processes. Work items link to code commits, PRs, builds. Customizable with custom fields, states, and workflows.",codeSnippets:[{language:"csharp",code:`// Azure Boards Work Item Types

Console.WriteLine("Work Item Hierarchy (Agile Process):");
Console.WriteLine("");
Console.WriteLine(" Epic                                                    ");
Console.WriteLine("    Feature                                           ");
Console.WriteLine("          User Story / Product Backlog Item           ");
Console.WriteLine("                Task                                  ");
Console.WriteLine("                Bug                                   ");
Console.WriteLine("");

Console.WriteLine("Process Templates:");
Console.WriteLine(" Agile - User Stories, Features, Epics");
Console.WriteLine(" Scrum - Product Backlog Items, Sprints");
Console.WriteLine(" CMMI - Requirements, Change Requests");
Console.WriteLine(" Basic - Issues, Epics (simplified)");

// Work Item States (Agile)
Console.WriteLine("User Story States:");
Console.WriteLine("New  Active  Resolved  Closed");

Console.WriteLine("Bug States:");
Console.WriteLine("New  Active  Resolved  Closed");

// Boards Features
Console.WriteLine("Kanban Board Features:");
Console.WriteLine(" Columns represent workflow states");
Console.WriteLine(" WIP (Work In Progress) limits");
Console.WriteLine(" Swimlanes for categorization");
Console.WriteLine(" Card customization");
Console.WriteLine(" Cumulative flow diagrams");

// Sprint Planning
Console.WriteLine("Sprint Features:");
Console.WriteLine(" Sprint backlog");
Console.WriteLine(" Capacity planning");
Console.WriteLine(" Burndown charts");
Console.WriteLine(" Velocity tracking");
Console.WriteLine(" Sprint retrospectives");`}]},{id:"q3",question:"How do you use Azure DevOps REST API for automation?",answer:"Azure DevOps provides comprehensive REST APIs for automating tasks. Authenticate using PAT (Personal Access Token), OAuth, or Service Principal. Common operations: create work items, trigger pipelines, manage repos, query builds. Use Azure DevOps CLI or REST calls directly.",codeSnippets:[{language:"csharp",code:`// Azure DevOps REST API Examples
using System.Net.Http.Headers;
using System.Text.Json;

public class AzureDevOpsClient
{
    private readonly HttpClient _httpClient;
    private readonly string _organization;
    private readonly string _project;
    
    public AzureDevOpsClient(string organization, string project, string pat)
    {
        _organization = organization;
        _project = project;
        _httpClient = new HttpClient();
        
        // Base URL for Azure DevOps Services
        _httpClient.BaseAddress = new Uri($"https://dev.azure.com/{organization}/");
        
        // Authentication with Personal Access Token (PAT)
        var credentials = Convert.ToBase64String(
            System.Text.Encoding.ASCII.GetBytes($":{pat}"));
        _httpClient.DefaultRequestHeaders.Authorization = 
            new AuthenticationHeaderValue("Basic", credentials);
    }
    
    // Create Work Item
    public async Task<JsonDocument> CreateWorkItemAsync(
        string workItemType, 
        string title, 
        string description)
    {
        var patchDocument = new[]
        {
            new { op = "add", path = "/fields/System.Title", value = title },
            new { op = "add", path = "/fields/System.Description", value = description }
        };
        
        var content = new StringContent(
            JsonSerializer.Serialize(patchDocument),
            System.Text.Encoding.UTF8,
            "application/json-patch+json");
        
        var response = await _httpClient.PostAsync(
            $"{_project}/_apis/wit/workitems/\${workItemType}?api-version=7.0",
            content);
        
        var json = await response.Content.ReadAsStringAsync();
        return JsonDocument.Parse(json);
    }
    
    // Query Work Items
    public async Task<JsonDocument> QueryWorkItemsAsync(string wiql)
    {
        var query = new { query = wiql };
        var content = new StringContent(
            JsonSerializer.Serialize(query),
            System.Text.Encoding.UTF8,
            "application/json");
        
        var response = await _httpClient.PostAsync(
            $"{_project}/_apis/wit/wiql?api-version=7.0",
            content);
        
        return JsonDocument.Parse(await response.Content.ReadAsStringAsync());
    }
    
    // Trigger Pipeline
    public async Task<JsonDocument> TriggerPipelineAsync(int pipelineId, string branch)
    {
        var body = new
        {
            resources = new
            {
                repositories = new
                {
                    self = new { refName = $"refs/heads/{branch}" }
                }
            }
        };
        
        var content = new StringContent(
            JsonSerializer.Serialize(body),
            System.Text.Encoding.UTF8,
            "application/json");
        
        var response = await _httpClient.PostAsync(
            $"{_project}/_apis/pipelines/{pipelineId}/runs?api-version=7.0",
            content);
        
        return JsonDocument.Parse(await response.Content.ReadAsStringAsync());
    }
}

// Usage
var client = new AzureDevOpsClient("myorg", "myproject", "PAT_TOKEN");
var workItem = await client.CreateWorkItemAsync("Task", "Implement feature", "Details...");

// Azure CLI examples
Console.WriteLine(@"
# Azure DevOps CLI
az devops configure --defaults organization=https://dev.azure.com/myorg project=myproject

# Create work item
az boards work-item create --type 'User Story' --title 'New feature'

# Query work items
az boards query --wiql ""SELECT [System.Id] FROM WorkItems WHERE [System.State] = 'Active'""

# Trigger pipeline
az pipelines run --name 'MyPipeline' --branch main
");`}]},{id:"q4",question:"How do you configure Azure DevOps dashboards and reporting?",answer:"Dashboards display widgets for project visibility. Built-in widgets: burndown charts, velocity, build status, PR status, work item queries. Analytics service provides advanced reporting with OData queries. Power BI integration for custom reports. Create multiple dashboards for different audiences (team, stakeholders).",codeSnippets:[{language:"csharp",code:`// Azure DevOps Dashboards & Analytics

Console.WriteLine("Dashboard Widget Categories:");
Console.WriteLine("");
Console.WriteLine(" Category          Widgets                              ");
Console.WriteLine("");
Console.WriteLine(" Boards            Burndown, Velocity, CFD, Sprint      ");
Console.WriteLine(" Repos             Code changes, PR stats               ");
Console.WriteLine(" Pipelines         Build history, Deploy status         ");
Console.WriteLine(" Test Plans        Test results, Coverage trends        ");
Console.WriteLine(" General           Markdown, Query results, Charts      ");
Console.WriteLine("");

// Common Dashboard Widgets
Console.WriteLine("Essential Widgets:");
Console.WriteLine(" Sprint Burndown - Track sprint progress");
Console.WriteLine(" Velocity - Team capacity over sprints");
Console.WriteLine(" Cumulative Flow - Work item flow visualization");
Console.WriteLine(" Build History - Recent build status");
Console.WriteLine(" Release Pipeline Overview - Deployment status");
Console.WriteLine(" Test Results Trend - Test pass/fail over time");
Console.WriteLine(" Query Results - Custom work item queries");

// Analytics OData Queries
Console.WriteLine(@"
// OData Analytics Query Example
// Get work items completed per sprint

GET https://analytics.dev.azure.com/{org}/{project}/_odata/v3.0/WorkItems?
    $filter=WorkItemType eq 'User Story' and State eq 'Closed'
    &$select=WorkItemId,Title,ClosedDate,IterationPath
    &$orderby=ClosedDate desc
");

// Power BI Integration
Console.WriteLine("Power BI Integration Steps:");
Console.WriteLine("1. Install Azure DevOps connector in Power BI");
Console.WriteLine("2. Connect using Organization URL");
Console.WriteLine("3. Select data tables (WorkItems, Builds, etc.)");
Console.WriteLine("4. Create custom visualizations");
Console.WriteLine("5. Schedule data refresh");

// Work Item Queries (WIQL)
Console.WriteLine(@"
-- WIQL Query Examples

-- Active bugs assigned to me
SELECT [System.Id], [System.Title], [System.State]
FROM WorkItems
WHERE [System.WorkItemType] = 'Bug'
  AND [System.State] = 'Active'
  AND [System.AssignedTo] = @Me

-- Items modified in last 7 days
SELECT [System.Id], [System.Title], [System.ChangedDate]
FROM WorkItems
WHERE [System.ChangedDate] >= @Today - 7
ORDER BY [System.ChangedDate] DESC

-- Sprint backlog
SELECT [System.Id], [System.Title], [System.State]
FROM WorkItems
WHERE [System.IterationPath] = @CurrentIteration
  AND [System.WorkItemType] IN ('User Story', 'Bug', 'Task')
");`}]},{id:"q5",question:"How do you manage permissions and security in Azure DevOps?",answer:"Azure DevOps uses role-based access control (RBAC). Levels: Organization, Project, Object (repo, pipeline). Built-in groups: Project Administrators, Contributors, Readers. Security namespaces control granular permissions. Service connections for external service access. Audit logs track all actions.",codeSnippets:[{language:"csharp",code:`// Azure DevOps Security & Permissions

Console.WriteLine("Permission Levels:");
Console.WriteLine("");
Console.WriteLine(" Level           Scope                                 ");
Console.WriteLine("");
Console.WriteLine(" Organization    All projects, billing, policies       ");
Console.WriteLine(" Project         Repos, pipelines, boards in project   ");
Console.WriteLine(" Object          Specific repo, pipeline, area path    ");
Console.WriteLine("");

// Built-in Security Groups
Console.WriteLine("Built-in Groups (Project Level):");
Console.WriteLine(" Project Administrators - Full control");
Console.WriteLine(" Contributors - Add/edit work items, code, pipelines");
Console.WriteLine(" Readers - View only");
Console.WriteLine(" Build Administrators - Manage build pipelines");
Console.WriteLine(" Release Administrators - Manage release pipelines");

// Organization-level Groups
Console.WriteLine("Organization Groups:");
Console.WriteLine(" Project Collection Administrators - Full org control");
Console.WriteLine(" Project Collection Build Administrators");
Console.WriteLine(" Project Collection Valid Users");

// Branch Policies
Console.WriteLine(@"
Branch Policies for main branch:

 Policy                         Setting                 

 Require minimum reviewers      2 reviewers             
 Check for linked work items    Required                
 Check for comment resolution   Required                
 Build validation               Required (CI pipeline)  
 Require merge strategy         Squash merge            

");

// Service Connections
Console.WriteLine("Service Connections:");
Console.WriteLine(" Azure Resource Manager - Deploy to Azure");
Console.WriteLine(" Docker Registry - Push/pull images");
Console.WriteLine(" Kubernetes - Deploy to AKS");
Console.WriteLine(" GitHub - Access GitHub repos");
Console.WriteLine(" Generic - Custom service with URL/credentials");

// CLI Commands for Security
Console.WriteLine(@"
# List project groups
az devops security group list --project MyProject

# Add user to group
az devops security group membership add   --group-id <group-id>   --member-id <user-id>

# Set repository permission
az repos policy approver-count create   --branch main   --repository-id <repo-id>   --minimum-approver-count 2   --creator-vote-counts false

# View audit logs
az devops audit-log query --start-time 2024-01-01
");

// Conditional Access
Console.WriteLine("Security Best Practices:");
Console.WriteLine(" Enable Azure AD Conditional Access");
Console.WriteLine(" Require MFA for all users");
Console.WriteLine(" Use service principals, not PATs, for automation");
Console.WriteLine(" Rotate secrets regularly");
Console.WriteLine(" Review audit logs periodically");
Console.WriteLine(" Apply principle of least privilege");`}]}]},ch={id:"azure-repos",name:"Azure Repos (Git)",questions:[{id:"q1",question:"What is Azure Repos and what version control systems does it support?",answer:"Azure Repos provides cloud-hosted Git repositories with unlimited private repos. Supports Git (distributed) and TFVC (centralized - legacy). Features: branch policies, pull requests, code reviews, branch protection, integration with Azure Pipelines. Free for up to 5 users, unlimited for Visual Studio subscribers.",codeSnippets:[{language:"csharp",code:`// Azure Repos Overview

Console.WriteLine("Azure Repos Features:");
Console.WriteLine("");
Console.WriteLine(" Feature               Description                      ");
Console.WriteLine("");
Console.WriteLine(" Git Repositories      Unlimited private repos          ");
Console.WriteLine(" Branch Policies       Protect branches with rules      ");
Console.WriteLine(" Pull Requests         Code review workflow             ");
Console.WriteLine(" Code Search           Search across all repos          ");
Console.WriteLine(" Web Editor            Edit files in browser            ");
Console.WriteLine(" SSH Support           Clone via SSH                    ");
Console.WriteLine("");

// Git vs TFVC
Console.WriteLine("Git vs TFVC:");
Console.WriteLine("");
Console.WriteLine(" Git (Recommended)     TFVC (Legacy)                    ");
Console.WriteLine("");
Console.WriteLine(" Distributed           Centralized                      ");
Console.WriteLine(" Full local history    Server-based history             ");
Console.WriteLine(" Fast branching        Slower branching                 ");
Console.WriteLine(" Offline commits       Requires server connection       ");
Console.WriteLine(" Industry standard     Microsoft-specific               ");
Console.WriteLine("");

// Clone Repository
Console.WriteLine(@"
# Clone from Azure Repos
git clone https://dev.azure.com/myorg/myproject/_git/myrepo

# Clone with SSH
git clone git@ssh.dev.azure.com:v3/myorg/myproject/myrepo

# Set upstream for existing repo
git remote add origin https://dev.azure.com/myorg/myproject/_git/myrepo
git push -u origin main
");`}]},{id:"q2",question:"How do you configure branch policies in Azure Repos?",answer:"Branch policies protect important branches. Options: minimum reviewers, linked work items, comment resolution, build validation, status checks, merge strategies. Applied per branch (main, release/*). Prevents direct pushes, requires PRs. Can be bypassed by admins if needed.",codeSnippets:[{language:"csharp",code:`// Azure Repos Branch Policies

Console.WriteLine("Branch Policy Options:");
Console.WriteLine("");
Console.WriteLine(" Policy                         Purpose                 ");
Console.WriteLine("");
Console.WriteLine(" Require minimum reviewers      Code review enforcement ");
Console.WriteLine(" Check for linked work items    Traceability            ");
Console.WriteLine(" Check for comment resolution   Address all feedback    ");
Console.WriteLine(" Limit merge types              Enforce merge strategy  ");
Console.WriteLine(" Build validation               CI must pass            ");
Console.WriteLine(" Status checks                  External validations    ");
Console.WriteLine(" Automatically include reviewers Required reviewers     ");
Console.WriteLine("");

// Configure via CLI
Console.WriteLine(@"
# Create minimum reviewers policy
az repos policy approver-count create   --branch main   --repository-id <repo-id>   --project MyProject   --minimum-approver-count 2   --creator-vote-counts false   --allow-downvotes false   --reset-on-source-push true

# Require linked work items
az repos policy work-item-linking create   --branch main   --repository-id <repo-id>   --project MyProject   --blocking true

# Add build validation
az repos policy build create   --branch main   --repository-id <repo-id>   --project MyProject   --build-definition-id <pipeline-id>   --display-name 'CI Build'   --queue-on-source-update-only true   --valid-duration 720

# Require comment resolution
az repos policy comment-required create   --branch main   --repository-id <repo-id>   --project MyProject   --blocking true
");

// Merge Strategies
Console.WriteLine("Merge Strategies:");
Console.WriteLine(" Merge (no fast-forward) - Preserves branch history");
Console.WriteLine(" Squash merge - Combines commits into one");
Console.WriteLine(" Rebase - Linear history, no merge commit");
Console.WriteLine(" Semi-linear merge - Rebase + merge commit");

// Auto-complete
Console.WriteLine("PR Auto-complete:");
Console.WriteLine(" Set when creating PR");
Console.WriteLine(" Merges automatically when all policies pass");
Console.WriteLine(" Optional: delete source branch after merge");`}]},{id:"q3",question:"How do you perform effective code reviews using Pull Requests?",answer:"Pull Requests (PRs) enable code review workflow. Features: diff view, inline comments, threads, suggestions, required reviewers, draft PRs, auto-complete. Link to work items for traceability. Use PR templates for consistency. Reviewers can Approve, Approve with suggestions, Wait for author, or Reject.",codeSnippets:[{language:"csharp",code:`// Azure Repos Pull Request Workflow

Console.WriteLine("Pull Request Lifecycle:");
Console.WriteLine("1. Create feature branch");
Console.WriteLine("2. Make changes and commit");
Console.WriteLine("3. Push branch to Azure Repos");
Console.WriteLine("4. Create Pull Request");
Console.WriteLine("5. Reviewers provide feedback");
Console.WriteLine("6. Address comments, push updates");
Console.WriteLine("7. Reviewers approve");
Console.WriteLine("8. Merge to target branch");

// Review Vote Options
Console.WriteLine("Reviewer Votes:");
Console.WriteLine("");
Console.WriteLine(" Vote                     Meaning                       ");
Console.WriteLine("");
Console.WriteLine(" Approved                 LGTM, ready to merge          ");
Console.WriteLine(" Approved with suggestions Minor issues, can merge      ");
Console.WriteLine(" Wait for author          Changes needed before approve ");
Console.WriteLine(" Rejected                 Significant issues            ");
Console.WriteLine(" No vote                  Just comments, no decision    ");
Console.WriteLine("");

// CLI Commands
Console.WriteLine(@"
# Create pull request
az repos pr create   --source-branch feature/my-feature   --target-branch main   --title 'Add new feature'   --description 'Implements feature X'   --work-items 123 456   --reviewers user@example.com

# List active PRs
az repos pr list --status active

# Add reviewer
az repos pr reviewer add --id <pr-id> --reviewers user@example.com

# Approve PR
az repos pr set-vote --id <pr-id> --vote approve

# Complete (merge) PR
az repos pr update --id <pr-id> --status completed

# Create draft PR (not ready for review)
az repos pr create   --source-branch feature/wip   --target-branch main   --title '[WIP] Work in progress'   --draft
");

// PR Templates
Console.WriteLine("PR Template (pull_request_template.md):");
Console.WriteLine(@"
## Description
<!-- Describe your changes -->

## Type of change
- [ ] Bug fix
- [ ] New feature
- [ ] Breaking change
- [ ] Documentation update

## Checklist
- [ ] Code follows style guidelines
- [ ] Self-review completed
- [ ] Tests added/updated
- [ ] Documentation updated

## Related Work Items
AB#123
");

// Code Review Best Practices
Console.WriteLine("Code Review Best Practices:");
Console.WriteLine(" Keep PRs small and focused");
Console.WriteLine(" Provide constructive feedback");
Console.WriteLine(" Use suggestions for simple fixes");
Console.WriteLine(" Review within 24 hours");
Console.WriteLine(" Automate style checks (linting)");`}]},{id:"q4",question:"What are Git hooks and how do you use them with Azure Repos?",answer:"Git hooks are scripts that run at specific Git events (pre-commit, pre-push, post-merge). Client-side hooks run locally. Server-side hooks not directly supported in Azure Repos - use branch policies and pipelines instead. Husky is popular for managing client-side hooks in Node.js projects.",codeSnippets:[{language:"csharp",code:`// Git Hooks with Azure Repos

Console.WriteLine("Common Git Hooks:");
Console.WriteLine("");
Console.WriteLine(" Hook           When it runs                           ");
Console.WriteLine("");
Console.WriteLine(" pre-commit     Before commit is created               ");
Console.WriteLine(" prepare-commit Before commit message editor           ");
Console.WriteLine(" commit-msg     After commit message entered           ");
Console.WriteLine(" pre-push       Before push to remote                  ");
Console.WriteLine(" post-merge     After merge completes                  ");
Console.WriteLine(" pre-rebase     Before rebase starts                   ");
Console.WriteLine("");

// Pre-commit hook example (bash)
Console.WriteLine(@"
#!/bin/sh
# .git/hooks/pre-commit

# Run linting
echo 'Running ESLint...'
npm run lint
if [ $? -ne 0 ]; then
  echo 'Lint failed. Please fix errors before committing.'
  exit 1
fi

# Run tests
echo 'Running tests...'
npm test
if [ $? -ne 0 ]; then
  echo 'Tests failed. Please fix before committing.'
  exit 1
fi

echo 'Pre-commit checks passed!'
exit 0
");

// Using Husky (Node.js)
Console.WriteLine(@"
// package.json - Husky setup
{
  ""scripts"": {
    ""prepare"": ""husky install"",
    ""lint"": ""eslint src/"",
    ""test"": ""jest""
  },
  ""devDependencies"": {
    ""husky"": ""^8.0.0"",
    ""lint-staged"": ""^13.0.0""
  },
  ""lint-staged"": {
    ""*.{ts,tsx}"": [""eslint --fix"", ""prettier --write""],
    ""*.{json,md}"": ""prettier --write""
  }
}

// .husky/pre-commit
#!/bin/sh
. ""$(dirname ""$0"")/_/husky.sh""
npx lint-staged

// .husky/commit-msg
#!/bin/sh
. ""$(dirname ""$0"")/_/husky.sh""
npx commitlint --edit $1
");

// Commit message validation
Console.WriteLine(@"
// commitlint.config.js - Conventional Commits
module.exports = {
  extends: ['@commitlint/config-conventional'],
  rules: {
    'type-enum': [2, 'always', [
      'feat', 'fix', 'docs', 'style', 
      'refactor', 'test', 'chore', 'revert'
    ]],
    'subject-max-length': [2, 'always', 72],
    'body-max-line-length': [2, 'always', 100]
  }
};

// Valid commit messages:
// feat: add user authentication
// fix: resolve null reference in OrderService
// docs: update API documentation
// refactor: extract validation logic
");

// Server-side alternatives in Azure DevOps
Console.WriteLine("Azure DevOps Alternatives to Server Hooks:");
Console.WriteLine(" Branch policies - Build validation, required reviewers");
Console.WriteLine(" Pipeline triggers - Run on PR creation");
Console.WriteLine(" Service hooks - Notify external services");
Console.WriteLine(" Azure Functions - Custom webhook handlers");`}]},{id:"q5",question:"How do you implement Git branching strategies in Azure Repos?",answer:"Common strategies: GitFlow (feature/develop/release/hotfix), GitHub Flow (feature branches + main), Trunk-Based (short-lived branches). Azure Repos supports all via branch policies. Choose based on team size, release frequency, CI/CD maturity. Trunk-based recommended for continuous deployment.",codeSnippets:[{language:"csharp",code:`// Git Branching Strategies

Console.WriteLine("GitFlow Strategy:");
Console.WriteLine(@"
main (production) 
                        \\           /           /
release/1.0            /
                          \\       /           /
develop 
               \\    \\       /
feature/A 
                      \\
feature/B 
");

Console.WriteLine("GitFlow Branches:");
Console.WriteLine(" main - Production-ready code");
Console.WriteLine(" develop - Integration branch");
Console.WriteLine(" feature/* - New features");
Console.WriteLine(" release/* - Release preparation");
Console.WriteLine(" hotfix/* - Production fixes");

Console.WriteLine("GitHub Flow (Simpler):");
Console.WriteLine(@"
main 
            \\   /       \\   /
feature/A          \\ /
                          X
feature/B 
");

Console.WriteLine("GitHub Flow Rules:");
Console.WriteLine(" main is always deployable");
Console.WriteLine(" Branch from main for features");
Console.WriteLine(" Open PR for discussion");
Console.WriteLine(" Merge to main and deploy");

Console.WriteLine("Trunk-Based Development:");
Console.WriteLine(@"
main 
        \\  /    \\  /    \\  /
                         
       (short-lived feature branches)
");

Console.WriteLine("Trunk-Based Rules:");
Console.WriteLine(" Very short-lived branches (< 1 day)");
Console.WriteLine(" Frequent integration to main");
Console.WriteLine(" Feature flags for incomplete work");
Console.WriteLine(" Continuous deployment");

// Branch naming conventions
Console.WriteLine(@"
Branch Naming Conventions:
feature/ABC-123-add-login       # Feature with work item
bugfix/ABC-456-fix-null-ref     # Bug fix
hotfix/critical-security-fix    # Production hotfix
release/v1.2.0                  # Release branch
experiment/new-algorithm        # Experimental work
");

// Configure branch policies for strategy
Console.WriteLine(@"
# Protect main branch (GitFlow/GitHub Flow)
az repos policy approver-count create --branch main --minimum-approver-count 2
az repos policy build create --branch main --build-definition-id <ci-pipeline>

# Protect develop branch (GitFlow)
az repos policy approver-count create --branch develop --minimum-approver-count 1

# Allow only squash merges to main
az repos policy merge-strategy create   --branch main   --repository-id <repo-id>   --allow-squash true   --allow-no-fast-forward false   --allow-rebase false
");`}]},{id:"q6",question:"How do you migrate repositories to Azure Repos?",answer:"Import from GitHub, Bitbucket, GitLab, or any Git URL. Use Import Repository feature in Azure DevOps UI or git commands. Preserves full history. For large repos, use Git LFS for large files. Migrate branch policies and CI/CD separately. Can mirror repos for gradual migration.",codeSnippets:[{language:"csharp",code:`// Repository Migration to Azure Repos

Console.WriteLine("Migration Options:");
Console.WriteLine("1. Import via Azure DevOps UI");
Console.WriteLine("2. Clone and push manually");
Console.WriteLine("3. Use az repos import command");

// Method 1: Azure DevOps UI
Console.WriteLine(@"
Azure DevOps Portal:
1. Go to Repos > Files
2. Click 'Import repository'
3. Select source type (Git, GitHub, etc.)
4. Enter clone URL
5. Provide credentials if private
6. Click 'Import'
");

// Method 2: Manual clone and push
Console.WriteLine(@"
# Clone from source (GitHub example)
git clone --mirror https://github.com/org/repo.git temp-clone
cd temp-clone

# Add Azure Repos as new remote
git remote add azure https://dev.azure.com/myorg/myproject/_git/myrepo

# Push all branches and tags
git push azure --all
git push azure --tags

# Cleanup
cd ..
rm -rf temp-clone
");

// Method 3: Azure CLI
Console.WriteLine(@"
# Import from GitHub
az repos import create   --git-source-url https://github.com/org/repo.git   --project MyProject   --repository MyRepo

# Import from private repo (with PAT)
az repos import create   --git-source-url https://github.com/org/private-repo.git   --project MyProject   --repository MyRepo   --requires-authorization
");

// Large File Storage (LFS)
Console.WriteLine(@"
# Install Git LFS
git lfs install

# Track large files before migration
git lfs track '*.zip'
git lfs track '*.psd'
git lfs track 'assets/**'

# .gitattributes
*.zip filter=lfs diff=lfs merge=lfs -text
*.psd filter=lfs diff=lfs merge=lfs -text
assets/** filter=lfs diff=lfs merge=lfs -text

# Migrate existing large files to LFS
git lfs migrate import --include='*.zip,*.psd'
");

// Migration Checklist
Console.WriteLine("Migration Checklist:");
Console.WriteLine(" Export/document current branch policies");
Console.WriteLine(" Document current CI/CD configuration");
Console.WriteLine(" Notify team of migration timeline");
Console.WriteLine(" Import repository");
Console.WriteLine(" Verify all branches and tags");
Console.WriteLine(" Set up branch policies");
Console.WriteLine(" Recreate CI/CD pipelines");
Console.WriteLine(" Update local clones with new remote");
Console.WriteLine(" Archive old repository");

// Update local repositories
Console.WriteLine(@"
# For team members - update remote URL
git remote set-url origin https://dev.azure.com/myorg/myproject/_git/myrepo

# Verify
git remote -v
");`}]}]},uh={id:"azure-pipelines",name:"Azure Pipelines (CI/CD)",questions:[{id:"q1",question:"What is Azure Pipelines and what are the differences between Classic and YAML pipelines?",answer:"Azure Pipelines is CI/CD service for building, testing, and deploying code. Classic pipelines use visual designer (UI-based). YAML pipelines define pipeline as code in azure-pipelines.yml. YAML recommended: version controlled, reviewable via PR, portable. Supports any language, platform (Windows, Linux, macOS), cloud (Azure, AWS, GCP).",codeSnippets:[{language:"csharp",code:`// Azure Pipelines Overview

Console.WriteLine("Pipeline Types:");
Console.WriteLine("");
Console.WriteLine(" Type            Description                           ");
Console.WriteLine("");
Console.WriteLine(" YAML Pipelines  Code-based, version controlled        ");
Console.WriteLine(" Classic Build   UI-based build definitions            ");
Console.WriteLine(" Classic Release UI-based release management           ");
Console.WriteLine("");

Console.WriteLine("YAML vs Classic:");
Console.WriteLine("");
Console.WriteLine(" YAML (Recommended)      Classic                        ");
Console.WriteLine("");
Console.WriteLine(" Pipeline as code        UI configuration               ");
Console.WriteLine(" Version controlled      Stored in Azure DevOps         ");
Console.WriteLine(" PR review for changes   No code review                 ");
Console.WriteLine(" Templates/reuse         Task groups                    ");
Console.WriteLine(" Multi-stage pipelines   Separate build/release         ");
Console.WriteLine("");

// Basic YAML Pipeline
Console.WriteLine(@"
# azure-pipelines.yml - Basic .NET Pipeline
trigger:
  - main
  - develop

pool:
  vmImage: 'ubuntu-latest'

variables:
  buildConfiguration: 'Release'
  dotnetVersion: '8.0.x'

steps:
- task: UseDotNet@2
  displayName: 'Install .NET SDK'
  inputs:
    version: '$(dotnetVersion)'

- task: DotNetCoreCLI@2
  displayName: 'Restore packages'
  inputs:
    command: 'restore'
    projects: '**/*.csproj'

- task: DotNetCoreCLI@2
  displayName: 'Build'
  inputs:
    command: 'build'
    projects: '**/*.csproj'
    arguments: '--configuration $(buildConfiguration) --no-restore'

- task: DotNetCoreCLI@2
  displayName: 'Run tests'
  inputs:
    command: 'test'
    projects: '**/*Tests.csproj'
    arguments: '--configuration $(buildConfiguration) --no-build --collect:""XPlat Code Coverage""'

- task: PublishBuildArtifacts@1
  displayName: 'Publish artifacts'
  inputs:
    pathToPublish: '$(Build.ArtifactStagingDirectory)'
    artifactName: 'drop'
");

Console.WriteLine("Supported Platforms:");
Console.WriteLine(" Windows (windows-latest, windows-2022)");
Console.WriteLine(" Linux (ubuntu-latest, ubuntu-22.04)");
Console.WriteLine(" macOS (macos-latest, macos-13)");
Console.WriteLine(" Self-hosted agents (any OS)");`}]},{id:"q2",question:"How do you create multi-stage YAML pipelines with environments and approvals?",answer:"Multi-stage pipelines define build, test, and deploy in single YAML file. Stages run sequentially or in parallel. Environments represent deployment targets (dev, staging, prod). Configure approvals and checks on environments. Use deployment jobs for environment-specific deployments with history tracking.",codeSnippets:[{language:"csharp",code:`// Multi-Stage Pipeline with Environments

Console.WriteLine(@"
# azure-pipelines.yml - Multi-Stage Pipeline
trigger:
  - main

variables:
  vmImage: 'ubuntu-latest'
  buildConfiguration: 'Release'

stages:
# Build Stage
- stage: Build
  displayName: 'Build and Test'
  jobs:
  - job: BuildJob
    pool:
      vmImage: $(vmImage)
    steps:
    - task: DotNetCoreCLI@2
      displayName: 'Build'
      inputs:
        command: 'build'
        projects: '**/*.csproj'
        arguments: '--configuration $(buildConfiguration)'
    
    - task: DotNetCoreCLI@2
      displayName: 'Test'
      inputs:
        command: 'test'
        projects: '**/*Tests.csproj'
    
    - task: DotNetCoreCLI@2
      displayName: 'Publish'
      inputs:
        command: 'publish'
        publishWebProjects: true
        arguments: '--configuration $(buildConfiguration) --output $(Build.ArtifactStagingDirectory)'
    
    - publish: $(Build.ArtifactStagingDirectory)
      artifact: drop

# Deploy to Development
- stage: DeployDev
  displayName: 'Deploy to Development'
  dependsOn: Build
  condition: succeeded()
  jobs:
  - deployment: DeployDev
    environment: 'development'
    pool:
      vmImage: $(vmImage)
    strategy:
      runOnce:
        deploy:
          steps:
          - download: current
            artifact: drop
          - task: AzureWebApp@1
            displayName: 'Deploy to Dev App Service'
            inputs:
              azureSubscription: 'Azure-Dev-Connection'
              appName: 'myapp-dev'
              package: '$(Pipeline.Workspace)/drop/*.zip'

# Deploy to Staging (with approval)
- stage: DeployStaging
  displayName: 'Deploy to Staging'
  dependsOn: DeployDev
  condition: succeeded()
  jobs:
  - deployment: DeployStaging
    environment: 'staging'  # Configure approval in Azure DevOps
    pool:
      vmImage: $(vmImage)
    strategy:
      runOnce:
        deploy:
          steps:
          - download: current
            artifact: drop
          - task: AzureWebApp@1
            inputs:
              azureSubscription: 'Azure-Staging-Connection'
              appName: 'myapp-staging'
              package: '$(Pipeline.Workspace)/drop/*.zip'

# Deploy to Production (with approval)
- stage: DeployProd
  displayName: 'Deploy to Production'
  dependsOn: DeployStaging
  condition: succeeded()
  jobs:
  - deployment: DeployProd
    environment: 'production'  # Configure approval in Azure DevOps
    pool:
      vmImage: $(vmImage)
    strategy:
      runOnce:
        deploy:
          steps:
          - download: current
            artifact: drop
          - task: AzureWebApp@1
            inputs:
              azureSubscription: 'Azure-Prod-Connection'
              appName: 'myapp-prod'
              package: '$(Pipeline.Workspace)/drop/*.zip'
");

Console.WriteLine("Environment Checks & Approvals:");
Console.WriteLine(" Pre-deployment approvals - Manual approval required");
Console.WriteLine(" Business hours - Deploy only during specified hours");
Console.WriteLine(" Branch control - Only from specific branches");
Console.WriteLine(" Required template - Must use specific template");
Console.WriteLine(" Invoke Azure Function - Custom validation");
Console.WriteLine(" Query Azure Monitor - Check health before deploy");`}]},{id:"q3",question:"How do you use pipeline templates for reusability?",answer:"Templates enable reusable pipeline components. Types: Step templates, Job templates, Stage templates, Variable templates. Store in same repo or separate template repo. Use extends keyword for pipeline inheritance. Parameters allow customization. Promotes consistency across teams.",codeSnippets:[{language:"csharp",code:`// Pipeline Templates

Console.WriteLine("Template Types:");
Console.WriteLine(" Step Template - Reusable steps");
Console.WriteLine(" Job Template - Reusable jobs");
Console.WriteLine(" Stage Template - Reusable stages");
Console.WriteLine(" Variable Template - Reusable variables");

// Step Template
Console.WriteLine(@"
# templates/dotnet-build-steps.yml
parameters:
- name: buildConfiguration
  type: string
  default: 'Release'
- name: projects
  type: string
  default: '**/*.csproj'

steps:
- task: DotNetCoreCLI@2
  displayName: 'Restore'
  inputs:
    command: 'restore'
    projects: '\${{ parameters.projects }}'

- task: DotNetCoreCLI@2
  displayName: 'Build'
  inputs:
    command: 'build'
    projects: '\${{ parameters.projects }}'
    arguments: '--configuration \${{ parameters.buildConfiguration }} --no-restore'

- task: DotNetCoreCLI@2
  displayName: 'Test'
  inputs:
    command: 'test'
    projects: '**/*Tests.csproj'
    arguments: '--configuration \${{ parameters.buildConfiguration }} --no-build'
");

// Job Template
Console.WriteLine(@"
# templates/dotnet-build-job.yml
parameters:
- name: vmImage
  type: string
  default: 'ubuntu-latest'
- name: buildConfiguration
  type: string
  default: 'Release'

jobs:
- job: Build
  pool:
    vmImage: \${{ parameters.vmImage }}
  steps:
  - template: dotnet-build-steps.yml
    parameters:
      buildConfiguration: \${{ parameters.buildConfiguration }}
  
  - task: PublishBuildArtifacts@1
    inputs:
      pathToPublish: '$(Build.ArtifactStagingDirectory)'
      artifactName: 'drop'
");

// Stage Template
Console.WriteLine(@"
# templates/deploy-stage.yml
parameters:
- name: environment
  type: string
- name: serviceConnection
  type: string
- name: appName
  type: string

stages:
- stage: Deploy_\${{ parameters.environment }}
  displayName: 'Deploy to \${{ parameters.environment }}'
  jobs:
  - deployment: Deploy
    environment: \${{ parameters.environment }}
    strategy:
      runOnce:
        deploy:
          steps:
          - download: current
            artifact: drop
          - task: AzureWebApp@1
            inputs:
              azureSubscription: \${{ parameters.serviceConnection }}
              appName: \${{ parameters.appName }}
              package: '$(Pipeline.Workspace)/drop/*.zip'
");

// Main Pipeline using templates
Console.WriteLine(@"
# azure-pipelines.yml
trigger:
  - main

stages:
- stage: Build
  jobs:
  - template: templates/dotnet-build-job.yml
    parameters:
      vmImage: 'ubuntu-latest'
      buildConfiguration: 'Release'

- template: templates/deploy-stage.yml
  parameters:
    environment: 'development'
    serviceConnection: 'Azure-Dev'
    appName: 'myapp-dev'

- template: templates/deploy-stage.yml
  parameters:
    environment: 'production'
    serviceConnection: 'Azure-Prod'
    appName: 'myapp-prod'
");

// Template from another repository
Console.WriteLine(@"
# Using templates from another repo
resources:
  repositories:
  - repository: templates
    type: git
    name: MyProject/pipeline-templates
    ref: refs/heads/main

stages:
- template: stages/dotnet-ci-cd.yml@templates
  parameters:
    solution: 'MyApp.sln'
    environments:
    - dev
    - prod
");`}]},{id:"q4",question:"How do you manage secrets and variables in Azure Pipelines?",answer:"Variables store values: pipeline variables, variable groups, YAML variables. Secret variables are encrypted and masked in logs. Variable groups can link to Azure Key Vault. Runtime expressions access variables. Use variable templates for shared config. Secret variables cannot be output to logs.",codeSnippets:[{language:"csharp",code:`// Variables and Secrets in Azure Pipelines

Console.WriteLine("Variable Types:");
Console.WriteLine("");
Console.WriteLine(" Type               Scope                               ");
Console.WriteLine("");
Console.WriteLine(" YAML variables     Pipeline file                       ");
Console.WriteLine(" Pipeline variables UI-defined, per pipeline            ");
Console.WriteLine(" Variable groups    Shared across pipelines             ");
Console.WriteLine(" Key Vault secrets  Azure Key Vault linked              ");
Console.WriteLine(" Runtime variables  Set during pipeline execution       ");
Console.WriteLine("");

// YAML Variables
Console.WriteLine(@"
# azure-pipelines.yml
variables:
  # Simple variable
  buildConfiguration: 'Release'
  
  # Variable with different values per stage
  \${{ if eq(variables['Build.SourceBranchName'], 'main') }}:
    environment: 'production'
  \${{ else }}:
    environment: 'development'

# Variable templates
variables:
- template: variables/common.yml
- template: variables/\${{ variables.environment }}.yml

# Variable groups (linked from UI/Library)
variables:
- group: 'my-variable-group'
- group: 'keyvault-secrets'  # Linked to Key Vault
");

// Variable Template
Console.WriteLine(@"
# variables/common.yml
variables:
  vmImage: 'ubuntu-latest'
  dotnetVersion: '8.0.x'
  nugetFeed: 'https://pkgs.dev.azure.com/myorg/_packaging/myfeed/nuget/v3/index.json'

# variables/production.yml
variables:
  appServiceName: 'myapp-prod'
  resourceGroup: 'myapp-prod-rg'
  azureSubscription: 'Azure-Prod-Connection'
");

// Accessing Variables
Console.WriteLine(\`
steps:
# Macro syntax - replaced before task runs
- script: echo 'Config: $(buildConfiguration)'

# Template expression - compile time
- script: echo 'Environment: \${{ variables.environment }}'

# Runtime expression - evaluated at runtime
- script: echo 'Branch: $[variables['Build.SourceBranchName']]'

# Set variable for later steps
- bash: |
    echo '##vso[task.setvariable variable=myVar]myValue'
    echo '##vso[task.setvariable variable=mySecret;issecret=true]secretValue'

# Use in later step
- script: echo 'Variable: $(myVar)'
\`);

// Key Vault Integration
Console.WriteLine(@"
# Create variable group linked to Key Vault (via UI or CLI)
az pipelines variable-group create   --name 'keyvault-secrets'   --authorize true   --variables ''   --project MyProject

# Link to Key Vault
az pipelines variable-group variable create   --group-id <group-id>   --name 'DbConnectionString'   --value ''   --secret true

# In pipeline
variables:
- group: keyvault-secrets  # Automatically fetches from Key Vault

steps:
- script: |
    # Secret is masked in logs as ***
    echo 'Connecting to database...'
    dotnet run --connection '$(DbConnectionString)'
");

// Secret best practices
Console.WriteLine("Secret Management Best Practices:");
Console.WriteLine(" Never hardcode secrets in YAML");
Console.WriteLine(" Use variable groups with Key Vault");
Console.WriteLine(" Mark variables as secret (masked in logs)");
Console.WriteLine(" Rotate secrets regularly");
Console.WriteLine(" Limit variable group access");
Console.WriteLine(" Use service connections instead of inline credentials");`}]},{id:"q5",question:"How do you set up CI/CD for containerized applications?",answer:"Build Docker image, push to registry (ACR, Docker Hub), deploy to orchestrator (AKS, ACI, App Service). Use Docker@2 task for build/push. AzureContainerApps@1 for Container Apps. KubernetesManifest@1 for AKS. Multi-stage Dockerfile for optimized images. Use image tags for versioning.",codeSnippets:[{language:"csharp",code:`// Container CI/CD Pipeline

Console.WriteLine(@"
# azure-pipelines.yml - Container Pipeline
trigger:
  - main

variables:
  dockerRegistry: 'myacr.azurecr.io'
  imageName: 'myapp'
  tag: '$(Build.BuildId)'

stages:
# Build and Push Container
- stage: Build
  displayName: 'Build Container'
  jobs:
  - job: BuildAndPush
    pool:
      vmImage: 'ubuntu-latest'
    steps:
    # Login to ACR
    - task: Docker@2
      displayName: 'Login to ACR'
      inputs:
        command: login
        containerRegistry: 'ACR-Connection'
    
    # Build and push image
    - task: Docker@2
      displayName: 'Build and Push'
      inputs:
        command: buildAndPush
        repository: $(imageName)
        dockerfile: '**/Dockerfile'
        containerRegistry: 'ACR-Connection'
        tags: |
          $(tag)
          latest
    
    # Scan for vulnerabilities (optional)
    - task: trivy@1
      displayName: 'Scan Image'
      inputs:
        image: '$(dockerRegistry)/$(imageName):$(tag)'
        severities: 'CRITICAL,HIGH'

# Deploy to AKS
- stage: DeployAKS
  displayName: 'Deploy to AKS'
  dependsOn: Build
  jobs:
  - deployment: DeployToAKS
    environment: 'aks-production'
    pool:
      vmImage: 'ubuntu-latest'
    strategy:
      runOnce:
        deploy:
          steps:
          # Update Kubernetes manifest with new image tag
          - task: KubernetesManifest@1
            displayName: 'Deploy to AKS'
            inputs:
              action: deploy
              connectionType: azureResourceManager
              azureSubscriptionConnection: 'Azure-Prod'
              azureResourceGroup: 'myapp-rg'
              kubernetesCluster: 'myaks'
              namespace: 'default'
              manifests: |
                k8s/deployment.yml
                k8s/service.yml
              containers: |
                $(dockerRegistry)/$(imageName):$(tag)

# Alternative: Deploy to Azure Container Apps
- stage: DeployContainerApps
  displayName: 'Deploy to Container Apps'
  dependsOn: Build
  jobs:
  - deployment: DeployToContainerApps
    environment: 'container-apps-production'
    pool:
      vmImage: 'ubuntu-latest'
    strategy:
      runOnce:
        deploy:
          steps:
          - task: AzureContainerApps@1
            displayName: 'Deploy to Container Apps'
            inputs:
              azureSubscription: 'Azure-Prod'
              containerAppName: 'myapp'
              resourceGroup: 'myapp-rg'
              imageToDeploy: '$(dockerRegistry)/$(imageName):$(tag)'
");

// Kubernetes Manifests
Console.WriteLine(@"
# k8s/deployment.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
      - name: myapp
        image: myacr.azurecr.io/myapp:latest  # Replaced by pipeline
        ports:
        - containerPort: 80
        resources:
          requests:
            memory: '128Mi'
            cpu: '100m'
          limits:
            memory: '256Mi'
            cpu: '500m'
");

// Dockerfile for .NET
Console.WriteLine(@"
# Dockerfile
FROM mcr.microsoft.com/dotnet/sdk:8.0 AS build
WORKDIR /src
COPY [""MyApp.csproj"", "".""]
RUN dotnet restore
COPY . .
RUN dotnet publish -c Release -o /app/publish

FROM mcr.microsoft.com/dotnet/aspnet:8.0
WORKDIR /app
COPY --from=build /app/publish .
EXPOSE 80
ENTRYPOINT [""dotnet"", ""MyApp.dll""]
");`}]},{id:"q6",question:"How do you implement deployment strategies like Blue-Green and Canary?",answer:"Blue-Green: two identical environments, switch traffic instantly. Canary: gradually shift traffic percentage. Azure Pipelines supports via deployment jobs and routing. AKS uses Service mesh or Ingress. App Service uses deployment slots. Rollback by reversing traffic.",codeSnippets:[{language:"csharp",code:`// Deployment Strategies in Azure Pipelines

Console.WriteLine("Deployment Strategies:");
Console.WriteLine("");
Console.WriteLine(" Strategy       Description                            ");
Console.WriteLine("");
Console.WriteLine(" runOnce        Deploy once, standard deployment       ");
Console.WriteLine(" rolling        Replace instances gradually            ");
Console.WriteLine(" canary         Deploy to subset, then full rollout    ");
Console.WriteLine("");

// Canary Deployment
Console.WriteLine(@"
# Canary Deployment Strategy
stages:
- stage: Deploy
  jobs:
  - deployment: DeployCanary
    environment: 'production'
    strategy:
      canary:
        increments: [10, 50]  # 10% then 50% then 100%
        preDeploy:
          steps:
          - script: echo 'Preparing canary deployment'
        deploy:
          steps:
          - task: KubernetesManifest@1
            inputs:
              action: deploy
              strategy: canary
              percentage: $(strategy.increment)
              manifests: 'k8s/*.yml'
        routeTraffic:
          steps:
          - task: KubernetesManifest@1
            inputs:
              action: patch
              resourceName: 'svc/myapp'
              patch: '{""spec"":{""selector"":{""track"":""canary""}}}'
        postRouteTraffic:
          steps:
          - task: Bash@3
            inputs:
              targetType: inline
              script: |
                # Run smoke tests
                ./run-smoke-tests.sh
        on:
          failure:
            steps:
            - task: KubernetesManifest@1
              inputs:
                action: reject
                manifests: 'k8s/*.yml'
          success:
            steps:
            - task: KubernetesManifest@1
              inputs:
                action: promote
                manifests: 'k8s/*.yml'
");

// Blue-Green with App Service Slots
Console.WriteLine(@"
# Blue-Green with Deployment Slots
stages:
- stage: DeployStaging
  jobs:
  - deployment: DeployToStaging
    environment: 'production-staging'
    strategy:
      runOnce:
        deploy:
          steps:
          # Deploy to staging slot
          - task: AzureWebApp@1
            inputs:
              azureSubscription: 'Azure-Prod'
              appName: 'myapp'
              deployToSlotOrASE: true
              slotName: 'staging'
              package: '$(Pipeline.Workspace)/drop/*.zip'
          
          # Run smoke tests on staging
          - task: Bash@3
            inputs:
              targetType: inline
              script: |
                curl -f https://myapp-staging.azurewebsites.net/health
                ./run-smoke-tests.sh https://myapp-staging.azurewebsites.net

- stage: SwapSlots
  dependsOn: DeployStaging
  jobs:
  - deployment: SwapToProduction
    environment: 'production'  # Manual approval configured here
    strategy:
      runOnce:
        deploy:
          steps:
          # Swap staging to production
          - task: AzureAppServiceManage@0
            inputs:
              azureSubscription: 'Azure-Prod'
              Action: 'Swap Slots'
              WebAppName: 'myapp'
              ResourceGroupName: 'myapp-rg'
              SourceSlot: 'staging'
              TargetSlot: 'production'
          
          # Monitor after swap
          - task: Bash@3
            inputs:
              targetType: inline
              script: |
                echo 'Monitoring production health...'
                sleep 60
                curl -f https://myapp.azurewebsites.net/health
");

// Rolling deployment
Console.WriteLine(@"
# Rolling Deployment (VMs/Scale Sets)
- deployment: RollingDeploy
  environment:
    name: 'production-vms'
    resourceType: VirtualMachine
  strategy:
    rolling:
      maxParallel: 2  # Deploy to 2 VMs at a time
      preDeploy:
        steps:
        - script: echo 'Pre-deploy script'
      deploy:
        steps:
        - task: IISWebAppDeploymentOnMachineGroup@0
          inputs:
            WebSiteName: 'Default Web Site'
            Package: '$(Pipeline.Workspace)/drop/*.zip'
      routeTraffic:
        steps:
        - script: echo 'Route traffic to updated VMs'
      postRouteTraffic:
        steps:
        - script: ./run-health-checks.sh
");`}]},{id:"q7",question:"How do you optimize pipeline performance and reduce build times?",answer:"Strategies: caching (NuGet, npm), parallel jobs, incremental builds, self-hosted agents with pre-installed tools. Use pipeline caching for dependencies. Split large pipelines into stages. Use conditional execution to skip unnecessary steps. Monitor with Pipeline Analytics.",codeSnippets:[{language:"csharp",code:`// Pipeline Performance Optimization

Console.WriteLine("Optimization Techniques:");
Console.WriteLine(" Caching dependencies (NuGet, npm, pip)");
Console.WriteLine(" Parallel job execution");
Console.WriteLine(" Incremental builds");
Console.WriteLine(" Self-hosted agents with cached tools");
Console.WriteLine(" Conditional step execution");
Console.WriteLine(" Artifact management");

// Pipeline Caching
Console.WriteLine(\`
# Cache NuGet packages
variables:
  NUGET_PACKAGES: $(Pipeline.Workspace)/.nuget/packages

steps:
- task: Cache@2
  displayName: 'Cache NuGet packages'
  inputs:
    key: 'nuget | "$(Agent.OS)" | **/packages.lock.json'
    restoreKeys: |
      nuget | "$(Agent.OS)"
      nuget
    path: $(NUGET_PACKAGES)

- task: DotNetCoreCLI@2
  inputs:
    command: 'restore'
    projects: '**/*.csproj'

# Cache npm packages
- task: Cache@2
  displayName: 'Cache npm packages'
  inputs:
    key: 'npm | "$(Agent.OS)" | package-lock.json'
    restoreKeys: |
      npm | "$(Agent.OS)"
    path: '$(Pipeline.Workspace)/.npm'

- task: Npm@1
  inputs:
    command: 'ci'
    workingDir: 'src/webapp'
\`);

// Parallel Jobs
Console.WriteLine(@"
# Run tests in parallel across multiple agents
stages:
- stage: Test
  jobs:
  - job: UnitTests
    pool:
      vmImage: 'ubuntu-latest'
    steps:
    - task: DotNetCoreCLI@2
      inputs:
        command: 'test'
        projects: '**/*UnitTests.csproj'
  
  - job: IntegrationTests
    pool:
      vmImage: 'ubuntu-latest'
    steps:
    - task: DotNetCoreCLI@2
      inputs:
        command: 'test'
        projects: '**/*IntegrationTests.csproj'
  
  - job: UITests
    pool:
      vmImage: 'windows-latest'
    steps:
    - task: VSTest@2
      inputs:
        testSelector: 'testAssemblies'
        testAssemblyVer2: '**/*UITests.dll'
");

// Conditional Execution
Console.WriteLine(@"
# Skip steps based on conditions
steps:
# Only run on main branch
- task: DotNetCoreCLI@2
  condition: eq(variables['Build.SourceBranch'], 'refs/heads/main')
  inputs:
    command: 'publish'

# Skip if no changes in specific path
- task: DotNetCoreCLI@2
  condition: |
    and(
      succeeded(),
      ne(variables['Build.Reason'], 'PullRequest'),
      contains(variables['Build.SourceVersionMessage'], '[skip-tests]')
    )
  inputs:
    command: 'test'

# Run only if files changed
trigger:
  paths:
    include:
    - src/*
    exclude:
    - docs/*
    - '*.md'
");

// Self-Hosted Agent optimization
Console.WriteLine("Self-Hosted Agent Benefits:");
Console.WriteLine(" Pre-installed SDKs and tools");
Console.WriteLine(" Persistent cache between builds");
Console.WriteLine(" Access to private network resources");
Console.WriteLine(" Custom hardware (GPU, more RAM)");
Console.WriteLine(" No queue wait time");

// Pipeline Analytics
Console.WriteLine("Monitor with Pipeline Analytics:");
Console.WriteLine(" Build duration trends");
Console.WriteLine(" Task duration breakdown");
Console.WriteLine(" Queue wait times");
Console.WriteLine(" Pass/fail rates");
Console.WriteLine(" Agent utilization");`}]},{id:"q8",question:"How do you integrate automated testing in Azure Pipelines?",answer:"Run unit, integration, UI tests in pipeline. Use test tasks: DotNetCoreCLI@2, VSTest@2, Maven@3, Npm@1. Publish test results for reporting. Code coverage with Cobertura/JaCoCo. Test Impact Analysis runs only affected tests. Flaky test detection identifies unreliable tests.",codeSnippets:[{language:"csharp",code:`// Automated Testing in Pipelines

Console.WriteLine(@"
# Comprehensive Testing Pipeline
stages:
- stage: Test
  jobs:
  # Unit Tests with Coverage
  - job: UnitTests
    pool:
      vmImage: 'ubuntu-latest'
    steps:
    - task: DotNetCoreCLI@2
      displayName: 'Run Unit Tests'
      inputs:
        command: 'test'
        projects: '**/*UnitTests.csproj'
        arguments: >
          --configuration Release
          --collect:""XPlat Code Coverage""
          --settings coverlet.runsettings
          --logger trx
          --results-directory $(Agent.TempDirectory)/TestResults
    
    # Publish test results
    - task: PublishTestResults@2
      displayName: 'Publish Test Results'
      inputs:
        testResultsFormat: 'VSTest'
        testResultsFiles: '**/*.trx'
        searchFolder: '$(Agent.TempDirectory)/TestResults'
        mergeTestResults: true
    
    # Publish code coverage
    - task: PublishCodeCoverageResults@2
      displayName: 'Publish Code Coverage'
      inputs:
        summaryFileLocation: '$(Agent.TempDirectory)/**/coverage.cobertura.xml'
        failIfCoverageEmpty: true
  
  # Integration Tests
  - job: IntegrationTests
    pool:
      vmImage: 'ubuntu-latest'
    services:
      sqlserver:
        image: mcr.microsoft.com/mssql/server:2022-latest
        env:
          SA_PASSWORD: YourStrong@Password
          ACCEPT_EULA: Y
      redis:
        image: redis:latest
    steps:
    - task: DotNetCoreCLI@2
      displayName: 'Run Integration Tests'
      inputs:
        command: 'test'
        projects: '**/*IntegrationTests.csproj'
      env:
        ConnectionStrings__Database: 'Server=sqlserver;Database=TestDb;User=sa;Password=YourStrong@Password'
        ConnectionStrings__Redis: 'redis:6379'
  
  # UI/E2E Tests with Playwright
  - job: E2ETests
    pool:
      vmImage: 'ubuntu-latest'
    steps:
    - task: NodeTool@0
      inputs:
        versionSpec: '18.x'
    
    - script: |
        npm ci
        npx playwright install --with-deps
      displayName: 'Install dependencies'
    
    - script: npx playwright test
      displayName: 'Run Playwright tests'
      env:
        BASE_URL: '$(WebApp.Url)'
    
    - task: PublishTestResults@2
      inputs:
        testResultsFormat: 'JUnit'
        testResultsFiles: 'playwright-results/*.xml'
    
    # Publish test artifacts (screenshots, videos)
    - publish: playwright-report
      artifact: playwright-report
      condition: always()
");

// Code Coverage Settings
Console.WriteLine(@"
<!-- coverlet.runsettings -->
<?xml version=""1.0"" encoding=""utf-8""?>
<RunSettings>
  <DataCollectionRunSettings>
    <DataCollectors>
      <DataCollector friendlyName=""XPlat Code Coverage"">
        <Configuration>
          <Format>cobertura,opencover</Format>
          <Exclude>[*Tests*]*,[*]*.Migrations.*</Exclude>
          <ExcludeByAttribute>Obsolete,GeneratedCodeAttribute</ExcludeByAttribute>
        </Configuration>
      </DataCollector>
    </DataCollectors>
  </DataCollectionRunSettings>
</RunSettings>
");

// Test Quality Gates
Console.WriteLine(@"
# Fail build if coverage below threshold
- task: BuildQualityChecks@9
  displayName: 'Check Code Coverage'
  inputs:
    checkCoverage: true
    coverageFailOption: 'fixed'
    coverageType: 'lines'
    coverageThreshold: '80'

# SonarQube analysis
- task: SonarQubePrepare@5
  inputs:
    SonarQube: 'SonarQube-Connection'
    scannerMode: 'MSBuild'
    projectKey: 'myapp'

- task: DotNetCoreCLI@2
  inputs:
    command: 'build'

- task: DotNetCoreCLI@2
  inputs:
    command: 'test'
    arguments: '--collect:""XPlat Code Coverage""'

- task: SonarQubeAnalyze@5

- task: SonarQubePublish@5
  inputs:
    pollingTimeoutSec: '300'
");`}]}]},dh={id:"azure-test-plans",name:"Azure Test Plans",questions:[{id:"q1",question:"What is Azure Test Plans and what testing capabilities does it provide?",answer:"Azure Test Plans provides manual and exploratory testing tools. Features: test cases, test suites, test plans, exploratory testing, test runs, test configurations. Links tests to work items and builds. Supports web, desktop, mobile testing. Captures screenshots, video, system info. Integrates with Azure Pipelines for automated tests.",codeSnippets:[{language:"csharp",code:`// Azure Test Plans Overview

Console.WriteLine("Azure Test Plans Features:");
Console.WriteLine("");
Console.WriteLine(" Feature               Description                      ");
Console.WriteLine("");
Console.WriteLine(" Test Plans            Organize testing activities      ");
Console.WriteLine(" Test Suites           Group related test cases         ");
Console.WriteLine(" Test Cases            Step-by-step test instructions   ");
Console.WriteLine(" Exploratory Testing   Ad-hoc testing with capture      ");
Console.WriteLine(" Test Configurations   Different environments/browsers  ");
Console.WriteLine(" Test Runs             Execute and track test results   ");
Console.WriteLine("");

// Test Plan Hierarchy
Console.WriteLine("Test Hierarchy:");
Console.WriteLine("Test Plan");
Console.WriteLine("   Test Suite (Static/Requirement/Query-based)");
Console.WriteLine("         Test Case");
Console.WriteLine("               Test Steps");
Console.WriteLine("                     Expected Results");

// Test Suite Types
Console.WriteLine("Test Suite Types:");
Console.WriteLine(" Static Suite - Manually add test cases");
Console.WriteLine(" Requirement-based Suite - Auto-linked to user stories");
Console.WriteLine(" Query-based Suite - Dynamic based on work item query");

// Test Configurations
Console.WriteLine("Test Configurations:");
Console.WriteLine(" Browser: Chrome, Firefox, Edge, Safari");
Console.WriteLine(" OS: Windows, macOS, Linux, iOS, Android");
Console.WriteLine(" Environment: Dev, Staging, Production");
Console.WriteLine(" Locale: en-US, de-DE, ja-JP");

// Licensing
Console.WriteLine("Licensing:");
Console.WriteLine(" Basic + Test Plans license required");
Console.WriteLine(" Visual Studio Enterprise subscribers included");
Console.WriteLine(" Stakeholder access for feedback only");`}]},{id:"q2",question:"How do you create and manage test cases in Azure Test Plans?",answer:"Test cases are work items with test steps. Each step has action and expected result. Steps can include parameters for data-driven testing. Shared steps reuse common sequences. Link test cases to user stories for traceability. Use Test Runner (web or desktop) to execute.",codeSnippets:[{language:"csharp",code:`// Creating and Managing Test Cases

Console.WriteLine("Test Case Components:");
Console.WriteLine(" Title - Descriptive name");
Console.WriteLine(" Area Path - Organizational hierarchy");
Console.WriteLine(" Iteration - Sprint association");
Console.WriteLine(" State - Design, Ready, Closed");
Console.WriteLine(" Priority - 1 (highest) to 4 (lowest)");
Console.WriteLine(" Steps - Actions and expected results");
Console.WriteLine(" Parameters - Data-driven values");
Console.WriteLine(" Links - Related work items, requirements");

// Test Case Example
Console.WriteLine(@"
Test Case: User Login
Priority: 1
State: Ready

Steps:

 #  Action                          Expected Result            

 1  Navigate to login page          Login form is displayed    
 2  Enter username: @Username       Username field populated   
 3  Enter password: @Password       Password field masked      
 4  Click Login button              User is logged in          
 5  Verify dashboard displayed      Welcome message shows name 


Parameters:

 @Username       @Password                

 user@test.com   ValidPass123             
 admin@test.com  AdminPass456             
 invalid@        WrongPass                

");

// Shared Steps
Console.WriteLine(@"
Shared Steps: Login Process
Used by multiple test cases

Steps:
1. Navigate to https://myapp.com/login
2. Enter username in email field
3. Enter password in password field
4. Click 'Sign In' button
5. Wait for dashboard to load

Usage in Test Case:
Step 1: [Shared Steps] Login Process
Step 2: Verify user profile shows correct name
Step 3: Navigate to Settings
");

// CLI for Test Cases
Console.WriteLine(@"
# Create test case
az boards work-item create   --type 'Test Case'   --title 'Verify user can login'   --area 'MyProject\\QA'   --iteration 'MyProject\\Sprint 1'

# Add test steps (via REST API)
PATCH https://dev.azure.com/{org}/{project}/_apis/wit/workitems/{id}?api-version=7.0
Content-Type: application/json-patch+json

[
  {
    ""op"": ""add"",
    ""path"": ""/fields/Microsoft.VSTS.TCM.Steps"",
    ""value"": ""<steps>
      <step id='1' type='ActionStep'>
        <parameterizedString>Navigate to login page</parameterizedString>
        <parameterizedString>Login form displayed</parameterizedString>
      </step>
    </steps>""
  }
]
");

// Best Practices
Console.WriteLine("Test Case Best Practices:");
Console.WriteLine(" Write clear, concise steps");
Console.WriteLine(" Include expected results for each step");
Console.WriteLine(" Use parameters for data-driven tests");
Console.WriteLine(" Create shared steps for common sequences");
Console.WriteLine(" Link to user stories/requirements");
Console.WriteLine(" Keep test cases independent");
Console.WriteLine(" Review and update regularly");`}]},{id:"q3",question:"How do you perform exploratory testing with Azure Test Plans?",answer:"Exploratory testing for ad-hoc, unscripted testing. Use Test & Feedback browser extension. Captures screenshots, screen recordings, system info automatically. Create bugs/tasks directly from findings. Session-based testing with goals. Link findings to work items. Great for finding edge cases and usability issues.",codeSnippets:[{language:"csharp",code:`// Exploratory Testing with Azure Test Plans

Console.WriteLine("Exploratory Testing Features:");
Console.WriteLine("");
Console.WriteLine(" Feature                 Description                    ");
Console.WriteLine("");
Console.WriteLine(" Test & Feedback ext.    Browser extension for Chrome   ");
Console.WriteLine(" Screenshot capture      Annotate and highlight         ");
Console.WriteLine(" Screen recording        Record video of session        ");
Console.WriteLine(" Bug creation            Create bugs with evidence      ");
Console.WriteLine(" Session timeline        Track all actions taken        ");
Console.WriteLine(" System info capture     Browser, OS, resolution        ");
Console.WriteLine("");

// Exploratory Testing Workflow
Console.WriteLine("Exploratory Testing Workflow:");
Console.WriteLine("1. Install 'Test & Feedback' browser extension");
Console.WriteLine("2. Connect to Azure DevOps organization");
Console.WriteLine("3. Start exploratory session");
Console.WriteLine("4. Explore the application");
Console.WriteLine("5. Capture screenshots/recordings for issues");
Console.WriteLine("6. Create bugs with captured evidence");
Console.WriteLine("7. End session and review findings");

// Session-Based Testing
Console.WriteLine(@"
Session-Based Test Management:

Session Charter:

 Mission: Test the checkout process for edge cases               
 Area: Shopping Cart  Payment  Confirmation                    
 Duration: 60 minutes                                            
 Tester: John Smith                                              
 Build: 2024.1.15                                                


Session Notes:
 Found issue with empty cart proceeding to payment
 Discount codes not validated server-side
 No confirmation email for guest checkout

Findings:
 3 bugs created
 2 improvement suggestions
 1 test case added for regression
");

// Bug Created from Exploratory Testing
Console.WriteLine(@"
Bug: Empty cart allows checkout
Created from exploratory session

Repro Steps:
1. Navigate to shopping cart (auto-captured)
2. Remove all items
3. Click 'Proceed to Checkout'
4. Payment page loads (should show error)

Attachments (auto-captured):
 Screenshot: empty-cart-checkout.png
 Screen recording: session-recording.webm
 System Info:
  - Browser: Chrome 120.0.6099.130
  - OS: Windows 11
  - Resolution: 1920x1080
  - URL: https://myapp.com/checkout
");

// Test & Feedback Extension Features
Console.WriteLine("Test & Feedback Capabilities:");
Console.WriteLine(" Connected mode - Link to Azure DevOps");
Console.WriteLine(" Standalone mode - Basic capture without Azure");
Console.WriteLine(" Annotate screenshots with drawing tools");
Console.WriteLine(" Add notes to timeline events");
Console.WriteLine(" Create work items: Bug, Task, Test Case");
Console.WriteLine(" Attach files and URLs");
Console.WriteLine(" Capture page load times");

// Metrics from Exploratory Testing
Console.WriteLine("Session Metrics:");
Console.WriteLine(" Session duration");
Console.WriteLine(" Bugs found per session");
Console.WriteLine(" Areas explored");
Console.WriteLine(" Screenshots/recordings created");
Console.WriteLine(" Test cases generated");`}]},{id:"q4",question:"How do you integrate automated tests with Azure Test Plans?",answer:"Link automated tests to test cases. Run from pipelines and report results to Test Plans. Use VSTest task or dotnet test. Test case automation status: Not Automated, Planned, Automated. Test runs show both manual and automated results. Use Test Impact Analysis for selective test runs.",codeSnippets:[{language:"csharp",code:`// Automated Tests Integration

Console.WriteLine("Automation Status in Test Cases:");
Console.WriteLine(" Not Automated - Manual test only");
Console.WriteLine(" Planned - Will be automated");
Console.WriteLine(" Automated - Linked to automated test method");

// Associate Automated Test with Test Case
Console.WriteLine(@"
// 1. Use TestCase attribute with Azure DevOps test case ID
[TestClass]
public class LoginTests
{
    [TestMethod]
    [TestProperty(""TestCaseId"", ""12345"")]  // Azure DevOps Test Case ID
    public void User_Should_Login_Successfully()
    {
        // Arrange
        var loginPage = new LoginPage(driver);
        
        // Act
        loginPage.Login(""user@test.com"", ""ValidPass123"");
        
        // Assert
        Assert.IsTrue(loginPage.IsLoggedIn());
    }
    
    [TestMethod]
    [TestProperty(""TestCaseId"", ""12346"")]
    [DataRow(""admin@test.com"", ""AdminPass"")]
    [DataRow(""user@test.com"", ""UserPass"")]
    public void User_Login_With_Parameters(string username, string password)
    {
        var loginPage = new LoginPage(driver);
        loginPage.Login(username, password);
        Assert.IsTrue(loginPage.IsLoggedIn());
    }
}
");

// Pipeline Configuration
Console.WriteLine(@"
# azure-pipelines.yml
- task: VSTest@2
  displayName: 'Run Automated Tests'
  inputs:
    testSelector: 'testAssemblies'
    testAssemblyVer2: |
      **\\*Tests.dll
      !**\\obj\\**
    searchFolder: '$(System.DefaultWorkingDirectory)'
    runSettingsFile: 'test.runsettings'
    # Link results to Test Plan
    testPlan: 'Sprint 1 Test Plan'
    testSuite: 'Automated Tests Suite'
    testConfiguration: 'Windows Chrome'
    publishRunAttachments: true
    
# Alternative: dotnet test with test plan publishing
- task: DotNetCoreCLI@2
  displayName: 'Run Tests'
  inputs:
    command: 'test'
    projects: '**/*Tests.csproj'
    arguments: '--configuration Release --logger trx'

- task: PublishTestResults@2
  inputs:
    testResultsFormat: 'VSTest'
    testResultsFiles: '**/*.trx'
    testPlanId: 123
    testSuiteId: 456
    testConfigurationId: 789
");

// Test Run Configuration
Console.WriteLine(@"
Test Configuration Setup:

 Configuration Name  Values                                    

 Browser             Chrome, Firefox, Edge                     
 Operating System    Windows 11, macOS Ventura                 
 Environment         Dev, QA, Staging                          


Matrix Testing:
Run automated tests against all configurations:
- Chrome + Windows 11 + QA
- Firefox + Windows 11 + QA
- Chrome + macOS + QA
");

// Test Impact Analysis
Console.WriteLine("Test Impact Analysis (TIA):");
Console.WriteLine(" Identifies tests affected by code changes");
Console.WriteLine(" Runs only relevant tests in PR validation");
Console.WriteLine(" Reduces test execution time significantly");
Console.WriteLine(" Requires code coverage data from previous runs");

Console.WriteLine(@"
# Enable TIA in pipeline
- task: VSTest@2
  inputs:
    runOnlyImpactedTests: true
    runAllTestsAfterXBuilds: 5  # Run all every 5 builds
");`}]},{id:"q5",question:"How do you track test progress and generate test reports?",answer:"Test Plans provides built-in progress tracking. Track by test outcome (Passed, Failed, Blocked, Not Run). Charts show trends over time. Export results to CSV/Excel. Use Test Analytics for insights. Integration with dashboard widgets. Query-based reports for custom views.",codeSnippets:[{language:"csharp",code:`// Test Progress Tracking and Reporting

Console.WriteLine("Test Outcomes:");
Console.WriteLine("");
Console.WriteLine(" Outcome      Description                               ");
Console.WriteLine("");
Console.WriteLine(" Passed       Test executed successfully                ");
Console.WriteLine(" Failed       Test found a defect                       ");
Console.WriteLine(" Blocked      Cannot execute (environment issue)        ");
Console.WriteLine(" Not Run      Not yet executed                          ");
Console.WriteLine(" Not Applicable  Test doesn't apply to this build       ");
Console.WriteLine("");

// Progress Tracking View
Console.WriteLine(@"
Test Plan Progress: Sprint 1 Testing

 Suite                Passed  Failed  Blocked  Not Run      

 Login Tests            8       1        0         1        
 Checkout Tests         5       2        1         2        
 User Profile Tests     4       0        0         6        
 Admin Tests            3       1        0         4        

 TOTAL                 20       4        1        13        
 Progress             52%     11%       3%        34%       

");

// Test Analytics
Console.WriteLine("Test Analytics Reports:");
Console.WriteLine(" Pass rate trends over time");
Console.WriteLine(" Test failure analysis");
Console.WriteLine(" Flaky tests identification");
Console.WriteLine(" Test duration trends");
Console.WriteLine(" Tester productivity metrics");

// Dashboard Widgets
Console.WriteLine("Dashboard Widgets for Testing:");
Console.WriteLine(" Test Results Trend - Pass/fail over builds");
Console.WriteLine(" Test Plans Progress - Outcome summary");
Console.WriteLine(" Requirements Quality - Requirements with tests");
Console.WriteLine(" Code Coverage - Percentage covered");
Console.WriteLine(" Build Quality - Test pass rate per build");

// Query-Based Reports
Console.WriteLine(@"
WIQL Queries for Test Reporting:

-- Test cases without automation
SELECT [System.Id], [System.Title]
FROM WorkItems
WHERE [System.WorkItemType] = 'Test Case'
  AND [Microsoft.VSTS.TCM.AutomationStatus] = 'Not Automated'
  AND [System.State] = 'Ready'

-- Failed test cases in current sprint
SELECT [System.Id], [System.Title], [Microsoft.VSTS.Common.Priority]
FROM WorkItems
WHERE [System.WorkItemType] = 'Test Case'
  AND [System.IterationPath] = @CurrentIteration
  AND [Microsoft.VSTS.TCM.LastTestRunOutcome] = 'Failed'

-- Test cases linked to high priority bugs
SELECT [System.Id], [System.Title]
FROM WorkItemLinks
WHERE ([System.Links.LinkType] = 'Tested By')
  AND ([Target].[System.WorkItemType] = 'Bug')
  AND ([Target].[Microsoft.VSTS.Common.Priority] = 1)
");

// REST API for Test Results
Console.WriteLine(@"
// Get test run results via REST API
GET https://dev.azure.com/{org}/{project}/_apis/test/runs/{runId}/results?api-version=7.0

Response:
{
  ""count"": 50,
  ""value"": [
    {
      ""id"": 1001,
      ""testCase"": { ""id"": ""12345"", ""name"": ""Login Test"" },
      ""outcome"": ""Passed"",
      ""durationInMs"": 1234,
      ""startedDate"": ""2024-01-15T10:00:00Z"",
      ""completedDate"": ""2024-01-15T10:00:01Z""
    }
  ]
}
");

// Export Options
Console.WriteLine("Export Options:");
Console.WriteLine(" Export test plan to Excel/CSV");
Console.WriteLine(" Print test cases for review");
Console.WriteLine(" Generate PDF reports");
Console.WriteLine(" Power BI integration for custom reports");`}]}]},ph={id:"azure-artifacts",name:"Azure Artifacts",questions:[{id:"q1",question:"What is Azure Artifacts and what package types does it support?",answer:"Azure Artifacts is package management service for hosting and sharing packages. Supports NuGet (.NET), npm (Node.js), Maven/Gradle (Java), Python (pip), Universal Packages (any files). Features: upstream sources, feed permissions, retention policies. Free tier: 2GB storage. Integrates with Azure Pipelines for CI/CD.",codeSnippets:[{language:"csharp",code:`// Azure Artifacts Overview

Console.WriteLine("Supported Package Types:");
Console.WriteLine("");
Console.WriteLine(" Package Type     Ecosystem        File Extension      ");
Console.WriteLine("");
Console.WriteLine(" NuGet            .NET             .nupkg              ");
Console.WriteLine(" npm              Node.js          .tgz                ");
Console.WriteLine(" Maven            Java             .jar, .pom          ");
Console.WriteLine(" Gradle           Java/Android     .jar, .aar          ");
Console.WriteLine(" Python           Python           .whl, .tar.gz       ");
Console.WriteLine(" Universal        Any              Any files           ");
Console.WriteLine("");

// Feed Concepts
Console.WriteLine("Feed Concepts:");
Console.WriteLine(" Feed - Container for packages");
Console.WriteLine(" View - Filter packages (e.g., @Release, @PreRelease)");
Console.WriteLine(" Upstream Source - Cache from public registries");
Console.WriteLine(" Retention Policy - Auto-delete old versions");

// Feed Visibility
Console.WriteLine("Feed Visibility:");
Console.WriteLine(" Project-scoped - Visible to project members");
Console.WriteLine(" Organization-scoped - Visible across organization");

// Pricing
Console.WriteLine("Pricing:");
Console.WriteLine(" Free: 2 GB storage included");
Console.WriteLine(" Additional: Pay per GB over limit");
Console.WriteLine(" Upstream caching doesn't count toward storage");

// Create Feed via CLI
Console.WriteLine(@"
# Create a new feed
az artifacts feed create   --name 'my-feed'   --project 'MyProject'   --visibility 'project'   --description 'Internal packages'

# List feeds
az artifacts feed list --project 'MyProject'

# Show feed details
az artifacts feed show --feed 'my-feed' --project 'MyProject'
");`}]},{id:"q2",question:"How do you publish and consume NuGet packages from Azure Artifacts?",answer:"Publish: use dotnet nuget push or NuGet CLI with feed URL. Configure nuget.config with feed source. Authenticate using PAT, Azure CLI credential, or credential provider. In pipelines, use NuGetAuthenticate task. Consume by adding feed to package sources. Upstream sources cache nuget.org packages.",codeSnippets:[{language:"csharp",code:`// NuGet Package Management with Azure Artifacts

// nuget.config for consuming packages
Console.WriteLine(@"
<?xml version=""1.0"" encoding=""utf-8""?>
<configuration>
  <packageSources>
    <clear />
    <add key=""nuget.org"" value=""https://api.nuget.org/v3/index.json"" />
    <add key=""MyFeed"" value=""https://pkgs.dev.azure.com/myorg/myproject/_packaging/my-feed/nuget/v3/index.json"" />
  </packageSources>
  <packageSourceCredentials>
    <MyFeed>
      <add key=""Username"" value=""anything"" />
      <add key=""ClearTextPassword"" value=""%NUGET_PAT%"" />
    </MyFeed>
  </packageSourceCredentials>
</configuration>
");

// Pack and Publish Commands
Console.WriteLine(@"
# Create NuGet package
dotnet pack -c Release -o ./nupkg

# Push to Azure Artifacts
dotnet nuget push ./nupkg/*.nupkg   --source https://pkgs.dev.azure.com/myorg/myproject/_packaging/my-feed/nuget/v3/index.json   --api-key az

# Using NuGet CLI
nuget push MyPackage.1.0.0.nupkg   -Source https://pkgs.dev.azure.com/myorg/myproject/_packaging/my-feed/nuget/v3/index.json   -ApiKey az
");

// Azure Pipelines - Publish NuGet
Console.WriteLine(@"
# azure-pipelines.yml - Publish NuGet Package
trigger:
  - main

pool:
  vmImage: 'ubuntu-latest'

variables:
  buildConfiguration: 'Release'
  packageVersion: '1.0.$(Build.BuildId)'

steps:
- task: DotNetCoreCLI@2
  displayName: 'Build'
  inputs:
    command: 'build'
    projects: '**/*.csproj'
    arguments: '--configuration $(buildConfiguration)'

- task: DotNetCoreCLI@2
  displayName: 'Pack'
  inputs:
    command: 'pack'
    packagesToPack: '**/MyLibrary.csproj'
    versioningScheme: 'byEnvVar'
    versionEnvVar: 'packageVersion'
    configuration: '$(buildConfiguration)'

# Authenticate to feed
- task: NuGetAuthenticate@1
  displayName: 'Authenticate to Azure Artifacts'

- task: NuGetCommand@2
  displayName: 'Push to Azure Artifacts'
  inputs:
    command: 'push'
    packagesToPush: '$(Build.ArtifactStagingDirectory)/**/*.nupkg'
    nuGetFeedType: 'internal'
    publishVstsFeed: 'myproject/my-feed'
    allowPackageConflicts: true
");

// Restore from Azure Artifacts
Console.WriteLine(@"
# Restore in pipeline
- task: DotNetCoreCLI@2
  displayName: 'Restore packages'
  inputs:
    command: 'restore'
    projects: '**/*.csproj'
    feedsToUse: 'select'
    vstsFeed: 'myproject/my-feed'
");

// .NET Project Configuration
Console.WriteLine(@"
<!-- MyLibrary.csproj -->
<Project Sdk=""Microsoft.NET.Sdk"">
  <PropertyGroup>
    <TargetFramework>net8.0</TargetFramework>
    <PackageId>MyCompany.MyLibrary</PackageId>
    <Version>1.0.0</Version>
    <Authors>MyCompany</Authors>
    <Description>Internal library for common operations</Description>
    <PackageTags>utilities;common</PackageTags>
    <RepositoryUrl>https://dev.azure.com/myorg/myproject/_git/mylibrary</RepositoryUrl>
  </PropertyGroup>
</Project>
");`}]},{id:"q3",question:"How do you configure upstream sources for package caching?",answer:"Upstream sources proxy public registries through Azure Artifacts. Benefits: single feed URL, cached packages for faster restores, availability if public registry down. Configure: nuget.org, npmjs.com, Maven Central, PyPI. Packages cached on first request. Order matters for version resolution.",codeSnippets:[{language:"csharp",code:`// Upstream Sources Configuration

Console.WriteLine("Upstream Source Benefits:");
Console.WriteLine(" Single feed URL for all packages");
Console.WriteLine(" Cached copies for faster restores");
Console.WriteLine(" Continued access if public registry unavailable");
Console.WriteLine(" Audit trail of packages used");
Console.WriteLine(" No storage cost for cached packages");

// Common Upstream Sources
Console.WriteLine("Default Upstream Sources:");
Console.WriteLine("");
Console.WriteLine(" Type     Name          URL                           ");
Console.WriteLine("");
Console.WriteLine(" NuGet    nuget.org     https://api.nuget.org/v3/...  ");
Console.WriteLine(" npm      npmjs         https://registry.npmjs.org    ");
Console.WriteLine(" Maven    Maven Central https://repo.maven.apache.org ");
Console.WriteLine(" Python   PyPI          https://pypi.org/simple       ");
Console.WriteLine("");

// Configure via CLI
Console.WriteLine(@"
# Add upstream source to existing feed
az artifacts feed update   --feed 'my-feed'   --project 'MyProject'   --upstream-sources '[
    {
      ""name"": ""nuget.org"",
      ""protocol"": ""nuget"",
      ""location"": ""https://api.nuget.org/v3/index.json"",
      ""upstreamSourceType"": ""public""
    },
    {
      ""name"": ""npmjs"",
      ""protocol"": ""npm"",
      ""location"": ""https://registry.npmjs.org"",
      ""upstreamSourceType"": ""public""
    }
  ]'
");

// Simplified nuget.config with upstream
Console.WriteLine(@"
<!-- With upstream sources, only need one feed -->
<?xml version=""1.0"" encoding=""utf-8""?>
<configuration>
  <packageSources>
    <clear />
    <!-- Single feed URL - upstreams handle nuget.org -->
    <add key=""AzureArtifacts"" value=""https://pkgs.dev.azure.com/myorg/_packaging/my-feed/nuget/v3/index.json"" />
  </packageSources>
</configuration>
");

// How Upstream Resolution Works
Console.WriteLine(@"
Package Resolution Order:
1. Check local feed for exact package version
2. If not found, check upstream sources in order
3. First upstream with package wins
4. Package is cached in local feed
5. Future requests served from cache

Example:
Request: Newtonsoft.Json 13.0.1
   Not in 'my-feed'
   Check 'nuget.org' upstream
   Found! Cache in 'my-feed'
   Return to client

Next Request: Newtonsoft.Json 13.0.1
   Found in 'my-feed' cache
   Return immediately (faster!)
");

// Upstream Source Priority
Console.WriteLine("Upstream Source Priority:");
Console.WriteLine(" Order determines resolution priority");
Console.WriteLine(" Put internal feeds first");
Console.WriteLine(" Public registries last");
Console.WriteLine(" Can have multiple upstreams per protocol");

// Internal Upstream (Feed-to-Feed)
Console.WriteLine(@"
# Add another Azure Artifacts feed as upstream
Feed: project-feed
  Upstream: organization-shared-feed
  Upstream: nuget.org

This allows:
- Project packages in project-feed
- Shared packages from organization-shared-feed
- Public packages from nuget.org
All through single URL!
");`}]},{id:"q4",question:"How do you manage npm packages in Azure Artifacts?",answer:"Configure .npmrc with feed URL and auth. Use vsts-npm-auth for authentication. Publish with npm publish. Scoped packages (@org/package) supported. Upstream to npmjs.com for caching. In pipelines, use Npm task with custom registry. npm audit for security scanning.",codeSnippets:[{language:"csharp",code:`// npm Package Management with Azure Artifacts

// .npmrc configuration
Console.WriteLine(@"
# .npmrc in project root
registry=https://pkgs.dev.azure.com/myorg/myproject/_packaging/my-feed/npm/registry/
always-auth=true

# For scoped packages
@mycompany:registry=https://pkgs.dev.azure.com/myorg/myproject/_packaging/my-feed/npm/registry/

# User-level .npmrc (for auth)
# ~/.npmrc
//pkgs.dev.azure.com/myorg/myproject/_packaging/my-feed/npm/registry/:username=anything
//pkgs.dev.azure.com/myorg/myproject/_packaging/my-feed/npm/registry/:_password=BASE64_ENCODED_PAT
//pkgs.dev.azure.com/myorg/myproject/_packaging/my-feed/npm/registry/:email=user@example.com
");

// Authentication helper
Console.WriteLine(@"
# Install vsts-npm-auth helper
npm install -g vsts-npm-auth

# Authenticate (interactive)
vsts-npm-auth -config .npmrc

# Or use Azure CLI
az artifacts npm config --feed my-feed --project MyProject
");

// Publishing npm packages
Console.WriteLine(@"
# package.json
{
  ""name"": ""@mycompany/my-library"",
  ""version"": ""1.0.0"",
  ""main"": ""dist/index.js"",
  ""types"": ""dist/index.d.ts"",
  ""files"": [""dist""],
  ""scripts"": {
    ""build"": ""tsc"",
    ""prepublishOnly"": ""npm run build""
  },
  ""publishConfig"": {
    ""registry"": ""https://pkgs.dev.azure.com/myorg/myproject/_packaging/my-feed/npm/registry/""
  }
}

# Publish command
npm publish
");

// Azure Pipelines - npm
Console.WriteLine(@"
# azure-pipelines.yml - npm CI/CD
trigger:
  - main

pool:
  vmImage: 'ubuntu-latest'

steps:
- task: NodeTool@0
  displayName: 'Install Node.js'
  inputs:
    versionSpec: '18.x'

# Authenticate to Azure Artifacts
- task: npmAuthenticate@0
  displayName: 'Authenticate npm'
  inputs:
    workingFile: '.npmrc'

# Install dependencies
- task: Npm@1
  displayName: 'Install packages'
  inputs:
    command: 'ci'
    workingDir: '.'

# Build
- script: npm run build
  displayName: 'Build'

# Test
- script: npm test
  displayName: 'Run tests'

# Publish (on main branch only)
- task: Npm@1
  displayName: 'Publish package'
  condition: eq(variables['Build.SourceBranch'], 'refs/heads/main')
  inputs:
    command: 'publish'
    workingDir: '.'
    publishRegistry: 'useFeed'
    publishFeed: 'myproject/my-feed'
");

// Version management
Console.WriteLine(@"
# Bump version before publish
npm version patch   # 1.0.0 -> 1.0.1
npm version minor   # 1.0.0 -> 1.1.0
npm version major   # 1.0.0 -> 2.0.0

# Prerelease versions
npm version prerelease --preid=beta  # 1.0.0-beta.0

# In pipeline - auto-version with build number
- script: |
    npm version 1.0.$(Build.BuildId) --no-git-tag-version
  displayName: 'Set version'
");

// Consuming packages
Console.WriteLine(@"
# Install from Azure Artifacts
npm install @mycompany/my-library

# Install specific version
npm install @mycompany/my-library@1.2.3

# package.json
{
  ""dependencies"": {
    ""@mycompany/my-library"": ""^1.0.0"",
    ""lodash"": ""^4.17.21""  // From npmjs via upstream
  }
}
");`}]},{id:"q5",question:"How do you use Universal Packages for arbitrary files?",answer:"Universal Packages store any file type (binaries, tools, datasets). No special format required - just files/folders. Use Azure CLI to publish and download. Version semantically. Great for large files, build tools, ML models, test data. Supports incremental uploads for large packages.",codeSnippets:[{language:"csharp",code:`// Universal Packages in Azure Artifacts

Console.WriteLine("Universal Package Use Cases:");
Console.WriteLine(" Large binary files (tools, SDKs)");
Console.WriteLine(" Machine learning models");
Console.WriteLine(" Test data sets");
Console.WriteLine(" Configuration bundles");
Console.WriteLine(" Build outputs for release");
Console.WriteLine(" Game assets");

// Publish Universal Package
Console.WriteLine(@"
# Publish a folder as universal package
az artifacts universal publish   --organization https://dev.azure.com/myorg   --project MyProject   --feed my-feed   --name my-tool   --version 1.0.0   --path ./dist   --description 'Internal build tool'

# Publish single file
az artifacts universal publish   --organization https://dev.azure.com/myorg   --project MyProject   --feed my-feed   --name ml-model   --version 2.1.0   --path ./models/trained-model.onnx

# Publish with latest version auto-increment
az artifacts universal publish   --feed my-feed   --name my-tool   --version 1.0.$(Build.BuildId)   --path ./dist
");

// Download Universal Package
Console.WriteLine(@"
# Download to specific folder
az artifacts universal download   --organization https://dev.azure.com/myorg   --project MyProject   --feed my-feed   --name my-tool   --version 1.0.0   --path ./tools

# Download latest version
az artifacts universal download   --feed my-feed   --name my-tool   --version '*'   --path ./tools
");

// Azure Pipelines Integration
Console.WriteLine(@"
# azure-pipelines.yml - Universal Packages
steps:
# Download universal package (e.g., build tools)
- task: UniversalPackages@0
  displayName: 'Download build tools'
  inputs:
    command: 'download'
    downloadDirectory: '$(Agent.ToolsDirectory)/my-tool'
    feedsToUse: 'internal'
    vstsFeed: 'myproject/my-feed'
    vstsFeedPackage: 'my-tool'
    vstsPackageVersion: '1.0.0'

# Use the downloaded tool
- script: |
    chmod +x $(Agent.ToolsDirectory)/my-tool/build.sh
    $(Agent.ToolsDirectory)/my-tool/build.sh
  displayName: 'Run build tool'

# Publish universal package (e.g., release artifacts)
- task: UniversalPackages@0
  displayName: 'Publish release package'
  inputs:
    command: 'publish'
    publishDirectory: '$(Build.ArtifactStagingDirectory)/release'
    feedsToUsePublish: 'internal'
    vstsFeedPublish: 'myproject/my-feed'
    vstsFeedPackagePublish: 'myapp-release'
    versionOption: 'custom'
    versionPublish: '$(Build.BuildNumber)'
    packagePublishDescription: 'Release build $(Build.BuildNumber)'
");

// Large File Handling
Console.WriteLine("Large Package Features:");
Console.WriteLine(" Incremental upload - only changed chunks");
Console.WriteLine(" Resume interrupted uploads");
Console.WriteLine(" Parallel download for faster retrieval");
Console.WriteLine(" Compression during transfer");
Console.WriteLine(" Maximum single file size: 4 TB");
Console.WriteLine(" Maximum package size: No limit");

// Version Patterns
Console.WriteLine(@"
Version Patterns:
 Exact: 1.0.0
 Latest: * (downloads newest version)
 Range: 1.0.* (latest 1.0.x)
 Prerelease: 1.0.0-beta.1
");`}]},{id:"q6",question:"How do you configure feed permissions and retention policies?",answer:"Feed permissions control who can read, publish, manage packages. Roles: Reader, Collaborator, Contributor, Owner. Retention policies auto-delete old package versions. Configure by package type, age, version count. Views (@Release, @Prerelease) filter packages. Promote packages between views.",codeSnippets:[{language:"csharp",code:`// Feed Permissions and Retention

Console.WriteLine("Feed Permission Roles:");
Console.WriteLine("");
Console.WriteLine(" Role           Read  Push  Unlist Delete Manage   ");
Console.WriteLine("");
Console.WriteLine(" Reader                                           ");
Console.WriteLine(" Collaborator         *                          ");
Console.WriteLine(" Contributor                                    ");
Console.WriteLine(" Owner                                        ");
Console.WriteLine("");
Console.WriteLine("* Collaborator can push packages from upstream sources");

// Set Permissions via CLI
Console.WriteLine(@"
# Add user/group permissions
az devops security permission update   --namespace-id '2725d2bc-7f2e-4c94-a49b-2e1d9a3d2f5c'   --subject 'user@example.com'   --token 'project/feed'   --allow-bit 7

# Common permission setup
# Project Contributors -> Contributor role
# Build Service account -> Contributor role (for CI/CD)
# Everyone -> Reader role
");

// Feed Views
Console.WriteLine("Feed Views:");
Console.WriteLine(" @Local - All packages (default)");
Console.WriteLine(" @Prerelease - Prerelease versions only");
Console.WriteLine(" @Release - Stable versions only");

Console.WriteLine(@"
# Promote package to Release view
az artifacts feed promote   --feed my-feed   --package-name my-package   --package-version 1.0.0   --view Release

# Consumers can target specific views
# NuGet: https://pkgs.dev.azure.com/myorg/_packaging/my-feed@Release/nuget/v3/index.json
# npm: https://pkgs.dev.azure.com/myorg/_packaging/my-feed@Release/npm/registry/
");

// Retention Policies
Console.WriteLine("Retention Policy Options:");
Console.WriteLine(" Maximum versions per package");
Console.WriteLine(" Days to keep recently downloaded");
Console.WriteLine(" Days to keep recently published");
Console.WriteLine(" Never delete packages in @Release view");

Console.WriteLine(@"
# Configure retention via REST API
PATCH https://feeds.dev.azure.com/{org}/{project}/_apis/packaging/feeds/{feedId}?api-version=7.0
Content-Type: application/json

{
  ""retentionPolicy"": {
    ""countLimit"": 10,              // Keep max 10 versions per package
    ""daysToKeepRecentlyDownloaded"": 30,  // Keep if downloaded in last 30 days
    ""ageLimitInDays"": 180          // Delete versions older than 180 days
  }
}

# Example retention scenarios:
# Scenario 1: Keep only latest 5 versions
countLimit: 5

# Scenario 2: Keep versions used in last 60 days
daysToKeepRecentlyDownloaded: 60

# Scenario 3: Delete very old packages
ageLimitInDays: 365

# Protected packages (won't be deleted):
# - Packages in @Release view
# - Packages with 'pinned' tag
");

// Audit and Compliance
Console.WriteLine("Feed Audit Trail:");
Console.WriteLine(" Package publish events");
Console.WriteLine(" Package download events");
Console.WriteLine(" Permission changes");
Console.WriteLine(" Retention deletions");
Console.WriteLine(" View promotions");

Console.WriteLine(@"
# Query audit logs
az devops audit-log query   --start-time 2024-01-01   --filter-type 'Packaging.Package*'
");`}]}]},mh={id:"azure-devops",name:"Azure DevOps",icon:"",topics:[lh,ch,uh,dh,ph]},dl=[my,wy,Ry,xy,qy,Qy,sh,mh],gh=Kt.lazy(()=>Tp(()=>import("./Navbar-B6nnr-q3.js"),[]).then(T=>({default:T.Navbar}))),yh=Kt.lazy(()=>Tp(()=>import("./ContentArea-BI1RHtXM.js"),[]).then(T=>({default:T.ContentArea})));function hh(){return ot.jsx("div",{className:"flex items-center justify-center h-full w-full bg-gradient-to-br from-gray-50 to-gray-100",children:ot.jsxs("div",{className:"flex flex-col items-center gap-4",children:[ot.jsx("div",{className:"w-12 h-12 border-4 border-indigo-200 border-t-indigo-600 rounded-full animate-spin"}),ot.jsx("span",{className:"text-gray-600 font-medium",children:"Loading..."})]})})}function vh(){const[T,ue]=Kt.useState(null),[j,y]=Kt.useState(null),[N,F]=Kt.useState(!0),Y=(Z,I)=>{if(ue(Z),I)y(I);else{const b=dl.find(B=>B.id===Z);b&&b.topics.length>0?y(b.topics[0].id):y(null)}};return Kt.useEffect(()=>{const Z=document.querySelector(".content-area");Z&&(Z.scrollTop=0)},[j]),ot.jsxs("div",{className:"app",children:[ot.jsx(Kt.Suspense,{fallback:ot.jsx("div",{className:"w-64 bg-gray-100 animate-pulse"}),children:ot.jsx(gh,{subjects:dl,selectedSubject:T,selectedTopic:j,onSubjectSelect:Y,onTopicSelect:y,isOpen:N,onToggle:()=>F(!N)})}),ot.jsx(Kt.Suspense,{fallback:ot.jsx(hh,{}),children:ot.jsx(yh,{subjects:dl,selectedSubject:T,selectedTopic:j,onSubjectSelect:Y,onTopicSelect:y})})]})}ry.createRoot(document.getElementById("root")).render(ot.jsx(Kt.StrictMode,{children:ot.jsx(vh,{})}));export{Tp as _,ot as j,Kt as r};
